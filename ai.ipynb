{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa44bbef",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import difflib\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import getpass\n",
    "from typing import Annotated, TypedDict, List\n",
    "import re\n",
    "import pickle\n",
    "import faiss\n",
    "\n",
    "# LangChain / LangGraph Imports\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ 0. RAG RETRIEVER (Single File Implementation)\n",
    "# ==============================================================================\n",
    "\n",
    "class SystemKBRetriever:\n",
    "    \"\"\"\n",
    "    Loads FAISS index + metadata created from your KB excel.\n",
    "    Uses ONLY the contract paragraph to retrieve similar examples.\n",
    "    \"\"\"\n",
    "    def __init__(self, kb_dir: str):\n",
    "        index_path = os.path.join(kb_dir, \"system_kb.faiss\")\n",
    "        meta_path = os.path.join(kb_dir, \"system_kb_meta.pkl\")\n",
    "\n",
    "        if not os.path.exists(index_path) or not os.path.exists(meta_path):\n",
    "            raise FileNotFoundError(\n",
    "                f\"‚ùå KB files not found in: {kb_dir}\\n\"\n",
    "                f\"Expected:\\n- {index_path}\\n- {meta_path}\\n\\n\"\n",
    "                f\"Build the KB first using your KB builder script.\"\n",
    "            )\n",
    "\n",
    "        print(f\"‚úÖ Loading FAISS Index: {index_path}\")\n",
    "        self.index = faiss.read_index(index_path)\n",
    "\n",
    "        print(f\"‚úÖ Loading KB Metadata: {meta_path}\")\n",
    "        with open(meta_path, \"rb\") as f:\n",
    "            self.meta = pickle.load(f)\n",
    "\n",
    "        print(f\"‚úÖ KB Loaded: {len(self.meta)} rows\")\n",
    "\n",
    "    def retrieve(self, query_text: str, top_k: int = 3):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        [\n",
    "          {\"score\": float, \"meta\": {...all 29 cols...}},\n",
    "          ...\n",
    "        ]\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "\n",
    "        query_text = str(query_text).strip()\n",
    "        if not query_text:\n",
    "            return []\n",
    "\n",
    "        # ‚úÖ Use embedding model only when needed (lazy load)\n",
    "        if not hasattr(self, \"embedder\"):\n",
    "            self.embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "        q_emb = self.embedder.encode([query_text], normalize_embeddings=True).astype(\"float32\")\n",
    "        scores, idxs = self.index.search(q_emb, top_k)\n",
    "\n",
    "        results = []\n",
    "        for score, idx in zip(scores[0], idxs[0]):\n",
    "            if idx < 0:\n",
    "                continue\n",
    "            results.append({\n",
    "                \"score\": float(score),\n",
    "                \"meta\": self.meta[idx]\n",
    "            })\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. CONFIGURATION & FILE PATHS\n",
    "# ==============================================================================\n",
    "\n",
    "# ‚¨áÔ∏è UPDATE PATHS HERE ‚¨áÔ∏è\n",
    "TAXONOMY_PATH = r'C:\\Users\\mukeshkr\\Desktop\\DefenseExtraction\\testing\\taxonomy.json'\n",
    "SUPPLIERS_PATH = r'C:\\Users\\mukeshkr\\Desktop\\DefenseExtraction\\testing\\suppliers.json'\n",
    "INPUT_EXCEL_PATH = r\"C:\\Users\\mukeshkr\\Desktop\\DefenseExtraction\\data\\source_file.xlsx\"\n",
    "OUTPUT_EXCEL_PATH = \"Processed_Defense_Data.xlsx\"\n",
    "\n",
    "# ‚úÖ RAG KB Directory (must contain system_kb.faiss + system_kb_meta.pkl)\n",
    "RAG_KB_DIR = r\"C:\\Users\\mukeshkr\\Desktop\\DefenseExtraction\\testing\\system_kb_store\"\n",
    "\n",
    "# Setup API Key\n",
    "if \"LLMFOUNDRY_TOKEN\" not in os.environ:\n",
    "    os.environ[\"LLMFOUNDRY_TOKEN\"] = getpass.getpass(\"Enter the LLM Foundry API Key: \")\n",
    "\n",
    "# Shared Client\n",
    "client = OpenAI(\n",
    "    api_key=f'{os.environ.get(\"LLMFOUNDRY_TOKEN\")}:my-test-project',\n",
    "    base_url=\"https://llmfoundry.straive.com/openai/v1/\",\n",
    ")\n",
    "\n",
    "# ‚úÖ Load retriever once globally\n",
    "retriever = SystemKBRetriever(kb_dir=RAG_KB_DIR)\n",
    "\n",
    "# --- FILE LOADING HELPERS ---\n",
    "def load_json_file(filename, default_value):\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            print(f\"‚úÖ Loaded {filename}\")\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Warning: Could not load {filename} ({e}). Using default.\")\n",
    "        return default_value\n",
    "\n",
    "# 1. Load Taxonomy\n",
    "raw_taxonomy = load_json_file(TAXONOMY_PATH, {})\n",
    "TAXONOMY_STR = json.dumps(raw_taxonomy, separators=(',', ':'))\n",
    "\n",
    "# 2. Load Suppliers\n",
    "SUPPLIER_LIST = load_json_file(SUPPLIERS_PATH, [\n",
    "    \"Dell Inc\", \"Boeing\", \"Lockheed Martin\", \"Raytheon Technologies\",\n",
    "    \"Northrop Grumman\", \"L3Harris\", \"BAE Systems\", \"General Dynamics\"\n",
    "])\n",
    "\n",
    "# 3. System Rules\n",
    "RULE_BOOK = {\n",
    "    \"defensive_countermeasures\": {\n",
    "        \"triggers\": [\"flare\", \"chaff\", \"countermeasure\", \"decoy\", \"mju-\", \"ale-\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Defensive Systems', Specific: 'Defensive Aid Suite'\"\n",
    "    },\n",
    "    \"radars_and_sensors\": {\n",
    "        \"triggers\": [\"radar\", \"sonar\", \"sensor\", \"an/apy\", \"an/tpy\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Sensors'\"\n",
    "    },\n",
    "    \"ammunition\": {\n",
    "        \"triggers\": [\"cartridge\", \"round\", \"projectile\", \" 5.56\", \" 7.62\", \"ammo\"],\n",
    "        \"guidance\": \"Market Segment: 'Weapon Systems', System Type (General): 'Ammunition'\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# 4. Geography Mapping\n",
    "GEOGRAPHY_MAPPING = {\n",
    "    \"North America\": [\"USA\", \"United States\", \"US\", \"Canada\", \"America\"],\n",
    "    \"Europe\": [\"UK\", \"United Kingdom\", \"Ukraine\", \"Germany\", \"France\", \"Italy\", \"Spain\", \"Poland\", \"Netherlands\", \"Norway\", \"Sweden\", \"Finland\", \"Denmark\", \"Belgium\"],\n",
    "    \"Asia-Pacific\": [\"Australia\", \"Japan\", \"South Korea\", \"Taiwan\", \"India\", \"Singapore\", \"New Zealand\"],\n",
    "    \"Middle East and North Africa\": [\"Israel\", \"Saudi Arabia\", \"UAE\", \"Egypt\", \"Qatar\", \"Kuwait\", \"Iraq\"],\n",
    "    \"International Organisations\": [\"NATO\", \"EU\", \"IFU\", \"UN\", \"NSPA\"]\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. HELPER FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def get_best_supplier_match(extracted_name):\n",
    "    \"\"\"Fuzzy matches the extracted name against the loaded SUPPLIER_LIST.\"\"\"\n",
    "    if not extracted_name or extracted_name.lower() in [\"unknown\", \"n/a\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    clean_name = extracted_name.strip()\n",
    "\n",
    "    supplier_map = {s.lower(): s for s in SUPPLIER_LIST}\n",
    "    if clean_name.lower() in supplier_map:\n",
    "        return supplier_map[clean_name.lower()]\n",
    "\n",
    "    matches = difflib.get_close_matches(clean_name, SUPPLIER_LIST, n=1, cutoff=0.6)\n",
    "    return matches[0] if matches else clean_name\n",
    "\n",
    "\n",
    "def calculate_mro_months(start_date_str, end_date_text, program_type):\n",
    "    \"\"\"Calculates duration only if Program Type is MRO/Support.\"\"\"\n",
    "    if program_type != \"MRO/Support\":\n",
    "        return \"Not Applicable\"\n",
    "\n",
    "    try:\n",
    "        if not start_date_str or not end_date_text or str(end_date_text).lower() in [\"unknown\", \"n/a\"]:\n",
    "            return \"Not Applicable\"\n",
    "\n",
    "        start = pd.to_datetime(start_date_str, dayfirst=True)\n",
    "        end = parser.parse(end_date_text, fuzzy=True)\n",
    "\n",
    "        diff = relativedelta(end, start)\n",
    "        total_months = (diff.years * 12) + diff.months\n",
    "        return str(max(0, int(total_months)))\n",
    "    except:\n",
    "        return \"Not Applicable\"\n",
    "\n",
    "\n",
    "def get_region_for_country(country_name):\n",
    "    \"\"\"Robust lookup handling casing/whitespace.\"\"\"\n",
    "    if not country_name or country_name.lower() in [\"unknown\", \"n/a\", \"not applicable\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    clean = country_name.strip().lower()\n",
    "\n",
    "    if clean in [\"us\", \"usa\", \"united states\", \"united states of america\"]:\n",
    "        return \"North America\"\n",
    "    if clean in [\"uk\", \"britain\", \"great britain\"]:\n",
    "        return \"Europe\"\n",
    "\n",
    "    for region, countries in GEOGRAPHY_MAPPING.items():\n",
    "        if any(c.lower() == clean for c in countries):\n",
    "            return region\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "# ‚úÖ Regex Designator Extractors (for System Name + Piloting)\n",
    "DESIGNATOR_PATTERNS = [\n",
    "    r\"\\bDDG[-\\s]?\\d+\\b\", r\"\\bCVN[-\\s]?\\d+\\b\", r\"\\bSSN[-\\s]?\\d+\\b\",\n",
    "    r\"\\bLCS[-\\s]?\\d+\\b\", r\"\\bLPD[-\\s]?\\d+\\b\", r\"\\bLHA[-\\s]?\\d+\\b\", r\"\\bLHD[-\\s]?\\d+\\b\",\n",
    "    r\"\\bF-\\d+\\b\", r\"\\bB-\\d+\\b\", r\"\\bC-\\d+\\b\", r\"\\bA-\\d+\\b\",\n",
    "    r\"\\bMQ-\\d+\\b\", r\"\\bRQ-\\d+\\b\",\n",
    "    r\"\\bAN\\/[A-Z0-9\\-]+\\b\",\n",
    "    r\"\\b(AIM|AGM|SM|RIM|MIM)-\\d+\\b\",\n",
    "]\n",
    "\n",
    "def extract_designators(text: str):\n",
    "    text = str(text)\n",
    "    found = []\n",
    "    for pat in DESIGNATOR_PATTERNS:\n",
    "        found.extend(re.findall(pat, text, flags=re.IGNORECASE))\n",
    "    cleaned = []\n",
    "    for f in found:\n",
    "        cleaned.append(f.upper().replace(\" \", \"\").replace(\"--\", \"-\"))\n",
    "    seen = set()\n",
    "    final = []\n",
    "    for x in cleaned:\n",
    "        if x not in seen:\n",
    "            final.append(x)\n",
    "            seen.add(x)\n",
    "    return final\n",
    "\n",
    "def detect_piloting_rule_based(text: str, designators: List[str]) -> str:\n",
    "    t = str(text).lower()\n",
    "\n",
    "    if any(d.startswith((\"MQ-\", \"RQ-\")) for d in designators):\n",
    "        return \"Uncrewed\"\n",
    "    if any(k in t for k in [\"unmanned\", \"uav\", \"drone\", \"autonomous\"]):\n",
    "        return \"Uncrewed\"\n",
    "\n",
    "    if any(d.startswith((\"DDG\", \"CVN\", \"SSN\", \"LCS\", \"LPD\", \"LHA\", \"LHD\")) for d in designators):\n",
    "        return \"Crewed\"\n",
    "    if \"uss \" in t:\n",
    "        return \"Crewed\"\n",
    "\n",
    "    return \"Not Applicable\"\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. TOOL DEFINITIONS (AGENTS)\n",
    "# ==============================================================================\n",
    "\n",
    "# --- AGENT 1: SOURCING ---\n",
    "class SourcingInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "    url: str = Field(description=\"Source URL.\")\n",
    "    date: str = Field(description=\"Contract Date.\")\n",
    "\n",
    "@tool(\"sourcing_extractor\")\n",
    "def sourcing_extractor(paragraph: str, url: str, date: str):\n",
    "    \"\"\"Stage 1: Prepares Metadata.\"\"\"\n",
    "    reported_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    notes = \"Standard extraction.\"\n",
    "    if \"modification\" in paragraph.lower():\n",
    "        notes = \"Contract Modification.\"\n",
    "    if \"split\" in paragraph.lower():\n",
    "        notes = \"Split award detected.\"\n",
    "\n",
    "    return {\n",
    "        \"Description of Contract\": paragraph,\n",
    "        \"Additional Notes (Internal Only)\": notes,\n",
    "        \"Source Link(s)\": url,\n",
    "        \"Contract Date\": date,\n",
    "        \"Reported Date (By SGA)\": reported_date\n",
    "    }\n",
    "\n",
    "\n",
    "# --- AGENT 2: GEOGRAPHY ---\n",
    "class GeographyInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "\n",
    "@tool(\"geography_extractor\")\n",
    "def geography_extractor(paragraph: str):\n",
    "    \"\"\"Stage 2: Geography Logic.\"\"\"\n",
    "    sys_prompt = \"\"\"\n",
    "Extract: Customer Country, Supplier Country, Customer Operator.\n",
    "Logic: If 'Navy awarded...', Operator is Navy.\n",
    "Return JSON:\n",
    "{\n",
    "  \"Customer Country\": \"...\",\n",
    "  \"Customer Operator\": \"...\",\n",
    "  \"Supplier Country\": \"...\"\n",
    "}\n",
    "\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": paragraph}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "    except Exception:\n",
    "        raw = {}\n",
    "\n",
    "    cust = raw.get(\"Customer Country\", \"Unknown\")\n",
    "    supp = raw.get(\"Supplier Country\", \"Unknown\")\n",
    "\n",
    "    domestic = \"Indigenous\" if cust.lower() == supp.lower() else \"Imported\"\n",
    "    if \"united states\" in cust.lower() and \"usa\" in supp.lower():\n",
    "        domestic = \"Indigenous\"\n",
    "\n",
    "    return {\n",
    "        \"Customer Region\": get_region_for_country(cust),\n",
    "        \"Customer Country\": cust,\n",
    "        \"Customer Operator\": raw.get(\"Customer Operator\", \"Unknown\"),\n",
    "        \"Supplier Region\": get_region_for_country(supp),\n",
    "        \"Supplier Country\": supp,\n",
    "        \"Domestic Content\": domestic\n",
    "    }\n",
    "\n",
    "\n",
    "# --- ‚úÖ AGENT 3: SYSTEM (UPGRADED WITH RAG + Evidence + Reason) ---\n",
    "class SystemInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "\n",
    "@tool(\"system_classifier\")\n",
    "def system_classifier(paragraph: str):\n",
    "    \"\"\"Stage 3: System classification using RAG + Rule Book + Evidence & Reason.\"\"\"\n",
    "    paragraph = str(paragraph).strip()\n",
    "    if not paragraph:\n",
    "        return {}\n",
    "\n",
    "    lower_text = paragraph.lower()\n",
    "\n",
    "    # RULE BOOK triggers\n",
    "    hints = [\n",
    "        f\"RULE: {v['guidance']}\"\n",
    "        for _, v in RULE_BOOK.items()\n",
    "        if any(t in lower_text for t in v[\"triggers\"])\n",
    "    ]\n",
    "    hint_str = \"\\n\".join(hints) if hints else \"No special override rules triggered.\"\n",
    "\n",
    "    # Local extraction\n",
    "    designators = extract_designators(paragraph)\n",
    "\n",
    "    # Rule-based piloting\n",
    "    piloting_rule = detect_piloting_rule_based(paragraph, designators)\n",
    "\n",
    "    # RAG Retrieval\n",
    "    rag_hits = retriever.retrieve(paragraph, top_k=3)\n",
    "\n",
    "    rag_examples = []\n",
    "    for hit in rag_hits:\n",
    "        meta = hit[\"meta\"]\n",
    "        rag_examples.append({\n",
    "            \"score\": round(hit[\"score\"], 4),\n",
    "            \"Market Segment\": meta.get(\"Market Segment\", \"\"),\n",
    "            \"System Type (General)\": meta.get(\"System Type (General)\", \"\"),\n",
    "            \"System Type (Specific)\": meta.get(\"System Type (Specific)\", \"\"),\n",
    "            \"System Name (General)\": meta.get(\"System Name (General)\", \"\"),\n",
    "            \"System Name (Specific)\": meta.get(\"System Name (Specific)\", \"\"),\n",
    "            \"System Piloting\": meta.get(\"System Piloting\", \"\"),\n",
    "            \"Supplier Name\": meta.get(\"Supplier Name\", \"\"),\n",
    "            \"Customer Operator\": meta.get(\"Customer Operator\", \"\"),\n",
    "            \"Snippet\": meta.get(\"Description of Contract\", \"\")[:220] + \"...\"\n",
    "        })\n",
    "\n",
    "    sys_prompt = f\"\"\"\n",
    "You are a Senior Defense System Classification Analyst.\n",
    "\n",
    "Use these inputs:\n",
    "1) RAG Similar Examples (top 3)\n",
    "2) Rule Book Overrides\n",
    "3) Extracted Designators\n",
    "\n",
    "RULE BOOK OVERRIDES:\n",
    "{hint_str}\n",
    "\n",
    "OUTPUT RULES:\n",
    "- Return ONLY a FLAT JSON object.\n",
    "- Every value must be a STRING.\n",
    "- Do NOT return nested JSON or lists.\n",
    "- Evidence must be copied EXACTLY from paragraph.\n",
    "- If evidence not present, use \"Not Found\".\n",
    "\n",
    "Return JSON exactly:\n",
    "{{\n",
    "  \"Market Segment\": \"\",\n",
    "  \"Market Segment Evidence\": \"\",\n",
    "  \"Market Segment Reason\": \"\",\n",
    "\n",
    "  \"System Type (General)\": \"\",\n",
    "  \"System Type (General) Evidence\": \"\",\n",
    "  \"System Type (General) Reason\": \"\",\n",
    "\n",
    "  \"System Type (Specific)\": \"\",\n",
    "  \"System Type (Specific) Evidence\": \"\",\n",
    "  \"System Type (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Name (General)\": \"\",\n",
    "  \"System Name (General) Evidence\": \"\",\n",
    "  \"System Name (General) Reason\": \"\",\n",
    "\n",
    "  \"System Name (Specific)\": \"\",\n",
    "  \"System Name (Specific) Evidence\": \"\",\n",
    "  \"System Name (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Piloting\": \"\",\n",
    "  \"System Piloting Evidence\": \"\",\n",
    "  \"System Piloting Reason\": \"\",\n",
    "\n",
    "  \"Confidence\": \"High/Medium/Low\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "INPUT PARAGRAPH:\n",
    "{paragraph}\n",
    "\n",
    "DESIGNATORS (regex extracted):\n",
    "{designators if designators else \"None\"}\n",
    "\n",
    "RULE-BASED PILOTING:\n",
    "{piloting_rule}\n",
    "\n",
    "RAG SIMILAR EXAMPLES:\n",
    "{json.dumps(rag_examples, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        result = json.loads(completion.choices[0].message.content)\n",
    "\n",
    "        # Hard override piloting (best accuracy)\n",
    "        result[\"System Piloting\"] = piloting_rule\n",
    "        if not result.get(\"System Piloting Reason\"):\n",
    "            result[\"System Piloting Reason\"] = \"Piloting derived using deterministic rules.\"\n",
    "        if not result.get(\"System Piloting Evidence\"):\n",
    "            result[\"System Piloting Evidence\"] = \"Not Found\"\n",
    "\n",
    "        # Ensure flat\n",
    "        for k, v in result.items():\n",
    "            if isinstance(v, (dict, list)):\n",
    "                result[k] = str(v)\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"Market Segment\": \"\",\n",
    "            \"System Type (General)\": \"\",\n",
    "            \"System Type (Specific)\": \"\",\n",
    "            \"System Name (General)\": \"\",\n",
    "            \"System Name (Specific)\": \"\",\n",
    "            \"System Piloting\": piloting_rule,\n",
    "            \"Market Segment Evidence\": \"Not Found\",\n",
    "            \"System Type (General) Evidence\": \"Not Found\",\n",
    "            \"System Type (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Name (General) Evidence\": \"Not Found\",\n",
    "            \"System Name (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Piloting Evidence\": \"Not Found\",\n",
    "            \"Market Segment Reason\": \"\",\n",
    "            \"System Type (General) Reason\": \"\",\n",
    "            \"System Type (Specific) Reason\": \"\",\n",
    "            \"System Name (General) Reason\": \"\",\n",
    "            \"System Name (Specific) Reason\": \"\",\n",
    "            \"System Piloting Reason\": \"Piloting derived using deterministic rules.\",\n",
    "            \"Confidence\": \"Low\",\n",
    "            \"Error\": str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "# --- AGENT 4: CONTRACT ---\n",
    "class ContractInfoInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "    contract_date: str = Field(description=\"Signed date.\")\n",
    "\n",
    "@tool(\"contract_extractor\")\n",
    "def contract_extractor(paragraph: str, contract_date: str):\n",
    "    \"\"\"Stage 4: Extracts Financials, Program Type, and Dates based on strict SOP.\"\"\"\n",
    "\n",
    "    system_instruction = \"\"\"\n",
    "You are a Defense Contract Financial Analyst. Extract data strictly following these SOP rules:\n",
    "\n",
    "1) Supplier Name: Extract the exact company name text found in paragraph.\n",
    "2) Program Type: Procurement / Training / MRO/Support / RDT&E / Upgrade / Other Service\n",
    "3) Value Certainty:\n",
    "   - Confirmed: fixed price/obligated stated\n",
    "   - Estimated: ceiling/potential/IDIQ/multi-award\n",
    "4) Quantity: number or Not Applicable\n",
    "5) G2G/B2G:\n",
    "   - G2G only if Foreign Military Sales (FMS)\n",
    "   - else B2G\n",
    "6) Completion Date: only needed for MRO duration calc\n",
    "\n",
    "Return JSON only.\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "Analyze contract:\n",
    "\"{paragraph}\"\n",
    "\n",
    "Signed Date: {contract_date}\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"raw_supplier_name\": \"\",\n",
    "  \"program_type\": \"\",\n",
    "  \"value_million_raw\": \"\",\n",
    "  \"currency_code\": \"\",\n",
    "  \"value_certainty\": \"\",\n",
    "  \"quantity\": \"\",\n",
    "  \"completion_date_text\": \"\",\n",
    "  \"g2g_b2g\": \"\",\n",
    "  \"value_note\": \"\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_instruction},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        return {\"Error\": str(e)}\n",
    "\n",
    "    final_supplier = get_best_supplier_match(raw.get(\"raw_supplier_name\"))\n",
    "    prog_type = raw.get(\"program_type\", \"Unknown\")\n",
    "    mro_months = calculate_mro_months(contract_date, raw.get(\"completion_date_text\"), prog_type)\n",
    "\n",
    "    try:\n",
    "        val_str = str(raw.get(\"value_million_raw\", \"0\")).replace(\",\", \"\").replace(\"$\", \"\")\n",
    "        val_float = float(val_str)\n",
    "        val_formatted = \"{:.3f}\".format(val_float)\n",
    "    except:\n",
    "        val_formatted = \"0.000\"\n",
    "\n",
    "    try:\n",
    "        dt = pd.to_datetime(contract_date)\n",
    "        sign_month = dt.strftime(\"%B\")\n",
    "        sign_year = str(dt.year)\n",
    "    except:\n",
    "        sign_month, sign_year = \"Unknown\", \"Unknown\"\n",
    "\n",
    "    val_note = raw.get(\"value_note\", \"Not Applicable\")\n",
    "    if \"split\" in paragraph.lower() and val_note == \"Not Applicable\":\n",
    "        val_note = \"Split contract; value distribution unclear.\"\n",
    "\n",
    "    return {\n",
    "        \"Supplier Name\": final_supplier,\n",
    "        \"Program Type\": prog_type,\n",
    "        \"Expected MRO Contract Duration (Months)\": mro_months,\n",
    "        \"Quantity\": raw.get(\"quantity\", \"Not Applicable\"),\n",
    "        \"Value Certainty\": raw.get(\"value_certainty\", \"Confirmed\"),\n",
    "        \"Value (Million)\": val_formatted,\n",
    "        \"Currency\": raw.get(\"currency_code\", \"USD$\"),\n",
    "        \"Value (USD$ Million)\": val_formatted,\n",
    "        \"Value Note (If Any)\": val_note,\n",
    "        \"G2G/B2G\": raw.get(\"g2g_b2g\", \"B2G\"),\n",
    "        \"Signing Month\": sign_month,\n",
    "        \"Signing Year\": sign_year\n",
    "    }\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. LANGGRAPH PIPELINE\n",
    "# ==============================================================================\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input_text: str\n",
    "    input_date: str\n",
    "    input_url: str\n",
    "    final_data: dict\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "\n",
    "def stage_1_sourcing(state: AgentState):\n",
    "    res = sourcing_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"url\": state[\"input_url\"],\n",
    "        \"date\": state[\"input_date\"]\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "def stage_2_geography(state: AgentState):\n",
    "    res = geography_extractor.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "def stage_3_system(state: AgentState):\n",
    "    res = system_classifier.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "def stage_4_contract(state: AgentState):\n",
    "    res = contract_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"contract_date\": state[\"input_date\"]\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Stage1\", stage_1_sourcing)\n",
    "workflow.add_node(\"Stage2\", stage_2_geography)\n",
    "workflow.add_node(\"Stage3\", stage_3_system)\n",
    "workflow.add_node(\"Stage4\", stage_4_contract)\n",
    "\n",
    "workflow.add_edge(START, \"Stage1\")\n",
    "workflow.add_edge(\"Stage1\", \"Stage2\")\n",
    "workflow.add_edge(\"Stage2\", \"Stage3\")\n",
    "workflow.add_edge(\"Stage3\", \"Stage4\")\n",
    "workflow.add_edge(\"Stage4\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. EXECUTION & FORMATTING\n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(f\"üìÇ Loading Input File: {INPUT_EXCEL_PATH}...\")\n",
    "\n",
    "    try:\n",
    "        df_input = pd.read_excel(INPUT_EXCEL_PATH)\n",
    "\n",
    "        required_cols = [\"Source URL\", \"Contract Date\", \"Contract Description\"]\n",
    "        if not all(col in df_input.columns for col in required_cols):\n",
    "            raise ValueError(f\"Excel file must contain columns: {required_cols}\")\n",
    "\n",
    "        print(f\"üöÄ Processing {len(df_input)} rows...\")\n",
    "        results = []\n",
    "\n",
    "        for index, row in df_input.iterrows():\n",
    "            print(f\"   -> Row {index + 1}...\")\n",
    "\n",
    "            desc = str(row[\"Contract Description\"]) if pd.notna(row[\"Contract Description\"]) else \"\"\n",
    "            c_date = str(row[\"Contract Date\"]) if pd.notna(row[\"Contract Date\"]) else str(datetime.date.today())\n",
    "            c_url = str(row[\"Source URL\"]) if pd.notna(row[\"Source URL\"]) else \"\"\n",
    "\n",
    "            initial_state = {\n",
    "                \"input_text\": desc,\n",
    "                \"input_date\": c_date,\n",
    "                \"input_url\": c_url,\n",
    "                \"final_data\": {},\n",
    "                \"messages\": []\n",
    "            }\n",
    "\n",
    "            output_state = app.invoke(initial_state)\n",
    "            results.append(output_state[\"final_data\"])\n",
    "\n",
    "        df_final = pd.DataFrame(results)\n",
    "\n",
    "        FINAL_COLUMNS = [\n",
    "            \"Customer Region\", \"Customer Country\", \"Customer Operator\",\n",
    "            \"Supplier Region\", \"Supplier Country\", \"Domestic Content\",\n",
    "\n",
    "            \"Market Segment\", \"Market Segment Evidence\", \"Market Segment Reason\",\n",
    "            \"System Type (General)\", \"System Type (General) Evidence\", \"System Type (General) Reason\",\n",
    "            \"System Type (Specific)\", \"System Type (Specific) Evidence\", \"System Type (Specific) Reason\",\n",
    "            \"System Name (General)\", \"System Name (General) Evidence\", \"System Name (General) Reason\",\n",
    "            \"System Name (Specific)\", \"System Name (Specific) Evidence\", \"System Name (Specific) Reason\",\n",
    "            \"System Piloting\", \"System Piloting Evidence\", \"System Piloting Reason\",\n",
    "            \"Confidence\",\n",
    "\n",
    "            \"Supplier Name\", \"Program Type\", \"Expected MRO Contract Duration (Months)\",\n",
    "            \"Quantity\", \"Value Certainty\", \"Value (Million)\", \"Currency\",\n",
    "            \"Value (USD$ Million)\", \"Value Note (If Any)\", \"G2G/B2G\",\n",
    "            \"Signing Month\", \"Signing Year\",\n",
    "\n",
    "            \"Description of Contract\",\n",
    "            \"Additional Notes (Internal Only)\",\n",
    "            \"Source Link(s)\",\n",
    "            \"Contract Date\",\n",
    "            \"Reported Date (By SGA)\"\n",
    "        ]\n",
    "\n",
    "        df_final = df_final.reindex(columns=FINAL_COLUMNS, fill_value=\"\")\n",
    "\n",
    "        df_final.to_excel(OUTPUT_EXCEL_PATH, index=False)\n",
    "\n",
    "        print(\"\\n‚úÖ Processing Complete!\")\n",
    "        print(f\"üíæ File saved to: {OUTPUT_EXCEL_PATH}\")\n",
    "        print(df_final.head().to_string())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
