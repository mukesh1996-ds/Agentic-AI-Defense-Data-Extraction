{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa44bbef",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import difflib\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import getpass\n",
    "from typing import Annotated, TypedDict, List\n",
    "import re\n",
    "import pickle\n",
    "import faiss\n",
    "\n",
    "# LangChain / LangGraph Imports\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ 0. RAG RETRIEVER (Single File Implementation)\n",
    "# ==============================================================================\n",
    "\n",
    "class SystemKBRetriever:\n",
    "    \"\"\"\n",
    "    Loads FAISS index + metadata created from your KB excel.\n",
    "    Uses ONLY the contract paragraph to retrieve similar examples.\n",
    "    \"\"\"\n",
    "    def __init__(self, kb_dir: str):\n",
    "        index_path = os.path.join(kb_dir, \"system_kb.faiss\")\n",
    "        meta_path = os.path.join(kb_dir, \"system_kb_meta.pkl\")\n",
    "\n",
    "        if not os.path.exists(index_path) or not os.path.exists(meta_path):\n",
    "            raise FileNotFoundError(\n",
    "                f\"‚ùå KB files not found in: {kb_dir}\\n\"\n",
    "                f\"Expected:\\n- {index_path}\\n- {meta_path}\\n\\n\"\n",
    "                f\"Build the KB first using your KB builder script.\"\n",
    "            )\n",
    "\n",
    "        print(f\"‚úÖ Loading FAISS Index: {index_path}\")\n",
    "        self.index = faiss.read_index(index_path)\n",
    "\n",
    "        print(f\"‚úÖ Loading KB Metadata: {meta_path}\")\n",
    "        with open(meta_path, \"rb\") as f:\n",
    "            self.meta = pickle.load(f)\n",
    "\n",
    "        print(f\"‚úÖ KB Loaded: {len(self.meta)} rows\")\n",
    "\n",
    "    def retrieve(self, query_text: str, top_k: int = 3):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        [\n",
    "          {\"score\": float, \"meta\": {...all 29 cols...}},\n",
    "          ...\n",
    "        ]\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "\n",
    "        query_text = str(query_text).strip()\n",
    "        if not query_text:\n",
    "            return []\n",
    "\n",
    "        # ‚úÖ Use embedding model only when needed (lazy load)\n",
    "        if not hasattr(self, \"embedder\"):\n",
    "            self.embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "        q_emb = self.embedder.encode([query_text], normalize_embeddings=True).astype(\"float32\")\n",
    "        scores, idxs = self.index.search(q_emb, top_k)\n",
    "\n",
    "        results = []\n",
    "        for score, idx in zip(scores[0], idxs[0]):\n",
    "            if idx < 0:\n",
    "                continue\n",
    "            results.append({\n",
    "                \"score\": float(score),\n",
    "                \"meta\": self.meta[idx]\n",
    "            })\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. CONFIGURATION & FILE PATHS\n",
    "# ==============================================================================\n",
    "\n",
    "# ‚¨áÔ∏è UPDATE PATHS HERE ‚¨áÔ∏è\n",
    "TAXONOMY_PATH = r'C:\\Users\\mukeshkr\\Desktop\\DefenseExtraction\\testing\\taxonomy.json'\n",
    "SUPPLIERS_PATH = r'C:\\Users\\mukeshkr\\Desktop\\DefenseExtraction\\testing\\suppliers.json'\n",
    "INPUT_EXCEL_PATH = r\"C:\\Users\\mukeshkr\\Desktop\\DefenseExtraction\\data\\source_file.xlsx\"\n",
    "OUTPUT_EXCEL_PATH = \"Processed_Defense_Data.xlsx\"\n",
    "\n",
    "# ‚úÖ RAG KB Directory (must contain system_kb.faiss + system_kb_meta.pkl)\n",
    "RAG_KB_DIR = r\"C:\\Users\\mukeshkr\\Desktop\\DefenseExtraction\\testing\\system_kb_store\"\n",
    "\n",
    "# Setup API Key\n",
    "if \"LLMFOUNDRY_TOKEN\" not in os.environ:\n",
    "    os.environ[\"LLMFOUNDRY_TOKEN\"] = getpass.getpass(\"Enter the LLM Foundry API Key: \")\n",
    "\n",
    "# Shared Client\n",
    "client = OpenAI(\n",
    "    api_key=f'{os.environ.get(\"LLMFOUNDRY_TOKEN\")}:my-test-project',\n",
    "    base_url=\"https://llmfoundry.straive.com/openai/v1/\",\n",
    ")\n",
    "\n",
    "# ‚úÖ Load retriever once globally\n",
    "retriever = SystemKBRetriever(kb_dir=RAG_KB_DIR)\n",
    "\n",
    "# --- FILE LOADING HELPERS ---\n",
    "def load_json_file(filename, default_value):\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            print(f\"‚úÖ Loaded {filename}\")\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Warning: Could not load {filename} ({e}). Using default.\")\n",
    "        return default_value\n",
    "\n",
    "# 1. Load Taxonomy\n",
    "raw_taxonomy = load_json_file(TAXONOMY_PATH, {})\n",
    "TAXONOMY_STR = json.dumps(raw_taxonomy, separators=(',', ':'))\n",
    "\n",
    "# 2. Load Suppliers\n",
    "SUPPLIER_LIST = load_json_file(SUPPLIERS_PATH, [\n",
    "    \"Dell Inc\", \"Boeing\", \"Lockheed Martin\", \"Raytheon Technologies\",\n",
    "    \"Northrop Grumman\", \"L3Harris\", \"BAE Systems\", \"General Dynamics\"\n",
    "])\n",
    "\n",
    "# 3. System Rules\n",
    "RULE_BOOK = {\n",
    "    \"defensive_countermeasures\": {\n",
    "        \"triggers\": [\"flare\", \"chaff\", \"countermeasure\", \"decoy\", \"mju-\", \"ale-\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Defensive Systems', Specific: 'Defensive Aid Suite'\"\n",
    "    },\n",
    "    \"radars_and_sensors\": {\n",
    "        \"triggers\": [\"radar\", \"sonar\", \"sensor\", \"an/apy\", \"an/tpy\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Sensors'\"\n",
    "    },\n",
    "    \"ammunition\": {\n",
    "        \"triggers\": [\"cartridge\", \"round\", \"projectile\", \" 5.56\", \" 7.62\", \"ammo\"],\n",
    "        \"guidance\": \"Market Segment: 'Weapon Systems', System Type (General): 'Ammunition'\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# 4. Geography Mapping\n",
    "GEOGRAPHY_MAPPING = {\n",
    "    \"North America\": [\"USA\", \"United States\", \"US\", \"Canada\", \"America\"],\n",
    "    \"Europe\": [\"UK\", \"United Kingdom\", \"Ukraine\", \"Germany\", \"France\", \"Italy\", \"Spain\", \"Poland\", \"Netherlands\", \"Norway\", \"Sweden\", \"Finland\", \"Denmark\", \"Belgium\"],\n",
    "    \"Asia-Pacific\": [\"Australia\", \"Japan\", \"South Korea\", \"Taiwan\", \"India\", \"Singapore\", \"New Zealand\"],\n",
    "    \"Middle East and North Africa\": [\"Israel\", \"Saudi Arabia\", \"UAE\", \"Egypt\", \"Qatar\", \"Kuwait\", \"Iraq\"],\n",
    "    \"International Organisations\": [\"NATO\", \"EU\", \"IFU\", \"UN\", \"NSPA\"]\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. HELPER FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def get_best_supplier_match(extracted_name):\n",
    "    \"\"\"Fuzzy matches the extracted name against the loaded SUPPLIER_LIST.\"\"\"\n",
    "    if not extracted_name or extracted_name.lower() in [\"unknown\", \"n/a\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    clean_name = extracted_name.strip()\n",
    "\n",
    "    supplier_map = {s.lower(): s for s in SUPPLIER_LIST}\n",
    "    if clean_name.lower() in supplier_map:\n",
    "        return supplier_map[clean_name.lower()]\n",
    "\n",
    "    matches = difflib.get_close_matches(clean_name, SUPPLIER_LIST, n=1, cutoff=0.6)\n",
    "    return matches[0] if matches else clean_name\n",
    "\n",
    "\n",
    "def calculate_mro_months(start_date_str, end_date_text, program_type):\n",
    "    \"\"\"Calculates duration only if Program Type is MRO/Support.\"\"\"\n",
    "    if program_type != \"MRO/Support\":\n",
    "        return \"Not Applicable\"\n",
    "\n",
    "    try:\n",
    "        if not start_date_str or not end_date_text or str(end_date_text).lower() in [\"unknown\", \"n/a\"]:\n",
    "            return \"Not Applicable\"\n",
    "\n",
    "        start = pd.to_datetime(start_date_str, dayfirst=True)\n",
    "        end = parser.parse(end_date_text, fuzzy=True)\n",
    "\n",
    "        diff = relativedelta(end, start)\n",
    "        total_months = (diff.years * 12) + diff.months\n",
    "        return str(max(0, int(total_months)))\n",
    "    except:\n",
    "        return \"Not Applicable\"\n",
    "\n",
    "\n",
    "def get_region_for_country(country_name):\n",
    "    \"\"\"Robust lookup handling casing/whitespace.\"\"\"\n",
    "    if not country_name or country_name.lower() in [\"unknown\", \"n/a\", \"not applicable\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    clean = country_name.strip().lower()\n",
    "\n",
    "    if clean in [\"us\", \"usa\", \"united states\", \"united states of america\"]:\n",
    "        return \"North America\"\n",
    "    if clean in [\"uk\", \"britain\", \"great britain\"]:\n",
    "        return \"Europe\"\n",
    "\n",
    "    for region, countries in GEOGRAPHY_MAPPING.items():\n",
    "        if any(c.lower() == clean for c in countries):\n",
    "            return region\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "# ‚úÖ Regex Designator Extractors (for System Name + Piloting)\n",
    "DESIGNATOR_PATTERNS = [\n",
    "    r\"\\bDDG[-\\s]?\\d+\\b\", r\"\\bCVN[-\\s]?\\d+\\b\", r\"\\bSSN[-\\s]?\\d+\\b\",\n",
    "    r\"\\bLCS[-\\s]?\\d+\\b\", r\"\\bLPD[-\\s]?\\d+\\b\", r\"\\bLHA[-\\s]?\\d+\\b\", r\"\\bLHD[-\\s]?\\d+\\b\",\n",
    "    r\"\\bF-\\d+\\b\", r\"\\bB-\\d+\\b\", r\"\\bC-\\d+\\b\", r\"\\bA-\\d+\\b\",\n",
    "    r\"\\bMQ-\\d+\\b\", r\"\\bRQ-\\d+\\b\",\n",
    "    r\"\\bAN\\/[A-Z0-9\\-]+\\b\",\n",
    "    r\"\\b(AIM|AGM|SM|RIM|MIM)-\\d+\\b\",\n",
    "]\n",
    "\n",
    "def extract_designators(text: str):\n",
    "    text = str(text)\n",
    "    found = []\n",
    "    for pat in DESIGNATOR_PATTERNS:\n",
    "        found.extend(re.findall(pat, text, flags=re.IGNORECASE))\n",
    "    cleaned = []\n",
    "    for f in found:\n",
    "        cleaned.append(f.upper().replace(\" \", \"\").replace(\"--\", \"-\"))\n",
    "    seen = set()\n",
    "    final = []\n",
    "    for x in cleaned:\n",
    "        if x not in seen:\n",
    "            final.append(x)\n",
    "            seen.add(x)\n",
    "    return final\n",
    "\n",
    "def detect_piloting_rule_based(text: str, designators: List[str]) -> str:\n",
    "    t = str(text).lower()\n",
    "\n",
    "    if any(d.startswith((\"MQ-\", \"RQ-\")) for d in designators):\n",
    "        return \"Uncrewed\"\n",
    "    if any(k in t for k in [\"unmanned\", \"uav\", \"drone\", \"autonomous\"]):\n",
    "        return \"Uncrewed\"\n",
    "\n",
    "    if any(d.startswith((\"DDG\", \"CVN\", \"SSN\", \"LCS\", \"LPD\", \"LHA\", \"LHD\")) for d in designators):\n",
    "        return \"Crewed\"\n",
    "    if \"uss \" in t:\n",
    "        return \"Crewed\"\n",
    "\n",
    "    return \"Not Applicable\"\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. TOOL DEFINITIONS (AGENTS)\n",
    "# ==============================================================================\n",
    "\n",
    "# --- AGENT 1: SOURCING ---\n",
    "class SourcingInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "    url: str = Field(description=\"Source URL.\")\n",
    "    date: str = Field(description=\"Contract Date.\")\n",
    "\n",
    "@tool(\"sourcing_extractor\")\n",
    "def sourcing_extractor(paragraph: str, url: str, date: str):\n",
    "    \"\"\"Stage 1: Prepares Metadata.\"\"\"\n",
    "    reported_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    notes = \"Standard extraction.\"\n",
    "    if \"modification\" in paragraph.lower():\n",
    "        notes = \"Contract Modification.\"\n",
    "    if \"split\" in paragraph.lower():\n",
    "        notes = \"Split award detected.\"\n",
    "\n",
    "    return {\n",
    "        \"Description of Contract\": paragraph,\n",
    "        \"Additional Notes (Internal Only)\": notes,\n",
    "        \"Source Link(s)\": url,\n",
    "        \"Contract Date\": date,\n",
    "        \"Reported Date (By SGA)\": reported_date\n",
    "    }\n",
    "\n",
    "\n",
    "# --- AGENT 2: GEOGRAPHY ---\n",
    "class GeographyInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "\n",
    "@tool(\"geography_extractor\")\n",
    "def geography_extractor(paragraph: str):\n",
    "    \"\"\"Stage 2: Geography Logic.\"\"\"\n",
    "    sys_prompt = \"\"\"\n",
    "Extract: Customer Country, Supplier Country, Customer Operator.\n",
    "Logic: If 'Navy awarded...', Operator is Navy.\n",
    "Return JSON:\n",
    "{\n",
    "  \"Customer Country\": \"...\",\n",
    "  \"Customer Operator\": \"...\",\n",
    "  \"Supplier Country\": \"...\"\n",
    "}\n",
    "\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": paragraph}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "    except Exception:\n",
    "        raw = {}\n",
    "\n",
    "    cust = raw.get(\"Customer Country\", \"Unknown\")\n",
    "    supp = raw.get(\"Supplier Country\", \"Unknown\")\n",
    "\n",
    "    domestic = \"Indigenous\" if cust.lower() == supp.lower() else \"Imported\"\n",
    "    if \"united states\" in cust.lower() and \"usa\" in supp.lower():\n",
    "        domestic = \"Indigenous\"\n",
    "\n",
    "    return {\n",
    "        \"Customer Region\": get_region_for_country(cust),\n",
    "        \"Customer Country\": cust,\n",
    "        \"Customer Operator\": raw.get(\"Customer Operator\", \"Unknown\"),\n",
    "        \"Supplier Region\": get_region_for_country(supp),\n",
    "        \"Supplier Country\": supp,\n",
    "        \"Domestic Content\": domestic\n",
    "    }\n",
    "\n",
    "\n",
    "# --- ‚úÖ AGENT 3: SYSTEM (UPGRADED WITH RAG + Evidence + Reason) ---\n",
    "class SystemInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "\n",
    "@tool(\"system_classifier\")\n",
    "def system_classifier(paragraph: str):\n",
    "    \"\"\"Stage 3: System classification using RAG + Rule Book + Evidence & Reason.\"\"\"\n",
    "    paragraph = str(paragraph).strip()\n",
    "    if not paragraph:\n",
    "        return {}\n",
    "\n",
    "    lower_text = paragraph.lower()\n",
    "\n",
    "    # RULE BOOK triggers\n",
    "    hints = [\n",
    "        f\"RULE: {v['guidance']}\"\n",
    "        for _, v in RULE_BOOK.items()\n",
    "        if any(t in lower_text for t in v[\"triggers\"])\n",
    "    ]\n",
    "    hint_str = \"\\n\".join(hints) if hints else \"No special override rules triggered.\"\n",
    "\n",
    "    # Local extraction\n",
    "    designators = extract_designators(paragraph)\n",
    "\n",
    "    # Rule-based piloting\n",
    "    piloting_rule = detect_piloting_rule_based(paragraph, designators)\n",
    "\n",
    "    # RAG Retrieval\n",
    "    rag_hits = retriever.retrieve(paragraph, top_k=3)\n",
    "\n",
    "    rag_examples = []\n",
    "    for hit in rag_hits:\n",
    "        meta = hit[\"meta\"]\n",
    "        rag_examples.append({\n",
    "            \"score\": round(hit[\"score\"], 4),\n",
    "            \"Market Segment\": meta.get(\"Market Segment\", \"\"),\n",
    "            \"System Type (General)\": meta.get(\"System Type (General)\", \"\"),\n",
    "            \"System Type (Specific)\": meta.get(\"System Type (Specific)\", \"\"),\n",
    "            \"System Name (General)\": meta.get(\"System Name (General)\", \"\"),\n",
    "            \"System Name (Specific)\": meta.get(\"System Name (Specific)\", \"\"),\n",
    "            \"System Piloting\": meta.get(\"System Piloting\", \"\"),\n",
    "            \"Supplier Name\": meta.get(\"Supplier Name\", \"\"),\n",
    "            \"Customer Operator\": meta.get(\"Customer Operator\", \"\"),\n",
    "            \"Snippet\": meta.get(\"Description of Contract\", \"\")[:220] + \"...\"\n",
    "        })\n",
    "\n",
    "    sys_prompt = f\"\"\"\n",
    "You are a Senior Defense System Classification Analyst.\n",
    "\n",
    "Use these inputs:\n",
    "1) RAG Similar Examples (top 3)\n",
    "2) Rule Book Overrides\n",
    "3) Extracted Designators\n",
    "\n",
    "RULE BOOK OVERRIDES:\n",
    "{hint_str}\n",
    "\n",
    "OUTPUT RULES:\n",
    "- Return ONLY a FLAT JSON object.\n",
    "- Every value must be a STRING.\n",
    "- Do NOT return nested JSON or lists.\n",
    "- Evidence must be copied EXACTLY from paragraph.\n",
    "- If evidence not present, use \"Not Found\".\n",
    "\n",
    "Return JSON exactly:\n",
    "{{\n",
    "  \"Market Segment\": \"\",\n",
    "  \"Market Segment Evidence\": \"\",\n",
    "  \"Market Segment Reason\": \"\",\n",
    "\n",
    "  \"System Type (General)\": \"\",\n",
    "  \"System Type (General) Evidence\": \"\",\n",
    "  \"System Type (General) Reason\": \"\",\n",
    "\n",
    "  \"System Type (Specific)\": \"\",\n",
    "  \"System Type (Specific) Evidence\": \"\",\n",
    "  \"System Type (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Name (General)\": \"\",\n",
    "  \"System Name (General) Evidence\": \"\",\n",
    "  \"System Name (General) Reason\": \"\",\n",
    "\n",
    "  \"System Name (Specific)\": \"\",\n",
    "  \"System Name (Specific) Evidence\": \"\",\n",
    "  \"System Name (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Piloting\": \"\",\n",
    "  \"System Piloting Evidence\": \"\",\n",
    "  \"System Piloting Reason\": \"\",\n",
    "\n",
    "  \"Confidence\": \"High/Medium/Low\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "INPUT PARAGRAPH:\n",
    "{paragraph}\n",
    "\n",
    "DESIGNATORS (regex extracted):\n",
    "{designators if designators else \"None\"}\n",
    "\n",
    "RULE-BASED PILOTING:\n",
    "{piloting_rule}\n",
    "\n",
    "RAG SIMILAR EXAMPLES:\n",
    "{json.dumps(rag_examples, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        result = json.loads(completion.choices[0].message.content)\n",
    "\n",
    "        # Hard override piloting (best accuracy)\n",
    "        result[\"System Piloting\"] = piloting_rule\n",
    "        if not result.get(\"System Piloting Reason\"):\n",
    "            result[\"System Piloting Reason\"] = \"Piloting derived using deterministic rules.\"\n",
    "        if not result.get(\"System Piloting Evidence\"):\n",
    "            result[\"System Piloting Evidence\"] = \"Not Found\"\n",
    "\n",
    "        # Ensure flat\n",
    "        for k, v in result.items():\n",
    "            if isinstance(v, (dict, list)):\n",
    "                result[k] = str(v)\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"Market Segment\": \"\",\n",
    "            \"System Type (General)\": \"\",\n",
    "            \"System Type (Specific)\": \"\",\n",
    "            \"System Name (General)\": \"\",\n",
    "            \"System Name (Specific)\": \"\",\n",
    "            \"System Piloting\": piloting_rule,\n",
    "            \"Market Segment Evidence\": \"Not Found\",\n",
    "            \"System Type (General) Evidence\": \"Not Found\",\n",
    "            \"System Type (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Name (General) Evidence\": \"Not Found\",\n",
    "            \"System Name (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Piloting Evidence\": \"Not Found\",\n",
    "            \"Market Segment Reason\": \"\",\n",
    "            \"System Type (General) Reason\": \"\",\n",
    "            \"System Type (Specific) Reason\": \"\",\n",
    "            \"System Name (General) Reason\": \"\",\n",
    "            \"System Name (Specific) Reason\": \"\",\n",
    "            \"System Piloting Reason\": \"Piloting derived using deterministic rules.\",\n",
    "            \"Confidence\": \"Low\",\n",
    "            \"Error\": str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "# --- AGENT 4: CONTRACT ---\n",
    "class ContractInfoInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "    contract_date: str = Field(description=\"Signed date.\")\n",
    "\n",
    "@tool(\"contract_extractor\")\n",
    "def contract_extractor(paragraph: str, contract_date: str):\n",
    "    \"\"\"Stage 4: Extracts Financials, Program Type, and Dates based on strict SOP.\"\"\"\n",
    "\n",
    "    system_instruction = \"\"\"\n",
    "You are a Defense Contract Financial Analyst. Extract data strictly following these SOP rules:\n",
    "\n",
    "1) Supplier Name: Extract the exact company name text found in paragraph.\n",
    "2) Program Type: Procurement / Training / MRO/Support / RDT&E / Upgrade / Other Service\n",
    "3) Value Certainty:\n",
    "   - Confirmed: fixed price/obligated stated\n",
    "   - Estimated: ceiling/potential/IDIQ/multi-award\n",
    "4) Quantity: number or Not Applicable\n",
    "5) G2G/B2G:\n",
    "   - G2G only if Foreign Military Sales (FMS)\n",
    "   - else B2G\n",
    "6) Completion Date: only needed for MRO duration calc\n",
    "\n",
    "Return JSON only.\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "Analyze contract:\n",
    "\"{paragraph}\"\n",
    "\n",
    "Signed Date: {contract_date}\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"raw_supplier_name\": \"\",\n",
    "  \"program_type\": \"\",\n",
    "  \"value_million_raw\": \"\",\n",
    "  \"currency_code\": \"\",\n",
    "  \"value_certainty\": \"\",\n",
    "  \"quantity\": \"\",\n",
    "  \"completion_date_text\": \"\",\n",
    "  \"g2g_b2g\": \"\",\n",
    "  \"value_note\": \"\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_instruction},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        return {\"Error\": str(e)}\n",
    "\n",
    "    final_supplier = get_best_supplier_match(raw.get(\"raw_supplier_name\"))\n",
    "    prog_type = raw.get(\"program_type\", \"Unknown\")\n",
    "    mro_months = calculate_mro_months(contract_date, raw.get(\"completion_date_text\"), prog_type)\n",
    "\n",
    "    try:\n",
    "        val_str = str(raw.get(\"value_million_raw\", \"0\")).replace(\",\", \"\").replace(\"$\", \"\")\n",
    "        val_float = float(val_str)\n",
    "        val_formatted = \"{:.3f}\".format(val_float)\n",
    "    except:\n",
    "        val_formatted = \"0.000\"\n",
    "\n",
    "    try:\n",
    "        dt = pd.to_datetime(contract_date)\n",
    "        sign_month = dt.strftime(\"%B\")\n",
    "        sign_year = str(dt.year)\n",
    "    except:\n",
    "        sign_month, sign_year = \"Unknown\", \"Unknown\"\n",
    "\n",
    "    val_note = raw.get(\"value_note\", \"Not Applicable\")\n",
    "    if \"split\" in paragraph.lower() and val_note == \"Not Applicable\":\n",
    "        val_note = \"Split contract; value distribution unclear.\"\n",
    "\n",
    "    return {\n",
    "        \"Supplier Name\": final_supplier,\n",
    "        \"Program Type\": prog_type,\n",
    "        \"Expected MRO Contract Duration (Months)\": mro_months,\n",
    "        \"Quantity\": raw.get(\"quantity\", \"Not Applicable\"),\n",
    "        \"Value Certainty\": raw.get(\"value_certainty\", \"Confirmed\"),\n",
    "        \"Value (Million)\": val_formatted,\n",
    "        \"Currency\": raw.get(\"currency_code\", \"USD$\"),\n",
    "        \"Value (USD$ Million)\": val_formatted,\n",
    "        \"Value Note (If Any)\": val_note,\n",
    "        \"G2G/B2G\": raw.get(\"g2g_b2g\", \"B2G\"),\n",
    "        \"Signing Month\": sign_month,\n",
    "        \"Signing Year\": sign_year\n",
    "    }\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. LANGGRAPH PIPELINE\n",
    "# ==============================================================================\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input_text: str\n",
    "    input_date: str\n",
    "    input_url: str\n",
    "    final_data: dict\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "\n",
    "def stage_1_sourcing(state: AgentState):\n",
    "    res = sourcing_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"url\": state[\"input_url\"],\n",
    "        \"date\": state[\"input_date\"]\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "def stage_2_geography(state: AgentState):\n",
    "    res = geography_extractor.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "def stage_3_system(state: AgentState):\n",
    "    res = system_classifier.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "def stage_4_contract(state: AgentState):\n",
    "    res = contract_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"contract_date\": state[\"input_date\"]\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Stage1\", stage_1_sourcing)\n",
    "workflow.add_node(\"Stage2\", stage_2_geography)\n",
    "workflow.add_node(\"Stage3\", stage_3_system)\n",
    "workflow.add_node(\"Stage4\", stage_4_contract)\n",
    "\n",
    "workflow.add_edge(START, \"Stage1\")\n",
    "workflow.add_edge(\"Stage1\", \"Stage2\")\n",
    "workflow.add_edge(\"Stage2\", \"Stage3\")\n",
    "workflow.add_edge(\"Stage3\", \"Stage4\")\n",
    "workflow.add_edge(\"Stage4\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. EXECUTION & FORMATTING\n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(f\"üìÇ Loading Input File: {INPUT_EXCEL_PATH}...\")\n",
    "\n",
    "    try:\n",
    "        df_input = pd.read_excel(INPUT_EXCEL_PATH)\n",
    "\n",
    "        required_cols = [\"Source URL\", \"Contract Date\", \"Contract Description\"]\n",
    "        if not all(col in df_input.columns for col in required_cols):\n",
    "            raise ValueError(f\"Excel file must contain columns: {required_cols}\")\n",
    "\n",
    "        print(f\"üöÄ Processing {len(df_input)} rows...\")\n",
    "        results = []\n",
    "\n",
    "        for index, row in df_input.iterrows():\n",
    "            print(f\"   -> Row {index + 1}...\")\n",
    "\n",
    "            desc = str(row[\"Contract Description\"]) if pd.notna(row[\"Contract Description\"]) else \"\"\n",
    "            c_date = str(row[\"Contract Date\"]) if pd.notna(row[\"Contract Date\"]) else str(datetime.date.today())\n",
    "            c_url = str(row[\"Source URL\"]) if pd.notna(row[\"Source URL\"]) else \"\"\n",
    "\n",
    "            initial_state = {\n",
    "                \"input_text\": desc,\n",
    "                \"input_date\": c_date,\n",
    "                \"input_url\": c_url,\n",
    "                \"final_data\": {},\n",
    "                \"messages\": []\n",
    "            }\n",
    "\n",
    "            output_state = app.invoke(initial_state)\n",
    "            results.append(output_state[\"final_data\"])\n",
    "\n",
    "        df_final = pd.DataFrame(results)\n",
    "\n",
    "        FINAL_COLUMNS = [\n",
    "            \"Customer Region\", \"Customer Country\", \"Customer Operator\",\n",
    "            \"Supplier Region\", \"Supplier Country\", \"Domestic Content\",\n",
    "\n",
    "            \"Market Segment\", \"Market Segment Evidence\", \"Market Segment Reason\",\n",
    "            \"System Type (General)\", \"System Type (General) Evidence\", \"System Type (General) Reason\",\n",
    "            \"System Type (Specific)\", \"System Type (Specific) Evidence\", \"System Type (Specific) Reason\",\n",
    "            \"System Name (General)\", \"System Name (General) Evidence\", \"System Name (General) Reason\",\n",
    "            \"System Name (Specific)\", \"System Name (Specific) Evidence\", \"System Name (Specific) Reason\",\n",
    "            \"System Piloting\", \"System Piloting Evidence\", \"System Piloting Reason\",\n",
    "            \"Confidence\",\n",
    "\n",
    "            \"Supplier Name\", \"Program Type\", \"Expected MRO Contract Duration (Months)\",\n",
    "            \"Quantity\", \"Value Certainty\", \"Value (Million)\", \"Currency\",\n",
    "            \"Value (USD$ Million)\", \"Value Note (If Any)\", \"G2G/B2G\",\n",
    "            \"Signing Month\", \"Signing Year\",\n",
    "\n",
    "            \"Description of Contract\",\n",
    "            \"Additional Notes (Internal Only)\",\n",
    "            \"Source Link(s)\",\n",
    "            \"Contract Date\",\n",
    "            \"Reported Date (By SGA)\"\n",
    "        ]\n",
    "\n",
    "        df_final = df_final.reindex(columns=FINAL_COLUMNS, fill_value=\"\")\n",
    "\n",
    "        df_final.to_excel(OUTPUT_EXCEL_PATH, index=False)\n",
    "\n",
    "        print(\"\\n‚úÖ Processing Complete!\")\n",
    "        print(f\"üíæ File saved to: {OUTPUT_EXCEL_PATH}\")\n",
    "        print(df_final.head().to_string())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3be6b49",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import getpass\n",
    "from typing import Annotated, TypedDict, List\n",
    "import re\n",
    "import pickle\n",
    "import faiss\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# LangChain / LangGraph Imports\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ RAG RETRIEVER (Single File Implementation)\n",
    "# ==============================================================================\n",
    "\n",
    "class SystemKBRetriever:\n",
    "    \"\"\"\n",
    "    Loads FAISS index + metadata created from your KB excel.\n",
    "    Uses ONLY the contract paragraph to retrieve similar examples.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kb_dir: str):\n",
    "        index_path = os.path.join(kb_dir, \"system_kb.faiss\")\n",
    "        meta_path = os.path.join(kb_dir, \"system_kb_meta.pkl\")\n",
    "\n",
    "        if not os.path.exists(index_path) or not os.path.exists(meta_path):\n",
    "            raise FileNotFoundError(\n",
    "                f\"‚ùå KB files not found in: {kb_dir}\\n\"\n",
    "                f\"Expected:\\n- {index_path}\\n- {meta_path}\\n\\n\"\n",
    "                f\"Build the KB first using your KB builder script.\"\n",
    "            )\n",
    "\n",
    "        print(f\"‚úÖ Loading FAISS Index: {index_path}\")\n",
    "        self.index = faiss.read_index(index_path)\n",
    "\n",
    "        print(f\"‚úÖ Loading KB Metadata: {meta_path}\")\n",
    "        with open(meta_path, \"rb\") as f:\n",
    "            self.meta = pickle.load(f)\n",
    "\n",
    "        print(f\"‚úÖ KB Loaded: {len(self.meta)} rows\")\n",
    "\n",
    "    def retrieve(self, query_text: str, top_k: int = 3):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        [\n",
    "          {\"score\": float, \"meta\": {...all 29 cols...}},\n",
    "          ...\n",
    "        ]\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "\n",
    "        query_text = str(query_text).strip()\n",
    "        if not query_text:\n",
    "            return []\n",
    "\n",
    "        # Use embedding model only when needed (lazy load)\n",
    "        if not hasattr(self, \"embedder\"):\n",
    "            self.embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "        q_emb = self.embedder.encode([query_text], normalize_embeddings=True).astype(\"float32\")\n",
    "        scores, idxs = self.index.search(q_emb, top_k)\n",
    "\n",
    "        results = []\n",
    "        for score, idx in zip(scores[0], idxs[0]):\n",
    "            if idx < 0:\n",
    "                continue\n",
    "            results.append({\"score\": float(score), \"meta\": self.meta[idx]})\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ 1. CONFIGURATION & FILE PATHS\n",
    "# ==============================================================================\n",
    "\n",
    "TAXONOMY_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\taxonomy.json\"\n",
    "SUPPLIERS_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\suppliers.json\"\n",
    "INPUT_EXCEL_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\data\\source_file.xlsx\"\n",
    "OUTPUT_EXCEL_PATH = \"Processed_Defense_Data.xlsx\"\n",
    "\n",
    "RAG_KB_DIR = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\system_kb_store\"\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ 2. API Setup\n",
    "# ==============================================================================\n",
    "\n",
    "if \"LLMFOUNDRY_TOKEN\" not in os.environ:\n",
    "    os.environ[\"LLMFOUNDRY_TOKEN\"] = getpass.getpass(\"Enter the LLM Foundry API Key: \")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=f'{os.environ.get(\"LLMFOUNDRY_TOKEN\")}:my-test-project',\n",
    "    base_url=\"https://llmfoundry.straive.com/openai/v1/\",\n",
    ")\n",
    "\n",
    "retriever = SystemKBRetriever(kb_dir=RAG_KB_DIR)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ 3. JSON Loaders\n",
    "# ==============================================================================\n",
    "\n",
    "def load_json_file(filename, default_value):\n",
    "    try:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            print(f\"‚úÖ Loaded: {filename}\")\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Warning: Could not load {filename} ({e}). Using default.\")\n",
    "        return default_value\n",
    "\n",
    "\n",
    "raw_taxonomy = load_json_file(TAXONOMY_PATH, {})\n",
    "TAXONOMY_STR = json.dumps(raw_taxonomy, separators=(\",\", \":\"))\n",
    "\n",
    "\n",
    "# ‚úÖ IMPORTANT: Supplier list MUST come from suppliers.json\n",
    "SUPPLIER_LIST = load_json_file(SUPPLIERS_PATH, [])\n",
    "if not SUPPLIER_LIST:\n",
    "    raise ValueError(\"‚ùå suppliers.json loaded 0 suppliers. Please verify the path.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ 4. Rule Book + Geography Mapping\n",
    "# ==============================================================================\n",
    "\n",
    "RULE_BOOK = {\n",
    "    \"defensive_countermeasures\": {\n",
    "        \"triggers\": [\"flare\", \"chaff\", \"countermeasure\", \"decoy\", \"mju-\", \"ale-\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Defensive Systems', Specific: 'Defensive Aid Suite'\",\n",
    "    },\n",
    "    \"radars_and_sensors\": {\n",
    "        \"triggers\": [\"radar\", \"sonar\", \"sensor\", \"an/apy\", \"an/tpy\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Sensors'\",\n",
    "    },\n",
    "    \"ammunition\": {\n",
    "        \"triggers\": [\"cartridge\", \"round\", \"projectile\", \" 5.56\", \" 7.62\", \"ammo\"],\n",
    "        \"guidance\": \"Market Segment: 'Weapon Systems', System Type (General): 'Ammunition'\",\n",
    "    },\n",
    "}\n",
    "\n",
    "GEOGRAPHY_MAPPING = {\n",
    "    \"North America\": [\"USA\", \"United States\", \"US\", \"Canada\", \"America\"],\n",
    "    \"Europe\": [\"UK\", \"United Kingdom\", \"Ukraine\", \"Germany\", \"France\", \"Italy\", \"Spain\", \"Poland\", \"Netherlands\", \"Norway\", \"Sweden\", \"Finland\", \"Denmark\", \"Belgium\"],\n",
    "    \"Asia-Pacific\": [\"Australia\", \"Japan\", \"South Korea\", \"Taiwan\", \"India\", \"Singapore\", \"New Zealand\"],\n",
    "    \"Middle East and North Africa\": [\"Israel\", \"Saudi Arabia\", \"UAE\", \"Egypt\", \"Qatar\", \"Kuwait\", \"Iraq\"],\n",
    "    \"International Organisations\": [\"NATO\", \"EU\", \"IFU\", \"UN\", \"NSPA\"],\n",
    "}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ 5. HELPER FUNCTIONS (Supplier Matching FIXED ‚úÖ‚úÖ‚úÖ)\n",
    "# ==============================================================================\n",
    "\n",
    "def normalize_supplier_text(x: str) -> str:\n",
    "    if not x:\n",
    "        return \"\"\n",
    "    x = str(x).strip()\n",
    "\n",
    "    # normalize unicode dashes\n",
    "    x = x.replace(\"‚Äì\", \"-\").replace(\"‚Äî\", \"-\")\n",
    "\n",
    "    # remove multiple spaces\n",
    "    x = re.sub(r\"\\s+\", \" \", x).strip()\n",
    "\n",
    "    # remove extra location after comma\n",
    "    # ex: \"General Dynamics NASSCO - San Diego, San Diego, California\"\n",
    "    x = x.split(\",\")[0].strip()\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def token_overlap_score(a: str, b: str) -> float:\n",
    "    a_tokens = set(re.findall(r\"[a-z0-9]+\", a.lower()))\n",
    "    b_tokens = set(re.findall(r\"[a-z0-9]+\", b.lower()))\n",
    "    if not a_tokens or not b_tokens:\n",
    "        return 0.0\n",
    "    return len(a_tokens & b_tokens) / max(len(a_tokens), len(b_tokens))\n",
    "\n",
    "\n",
    "def get_best_supplier_match(extracted_supplier: str):\n",
    "    \"\"\"\n",
    "    ‚úÖ FINAL Supplier Name MUST be from SUPPLIER_LIST (suppliers.json)\n",
    "    Returns:\n",
    "      (best_supplier_name, best_score)\n",
    "    \"\"\"\n",
    "    if not extracted_supplier:\n",
    "        return \"Unknown\", 0.0\n",
    "\n",
    "    extracted_supplier = normalize_supplier_text(extracted_supplier)\n",
    "    low = extracted_supplier.lower()\n",
    "\n",
    "    if low in [\"unknown\", \"n/a\", \"not applicable\"]:\n",
    "        return \"Unknown\", 0.0\n",
    "\n",
    "    # 1) Exact match\n",
    "    supplier_map = {s.lower(): s for s in SUPPLIER_LIST}\n",
    "    if low in supplier_map:\n",
    "        return supplier_map[low], 1.0\n",
    "\n",
    "    # 2) Containment match (best practical for long extracted)\n",
    "    containment_hits = [s for s in SUPPLIER_LIST if s.lower() in low]\n",
    "    if containment_hits:\n",
    "        containment_hits.sort(key=len, reverse=True)  # longest = most specific\n",
    "        return containment_hits[0], 0.95\n",
    "\n",
    "    # 3) Hybrid fuzzy match over supplier list\n",
    "    best_name = \"Unknown\"\n",
    "    best_score = 0.0\n",
    "\n",
    "    for s in SUPPLIER_LIST:\n",
    "        s_clean = normalize_supplier_text(s)\n",
    "\n",
    "        seq = SequenceMatcher(None, low, s_clean.lower()).ratio()\n",
    "        tok = token_overlap_score(extracted_supplier, s_clean)\n",
    "\n",
    "        final = (0.65 * tok) + (0.35 * seq)\n",
    "\n",
    "        if final > best_score:\n",
    "            best_score = final\n",
    "            best_name = s\n",
    "\n",
    "    # strict cutoff: avoid wrong match\n",
    "    if best_score < 0.45:\n",
    "        return \"Unknown\", best_score\n",
    "\n",
    "    return best_name, best_score\n",
    "\n",
    "\n",
    "def calculate_mro_months(start_date_str, end_date_text, program_type):\n",
    "    \"\"\"Calculates duration only if Program Type is MRO/Support.\"\"\"\n",
    "    if program_type != \"MRO/Support\":\n",
    "        return \"Not Applicable\"\n",
    "\n",
    "    try:\n",
    "        if not start_date_str or not end_date_text or str(end_date_text).lower() in [\"unknown\", \"n/a\"]:\n",
    "            return \"Not Applicable\"\n",
    "\n",
    "        start = pd.to_datetime(start_date_str, dayfirst=True)\n",
    "        end = parser.parse(end_date_text, fuzzy=True)\n",
    "\n",
    "        diff = relativedelta(end, start)\n",
    "        total_months = (diff.years * 12) + diff.months\n",
    "        return str(max(0, int(total_months)))\n",
    "    except:\n",
    "        return \"Not Applicable\"\n",
    "\n",
    "\n",
    "def get_region_for_country(country_name):\n",
    "    \"\"\"Robust lookup handling casing/whitespace.\"\"\"\n",
    "    if not country_name or country_name.lower() in [\"unknown\", \"n/a\", \"not applicable\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    clean = country_name.strip().lower()\n",
    "\n",
    "    if clean in [\"us\", \"usa\", \"united states\", \"united states of america\"]:\n",
    "        return \"North America\"\n",
    "    if clean in [\"uk\", \"britain\", \"great britain\"]:\n",
    "        return \"Europe\"\n",
    "\n",
    "    for region, countries in GEOGRAPHY_MAPPING.items():\n",
    "        if any(c.lower() == clean for c in countries):\n",
    "            return region\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ 6. Designators (System Name + Piloting)\n",
    "# ==============================================================================\n",
    "\n",
    "DESIGNATOR_PATTERNS = [\n",
    "    r\"\\bDDG[-\\s]?\\d+\\b\", r\"\\bCVN[-\\s]?\\d+\\b\", r\"\\bSSN[-\\s]?\\d+\\b\",\n",
    "    r\"\\bLCS[-\\s]?\\d+\\b\", r\"\\bLPD[-\\s]?\\d+\\b\", r\"\\bLHA[-\\s]?\\d+\\b\", r\"\\bLHD[-\\s]?\\d+\\b\",\n",
    "    r\"\\bF-\\d+\\b\", r\"\\bB-\\d+\\b\", r\"\\bC-\\d+\\b\", r\"\\bA-\\d+\\b\",\n",
    "    r\"\\bMQ-\\d+\\b\", r\"\\bRQ-\\d+\\b\",\n",
    "    r\"\\bAN\\/[A-Z0-9\\-]+\\b\",\n",
    "    r\"\\b(AIM|AGM|SM|RIM|MIM)-\\d+\\b\",\n",
    "]\n",
    "\n",
    "def extract_designators(text: str):\n",
    "    text = str(text)\n",
    "    found = []\n",
    "    for pat in DESIGNATOR_PATTERNS:\n",
    "        found.extend(re.findall(pat, text, flags=re.IGNORECASE))\n",
    "\n",
    "    cleaned = []\n",
    "    for f in found:\n",
    "        cleaned.append(f.upper().replace(\" \", \"\").replace(\"--\", \"-\"))\n",
    "\n",
    "    seen = set()\n",
    "    final = []\n",
    "    for x in cleaned:\n",
    "        if x not in seen:\n",
    "            final.append(x)\n",
    "            seen.add(x)\n",
    "    return final\n",
    "\n",
    "\n",
    "def detect_piloting_rule_based(text: str, designators: List[str]) -> str:\n",
    "    t = str(text).lower()\n",
    "\n",
    "    if any(d.startswith((\"MQ-\", \"RQ-\")) for d in designators):\n",
    "        return \"Uncrewed\"\n",
    "    if any(k in t for k in [\"unmanned\", \"uav\", \"drone\", \"autonomous\"]):\n",
    "        return \"Uncrewed\"\n",
    "\n",
    "    if any(d.startswith((\"DDG\", \"CVN\", \"SSN\", \"LCS\", \"LPD\", \"LHA\", \"LHD\")) for d in designators):\n",
    "        return \"Crewed\"\n",
    "    if \"uss \" in t:\n",
    "        return \"Crewed\"\n",
    "\n",
    "    return \"Not Applicable\"\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ 7. TOOL DEFINITIONS (Agents)\n",
    "# ==============================================================================\n",
    "\n",
    "# --- AGENT 1: SOURCING ---\n",
    "class SourcingInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "    url: str = Field(description=\"Source URL.\")\n",
    "    date: str = Field(description=\"Contract Date.\")\n",
    "\n",
    "@tool(\"sourcing_extractor\")\n",
    "def sourcing_extractor(paragraph: str, url: str, date: str):\n",
    "    reported_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    notes = \"Standard extraction.\"\n",
    "    if \"modification\" in paragraph.lower():\n",
    "        notes = \"Contract Modification.\"\n",
    "    if \"split\" in paragraph.lower():\n",
    "        notes = \"Split award detected.\"\n",
    "\n",
    "    return {\n",
    "        \"Description of Contract\": paragraph,\n",
    "        \"Additional Notes (Internal Only)\": notes,\n",
    "        \"Source Link(s)\": url,\n",
    "        \"Contract Date\": date,\n",
    "        \"Reported Date (By SGA)\": reported_date\n",
    "    }\n",
    "\n",
    "\n",
    "# --- AGENT 2: GEOGRAPHY ---\n",
    "class GeographyInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "\n",
    "@tool(\"geography_extractor\")\n",
    "def geography_extractor(paragraph: str):\n",
    "    sys_prompt = \"\"\"\n",
    "Extract: Customer Country, Supplier Country, Customer Operator.\n",
    "Logic: If 'Navy awarded...', Operator is Navy.\n",
    "Return JSON:\n",
    "{\n",
    "  \"Customer Country\": \"...\",\n",
    "  \"Customer Operator\": \"...\",\n",
    "  \"Supplier Country\": \"...\"\n",
    "}\n",
    "\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": paragraph}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "    except Exception:\n",
    "        raw = {}\n",
    "\n",
    "    cust = raw.get(\"Customer Country\", \"Unknown\")\n",
    "    supp = raw.get(\"Supplier Country\", \"Unknown\")\n",
    "\n",
    "    domestic = \"Indigenous\" if cust.lower() == supp.lower() else \"Imported\"\n",
    "    if \"united states\" in cust.lower() and \"usa\" in supp.lower():\n",
    "        domestic = \"Indigenous\"\n",
    "\n",
    "    return {\n",
    "        \"Customer Region\": get_region_for_country(cust),\n",
    "        \"Customer Country\": cust,\n",
    "        \"Customer Operator\": raw.get(\"Customer Operator\", \"Unknown\"),\n",
    "        \"Supplier Region\": get_region_for_country(supp),\n",
    "        \"Supplier Country\": supp,\n",
    "        \"Domestic Content\": domestic\n",
    "    }\n",
    "\n",
    "\n",
    "# --- AGENT 3: SYSTEM (RAG + Evidence + Reason) ---\n",
    "class SystemInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "\n",
    "@tool(\"system_classifier\")\n",
    "def system_classifier(paragraph: str):\n",
    "    paragraph = str(paragraph).strip()\n",
    "    if not paragraph:\n",
    "        return {}\n",
    "\n",
    "    lower_text = paragraph.lower()\n",
    "\n",
    "    hints = [\n",
    "        f\"RULE: {v['guidance']}\"\n",
    "        for _, v in RULE_BOOK.items()\n",
    "        if any(t in lower_text for t in v[\"triggers\"])\n",
    "    ]\n",
    "    hint_str = \"\\n\".join(hints) if hints else \"No special override rules triggered.\"\n",
    "\n",
    "    designators = extract_designators(paragraph)\n",
    "    piloting_rule = detect_piloting_rule_based(paragraph, designators)\n",
    "\n",
    "    rag_hits = retriever.retrieve(paragraph, top_k=3)\n",
    "\n",
    "    rag_examples = []\n",
    "    for hit in rag_hits:\n",
    "        meta = hit[\"meta\"]\n",
    "        rag_examples.append({\n",
    "            \"score\": round(hit[\"score\"], 4),\n",
    "            \"Market Segment\": meta.get(\"Market Segment\", \"\"),\n",
    "            \"System Type (General)\": meta.get(\"System Type (General)\", \"\"),\n",
    "            \"System Type (Specific)\": meta.get(\"System Type (Specific)\", \"\"),\n",
    "            \"System Name (General)\": meta.get(\"System Name (General)\", \"\"),\n",
    "            \"System Name (Specific)\": meta.get(\"System Name (Specific)\", \"\"),\n",
    "            \"System Piloting\": meta.get(\"System Piloting\", \"\"),\n",
    "            \"Supplier Name\": meta.get(\"Supplier Name\", \"\"),\n",
    "            \"Customer Operator\": meta.get(\"Customer Operator\", \"\"),\n",
    "            \"Snippet\": meta.get(\"Description of Contract\", \"\")[:220] + \"...\"\n",
    "        })\n",
    "\n",
    "    sys_prompt = f\"\"\"\n",
    "You are a Senior Defense System Classification Analyst.\n",
    "\n",
    "Use these inputs:\n",
    "1) RAG Similar Examples (top 3)\n",
    "2) Rule Book Overrides\n",
    "3) Extracted Designators\n",
    "\n",
    "RULE BOOK OVERRIDES:\n",
    "{hint_str}\n",
    "\n",
    "OUTPUT RULES:\n",
    "- Return ONLY a FLAT JSON object.\n",
    "- Every value must be a STRING.\n",
    "- Do NOT return nested JSON or lists.\n",
    "- Evidence must be copied EXACTLY from paragraph.\n",
    "- If evidence not present, use \"Not Found\".\n",
    "\n",
    "Return JSON exactly:\n",
    "{{\n",
    "  \"Market Segment\": \"\",\n",
    "  \"Market Segment Evidence\": \"\",\n",
    "  \"Market Segment Reason\": \"\",\n",
    "\n",
    "  \"System Type (General)\": \"\",\n",
    "  \"System Type (General) Evidence\": \"\",\n",
    "  \"System Type (General) Reason\": \"\",\n",
    "\n",
    "  \"System Type (Specific)\": \"\",\n",
    "  \"System Type (Specific) Evidence\": \"\",\n",
    "  \"System Type (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Name (General)\": \"\",\n",
    "  \"System Name (General) Evidence\": \"\",\n",
    "  \"System Name (General) Reason\": \"\",\n",
    "\n",
    "  \"System Name (Specific)\": \"\",\n",
    "  \"System Name (Specific) Evidence\": \"\",\n",
    "  \"System Name (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Piloting\": \"\",\n",
    "  \"System Piloting Evidence\": \"\",\n",
    "  \"System Piloting Reason\": \"\",\n",
    "\n",
    "  \"Confidence\": \"High/Medium/Low\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "INPUT PARAGRAPH:\n",
    "{paragraph}\n",
    "\n",
    "DESIGNATORS (regex extracted):\n",
    "{designators if designators else \"None\"}\n",
    "\n",
    "RULE-BASED PILOTING:\n",
    "{piloting_rule}\n",
    "\n",
    "RAG SIMILAR EXAMPLES:\n",
    "{json.dumps(rag_examples, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        result = json.loads(completion.choices[0].message.content)\n",
    "\n",
    "        # Piloting override\n",
    "        result[\"System Piloting\"] = piloting_rule\n",
    "        if not result.get(\"System Piloting Reason\"):\n",
    "            result[\"System Piloting Reason\"] = \"Piloting derived using deterministic rules.\"\n",
    "        if not result.get(\"System Piloting Evidence\"):\n",
    "            result[\"System Piloting Evidence\"] = \"Not Found\"\n",
    "\n",
    "        # Ensure flat\n",
    "        for k, v in result.items():\n",
    "            if isinstance(v, (dict, list)):\n",
    "                result[k] = str(v)\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"Market Segment\": \"\",\n",
    "            \"System Type (General)\": \"\",\n",
    "            \"System Type (Specific)\": \"\",\n",
    "            \"System Name (General)\": \"\",\n",
    "            \"System Name (Specific)\": \"\",\n",
    "            \"System Piloting\": piloting_rule,\n",
    "            \"Market Segment Evidence\": \"Not Found\",\n",
    "            \"System Type (General) Evidence\": \"Not Found\",\n",
    "            \"System Type (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Name (General) Evidence\": \"Not Found\",\n",
    "            \"System Name (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Piloting Evidence\": \"Not Found\",\n",
    "            \"Market Segment Reason\": \"\",\n",
    "            \"System Type (General) Reason\": \"\",\n",
    "            \"System Type (Specific) Reason\": \"\",\n",
    "            \"System Name (General) Reason\": \"\",\n",
    "            \"System Name (Specific) Reason\": \"\",\n",
    "            \"System Piloting Reason\": \"Piloting derived using deterministic rules.\",\n",
    "            \"Confidence\": \"Low\",\n",
    "            \"Error\": str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "# --- AGENT 4: CONTRACT (Supplier Match FIXED ‚úÖ‚úÖ‚úÖ) ---\n",
    "class ContractInfoInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "    contract_date: str = Field(description=\"Signed date.\")\n",
    "\n",
    "@tool(\"contract_extractor\")\n",
    "def contract_extractor(paragraph: str, contract_date: str):\n",
    "    system_instruction = \"\"\"\n",
    "You are a Defense Contract Financial Analyst. Extract data strictly following these SOP rules:\n",
    "\n",
    "1) Supplier Name: Extract exact company name as written in paragraph.\n",
    "2) Program Type: Procurement / Training / MRO/Support / RDT&E / Upgrade / Other Service\n",
    "3) Value Certainty:\n",
    "   - Confirmed: fixed price/obligated stated\n",
    "   - Estimated: ceiling/potential/IDIQ/multi-award\n",
    "4) Quantity: number or Not Applicable\n",
    "5) G2G/B2G:\n",
    "   - G2G only if Foreign Military Sales (FMS)\n",
    "   - else B2G\n",
    "6) Completion Date: only needed for MRO duration calc\n",
    "\n",
    "Return JSON only.\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "Analyze contract:\n",
    "\"{paragraph}\"\n",
    "\n",
    "Signed Date: {contract_date}\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"raw_supplier_name\": \"\",\n",
    "  \"program_type\": \"\",\n",
    "  \"value_million_raw\": \"\",\n",
    "  \"currency_code\": \"\",\n",
    "  \"value_certainty\": \"\",\n",
    "  \"quantity\": \"\",\n",
    "  \"completion_date_text\": \"\",\n",
    "  \"g2g_b2g\": \"\",\n",
    "  \"value_note\": \"\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_instruction},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        return {\"Error\": str(e)}\n",
    "\n",
    "    raw_supplier = str(raw.get(\"raw_supplier_name\", \"\")).strip()\n",
    "\n",
    "    # ‚úÖ Fallback supplier extraction if LLM returns blank\n",
    "    if not raw_supplier:\n",
    "        m = re.search(r\"^(.*?)( is awarded| is being awarded)\", paragraph, flags=re.IGNORECASE)\n",
    "        if m:\n",
    "            raw_supplier = m.group(1).strip()\n",
    "\n",
    "    # ‚úÖ FINAL supplier must come from suppliers.json best match\n",
    "    final_supplier, supplier_match_score = get_best_supplier_match(raw_supplier)\n",
    "\n",
    "    prog_type = raw.get(\"program_type\", \"Unknown\")\n",
    "    mro_months = calculate_mro_months(contract_date, raw.get(\"completion_date_text\"), prog_type)\n",
    "\n",
    "    try:\n",
    "        val_str = str(raw.get(\"value_million_raw\", \"0\")).replace(\",\", \"\").replace(\"$\", \"\")\n",
    "        val_float = float(val_str)\n",
    "        val_formatted = \"{:.3f}\".format(val_float)\n",
    "    except:\n",
    "        val_formatted = \"0.000\"\n",
    "\n",
    "    try:\n",
    "        dt = pd.to_datetime(contract_date)\n",
    "        sign_month = dt.strftime(\"%B\")\n",
    "        sign_year = str(dt.year)\n",
    "    except:\n",
    "        sign_month, sign_year = \"Unknown\", \"Unknown\"\n",
    "\n",
    "    val_note = raw.get(\"value_note\", \"Not Applicable\")\n",
    "    if \"split\" in paragraph.lower() and val_note == \"Not Applicable\":\n",
    "        val_note = \"Split contract; value distribution unclear.\"\n",
    "\n",
    "    return {\n",
    "        # ‚úÖ Final output supplier from JSON\n",
    "        \"Supplier Name\": final_supplier,\n",
    "\n",
    "        # ‚úÖ Debug (optional but VERY useful)\n",
    "        \"Supplier Name Raw (LLM)\": raw_supplier,\n",
    "        \"Supplier Match Score\": round(float(supplier_match_score), 3),\n",
    "\n",
    "        \"Program Type\": prog_type,\n",
    "        \"Expected MRO Contract Duration (Months)\": mro_months,\n",
    "        \"Quantity\": raw.get(\"quantity\", \"Not Applicable\"),\n",
    "        \"Value Certainty\": raw.get(\"value_certainty\", \"Confirmed\"),\n",
    "        \"Value (Million)\": val_formatted,\n",
    "        \"Currency\": raw.get(\"currency_code\", \"USD$\"),\n",
    "        \"Value (USD$ Million)\": val_formatted,\n",
    "        \"Value Note (If Any)\": val_note,\n",
    "        \"G2G/B2G\": raw.get(\"g2g_b2g\", \"B2G\"),\n",
    "        \"Signing Month\": sign_month,\n",
    "        \"Signing Year\": sign_year\n",
    "    }\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ 8. LANGGRAPH PIPELINE\n",
    "# ==============================================================================\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input_text: str\n",
    "    input_date: str\n",
    "    input_url: str\n",
    "    final_data: dict\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "\n",
    "def stage_1_sourcing(state: AgentState):\n",
    "    res = sourcing_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"url\": state[\"input_url\"],\n",
    "        \"date\": state[\"input_date\"]\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "def stage_2_geography(state: AgentState):\n",
    "    res = geography_extractor.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "def stage_3_system(state: AgentState):\n",
    "    res = system_classifier.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "def stage_4_contract(state: AgentState):\n",
    "    res = contract_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"contract_date\": state[\"input_date\"]\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Stage1\", stage_1_sourcing)\n",
    "workflow.add_node(\"Stage2\", stage_2_geography)\n",
    "workflow.add_node(\"Stage3\", stage_3_system)\n",
    "workflow.add_node(\"Stage4\", stage_4_contract)\n",
    "\n",
    "workflow.add_edge(START, \"Stage1\")\n",
    "workflow.add_edge(\"Stage1\", \"Stage2\")\n",
    "workflow.add_edge(\"Stage2\", \"Stage3\")\n",
    "workflow.add_edge(\"Stage3\", \"Stage4\")\n",
    "workflow.add_edge(\"Stage4\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ 9. EXECUTION & OUTPUT FORMAT\n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(f\"üìÇ Loading Input File: {INPUT_EXCEL_PATH}...\")\n",
    "\n",
    "    try:\n",
    "        df_input = pd.read_excel(INPUT_EXCEL_PATH)\n",
    "\n",
    "        required_cols = [\"Source URL\", \"Contract Date\", \"Contract Description\"]\n",
    "        if not all(col in df_input.columns for col in required_cols):\n",
    "            raise ValueError(f\"Excel file must contain columns: {required_cols}\")\n",
    "\n",
    "        print(f\"üöÄ Processing {len(df_input)} rows...\")\n",
    "        results = []\n",
    "\n",
    "        for index, row in df_input.iterrows():\n",
    "            print(f\"   -> Row {index + 1}...\")\n",
    "\n",
    "            desc = str(row[\"Contract Description\"]) if pd.notna(row[\"Contract Description\"]) else \"\"\n",
    "            c_date = str(row[\"Contract Date\"]) if pd.notna(row[\"Contract Date\"]) else str(datetime.date.today())\n",
    "            c_url = str(row[\"Source URL\"]) if pd.notna(row[\"Source URL\"]) else \"\"\n",
    "\n",
    "            initial_state = {\n",
    "                \"input_text\": desc,\n",
    "                \"input_date\": c_date,\n",
    "                \"input_url\": c_url,\n",
    "                \"final_data\": {},\n",
    "                \"messages\": []\n",
    "            }\n",
    "\n",
    "            output_state = app.invoke(initial_state)\n",
    "            results.append(output_state[\"final_data\"])\n",
    "\n",
    "        df_final = pd.DataFrame(results)\n",
    "\n",
    "        FINAL_COLUMNS = [\n",
    "            \"Customer Region\", \"Customer Country\", \"Customer Operator\",\n",
    "            \"Supplier Region\", \"Supplier Country\", \"Domestic Content\",\n",
    "\n",
    "            \"Market Segment\", \"Market Segment Evidence\", \"Market Segment Reason\",\n",
    "            \"System Type (General)\", \"System Type (General) Evidence\", \"System Type (General) Reason\",\n",
    "            \"System Type (Specific)\", \"System Type (Specific) Evidence\", \"System Type (Specific) Reason\",\n",
    "            \"System Name (General)\", \"System Name (General) Evidence\", \"System Name (General) Reason\",\n",
    "            \"System Name (Specific)\", \"System Name (Specific) Evidence\", \"System Name (Specific) Reason\",\n",
    "            \"System Piloting\", \"System Piloting Evidence\", \"System Piloting Reason\",\n",
    "            \"Confidence\",\n",
    "\n",
    "            # ‚úÖ Supplier Debug (optional but recommended)\n",
    "            \"Supplier Name Raw (LLM)\",\n",
    "            \"Supplier Match Score\",\n",
    "\n",
    "            \"Supplier Name\", \"Program Type\", \"Expected MRO Contract Duration (Months)\",\n",
    "            \"Quantity\", \"Value Certainty\", \"Value (Million)\", \"Currency\",\n",
    "            \"Value (USD$ Million)\", \"Value Note (If Any)\", \"G2G/B2G\",\n",
    "            \"Signing Month\", \"Signing Year\",\n",
    "\n",
    "            \"Description of Contract\",\n",
    "            \"Additional Notes (Internal Only)\",\n",
    "            \"Source Link(s)\",\n",
    "            \"Contract Date\",\n",
    "            \"Reported Date (By SGA)\"\n",
    "        ]\n",
    "\n",
    "        df_final = df_final.reindex(columns=FINAL_COLUMNS, fill_value=\"\")\n",
    "        df_final.to_excel(OUTPUT_EXCEL_PATH, index=False)\n",
    "\n",
    "        print(\"\\n‚úÖ Processing Complete!\")\n",
    "        print(f\"üíæ File saved to: {OUTPUT_EXCEL_PATH}\")\n",
    "        print(df_final.head().to_string())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ca495b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import difflib\n",
    "import pickle\n",
    "import datetime\n",
    "from typing import Annotated, TypedDict, List, Dict, Any\n",
    "\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import getpass\n",
    "\n",
    "# LangGraph / LangChain\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "\n",
    "# Excel formatting\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill, Font\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 0) DEBUG LOGGING HELPERS\n",
    "# ==============================================================================\n",
    "\n",
    "def log_block(title: str, content: str):\n",
    "    \"\"\"\n",
    "    Prints a clearly separated block in console logs.\n",
    "\n",
    "    Why this matters:\n",
    "    - You want to validate LLM extraction decisions row-by-row.\n",
    "    - Helps debugging issues in specific stages like System Classification or Split logic.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(title)\n",
    "    print(\"=\" * 100)\n",
    "    print(content)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 1) RAG RETRIEVER (FAISS + Metadata)\n",
    "# ==============================================================================\n",
    "\n",
    "class SystemKBRetriever:\n",
    "    \"\"\"\n",
    "    RAG Retriever for Defense System Classification.\n",
    "\n",
    "    Purpose:\n",
    "    - Loads FAISS vector index (system_kb.faiss)\n",
    "    - Loads metadata rows (system_kb_meta.pkl)\n",
    "    - Retrieves top-k similar historical examples\n",
    "      using semantic embeddings over \"Description of Contract\".\n",
    "\n",
    "    Why this improves accuracy:\n",
    "    - Your taxonomy-based system classification becomes consistent\n",
    "      because the model sees \"known-good labeled examples\" from your excel KB.\n",
    "\n",
    "    Output:\n",
    "    retrieve(query_text) returns:\n",
    "      [\n",
    "        {\"score\": float, \"meta\": {all KB columns}},\n",
    "        ...\n",
    "      ]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kb_dir: str, embed_model: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self.kb_dir = kb_dir\n",
    "        self.embed_model = embed_model\n",
    "\n",
    "        index_path = os.path.join(kb_dir, \"system_kb.faiss\")\n",
    "        meta_path = os.path.join(kb_dir, \"system_kb_meta.pkl\")\n",
    "\n",
    "        if not os.path.exists(index_path) or not os.path.exists(meta_path):\n",
    "            raise FileNotFoundError(\n",
    "                f\"‚ùå KB files not found in: {kb_dir}\\n\"\n",
    "                f\"Expected:\\n- {index_path}\\n- {meta_path}\\n\\n\"\n",
    "                f\"Build the KB first using your KB builder script.\"\n",
    "            )\n",
    "\n",
    "        print(f\"‚úÖ Loading FAISS Index: {index_path}\")\n",
    "        self.index = faiss.read_index(index_path)\n",
    "\n",
    "        print(f\"‚úÖ Loading KB Metadata: {meta_path}\")\n",
    "        with open(meta_path, \"rb\") as f:\n",
    "            self.meta = pickle.load(f)\n",
    "\n",
    "        print(f\"‚úÖ KB Loaded rows: {len(self.meta)}\")\n",
    "\n",
    "        self.embedder = None\n",
    "\n",
    "    def _lazy_load_embedder(self):\n",
    "        \"\"\"\n",
    "        Lazy-load the embedding model only when needed.\n",
    "\n",
    "        Why:\n",
    "        - Faster pipeline startup\n",
    "        - Avoids memory overhead until the first retrieval call\n",
    "        \"\"\"\n",
    "        if self.embedder is None:\n",
    "            from sentence_transformers import SentenceTransformer\n",
    "            self.embedder = SentenceTransformer(self.embed_model)\n",
    "\n",
    "    def retrieve(self, query_text: str, top_k: int = 3):\n",
    "        \"\"\"\n",
    "        Retrieves top-k semantic matches from the KB.\n",
    "\n",
    "        Parameters:\n",
    "        - query_text: input paragraph\n",
    "        - top_k: number of examples\n",
    "\n",
    "        Returns:\n",
    "        - List of dicts with score + metadata row.\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "\n",
    "        query_text = str(query_text).strip()\n",
    "        if not query_text:\n",
    "            return []\n",
    "\n",
    "        self._lazy_load_embedder()\n",
    "\n",
    "        q_emb = self.embedder.encode([query_text], normalize_embeddings=True).astype(\"float32\")\n",
    "        scores, idxs = self.index.search(q_emb, top_k)\n",
    "\n",
    "        results = []\n",
    "        for score, idx in zip(scores[0], idxs[0]):\n",
    "            if idx < 0:\n",
    "                continue\n",
    "            results.append({\"score\": float(score), \"meta\": self.meta[idx]})\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2) CONFIGURATION & FILE PATHS\n",
    "# ==============================================================================\n",
    "\n",
    "TAXONOMY_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\taxonomy.json\"\n",
    "SUPPLIERS_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\suppliers.json\"\n",
    "INPUT_EXCEL_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\data\\source_file.xlsx\"\n",
    "OUTPUT_EXCEL_PATH = \"Processed_Defense_Data.xlsx\"\n",
    "\n",
    "RAG_KB_DIR = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\system_kb_store\"\n",
    "\n",
    "\n",
    "# Setup API key once\n",
    "if \"LLMFOUNDRY_TOKEN\" not in os.environ:\n",
    "    os.environ[\"LLMFOUNDRY_TOKEN\"] = getpass.getpass(\"Enter the LLM Foundry API Key: \")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=f'{os.environ.get(\"LLMFOUNDRY_TOKEN\")}:my-test-project',\n",
    "    base_url=\"https://llmfoundry.straive.com/openai/v1/\",\n",
    ")\n",
    "\n",
    "retriever = SystemKBRetriever(kb_dir=RAG_KB_DIR)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3) LOAD JSON HELPERS\n",
    "# ==============================================================================\n",
    "\n",
    "def load_json_file(filename, default_value):\n",
    "    \"\"\"\n",
    "    Loads a JSON file safely.\n",
    "\n",
    "    Why:\n",
    "    - Your taxonomy and supplier list must load reliably\n",
    "    - Prevents pipeline crash if the file is missing\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            print(f\"‚úÖ Loaded: {filename}\")\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Warning: Could not load {filename} ({e}). Using default.\")\n",
    "        return default_value\n",
    "\n",
    "\n",
    "raw_taxonomy = load_json_file(TAXONOMY_PATH, {})\n",
    "TAXONOMY_STR = json.dumps(raw_taxonomy, separators=(\",\", \":\"))\n",
    "\n",
    "SUPPLIER_LIST = load_json_file(SUPPLIERS_PATH, [\n",
    "    \"Dell Inc\", \"Boeing\", \"Lockheed Martin\", \"Raytheon Technologies\",\n",
    "    \"Northrop Grumman\", \"L3Harris\", \"BAE Systems\", \"General Dynamics\"\n",
    "])\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4) RULE BOOK + GEOGRAPHY\n",
    "# ==============================================================================\n",
    "\n",
    "RULE_BOOK = {\n",
    "    \"defensive_countermeasures\": {\n",
    "        \"triggers\": [\"flare\", \"chaff\", \"countermeasure\", \"decoy\", \"mju-\", \"ale-\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Defensive Systems', Specific: 'Defensive Aid Suite'\"\n",
    "    },\n",
    "    \"radars_and_sensors\": {\n",
    "        \"triggers\": [\"radar\", \"sonar\", \"sensor\", \"an/apy\", \"an/tpy\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Sensors'\"\n",
    "    },\n",
    "    \"ammunition\": {\n",
    "        \"triggers\": [\"cartridge\", \"round\", \"projectile\", \" 5.56\", \" 7.62\", \"ammo\"],\n",
    "        \"guidance\": \"Market Segment: 'Weapon Systems', System Type (General): 'Ammunition'\"\n",
    "    }\n",
    "}\n",
    "\n",
    "GEOGRAPHY_MAPPING = {\n",
    "    \"North America\": [\"USA\", \"United States\", \"US\", \"United States of America\", \"Canada\", \"America\"],\n",
    "    \"Europe\": [\"UK\", \"United Kingdom\", \"Ukraine\", \"Germany\", \"France\", \"Italy\", \"Spain\", \"Poland\", \"Netherlands\",\n",
    "               \"Norway\", \"Sweden\", \"Finland\", \"Denmark\", \"Belgium\"],\n",
    "    \"Asia-Pacific\": [\"Australia\", \"Japan\", \"South Korea\", \"Taiwan\", \"India\", \"Singapore\", \"New Zealand\"],\n",
    "    \"Middle East and North Africa\": [\"Israel\", \"Saudi Arabia\", \"UAE\", \"United Arab Emirates\", \"Egypt\", \"Qatar\", \"Kuwait\", \"Iraq\"],\n",
    "    \"International Organisations\": [\"NATO\", \"EU\", \"IFU\", \"UN\", \"NSPA\"]\n",
    "}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 5) BASE HELPERS (Supplier + Dates + Region + Designators)\n",
    "# ==============================================================================\n",
    "\n",
    "def get_best_supplier_match(extracted_name: str):\n",
    "    \"\"\"\n",
    "    Supplier standardization function.\n",
    "\n",
    "    Steps:\n",
    "    1) Exact match with suppliers.json\n",
    "    2) Fuzzy match (difflib) to find best candidate\n",
    "    3) If no match, return extracted text\n",
    "\n",
    "    Goal:\n",
    "    - Ensure supplier name output matches \"standard supplier taxonomy\"\n",
    "      used by your client.\n",
    "    \"\"\"\n",
    "    if not extracted_name or str(extracted_name).strip().lower() in [\"unknown\", \"n/a\", \"not applicable\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    clean_name = str(extracted_name).strip()\n",
    "\n",
    "    supplier_map = {s.lower(): s for s in SUPPLIER_LIST}\n",
    "    if clean_name.lower() in supplier_map:\n",
    "        return supplier_map[clean_name.lower()]\n",
    "\n",
    "    matches = difflib.get_close_matches(clean_name, SUPPLIER_LIST, n=1, cutoff=0.6)\n",
    "    return matches[0] if matches else clean_name\n",
    "\n",
    "\n",
    "def calculate_mro_months(start_date_str, end_date_text, program_type):\n",
    "    \"\"\"\n",
    "    Calculates MRO duration in months.\n",
    "\n",
    "    Rule:\n",
    "    - ONLY valid if program_type == \"MRO/Support\"\n",
    "    \"\"\"\n",
    "    if program_type != \"MRO/Support\":\n",
    "        return \"Not Applicable\"\n",
    "    try:\n",
    "        if not start_date_str or not end_date_text:\n",
    "            return \"Not Applicable\"\n",
    "\n",
    "        start = pd.to_datetime(start_date_str, dayfirst=True)\n",
    "        end = parser.parse(str(end_date_text), fuzzy=True)\n",
    "\n",
    "        diff = relativedelta(end, start)\n",
    "        total_months = diff.years * 12 + diff.months\n",
    "        return str(max(0, int(total_months)))\n",
    "    except:\n",
    "        return \"Not Applicable\"\n",
    "\n",
    "\n",
    "def get_region_for_country(country_name):\n",
    "    \"\"\"\n",
    "    Maps country name -> region string.\n",
    "    Uses GEOGRAPHY_MAPPING.\n",
    "    \"\"\"\n",
    "    if not country_name or str(country_name).strip().lower() in [\"unknown\", \"n/a\", \"not applicable\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    clean = str(country_name).strip().lower()\n",
    "\n",
    "    if clean in [\"us\", \"usa\", \"u.s.\", \"united states\", \"united states of america\"]:\n",
    "        return \"North America\"\n",
    "    if clean in [\"uk\", \"u.k.\", \"britain\", \"great britain\"]:\n",
    "        return \"Europe\"\n",
    "\n",
    "    for region, countries in GEOGRAPHY_MAPPING.items():\n",
    "        if any(c.lower() == clean for c in countries):\n",
    "            return region\n",
    "\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "DESIGNATOR_PATTERNS = [\n",
    "    r\"\\bDDG[-\\s]?\\d+\\b\", r\"\\bCVN[-\\s]?\\d+\\b\", r\"\\bSSN[-\\s]?\\d+\\b\",\n",
    "    r\"\\bLCS[-\\s]?\\d+\\b\", r\"\\bLPD[-\\s]?\\d+\\b\", r\"\\bLHA[-\\s]?\\d+\\b\", r\"\\bLHD[-\\s]?\\d+\\b\",\n",
    "    r\"\\bF-\\d+\\b\", r\"\\bB-\\d+\\b\", r\"\\bC-\\d+\\b\", r\"\\bA-\\d+\\b\",\n",
    "    r\"\\bMQ-\\d+\\b\", r\"\\bRQ-\\d+\\b\",\n",
    "    r\"\\bAN\\/[A-Z0-9\\-]+\\b\",\n",
    "    r\"\\b(AIM|AGM|SM|RIM|MIM)-\\d+\\b\",\n",
    "]\n",
    "\n",
    "def extract_designators(text: str):\n",
    "    \"\"\"\n",
    "    Extracts common defense platform designators from paragraph.\n",
    "\n",
    "    Examples:\n",
    "    - DDG-51, CVN-78\n",
    "    - MQ-9, RQ-4\n",
    "    - AIM-9X\n",
    "    - AN/APY-10\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    found = []\n",
    "    for pat in DESIGNATOR_PATTERNS:\n",
    "        found.extend(re.findall(pat, text, flags=re.IGNORECASE))\n",
    "    cleaned = []\n",
    "    for f in found:\n",
    "        cleaned.append(f.upper().replace(\" \", \"\").replace(\"--\", \"-\"))\n",
    "    final = []\n",
    "    seen = set()\n",
    "    for x in cleaned:\n",
    "        if x not in seen:\n",
    "            final.append(x)\n",
    "            seen.add(x)\n",
    "    return final\n",
    "\n",
    "\n",
    "def detect_piloting_rule_based(text: str, designators: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Deterministic piloting classification to reduce model errors.\n",
    "\n",
    "    Output:\n",
    "    - \"Crewed\"\n",
    "    - \"Uncrewed\"\n",
    "    - \"Not Applicable\"\n",
    "    \"\"\"\n",
    "    t = str(text).lower()\n",
    "\n",
    "    if any(d.startswith((\"MQ-\", \"RQ-\")) for d in designators):\n",
    "        return \"Uncrewed\"\n",
    "    if any(k in t for k in [\"unmanned\", \"uav\", \"drone\", \"autonomous\"]):\n",
    "        return \"Uncrewed\"\n",
    "\n",
    "    if any(d.startswith((\"DDG\", \"CVN\", \"SSN\", \"LCS\", \"LPD\", \"LHA\", \"LHD\")) for d in designators):\n",
    "        return \"Crewed\"\n",
    "    if \"uss \" in t:\n",
    "        return \"Crewed\"\n",
    "\n",
    "    return \"Not Applicable\"\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 6) ENHANCED SPLIT ENGINE (Multi-operator / Multi-country / Multi-supplier / Multi-value)\n",
    "# ==============================================================================\n",
    "\n",
    "def parse_operator_quantity_allocations(paragraph: str):\n",
    "    \"\"\"\n",
    "    Detects quantity allocations by operator.\n",
    "\n",
    "    Example patterns:\n",
    "      - \"212 for the Navy\"\n",
    "      - \"187 for the Air Force\"\n",
    "      - \"84 for Foreign Military Sales (FMS) customers\"\n",
    "\n",
    "    Output:\n",
    "      [\n",
    "        {\"operator\": \"Navy\", \"quantity\": \"212\", \"g2g_b2g\": \"B2G\"},\n",
    "        {\"operator\": \"Foreign Assistance\", \"quantity\": \"84\", \"g2g_b2g\": \"G2G\"}\n",
    "      ]\n",
    "    \"\"\"\n",
    "    text = str(paragraph)\n",
    "    allocations = []\n",
    "\n",
    "    pattern = r\"(\\d+)\\s+for\\s+the\\s+(Navy|Air Force|Army|Marine Corps)\"\n",
    "    matches = re.findall(pattern, text, flags=re.IGNORECASE)\n",
    "    for qty, op in matches:\n",
    "        allocations.append({\"operator\": op.title(), \"quantity\": qty, \"g2g_b2g\": \"B2G\"})\n",
    "\n",
    "    fms_pattern = r\"(\\d+)\\s+for\\s+(?:Foreign Military Sales\\s*\\(FMS\\)\\s*customers|FMS\\s*customers|a\\s*FMS\\s*customer|FMS)\"\n",
    "    fms_matches = re.findall(fms_pattern, text, flags=re.IGNORECASE)\n",
    "    for qty in fms_matches:\n",
    "        allocations.append({\"operator\": \"Foreign Assistance\", \"quantity\": qty, \"g2g_b2g\": \"G2G\"})\n",
    "\n",
    "    unique = []\n",
    "    seen = set()\n",
    "    for a in allocations:\n",
    "        key = (a[\"operator\"], a[\"quantity\"], a[\"g2g_b2g\"])\n",
    "        if key not in seen:\n",
    "            unique.append(a)\n",
    "            seen.add(key)\n",
    "\n",
    "    return unique\n",
    "\n",
    "\n",
    "def parse_fms_countries(paragraph: str):\n",
    "    \"\"\"\n",
    "    Extracts FMS customer country list.\n",
    "\n",
    "    Looks for:\n",
    "      'governments of Australia, Bahrain, Belgium...'\n",
    "\n",
    "    Output: [\"Australia\", \"Bahrain\", ...]\n",
    "    \"\"\"\n",
    "    text = str(paragraph)\n",
    "\n",
    "    m = re.search(\n",
    "        r\"governments of (.+?)(?:\\.\\s| Work will be performed| Fiscal| This contract|$)\",\n",
    "        text,\n",
    "        flags=re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "    if not m:\n",
    "        return []\n",
    "\n",
    "    block = m.group(1)\n",
    "    raw = re.split(r\",|\\band\\b\", block)\n",
    "\n",
    "    countries = []\n",
    "    for c in raw:\n",
    "        c = c.strip()\n",
    "        if 2 < len(c) <= 40:\n",
    "            countries.append(c)\n",
    "\n",
    "    final = []\n",
    "    seen = set()\n",
    "    for c in countries:\n",
    "        if c.lower() not in seen:\n",
    "            final.append(c)\n",
    "            seen.add(c.lower())\n",
    "\n",
    "    return final\n",
    "\n",
    "\n",
    "def parse_multiple_suppliers(paragraph: str):\n",
    "    \"\"\"\n",
    "    Attempts to detect multi-supplier contract statements.\n",
    "\n",
    "    Examples:\n",
    "    - \"Lockheed Martin and Raytheon were awarded...\"\n",
    "    - \"Boeing, Northrop Grumman, and General Dynamics...\"\n",
    "    - \"multiple awardees include...\"\n",
    "\n",
    "    Output:\n",
    "      [\"Lockheed Martin\", \"Raytheon\"]\n",
    "    \"\"\"\n",
    "    text = str(paragraph)\n",
    "    lower = text.lower()\n",
    "\n",
    "    if \" and \" not in lower and \",\" not in lower:\n",
    "        return []\n",
    "\n",
    "    candidates = []\n",
    "    for supplier in SUPPLIER_LIST:\n",
    "        if supplier.lower() in lower:\n",
    "            candidates.append(supplier)\n",
    "\n",
    "    # If multiple suppliers found ‚Üí split required\n",
    "    candidates = list(dict.fromkeys(candidates))\n",
    "    return candidates if len(candidates) >= 2 else []\n",
    "\n",
    "\n",
    "def parse_multiple_values(paragraph: str):\n",
    "    \"\"\"\n",
    "    Detects multiple financial values in paragraph.\n",
    "\n",
    "    Examples:\n",
    "    - \"$328,156,454\"\n",
    "    - \"ceiling value of $500 million\"\n",
    "    - \"base value $20 million and option value $10 million\"\n",
    "\n",
    "    Output:\n",
    "      [\"328,156,454\", \"500\", ...] (raw strings)\n",
    "    \"\"\"\n",
    "    text = str(paragraph)\n",
    "\n",
    "    # $328,156,454\n",
    "    money_pattern = r\"\\$([\\d,]+(?:\\.\\d+)?)\"\n",
    "    vals = re.findall(money_pattern, text)\n",
    "\n",
    "    # remove duplicates\n",
    "    vals = list(dict.fromkeys(vals))\n",
    "    return vals\n",
    "\n",
    "\n",
    "def parse_share_percentages(paragraph: str):\n",
    "    \"\"\"\n",
    "    Detects share splits like:\n",
    "      '60% for Company A and 40% for Company B'\n",
    "\n",
    "    Output:\n",
    "      [\n",
    "        {\"supplier\": \"Company A\", \"percentage\": \"60\"},\n",
    "        {\"supplier\": \"Company B\", \"percentage\": \"40\"}\n",
    "      ]\n",
    "    \"\"\"\n",
    "    text = str(paragraph)\n",
    "    result = []\n",
    "\n",
    "    percent_pattern = r\"(\\d+)\\s?%\\s+(?:for\\s+)?([A-Z][A-Za-z0-9&\\-\\.\\s]+)\"\n",
    "    matches = re.findall(percent_pattern, text)\n",
    "\n",
    "    for pct, name in matches:\n",
    "        name = name.strip()\n",
    "        # Try to best-match supplier name list\n",
    "        supplier_std = get_best_supplier_match(name)\n",
    "        result.append({\"supplier\": supplier_std, \"percentage\": pct})\n",
    "\n",
    "    # keep only valid multi splits\n",
    "    if len(result) >= 2:\n",
    "        return result\n",
    "    return []\n",
    "\n",
    "\n",
    "def detect_multi_country_presence(paragraph: str):\n",
    "    \"\"\"\n",
    "    Lightweight country scan from mapping lists to detect multi-country mention.\n",
    "    \"\"\"\n",
    "    text = str(paragraph).lower()\n",
    "    countries_found = set()\n",
    "\n",
    "    for region, countries in GEOGRAPHY_MAPPING.items():\n",
    "        for c in countries:\n",
    "            if c.lower() in text:\n",
    "                countries_found.add(c)\n",
    "\n",
    "    return list(countries_found)\n",
    "\n",
    "\n",
    "def split_rows_engine(base_row: dict, paragraph: str):\n",
    "    \"\"\"\n",
    "    MASTER SPLIT ENGINE.\n",
    "\n",
    "    Goal:\n",
    "    - Takes one extracted row (base_row)\n",
    "    - Produces 1..N output rows depending on split conditions\n",
    "\n",
    "    Split triggers supported:\n",
    "    1) Operator allocation splits (Navy/Air Force/FMS)\n",
    "    2) Multi-country FMS customer lists\n",
    "    3) Multi supplier mentions\n",
    "    4) Multi values inside same paragraph\n",
    "    5) Percent share splits\n",
    "    6) Multi-country region scan\n",
    "\n",
    "    Important:\n",
    "    - Only split-driving columns should change.\n",
    "    - Shared columns remain consistent.\n",
    "    \"\"\"\n",
    "    paragraph = str(paragraph)\n",
    "\n",
    "    allocations = parse_operator_quantity_allocations(paragraph)\n",
    "    fms_countries = parse_fms_countries(paragraph)\n",
    "    multi_suppliers = parse_multiple_suppliers(paragraph)\n",
    "    multi_values = parse_multiple_values(paragraph)\n",
    "    share_splits = parse_share_percentages(paragraph)\n",
    "    multi_countries = detect_multi_country_presence(paragraph)\n",
    "\n",
    "    split_reasons = []\n",
    "\n",
    "    if allocations:\n",
    "        split_reasons.append(\"Multi-operator allocation found\")\n",
    "    if fms_countries:\n",
    "        split_reasons.append(\"FMS multi-country list found\")\n",
    "    if multi_suppliers:\n",
    "        split_reasons.append(\"Multi-supplier mention found\")\n",
    "    if len(multi_values) >= 2:\n",
    "        split_reasons.append(\"Multiple financial values found\")\n",
    "    if share_splits:\n",
    "        split_reasons.append(\"Percentage share split found\")\n",
    "    if len(multi_countries) >= 2:\n",
    "        split_reasons.append(\"Multiple countries detected in text\")\n",
    "\n",
    "    if not split_reasons:\n",
    "        base_row[\"Split Flag\"] = \"No\"\n",
    "        base_row[\"Split Reason\"] = \"No split condition found\"\n",
    "        return [base_row]\n",
    "\n",
    "    # Start with one base row\n",
    "    rows = [base_row.copy()]\n",
    "    base_reason = \" | \".join(split_reasons)\n",
    "\n",
    "    # 1) Multi supplier split\n",
    "    if multi_suppliers:\n",
    "        new_rows = []\n",
    "        for r in rows:\n",
    "            for s in multi_suppliers:\n",
    "                rr = r.copy()\n",
    "                rr[\"Supplier Name\"] = s\n",
    "                rr[\"Split Flag\"] = \"Yes\"\n",
    "                rr[\"Split Reason\"] = f\"{base_reason} (Supplier split)\"\n",
    "                new_rows.append(rr)\n",
    "        rows = new_rows\n",
    "\n",
    "    # 2) Operator split\n",
    "    if allocations:\n",
    "        new_rows = []\n",
    "        for r in rows:\n",
    "            for alloc in allocations:\n",
    "                rr = r.copy()\n",
    "                rr[\"Customer Operator\"] = alloc[\"operator\"]\n",
    "                rr[\"Quantity\"] = alloc[\"quantity\"]\n",
    "                rr[\"G2G/B2G\"] = alloc[\"g2g_b2g\"]\n",
    "                rr[\"Split Flag\"] = \"Yes\"\n",
    "                rr[\"Split Reason\"] = f\"{base_reason} (Operator/Quantity split)\"\n",
    "                new_rows.append(rr)\n",
    "        rows = new_rows\n",
    "\n",
    "    # 3) Share split ‚Üí can modify Value Note\n",
    "    if share_splits:\n",
    "        new_rows = []\n",
    "        for r in rows:\n",
    "            for sh in share_splits:\n",
    "                rr = r.copy()\n",
    "                rr[\"Supplier Name\"] = sh[\"supplier\"]\n",
    "                rr[\"Value Note (If Any)\"] = f\"Share split detected: {sh['percentage']}%\"\n",
    "                rr[\"Split Flag\"] = \"Yes\"\n",
    "                rr[\"Split Reason\"] = f\"{base_reason} (Share % split)\"\n",
    "                new_rows.append(rr)\n",
    "        rows = new_rows\n",
    "\n",
    "    # 4) Multi financial values split (optional)\n",
    "    # Here we do NOT override your Value (Million) because that comes from contract_extractor,\n",
    "    # but we store in Value Note as cross-reference.\n",
    "    if len(multi_values) >= 2:\n",
    "        for r in rows:\n",
    "            note = r.get(\"Value Note (If Any)\", \"Not Applicable\")\n",
    "            r[\"Value Note (If Any)\"] = f\"{note} | Multiple values detected: {multi_values[:5]}\"\n",
    "\n",
    "    # 5) FMS country split applied ONLY when G2G rows exist\n",
    "    if fms_countries:\n",
    "        final_rows = []\n",
    "        for r in rows:\n",
    "            if r.get(\"G2G/B2G\") == \"G2G\":\n",
    "                for c in fms_countries:\n",
    "                    rr = r.copy()\n",
    "                    rr[\"Customer Country\"] = c\n",
    "                    rr[\"Customer Region\"] = get_region_for_country(c)\n",
    "                    rr[\"Split Flag\"] = \"Yes\"\n",
    "                    rr[\"Split Reason\"] = f\"{base_reason} (FMS country split)\"\n",
    "                    final_rows.append(rr)\n",
    "            else:\n",
    "                final_rows.append(r)\n",
    "        rows = final_rows\n",
    "\n",
    "    # Always ensure flags exist\n",
    "    for r in rows:\n",
    "        r.setdefault(\"Split Flag\", \"Yes\")\n",
    "        r.setdefault(\"Split Reason\", base_reason)\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 7) AGENTS / TOOLS\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Stage 1: Sourcing ---\n",
    "class SourcingInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    url: str = Field(description=\"Source URL of the contract announcement/news.\")\n",
    "    date: str = Field(description=\"Contract date in Excel (string).\")\n",
    "\n",
    "@tool(\"sourcing_extractor\")\n",
    "def sourcing_extractor(paragraph: str, url: str, date: str):\n",
    "    \"\"\"\n",
    "    Stage 1: SOURCING EXTRACTOR\n",
    "\n",
    "    Goal:\n",
    "    - Build the base skeleton row containing:\n",
    "      - Description of Contract (raw paragraph)\n",
    "      - Source Link(s)\n",
    "      - Contract Date\n",
    "      - Reported Date (By SGA)\n",
    "      - Additional Notes (Internal Only)\n",
    "\n",
    "    Why needed:\n",
    "    - These columns remain SAME even if contract splits into multiple rows.\n",
    "    \"\"\"\n",
    "    reported_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    notes = \"Standard extraction.\"\n",
    "    if \"modification\" in str(paragraph).lower():\n",
    "        notes = \"Contract Modification.\"\n",
    "    if \"split\" in str(paragraph).lower():\n",
    "        notes = \"Split award detected.\"\n",
    "\n",
    "    return {\n",
    "        \"Description of Contract\": paragraph,\n",
    "        \"Additional Notes (Internal Only)\": notes,\n",
    "        \"Source Link(s)\": url,\n",
    "        \"Contract Date\": date,\n",
    "        \"Reported Date (By SGA)\": reported_date\n",
    "    }\n",
    "\n",
    "\n",
    "# --- Stage 2: Geography ---\n",
    "class GeographyInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "\n",
    "@tool(\"geography_extractor\")\n",
    "def geography_extractor(paragraph: str):\n",
    "    \"\"\"\n",
    "    Stage 2: GEOGRAPHY EXTRACTOR\n",
    "\n",
    "    Goal:\n",
    "    - Identify:\n",
    "      - Customer Country\n",
    "      - Customer Operator\n",
    "      - Supplier Country\n",
    "    - Derive:\n",
    "      - Customer Region\n",
    "      - Supplier Region\n",
    "      - Domestic Content (Indigenous vs Imported)\n",
    "\n",
    "    Why needed:\n",
    "    - Geography can be split-driving when multiple customer countries exist.\n",
    "    \"\"\"\n",
    "    sys_prompt = \"\"\"\n",
    "Extract: Customer Country, Supplier Country, Customer Operator.\n",
    "Logic: If 'Navy awarded...', operator is Navy.\n",
    "Return JSON:\n",
    "{\n",
    "  \"Customer Country\": \"...\",\n",
    "  \"Customer Operator\": \"...\",\n",
    "  \"Supplier Country\": \"...\"\n",
    "}\n",
    "\"\"\"\n",
    "    log_block(\"HUMAN MESSAGE (Stage2 - Geography)\", paragraph)\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"system\", \"content\": sys_prompt},\n",
    "                      {\"role\": \"user\", \"content\": paragraph}],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "        log_block(\"AI RESPONSE (Stage2 - Geography)\", json.dumps(raw, indent=2))\n",
    "    except Exception as e:\n",
    "        raw = {}\n",
    "        log_block(\"AI ERROR (Stage2 - Geography)\", str(e))\n",
    "\n",
    "    cust = raw.get(\"Customer Country\", \"Unknown\")\n",
    "    supp = raw.get(\"Supplier Country\", \"Unknown\")\n",
    "\n",
    "    domestic = \"Indigenous\" if str(cust).lower() == str(supp).lower() else \"Imported\"\n",
    "\n",
    "    return {\n",
    "        \"Customer Region\": get_region_for_country(cust),\n",
    "        \"Customer Country\": cust,\n",
    "        \"Customer Operator\": raw.get(\"Customer Operator\", \"Unknown\"),\n",
    "        \"Supplier Region\": get_region_for_country(supp),\n",
    "        \"Supplier Country\": supp,\n",
    "        \"Domestic Content\": domestic\n",
    "    }\n",
    "\n",
    "\n",
    "# --- Stage 3: System Classification (RAG + Evidence + Reason) ---\n",
    "class SystemInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "\n",
    "@tool(\"system_classifier\")\n",
    "def system_classifier(paragraph: str):\n",
    "    \"\"\"\n",
    "    Stage 3: SYSTEM CLASSIFIER (RAG-ENHANCED)\n",
    "\n",
    "    Goal:\n",
    "    - Extract system-level labels using:\n",
    "      ‚úÖ Taxonomy reference\n",
    "      ‚úÖ Rule book triggers\n",
    "      ‚úÖ RAG similar examples\n",
    "      ‚úÖ Deterministic piloting override\n",
    "\n",
    "    Output:\n",
    "    - Adds Evidence + Reason for:\n",
    "      - Market Segment\n",
    "      - System Type (General)\n",
    "      - System Type (Specific)\n",
    "      - System Name (General)\n",
    "      - System Name (Specific)\n",
    "      - System Piloting\n",
    "\n",
    "    Why this matters:\n",
    "    - Your biggest accuracy issues were in:\n",
    "      Market, System Type, System Name, System Piloting\n",
    "    - RAG makes results consistent with your labeled history dataset\n",
    "    \"\"\"\n",
    "    paragraph = str(paragraph).strip()\n",
    "    if not paragraph:\n",
    "        return {}\n",
    "\n",
    "    log_block(\"HUMAN MESSAGE (Stage3 - System)\", paragraph)\n",
    "\n",
    "    lower_text = paragraph.lower()\n",
    "    hints = [\n",
    "        f\"RULE: {v['guidance']}\"\n",
    "        for _, v in RULE_BOOK.items()\n",
    "        if any(t in lower_text for t in v[\"triggers\"])\n",
    "    ]\n",
    "    hint_str = \"\\n\".join(hints) if hints else \"No special override rules triggered.\"\n",
    "\n",
    "    designators = extract_designators(paragraph)\n",
    "    piloting_rule = detect_piloting_rule_based(paragraph, designators)\n",
    "\n",
    "    rag_hits = retriever.retrieve(paragraph, top_k=3)\n",
    "    rag_examples = []\n",
    "    for hit in rag_hits:\n",
    "        meta = hit[\"meta\"]\n",
    "        rag_examples.append({\n",
    "            \"score\": round(hit[\"score\"], 4),\n",
    "            \"Market Segment\": meta.get(\"Market Segment\", \"\"),\n",
    "            \"System Type (General)\": meta.get(\"System Type (General)\", \"\"),\n",
    "            \"System Type (Specific)\": meta.get(\"System Type (Specific)\", \"\"),\n",
    "            \"System Name (General)\": meta.get(\"System Name (General)\", \"\"),\n",
    "            \"System Name (Specific)\": meta.get(\"System Name (Specific)\", \"\"),\n",
    "            \"System Piloting\": meta.get(\"System Piloting\", \"\"),\n",
    "            \"Snippet\": meta.get(\"Description of Contract\", \"\")[:220] + \"...\"\n",
    "        })\n",
    "\n",
    "    sys_prompt = f\"\"\"\n",
    "You are a Senior Defense System Classification Analyst.\n",
    "\n",
    "REFERENCE TAXONOMY:\n",
    "{TAXONOMY_STR}\n",
    "\n",
    "RULE BOOK OVERRIDES:\n",
    "{hint_str}\n",
    "\n",
    "OUTPUT RULES:\n",
    "- Return ONLY a FLAT JSON object.\n",
    "- Every value must be a STRING.\n",
    "- Do NOT return nested objects or lists.\n",
    "- Evidence must be copied EXACTLY from paragraph text.\n",
    "- If evidence not present, output \"Not Found\".\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"Market Segment\": \"\",\n",
    "  \"Market Segment Evidence\": \"\",\n",
    "  \"Market Segment Reason\": \"\",\n",
    "\n",
    "  \"System Type (General)\": \"\",\n",
    "  \"System Type (General) Evidence\": \"\",\n",
    "  \"System Type (General) Reason\": \"\",\n",
    "\n",
    "  \"System Type (Specific)\": \"\",\n",
    "  \"System Type (Specific) Evidence\": \"\",\n",
    "  \"System Type (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Name (General)\": \"\",\n",
    "  \"System Name (General) Evidence\": \"\",\n",
    "  \"System Name (General) Reason\": \"\",\n",
    "\n",
    "  \"System Name (Specific)\": \"\",\n",
    "  \"System Name (Specific) Evidence\": \"\",\n",
    "  \"System Name (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Piloting\": \"\",\n",
    "  \"System Piloting Evidence\": \"\",\n",
    "  \"System Piloting Reason\": \"\",\n",
    "\n",
    "  \"Confidence\": \"High/Medium/Low\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "PARAGRAPH:\n",
    "{paragraph}\n",
    "\n",
    "DESIGNATORS (regex extracted):\n",
    "{designators if designators else \"None\"}\n",
    "\n",
    "RULE BASED PILOTING:\n",
    "{piloting_rule}\n",
    "\n",
    "RAG EXAMPLES:\n",
    "{json.dumps(rag_examples, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"system\", \"content\": sys_prompt},\n",
    "                      {\"role\": \"user\", \"content\": user_prompt}],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        result = json.loads(completion.choices[0].message.content)\n",
    "        log_block(\"AI RESPONSE (Stage3 - System)\", json.dumps(result, indent=2))\n",
    "\n",
    "        # Hard override piloting (best accuracy)\n",
    "        result[\"System Piloting\"] = piloting_rule\n",
    "        result.setdefault(\"System Piloting Evidence\", \"Not Found\")\n",
    "        result.setdefault(\"System Piloting Reason\", \"Derived from deterministic piloting rules.\")\n",
    "\n",
    "        # Ensure flat\n",
    "        for k, v in result.items():\n",
    "            if isinstance(v, (dict, list)):\n",
    "                result[k] = str(v)\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        log_block(\"AI ERROR (Stage3 - System)\", str(e))\n",
    "        return {\n",
    "            \"Market Segment\": \"\",\n",
    "            \"Market Segment Evidence\": \"Not Found\",\n",
    "            \"Market Segment Reason\": \"\",\n",
    "\n",
    "            \"System Type (General)\": \"\",\n",
    "            \"System Type (General) Evidence\": \"Not Found\",\n",
    "            \"System Type (General) Reason\": \"\",\n",
    "\n",
    "            \"System Type (Specific)\": \"\",\n",
    "            \"System Type (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Type (Specific) Reason\": \"\",\n",
    "\n",
    "            \"System Name (General)\": \"\",\n",
    "            \"System Name (General) Evidence\": \"Not Found\",\n",
    "            \"System Name (General) Reason\": \"\",\n",
    "\n",
    "            \"System Name (Specific)\": \"\",\n",
    "            \"System Name (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Name (Specific) Reason\": \"\",\n",
    "\n",
    "            \"System Piloting\": piloting_rule,\n",
    "            \"System Piloting Evidence\": \"Not Found\",\n",
    "            \"System Piloting Reason\": \"Derived from deterministic piloting rules.\",\n",
    "\n",
    "            \"Confidence\": \"Low\",\n",
    "            \"Error\": str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "# --- Stage 4: Contract Extractor ---\n",
    "class ContractInfoInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    contract_date: str = Field(description=\"Contract date as string.\")\n",
    "\n",
    "@tool(\"contract_extractor\")\n",
    "def contract_extractor(paragraph: str, contract_date: str):\n",
    "    \"\"\"\n",
    "    Stage 4: CONTRACT EXTRACTOR\n",
    "\n",
    "    Goal:\n",
    "    - Extract the contract financial + program details:\n",
    "      - Supplier Name (raw)\n",
    "      - Program Type\n",
    "      - Quantity\n",
    "      - Value (Million)\n",
    "      - Currency\n",
    "      - Value Certainty\n",
    "      - G2G/B2G\n",
    "      - Completion Date Text\n",
    "\n",
    "    Critical improvement:\n",
    "    - Supplier Name returned from model is ALWAYS standardized\n",
    "      using suppliers.json fuzzy match.\n",
    "    \"\"\"\n",
    "    system_instruction = \"\"\"\n",
    "You are a Defense Contract Financial Analyst.\n",
    "\n",
    "Rules:\n",
    "1) raw_supplier_name: extract exact supplier from paragraph\n",
    "2) program_type: Procurement/Training/MRO/Support/RDT&E/Upgrade/Other Service\n",
    "3) value_certainty: Confirmed vs Estimated\n",
    "4) quantity: extract numeric units if found else Not Applicable\n",
    "5) g2g_b2g: G2G only if FMS mentioned else B2G\n",
    "6) completion_date_text: for MRO calc only\n",
    "\n",
    "Return JSON only.\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "PARAGRAPH:\n",
    "{paragraph}\n",
    "\n",
    "SIGNED DATE:\n",
    "{contract_date}\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"raw_supplier_name\": \"\",\n",
    "  \"program_type\": \"\",\n",
    "  \"value_million_raw\": \"\",\n",
    "  \"currency_code\": \"\",\n",
    "  \"value_certainty\": \"\",\n",
    "  \"quantity\": \"\",\n",
    "  \"completion_date_text\": \"\",\n",
    "  \"g2g_b2g\": \"\",\n",
    "  \"value_note\": \"\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    log_block(\"HUMAN MESSAGE (Stage4 - Contract)\", paragraph)\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"system\", \"content\": system_instruction},\n",
    "                      {\"role\": \"user\", \"content\": user_prompt}],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "        log_block(\"AI RESPONSE (Stage4 - Contract)\", json.dumps(raw, indent=2))\n",
    "    except Exception as e:\n",
    "        log_block(\"AI ERROR (Stage4 - Contract)\", str(e))\n",
    "        return {\"Error\": str(e)}\n",
    "\n",
    "    final_supplier = get_best_supplier_match(raw.get(\"raw_supplier_name\"))\n",
    "\n",
    "    prog_type = raw.get(\"program_type\", \"Unknown\")\n",
    "    mro_months = calculate_mro_months(contract_date, raw.get(\"completion_date_text\"), prog_type)\n",
    "\n",
    "    try:\n",
    "        val_str = str(raw.get(\"value_million_raw\", \"0\")).replace(\",\", \"\").replace(\"$\", \"\")\n",
    "        val_float = float(val_str)\n",
    "        val_formatted = \"{:.3f}\".format(val_float)\n",
    "    except:\n",
    "        val_formatted = \"0.000\"\n",
    "\n",
    "    try:\n",
    "        dt = pd.to_datetime(contract_date)\n",
    "        sign_month = dt.strftime(\"%B\")\n",
    "        sign_year = str(dt.year)\n",
    "    except:\n",
    "        sign_month, sign_year = \"Unknown\", \"Unknown\"\n",
    "\n",
    "    return {\n",
    "        \"Supplier Name\": final_supplier,\n",
    "        \"Program Type\": prog_type,\n",
    "        \"Expected MRO Contract Duration (Months)\": mro_months,\n",
    "        \"Quantity\": raw.get(\"quantity\", \"Not Applicable\"),\n",
    "        \"Value Certainty\": raw.get(\"value_certainty\", \"Confirmed\"),\n",
    "        \"Value (Million)\": val_formatted,\n",
    "        \"Currency\": raw.get(\"currency_code\", \"USD$\"),\n",
    "        \"Value (USD$ Million)\": val_formatted,\n",
    "        \"Value Note (If Any)\": raw.get(\"value_note\", \"Not Applicable\"),\n",
    "        \"G2G/B2G\": raw.get(\"g2g_b2g\", \"B2G\"),\n",
    "        \"Signing Month\": sign_month,\n",
    "        \"Signing Year\": sign_year\n",
    "    }\n",
    "\n",
    "\n",
    "# --- Stage 5: Split Agent ---\n",
    "class SplitterInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    base_row: dict = Field(description=\"Final extracted row after Stage1-4.\")\n",
    "\n",
    "@tool(\"splitter_agent\")\n",
    "def splitter_agent(paragraph: str, base_row: dict):\n",
    "    \"\"\"\n",
    "    Stage 5: SPLITTER AGENT\n",
    "\n",
    "    Goal:\n",
    "    - Detect whether the extracted row must be split into multiple output rows.\n",
    "    - Uses split_rows_engine() to apply deterministic split logic.\n",
    "    - Ensures the split matches patterns found in your sample_data.\n",
    "\n",
    "    Output:\n",
    "    - Returns {\"rows\": [row1, row2, ...]}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        rows = split_rows_engine(base_row, paragraph)\n",
    "        for r in rows:\n",
    "            r.setdefault(\"Split Flag\", \"No\")\n",
    "            r.setdefault(\"Split Reason\", \"\")\n",
    "        return {\"rows\": rows}\n",
    "    except Exception as e:\n",
    "        base_row[\"Split Flag\"] = \"Error\"\n",
    "        base_row[\"Split Reason\"] = f\"Split failed: {str(e)}\"\n",
    "        return {\"rows\": [base_row]}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 8) LANGGRAPH PIPELINE\n",
    "# ==============================================================================\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    State object passed between LangGraph stages.\n",
    "\n",
    "    Contains:\n",
    "    - Raw inputs (text, date, url)\n",
    "    - Aggregated extraction dict (final_data)\n",
    "    - Final output rows (final_rows) after splitting\n",
    "    \"\"\"\n",
    "    input_text: str\n",
    "    input_date: str\n",
    "    input_url: str\n",
    "    final_data: dict\n",
    "    final_rows: list\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "def stage_1_sourcing(state: AgentState):\n",
    "    \"\"\"\n",
    "    Node Stage1: Runs sourcing_extractor tool and updates final_data.\n",
    "    \"\"\"\n",
    "    res = sourcing_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"url\": state[\"input_url\"],\n",
    "        \"date\": state[\"input_date\"],\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_2_geography(state: AgentState):\n",
    "    \"\"\"\n",
    "    Node Stage2: Extracts geography fields and updates final_data.\n",
    "    \"\"\"\n",
    "    res = geography_extractor.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_3_system(state: AgentState):\n",
    "    \"\"\"\n",
    "    Node Stage3: System classification using RAG + evidence + reason.\n",
    "    \"\"\"\n",
    "    res = system_classifier.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_4_contract(state: AgentState):\n",
    "    \"\"\"\n",
    "    Node Stage4: Extracts supplier/program/financial/quantity.\n",
    "    Supplier name is standardized via suppliers.json fuzzy match.\n",
    "    \"\"\"\n",
    "    res = contract_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"contract_date\": state[\"input_date\"]\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_5_split(state: AgentState):\n",
    "    \"\"\"\n",
    "    Node Stage5: Applies split logic to create 1..N rows based on paragraph.\n",
    "    \"\"\"\n",
    "    res = splitter_agent.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"base_row\": state[\"final_data\"]\n",
    "    })\n",
    "    return {\"final_rows\": res.get(\"rows\", [state[\"final_data\"]])}\n",
    "\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Stage1\", stage_1_sourcing)\n",
    "workflow.add_node(\"Stage2\", stage_2_geography)\n",
    "workflow.add_node(\"Stage3\", stage_3_system)\n",
    "workflow.add_node(\"Stage4\", stage_4_contract)\n",
    "workflow.add_node(\"Stage5\", stage_5_split)\n",
    "\n",
    "workflow.add_edge(START, \"Stage1\")\n",
    "workflow.add_edge(\"Stage1\", \"Stage2\")\n",
    "workflow.add_edge(\"Stage2\", \"Stage3\")\n",
    "workflow.add_edge(\"Stage3\", \"Stage4\")\n",
    "workflow.add_edge(\"Stage4\", \"Stage5\")\n",
    "workflow.add_edge(\"Stage5\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 9) GRAPH VISUALIZATION (OFFLINE SAFE)\n",
    "# ==============================================================================\n",
    "\n",
    "def export_workflow_mermaid(app_obj, out_file=\"workflow.mmd\"):\n",
    "    \"\"\"\n",
    "    Exports Mermaid graph as TEXT locally (no mermaid.ink required).\n",
    "\n",
    "    Why:\n",
    "    - Office laptops often block mermaid.ink API calls\n",
    "    - You still need graph visualization / documentation\n",
    "\n",
    "    Output:\n",
    "    - A workflow.mmd file (Mermaid format)\n",
    "    \"\"\"\n",
    "    mmd = app_obj.get_graph().draw_mermaid()\n",
    "    with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(mmd)\n",
    "    print(f\"‚úÖ Workflow Mermaid saved locally: {out_file}\")\n",
    "    return out_file\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 10) EXCEL HIGHLIGHTING FEATURE\n",
    "# ==============================================================================\n",
    "\n",
    "def highlight_evidence_reason_columns(excel_path: str):\n",
    "    \"\"\"\n",
    "    Highlights Evidence + Reason columns in output Excel.\n",
    "\n",
    "    Evidence Columns:\n",
    "    - colored light yellow\n",
    "    Reason Columns:\n",
    "    - colored light blue\n",
    "\n",
    "    Goal:\n",
    "    - Your team can validate 'why this label was chosen'\n",
    "      without confusion.\n",
    "    \"\"\"\n",
    "    wb = load_workbook(excel_path)\n",
    "    ws = wb.active\n",
    "\n",
    "    header = [cell.value for cell in ws[1]]\n",
    "\n",
    "    evidence_cols = []\n",
    "    reason_cols = []\n",
    "\n",
    "    for idx, col_name in enumerate(header, start=1):\n",
    "        if isinstance(col_name, str) and \"Evidence\" in col_name:\n",
    "            evidence_cols.append(idx)\n",
    "        if isinstance(col_name, str) and \"Reason\" in col_name:\n",
    "            reason_cols.append(idx)\n",
    "\n",
    "    evidence_fill = PatternFill(start_color=\"FFF2CC\", end_color=\"FFF2CC\", fill_type=\"solid\")  # Yellow\n",
    "    reason_fill = PatternFill(start_color=\"D9E1F2\", end_color=\"D9E1F2\", fill_type=\"solid\")    # Blue\n",
    "    header_font = Font(bold=True)\n",
    "\n",
    "    for col_idx in evidence_cols:\n",
    "        ws.cell(row=1, column=col_idx).fill = evidence_fill\n",
    "        ws.cell(row=1, column=col_idx).font = header_font\n",
    "\n",
    "    for col_idx in reason_cols:\n",
    "        ws.cell(row=1, column=col_idx).fill = reason_fill\n",
    "        ws.cell(row=1, column=col_idx).font = header_font\n",
    "\n",
    "    for row in range(2, ws.max_row + 1):\n",
    "        for col_idx in evidence_cols:\n",
    "            ws.cell(row=row, column=col_idx).fill = evidence_fill\n",
    "        for col_idx in reason_cols:\n",
    "            ws.cell(row=row, column=col_idx).fill = reason_fill\n",
    "\n",
    "    wb.save(excel_path)\n",
    "    print(\"‚úÖ Evidence + Reason columns highlighted successfully.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 11) MAIN EXECUTION\n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(f\"\\nüìå Loading Input File: {INPUT_EXCEL_PATH}\")\n",
    "\n",
    "    # Offline safe workflow graph\n",
    "    export_workflow_mermaid(app, out_file=\"workflow.mmd\")\n",
    "\n",
    "    try:\n",
    "        df_input = pd.read_excel(INPUT_EXCEL_PATH)\n",
    "\n",
    "        required_cols = [\"Source URL\", \"Contract Date\", \"Contract Description\"]\n",
    "        if not all(col in df_input.columns for col in required_cols):\n",
    "            raise ValueError(f\"Excel file must contain columns: {required_cols}\")\n",
    "\n",
    "        print(f\"üöÄ Processing {len(df_input)} rows...\")\n",
    "        results = []\n",
    "\n",
    "        for index, row in df_input.iterrows():\n",
    "            print(f\"\\nüîπ Row {index + 1}/{len(df_input)}\")\n",
    "\n",
    "            desc = str(row[\"Contract Description\"]) if pd.notna(row[\"Contract Description\"]) else \"\"\n",
    "            c_date = str(row[\"Contract Date\"]) if pd.notna(row[\"Contract Date\"]) else str(datetime.date.today())\n",
    "            c_url = str(row[\"Source URL\"]) if pd.notna(row[\"Source URL\"]) else \"\"\n",
    "\n",
    "            initial_state = {\n",
    "                \"input_text\": desc,\n",
    "                \"input_date\": c_date,\n",
    "                \"input_url\": c_url,\n",
    "                \"final_data\": {},\n",
    "                \"final_rows\": [],\n",
    "                \"messages\": []\n",
    "            }\n",
    "\n",
    "            output_state = app.invoke(initial_state)\n",
    "\n",
    "            rows = output_state.get(\"final_rows\", [])\n",
    "            if not rows:\n",
    "                rows = [output_state.get(\"final_data\", {})]\n",
    "\n",
    "            results.extend(rows)\n",
    "\n",
    "        df_final = pd.DataFrame(results)\n",
    "\n",
    "        FINAL_COLUMNS = [\n",
    "            \"Customer Region\", \"Customer Country\", \"Customer Operator\",\n",
    "            \"Supplier Region\", \"Supplier Country\", \"Domestic Content\",\n",
    "\n",
    "            \"Split Flag\", \"Split Reason\",\n",
    "\n",
    "            \"Market Segment\", \"Market Segment Evidence\", \"Market Segment Reason\",\n",
    "            \"System Type (General)\", \"System Type (General) Evidence\", \"System Type (General) Reason\",\n",
    "            \"System Type (Specific)\", \"System Type (Specific) Evidence\", \"System Type (Specific) Reason\",\n",
    "            \"System Name (General)\", \"System Name (General) Evidence\", \"System Name (General) Reason\",\n",
    "            \"System Name (Specific)\", \"System Name (Specific) Evidence\", \"System Name (Specific) Reason\",\n",
    "            \"System Piloting\", \"System Piloting Evidence\", \"System Piloting Reason\",\n",
    "            \"Confidence\",\n",
    "\n",
    "            \"Supplier Name\", \"Program Type\", \"Expected MRO Contract Duration (Months)\",\n",
    "            \"Quantity\", \"Value Certainty\", \"Value (Million)\", \"Currency\",\n",
    "            \"Value (USD$ Million)\", \"Value Note (If Any)\", \"G2G/B2G\",\n",
    "            \"Signing Month\", \"Signing Year\",\n",
    "\n",
    "            \"Description of Contract\",\n",
    "            \"Additional Notes (Internal Only)\",\n",
    "            \"Source Link(s)\",\n",
    "            \"Contract Date\",\n",
    "            \"Reported Date (By SGA)\"\n",
    "        ]\n",
    "\n",
    "        df_final = df_final.reindex(columns=FINAL_COLUMNS, fill_value=\"\")\n",
    "        df_final.to_excel(OUTPUT_EXCEL_PATH, index=False)\n",
    "\n",
    "        # Highlight Evidence + Reason\n",
    "        highlight_evidence_reason_columns(OUTPUT_EXCEL_PATH)\n",
    "\n",
    "        print(\"\\n‚úÖ Processing Complete!\")\n",
    "        print(f\"üíæ Output File Saved: {OUTPUT_EXCEL_PATH}\")\n",
    "        print(df_final.head(3).to_string(index=False))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
