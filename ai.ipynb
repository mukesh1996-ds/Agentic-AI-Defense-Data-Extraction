{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa44bbef",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import difflib\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import getpass\n",
    "from typing import Annotated, TypedDict, List\n",
    "import re\n",
    "import pickle\n",
    "import faiss\n",
    "\n",
    "# LangChain / LangGraph Imports\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ 0. RAG RETRIEVER (Single File Implementation)\n",
    "# ==============================================================================\n",
    "\n",
    "class SystemKBRetriever:\n",
    "    \"\"\"\n",
    "    Loads FAISS index + metadata created from your KB excel.\n",
    "    Uses ONLY the contract paragraph to retrieve similar examples.\n",
    "    \"\"\"\n",
    "    def __init__(self, kb_dir: str):\n",
    "        index_path = os.path.join(kb_dir, \"system_kb.faiss\")\n",
    "        meta_path = os.path.join(kb_dir, \"system_kb_meta.pkl\")\n",
    "\n",
    "        if not os.path.exists(index_path) or not os.path.exists(meta_path):\n",
    "            raise FileNotFoundError(\n",
    "                f\"‚ùå KB files not found in: {kb_dir}\\n\"\n",
    "                f\"Expected:\\n- {index_path}\\n- {meta_path}\\n\\n\"\n",
    "                f\"Build the KB first using your KB builder script.\"\n",
    "            )\n",
    "\n",
    "        print(f\"‚úÖ Loading FAISS Index: {index_path}\")\n",
    "        self.index = faiss.read_index(index_path)\n",
    "\n",
    "        print(f\"‚úÖ Loading KB Metadata: {meta_path}\")\n",
    "        with open(meta_path, \"rb\") as f:\n",
    "            self.meta = pickle.load(f)\n",
    "\n",
    "        print(f\"‚úÖ KB Loaded: {len(self.meta)} rows\")\n",
    "\n",
    "    def retrieve(self, query_text: str, top_k: int = 3):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        [\n",
    "          {\"score\": float, \"meta\": {...all 29 cols...}},\n",
    "          ...\n",
    "        ]\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "\n",
    "        query_text = str(query_text).strip()\n",
    "        if not query_text:\n",
    "            return []\n",
    "\n",
    "        # ‚úÖ Use embedding model only when needed (lazy load)\n",
    "        if not hasattr(self, \"embedder\"):\n",
    "            self.embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "        q_emb = self.embedder.encode([query_text], normalize_embeddings=True).astype(\"float32\")\n",
    "        scores, idxs = self.index.search(q_emb, top_k)\n",
    "\n",
    "        results = []\n",
    "        for score, idx in zip(scores[0], idxs[0]):\n",
    "            if idx < 0:\n",
    "                continue\n",
    "            results.append({\n",
    "                \"score\": float(score),\n",
    "                \"meta\": self.meta[idx]\n",
    "            })\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. CONFIGURATION & FILE PATHS\n",
    "# ==============================================================================\n",
    "\n",
    "# ‚¨áÔ∏è UPDATE PATHS HERE ‚¨áÔ∏è\n",
    "TAXONOMY_PATH = r'C:\\Users\\mukeshkr\\Desktop\\DefenseExtraction\\testing\\taxonomy.json'\n",
    "SUPPLIERS_PATH = r'C:\\Users\\mukeshkr\\Desktop\\DefenseExtraction\\testing\\suppliers.json'\n",
    "INPUT_EXCEL_PATH = r\"C:\\Users\\mukeshkr\\Desktop\\DefenseExtraction\\data\\source_file.xlsx\"\n",
    "OUTPUT_EXCEL_PATH = \"Processed_Defense_Data.xlsx\"\n",
    "\n",
    "# ‚úÖ RAG KB Directory (must contain system_kb.faiss + system_kb_meta.pkl)\n",
    "RAG_KB_DIR = r\"C:\\Users\\mukeshkr\\Desktop\\DefenseExtraction\\testing\\system_kb_store\"\n",
    "\n",
    "# Setup API Key\n",
    "if \"LLMFOUNDRY_TOKEN\" not in os.environ:\n",
    "    os.environ[\"LLMFOUNDRY_TOKEN\"] = getpass.getpass(\"Enter the LLM Foundry API Key: \")\n",
    "\n",
    "# Shared Client\n",
    "client = OpenAI(\n",
    "    api_key=f'{os.environ.get(\"LLMFOUNDRY_TOKEN\")}:my-test-project',\n",
    "    base_url=\"https://llmfoundry.straive.com/openai/v1/\",\n",
    ")\n",
    "\n",
    "# ‚úÖ Load retriever once globally\n",
    "retriever = SystemKBRetriever(kb_dir=RAG_KB_DIR)\n",
    "\n",
    "# --- FILE LOADING HELPERS ---\n",
    "def load_json_file(filename, default_value):\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            print(f\"‚úÖ Loaded {filename}\")\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Warning: Could not load {filename} ({e}). Using default.\")\n",
    "        return default_value\n",
    "\n",
    "# 1. Load Taxonomy\n",
    "raw_taxonomy = load_json_file(TAXONOMY_PATH, {})\n",
    "TAXONOMY_STR = json.dumps(raw_taxonomy, separators=(',', ':'))\n",
    "\n",
    "# 2. Load Suppliers\n",
    "SUPPLIER_LIST = load_json_file(SUPPLIERS_PATH, [\n",
    "    \"Dell Inc\", \"Boeing\", \"Lockheed Martin\", \"Raytheon Technologies\",\n",
    "    \"Northrop Grumman\", \"L3Harris\", \"BAE Systems\", \"General Dynamics\"\n",
    "])\n",
    "\n",
    "# 3. System Rules\n",
    "RULE_BOOK = {\n",
    "    \"defensive_countermeasures\": {\n",
    "        \"triggers\": [\"flare\", \"chaff\", \"countermeasure\", \"decoy\", \"mju-\", \"ale-\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Defensive Systems', Specific: 'Defensive Aid Suite'\"\n",
    "    },\n",
    "    \"radars_and_sensors\": {\n",
    "        \"triggers\": [\"radar\", \"sonar\", \"sensor\", \"an/apy\", \"an/tpy\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Sensors'\"\n",
    "    },\n",
    "    \"ammunition\": {\n",
    "        \"triggers\": [\"cartridge\", \"round\", \"projectile\", \" 5.56\", \" 7.62\", \"ammo\"],\n",
    "        \"guidance\": \"Market Segment: 'Weapon Systems', System Type (General): 'Ammunition'\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# 4. Geography Mapping\n",
    "GEOGRAPHY_MAPPING = {\n",
    "    \"North America\": [\"USA\", \"United States\", \"US\", \"Canada\", \"America\"],\n",
    "    \"Europe\": [\"UK\", \"United Kingdom\", \"Ukraine\", \"Germany\", \"France\", \"Italy\", \"Spain\", \"Poland\", \"Netherlands\", \"Norway\", \"Sweden\", \"Finland\", \"Denmark\", \"Belgium\"],\n",
    "    \"Asia-Pacific\": [\"Australia\", \"Japan\", \"South Korea\", \"Taiwan\", \"India\", \"Singapore\", \"New Zealand\"],\n",
    "    \"Middle East and North Africa\": [\"Israel\", \"Saudi Arabia\", \"UAE\", \"Egypt\", \"Qatar\", \"Kuwait\", \"Iraq\"],\n",
    "    \"International Organisations\": [\"NATO\", \"EU\", \"IFU\", \"UN\", \"NSPA\"]\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. HELPER FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def get_best_supplier_match(extracted_name):\n",
    "    \"\"\"Fuzzy matches the extracted name against the loaded SUPPLIER_LIST.\"\"\"\n",
    "    if not extracted_name or extracted_name.lower() in [\"unknown\", \"n/a\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    clean_name = extracted_name.strip()\n",
    "\n",
    "    supplier_map = {s.lower(): s for s in SUPPLIER_LIST}\n",
    "    if clean_name.lower() in supplier_map:\n",
    "        return supplier_map[clean_name.lower()]\n",
    "\n",
    "    matches = difflib.get_close_matches(clean_name, SUPPLIER_LIST, n=1, cutoff=0.6)\n",
    "    return matches[0] if matches else clean_name\n",
    "\n",
    "\n",
    "def calculate_mro_months(start_date_str, end_date_text, program_type):\n",
    "    \"\"\"Calculates duration only if Program Type is MRO/Support.\"\"\"\n",
    "    if program_type != \"MRO/Support\":\n",
    "        return \"Not Applicable\"\n",
    "\n",
    "    try:\n",
    "        if not start_date_str or not end_date_text or str(end_date_text).lower() in [\"unknown\", \"n/a\"]:\n",
    "            return \"Not Applicable\"\n",
    "\n",
    "        start = pd.to_datetime(start_date_str, dayfirst=True)\n",
    "        end = parser.parse(end_date_text, fuzzy=True)\n",
    "\n",
    "        diff = relativedelta(end, start)\n",
    "        total_months = (diff.years * 12) + diff.months\n",
    "        return str(max(0, int(total_months)))\n",
    "    except:\n",
    "        return \"Not Applicable\"\n",
    "\n",
    "\n",
    "def get_region_for_country(country_name):\n",
    "    \"\"\"Robust lookup handling casing/whitespace.\"\"\"\n",
    "    if not country_name or country_name.lower() in [\"unknown\", \"n/a\", \"not applicable\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    clean = country_name.strip().lower()\n",
    "\n",
    "    if clean in [\"us\", \"usa\", \"united states\", \"united states of america\"]:\n",
    "        return \"North America\"\n",
    "    if clean in [\"uk\", \"britain\", \"great britain\"]:\n",
    "        return \"Europe\"\n",
    "\n",
    "    for region, countries in GEOGRAPHY_MAPPING.items():\n",
    "        if any(c.lower() == clean for c in countries):\n",
    "            return region\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "# ‚úÖ Regex Designator Extractors (for System Name + Piloting)\n",
    "DESIGNATOR_PATTERNS = [\n",
    "    r\"\\bDDG[-\\s]?\\d+\\b\", r\"\\bCVN[-\\s]?\\d+\\b\", r\"\\bSSN[-\\s]?\\d+\\b\",\n",
    "    r\"\\bLCS[-\\s]?\\d+\\b\", r\"\\bLPD[-\\s]?\\d+\\b\", r\"\\bLHA[-\\s]?\\d+\\b\", r\"\\bLHD[-\\s]?\\d+\\b\",\n",
    "    r\"\\bF-\\d+\\b\", r\"\\bB-\\d+\\b\", r\"\\bC-\\d+\\b\", r\"\\bA-\\d+\\b\",\n",
    "    r\"\\bMQ-\\d+\\b\", r\"\\bRQ-\\d+\\b\",\n",
    "    r\"\\bAN\\/[A-Z0-9\\-]+\\b\",\n",
    "    r\"\\b(AIM|AGM|SM|RIM|MIM)-\\d+\\b\",\n",
    "]\n",
    "\n",
    "def extract_designators(text: str):\n",
    "    text = str(text)\n",
    "    found = []\n",
    "    for pat in DESIGNATOR_PATTERNS:\n",
    "        found.extend(re.findall(pat, text, flags=re.IGNORECASE))\n",
    "    cleaned = []\n",
    "    for f in found:\n",
    "        cleaned.append(f.upper().replace(\" \", \"\").replace(\"--\", \"-\"))\n",
    "    seen = set()\n",
    "    final = []\n",
    "    for x in cleaned:\n",
    "        if x not in seen:\n",
    "            final.append(x)\n",
    "            seen.add(x)\n",
    "    return final\n",
    "\n",
    "def detect_piloting_rule_based(text: str, designators: List[str]) -> str:\n",
    "    t = str(text).lower()\n",
    "\n",
    "    if any(d.startswith((\"MQ-\", \"RQ-\")) for d in designators):\n",
    "        return \"Uncrewed\"\n",
    "    if any(k in t for k in [\"unmanned\", \"uav\", \"drone\", \"autonomous\"]):\n",
    "        return \"Uncrewed\"\n",
    "\n",
    "    if any(d.startswith((\"DDG\", \"CVN\", \"SSN\", \"LCS\", \"LPD\", \"LHA\", \"LHD\")) for d in designators):\n",
    "        return \"Crewed\"\n",
    "    if \"uss \" in t:\n",
    "        return \"Crewed\"\n",
    "\n",
    "    return \"Not Applicable\"\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. TOOL DEFINITIONS (AGENTS)\n",
    "# ==============================================================================\n",
    "\n",
    "# --- AGENT 1: SOURCING ---\n",
    "class SourcingInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "    url: str = Field(description=\"Source URL.\")\n",
    "    date: str = Field(description=\"Contract Date.\")\n",
    "\n",
    "@tool(\"sourcing_extractor\")\n",
    "def sourcing_extractor(paragraph: str, url: str, date: str):\n",
    "    \"\"\"Stage 1: Prepares Metadata.\"\"\"\n",
    "    reported_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    notes = \"Standard extraction.\"\n",
    "    if \"modification\" in paragraph.lower():\n",
    "        notes = \"Contract Modification.\"\n",
    "    if \"split\" in paragraph.lower():\n",
    "        notes = \"Split award detected.\"\n",
    "\n",
    "    return {\n",
    "        \"Description of Contract\": paragraph,\n",
    "        \"Additional Notes (Internal Only)\": notes,\n",
    "        \"Source Link(s)\": url,\n",
    "        \"Contract Date\": date,\n",
    "        \"Reported Date (By SGA)\": reported_date\n",
    "    }\n",
    "\n",
    "\n",
    "# --- AGENT 2: GEOGRAPHY ---\n",
    "class GeographyInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "\n",
    "@tool(\"geography_extractor\")\n",
    "def geography_extractor(paragraph: str):\n",
    "    \"\"\"Stage 2: Geography Logic.\"\"\"\n",
    "    sys_prompt = \"\"\"\n",
    "Extract: Customer Country, Supplier Country, Customer Operator.\n",
    "Logic: If 'Navy awarded...', Operator is Navy.\n",
    "Return JSON:\n",
    "{\n",
    "  \"Customer Country\": \"...\",\n",
    "  \"Customer Operator\": \"...\",\n",
    "  \"Supplier Country\": \"...\"\n",
    "}\n",
    "\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": paragraph}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "    except Exception:\n",
    "        raw = {}\n",
    "\n",
    "    cust = raw.get(\"Customer Country\", \"Unknown\")\n",
    "    supp = raw.get(\"Supplier Country\", \"Unknown\")\n",
    "\n",
    "    domestic = \"Indigenous\" if cust.lower() == supp.lower() else \"Imported\"\n",
    "    if \"united states\" in cust.lower() and \"usa\" in supp.lower():\n",
    "        domestic = \"Indigenous\"\n",
    "\n",
    "    return {\n",
    "        \"Customer Region\": get_region_for_country(cust),\n",
    "        \"Customer Country\": cust,\n",
    "        \"Customer Operator\": raw.get(\"Customer Operator\", \"Unknown\"),\n",
    "        \"Supplier Region\": get_region_for_country(supp),\n",
    "        \"Supplier Country\": supp,\n",
    "        \"Domestic Content\": domestic\n",
    "    }\n",
    "\n",
    "\n",
    "# --- ‚úÖ AGENT 3: SYSTEM (UPGRADED WITH RAG + Evidence + Reason) ---\n",
    "class SystemInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "\n",
    "@tool(\"system_classifier\")\n",
    "def system_classifier(paragraph: str):\n",
    "    \"\"\"Stage 3: System classification using RAG + Rule Book + Evidence & Reason.\"\"\"\n",
    "    paragraph = str(paragraph).strip()\n",
    "    if not paragraph:\n",
    "        return {}\n",
    "\n",
    "    lower_text = paragraph.lower()\n",
    "\n",
    "    # RULE BOOK triggers\n",
    "    hints = [\n",
    "        f\"RULE: {v['guidance']}\"\n",
    "        for _, v in RULE_BOOK.items()\n",
    "        if any(t in lower_text for t in v[\"triggers\"])\n",
    "    ]\n",
    "    hint_str = \"\\n\".join(hints) if hints else \"No special override rules triggered.\"\n",
    "\n",
    "    # Local extraction\n",
    "    designators = extract_designators(paragraph)\n",
    "\n",
    "    # Rule-based piloting\n",
    "    piloting_rule = detect_piloting_rule_based(paragraph, designators)\n",
    "\n",
    "    # RAG Retrieval\n",
    "    rag_hits = retriever.retrieve(paragraph, top_k=3)\n",
    "\n",
    "    rag_examples = []\n",
    "    for hit in rag_hits:\n",
    "        meta = hit[\"meta\"]\n",
    "        rag_examples.append({\n",
    "            \"score\": round(hit[\"score\"], 4),\n",
    "            \"Market Segment\": meta.get(\"Market Segment\", \"\"),\n",
    "            \"System Type (General)\": meta.get(\"System Type (General)\", \"\"),\n",
    "            \"System Type (Specific)\": meta.get(\"System Type (Specific)\", \"\"),\n",
    "            \"System Name (General)\": meta.get(\"System Name (General)\", \"\"),\n",
    "            \"System Name (Specific)\": meta.get(\"System Name (Specific)\", \"\"),\n",
    "            \"System Piloting\": meta.get(\"System Piloting\", \"\"),\n",
    "            \"Supplier Name\": meta.get(\"Supplier Name\", \"\"),\n",
    "            \"Customer Operator\": meta.get(\"Customer Operator\", \"\"),\n",
    "            \"Snippet\": meta.get(\"Description of Contract\", \"\")[:220] + \"...\"\n",
    "        })\n",
    "\n",
    "    sys_prompt = f\"\"\"\n",
    "You are a Senior Defense System Classification Analyst.\n",
    "\n",
    "Use these inputs:\n",
    "1) RAG Similar Examples (top 3)\n",
    "2) Rule Book Overrides\n",
    "3) Extracted Designators\n",
    "\n",
    "RULE BOOK OVERRIDES:\n",
    "{hint_str}\n",
    "\n",
    "OUTPUT RULES:\n",
    "- Return ONLY a FLAT JSON object.\n",
    "- Every value must be a STRING.\n",
    "- Do NOT return nested JSON or lists.\n",
    "- Evidence must be copied EXACTLY from paragraph.\n",
    "- If evidence not present, use \"Not Found\".\n",
    "\n",
    "Return JSON exactly:\n",
    "{{\n",
    "  \"Market Segment\": \"\",\n",
    "  \"Market Segment Evidence\": \"\",\n",
    "  \"Market Segment Reason\": \"\",\n",
    "\n",
    "  \"System Type (General)\": \"\",\n",
    "  \"System Type (General) Evidence\": \"\",\n",
    "  \"System Type (General) Reason\": \"\",\n",
    "\n",
    "  \"System Type (Specific)\": \"\",\n",
    "  \"System Type (Specific) Evidence\": \"\",\n",
    "  \"System Type (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Name (General)\": \"\",\n",
    "  \"System Name (General) Evidence\": \"\",\n",
    "  \"System Name (General) Reason\": \"\",\n",
    "\n",
    "  \"System Name (Specific)\": \"\",\n",
    "  \"System Name (Specific) Evidence\": \"\",\n",
    "  \"System Name (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Piloting\": \"\",\n",
    "  \"System Piloting Evidence\": \"\",\n",
    "  \"System Piloting Reason\": \"\",\n",
    "\n",
    "  \"Confidence\": \"High/Medium/Low\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "INPUT PARAGRAPH:\n",
    "{paragraph}\n",
    "\n",
    "DESIGNATORS (regex extracted):\n",
    "{designators if designators else \"None\"}\n",
    "\n",
    "RULE-BASED PILOTING:\n",
    "{piloting_rule}\n",
    "\n",
    "RAG SIMILAR EXAMPLES:\n",
    "{json.dumps(rag_examples, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        result = json.loads(completion.choices[0].message.content)\n",
    "\n",
    "        # Hard override piloting (best accuracy)\n",
    "        result[\"System Piloting\"] = piloting_rule\n",
    "        if not result.get(\"System Piloting Reason\"):\n",
    "            result[\"System Piloting Reason\"] = \"Piloting derived using deterministic rules.\"\n",
    "        if not result.get(\"System Piloting Evidence\"):\n",
    "            result[\"System Piloting Evidence\"] = \"Not Found\"\n",
    "\n",
    "        # Ensure flat\n",
    "        for k, v in result.items():\n",
    "            if isinstance(v, (dict, list)):\n",
    "                result[k] = str(v)\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"Market Segment\": \"\",\n",
    "            \"System Type (General)\": \"\",\n",
    "            \"System Type (Specific)\": \"\",\n",
    "            \"System Name (General)\": \"\",\n",
    "            \"System Name (Specific)\": \"\",\n",
    "            \"System Piloting\": piloting_rule,\n",
    "            \"Market Segment Evidence\": \"Not Found\",\n",
    "            \"System Type (General) Evidence\": \"Not Found\",\n",
    "            \"System Type (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Name (General) Evidence\": \"Not Found\",\n",
    "            \"System Name (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Piloting Evidence\": \"Not Found\",\n",
    "            \"Market Segment Reason\": \"\",\n",
    "            \"System Type (General) Reason\": \"\",\n",
    "            \"System Type (Specific) Reason\": \"\",\n",
    "            \"System Name (General) Reason\": \"\",\n",
    "            \"System Name (Specific) Reason\": \"\",\n",
    "            \"System Piloting Reason\": \"Piloting derived using deterministic rules.\",\n",
    "            \"Confidence\": \"Low\",\n",
    "            \"Error\": str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "# --- AGENT 4: CONTRACT ---\n",
    "class ContractInfoInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "    contract_date: str = Field(description=\"Signed date.\")\n",
    "\n",
    "@tool(\"contract_extractor\")\n",
    "def contract_extractor(paragraph: str, contract_date: str):\n",
    "    \"\"\"Stage 4: Extracts Financials, Program Type, and Dates based on strict SOP.\"\"\"\n",
    "\n",
    "    system_instruction = \"\"\"\n",
    "You are a Defense Contract Financial Analyst. Extract data strictly following these SOP rules:\n",
    "\n",
    "1) Supplier Name: Extract the exact company name text found in paragraph.\n",
    "2) Program Type: Procurement / Training / MRO/Support / RDT&E / Upgrade / Other Service\n",
    "3) Value Certainty:\n",
    "   - Confirmed: fixed price/obligated stated\n",
    "   - Estimated: ceiling/potential/IDIQ/multi-award\n",
    "4) Quantity: number or Not Applicable\n",
    "5) G2G/B2G:\n",
    "   - G2G only if Foreign Military Sales (FMS)\n",
    "   - else B2G\n",
    "6) Completion Date: only needed for MRO duration calc\n",
    "\n",
    "Return JSON only.\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "Analyze contract:\n",
    "\"{paragraph}\"\n",
    "\n",
    "Signed Date: {contract_date}\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"raw_supplier_name\": \"\",\n",
    "  \"program_type\": \"\",\n",
    "  \"value_million_raw\": \"\",\n",
    "  \"currency_code\": \"\",\n",
    "  \"value_certainty\": \"\",\n",
    "  \"quantity\": \"\",\n",
    "  \"completion_date_text\": \"\",\n",
    "  \"g2g_b2g\": \"\",\n",
    "  \"value_note\": \"\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_instruction},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        return {\"Error\": str(e)}\n",
    "\n",
    "    final_supplier = get_best_supplier_match(raw.get(\"raw_supplier_name\"))\n",
    "    prog_type = raw.get(\"program_type\", \"Unknown\")\n",
    "    mro_months = calculate_mro_months(contract_date, raw.get(\"completion_date_text\"), prog_type)\n",
    "\n",
    "    try:\n",
    "        val_str = str(raw.get(\"value_million_raw\", \"0\")).replace(\",\", \"\").replace(\"$\", \"\")\n",
    "        val_float = float(val_str)\n",
    "        val_formatted = \"{:.3f}\".format(val_float)\n",
    "    except:\n",
    "        val_formatted = \"0.000\"\n",
    "\n",
    "    try:\n",
    "        dt = pd.to_datetime(contract_date)\n",
    "        sign_month = dt.strftime(\"%B\")\n",
    "        sign_year = str(dt.year)\n",
    "    except:\n",
    "        sign_month, sign_year = \"Unknown\", \"Unknown\"\n",
    "\n",
    "    val_note = raw.get(\"value_note\", \"Not Applicable\")\n",
    "    if \"split\" in paragraph.lower() and val_note == \"Not Applicable\":\n",
    "        val_note = \"Split contract; value distribution unclear.\"\n",
    "\n",
    "    return {\n",
    "        \"Supplier Name\": final_supplier,\n",
    "        \"Program Type\": prog_type,\n",
    "        \"Expected MRO Contract Duration (Months)\": mro_months,\n",
    "        \"Quantity\": raw.get(\"quantity\", \"Not Applicable\"),\n",
    "        \"Value Certainty\": raw.get(\"value_certainty\", \"Confirmed\"),\n",
    "        \"Value (Million)\": val_formatted,\n",
    "        \"Currency\": raw.get(\"currency_code\", \"USD$\"),\n",
    "        \"Value (USD$ Million)\": val_formatted,\n",
    "        \"Value Note (If Any)\": val_note,\n",
    "        \"G2G/B2G\": raw.get(\"g2g_b2g\", \"B2G\"),\n",
    "        \"Signing Month\": sign_month,\n",
    "        \"Signing Year\": sign_year\n",
    "    }\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. LANGGRAPH PIPELINE\n",
    "# ==============================================================================\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input_text: str\n",
    "    input_date: str\n",
    "    input_url: str\n",
    "    final_data: dict\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "\n",
    "def stage_1_sourcing(state: AgentState):\n",
    "    res = sourcing_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"url\": state[\"input_url\"],\n",
    "        \"date\": state[\"input_date\"]\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "def stage_2_geography(state: AgentState):\n",
    "    res = geography_extractor.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "def stage_3_system(state: AgentState):\n",
    "    res = system_classifier.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "def stage_4_contract(state: AgentState):\n",
    "    res = contract_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"contract_date\": state[\"input_date\"]\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Stage1\", stage_1_sourcing)\n",
    "workflow.add_node(\"Stage2\", stage_2_geography)\n",
    "workflow.add_node(\"Stage3\", stage_3_system)\n",
    "workflow.add_node(\"Stage4\", stage_4_contract)\n",
    "\n",
    "workflow.add_edge(START, \"Stage1\")\n",
    "workflow.add_edge(\"Stage1\", \"Stage2\")\n",
    "workflow.add_edge(\"Stage2\", \"Stage3\")\n",
    "workflow.add_edge(\"Stage3\", \"Stage4\")\n",
    "workflow.add_edge(\"Stage4\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. EXECUTION & FORMATTING\n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(f\"üìÇ Loading Input File: {INPUT_EXCEL_PATH}...\")\n",
    "\n",
    "    try:\n",
    "        df_input = pd.read_excel(INPUT_EXCEL_PATH)\n",
    "\n",
    "        required_cols = [\"Source URL\", \"Contract Date\", \"Contract Description\"]\n",
    "        if not all(col in df_input.columns for col in required_cols):\n",
    "            raise ValueError(f\"Excel file must contain columns: {required_cols}\")\n",
    "\n",
    "        print(f\"üöÄ Processing {len(df_input)} rows...\")\n",
    "        results = []\n",
    "\n",
    "        for index, row in df_input.iterrows():\n",
    "            print(f\"   -> Row {index + 1}...\")\n",
    "\n",
    "            desc = str(row[\"Contract Description\"]) if pd.notna(row[\"Contract Description\"]) else \"\"\n",
    "            c_date = str(row[\"Contract Date\"]) if pd.notna(row[\"Contract Date\"]) else str(datetime.date.today())\n",
    "            c_url = str(row[\"Source URL\"]) if pd.notna(row[\"Source URL\"]) else \"\"\n",
    "\n",
    "            initial_state = {\n",
    "                \"input_text\": desc,\n",
    "                \"input_date\": c_date,\n",
    "                \"input_url\": c_url,\n",
    "                \"final_data\": {},\n",
    "                \"messages\": []\n",
    "            }\n",
    "\n",
    "            output_state = app.invoke(initial_state)\n",
    "            results.append(output_state[\"final_data\"])\n",
    "\n",
    "        df_final = pd.DataFrame(results)\n",
    "\n",
    "        FINAL_COLUMNS = [\n",
    "            \"Customer Region\", \"Customer Country\", \"Customer Operator\",\n",
    "            \"Supplier Region\", \"Supplier Country\", \"Domestic Content\",\n",
    "\n",
    "            \"Market Segment\", \"Market Segment Evidence\", \"Market Segment Reason\",\n",
    "            \"System Type (General)\", \"System Type (General) Evidence\", \"System Type (General) Reason\",\n",
    "            \"System Type (Specific)\", \"System Type (Specific) Evidence\", \"System Type (Specific) Reason\",\n",
    "            \"System Name (General)\", \"System Name (General) Evidence\", \"System Name (General) Reason\",\n",
    "            \"System Name (Specific)\", \"System Name (Specific) Evidence\", \"System Name (Specific) Reason\",\n",
    "            \"System Piloting\", \"System Piloting Evidence\", \"System Piloting Reason\",\n",
    "            \"Confidence\",\n",
    "\n",
    "            \"Supplier Name\", \"Program Type\", \"Expected MRO Contract Duration (Months)\",\n",
    "            \"Quantity\", \"Value Certainty\", \"Value (Million)\", \"Currency\",\n",
    "            \"Value (USD$ Million)\", \"Value Note (If Any)\", \"G2G/B2G\",\n",
    "            \"Signing Month\", \"Signing Year\",\n",
    "\n",
    "            \"Description of Contract\",\n",
    "            \"Additional Notes (Internal Only)\",\n",
    "            \"Source Link(s)\",\n",
    "            \"Contract Date\",\n",
    "            \"Reported Date (By SGA)\"\n",
    "        ]\n",
    "\n",
    "        df_final = df_final.reindex(columns=FINAL_COLUMNS, fill_value=\"\")\n",
    "\n",
    "        df_final.to_excel(OUTPUT_EXCEL_PATH, index=False)\n",
    "\n",
    "        print(\"\\n‚úÖ Processing Complete!\")\n",
    "        print(f\"üíæ File saved to: {OUTPUT_EXCEL_PATH}\")\n",
    "        print(df_final.head().to_string())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3be6b49",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import getpass\n",
    "from typing import Annotated, TypedDict, List\n",
    "import re\n",
    "import pickle\n",
    "import faiss\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# LangChain / LangGraph Imports\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ RAG RETRIEVER (Single File Implementation)\n",
    "# ==============================================================================\n",
    "\n",
    "class SystemKBRetriever:\n",
    "    \"\"\"\n",
    "    Loads FAISS index + metadata created from your KB excel.\n",
    "    Uses ONLY the contract paragraph to retrieve similar examples.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kb_dir: str):\n",
    "        index_path = os.path.join(kb_dir, \"system_kb.faiss\")\n",
    "        meta_path = os.path.join(kb_dir, \"system_kb_meta.pkl\")\n",
    "\n",
    "        if not os.path.exists(index_path) or not os.path.exists(meta_path):\n",
    "            raise FileNotFoundError(\n",
    "                f\"‚ùå KB files not found in: {kb_dir}\\n\"\n",
    "                f\"Expected:\\n- {index_path}\\n- {meta_path}\\n\\n\"\n",
    "                f\"Build the KB first using your KB builder script.\"\n",
    "            )\n",
    "\n",
    "        print(f\"‚úÖ Loading FAISS Index: {index_path}\")\n",
    "        self.index = faiss.read_index(index_path)\n",
    "\n",
    "        print(f\"‚úÖ Loading KB Metadata: {meta_path}\")\n",
    "        with open(meta_path, \"rb\") as f:\n",
    "            self.meta = pickle.load(f)\n",
    "\n",
    "        print(f\"‚úÖ KB Loaded: {len(self.meta)} rows\")\n",
    "\n",
    "    def retrieve(self, query_text: str, top_k: int = 3):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        [\n",
    "          {\"score\": float, \"meta\": {...all 29 cols...}},\n",
    "          ...\n",
    "        ]\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "\n",
    "        query_text = str(query_text).strip()\n",
    "        if not query_text:\n",
    "            return []\n",
    "\n",
    "        # Use embedding model only when needed (lazy load)\n",
    "        if not hasattr(self, \"embedder\"):\n",
    "            self.embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "        q_emb = self.embedder.encode([query_text], normalize_embeddings=True).astype(\"float32\")\n",
    "        scores, idxs = self.index.search(q_emb, top_k)\n",
    "\n",
    "        results = []\n",
    "        for score, idx in zip(scores[0], idxs[0]):\n",
    "            if idx < 0:\n",
    "                continue\n",
    "            results.append({\"score\": float(score), \"meta\": self.meta[idx]})\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ 1. CONFIGURATION & FILE PATHS\n",
    "# ==============================================================================\n",
    "\n",
    "TAXONOMY_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\taxonomy.json\"\n",
    "SUPPLIERS_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\suppliers.json\"\n",
    "INPUT_EXCEL_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\data\\source_file.xlsx\"\n",
    "OUTPUT_EXCEL_PATH = \"Processed_Defense_Data.xlsx\"\n",
    "\n",
    "RAG_KB_DIR = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\system_kb_store\"\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ 2. API Setup\n",
    "# ==============================================================================\n",
    "\n",
    "if \"LLMFOUNDRY_TOKEN\" not in os.environ:\n",
    "    os.environ[\"LLMFOUNDRY_TOKEN\"] = getpass.getpass(\"Enter the LLM Foundry API Key: \")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=f'{os.environ.get(\"LLMFOUNDRY_TOKEN\")}:my-test-project',\n",
    "    base_url=\"https://llmfoundry.straive.com/openai/v1/\",\n",
    ")\n",
    "\n",
    "retriever = SystemKBRetriever(kb_dir=RAG_KB_DIR)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ 3. JSON Loaders\n",
    "# ==============================================================================\n",
    "\n",
    "def load_json_file(filename, default_value):\n",
    "    try:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            print(f\"‚úÖ Loaded: {filename}\")\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Warning: Could not load {filename} ({e}). Using default.\")\n",
    "        return default_value\n",
    "\n",
    "\n",
    "raw_taxonomy = load_json_file(TAXONOMY_PATH, {})\n",
    "TAXONOMY_STR = json.dumps(raw_taxonomy, separators=(\",\", \":\"))\n",
    "\n",
    "\n",
    "# ‚úÖ IMPORTANT: Supplier list MUST come from suppliers.json\n",
    "SUPPLIER_LIST = load_json_file(SUPPLIERS_PATH, [])\n",
    "if not SUPPLIER_LIST:\n",
    "    raise ValueError(\"‚ùå suppliers.json loaded 0 suppliers. Please verify the path.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ 4. Rule Book + Geography Mapping\n",
    "# ==============================================================================\n",
    "\n",
    "RULE_BOOK = {\n",
    "    \"defensive_countermeasures\": {\n",
    "        \"triggers\": [\"flare\", \"chaff\", \"countermeasure\", \"decoy\", \"mju-\", \"ale-\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Defensive Systems', Specific: 'Defensive Aid Suite'\",\n",
    "    },\n",
    "    \"radars_and_sensors\": {\n",
    "        \"triggers\": [\"radar\", \"sonar\", \"sensor\", \"an/apy\", \"an/tpy\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Sensors'\",\n",
    "    },\n",
    "    \"ammunition\": {\n",
    "        \"triggers\": [\"cartridge\", \"round\", \"projectile\", \" 5.56\", \" 7.62\", \"ammo\"],\n",
    "        \"guidance\": \"Market Segment: 'Weapon Systems', System Type (General): 'Ammunition'\",\n",
    "    },\n",
    "}\n",
    "\n",
    "GEOGRAPHY_MAPPING = {\n",
    "    \"North America\": [\"USA\", \"United States\", \"US\", \"Canada\", \"America\"],\n",
    "    \"Europe\": [\"UK\", \"United Kingdom\", \"Ukraine\", \"Germany\", \"France\", \"Italy\", \"Spain\", \"Poland\", \"Netherlands\", \"Norway\", \"Sweden\", \"Finland\", \"Denmark\", \"Belgium\"],\n",
    "    \"Asia-Pacific\": [\"Australia\", \"Japan\", \"South Korea\", \"Taiwan\", \"India\", \"Singapore\", \"New Zealand\"],\n",
    "    \"Middle East and North Africa\": [\"Israel\", \"Saudi Arabia\", \"UAE\", \"Egypt\", \"Qatar\", \"Kuwait\", \"Iraq\"],\n",
    "    \"International Organisations\": [\"NATO\", \"EU\", \"IFU\", \"UN\", \"NSPA\"],\n",
    "}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ 5. HELPER FUNCTIONS (Supplier Matching FIXED ‚úÖ‚úÖ‚úÖ)\n",
    "# ==============================================================================\n",
    "\n",
    "def normalize_supplier_text(x: str) -> str:\n",
    "    if not x:\n",
    "        return \"\"\n",
    "    x = str(x).strip()\n",
    "\n",
    "    # normalize unicode dashes\n",
    "    x = x.replace(\"‚Äì\", \"-\").replace(\"‚Äî\", \"-\")\n",
    "\n",
    "    # remove multiple spaces\n",
    "    x = re.sub(r\"\\s+\", \" \", x).strip()\n",
    "\n",
    "    # remove extra location after comma\n",
    "    # ex: \"General Dynamics NASSCO - San Diego, San Diego, California\"\n",
    "    x = x.split(\",\")[0].strip()\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def token_overlap_score(a: str, b: str) -> float:\n",
    "    a_tokens = set(re.findall(r\"[a-z0-9]+\", a.lower()))\n",
    "    b_tokens = set(re.findall(r\"[a-z0-9]+\", b.lower()))\n",
    "    if not a_tokens or not b_tokens:\n",
    "        return 0.0\n",
    "    return len(a_tokens & b_tokens) / max(len(a_tokens), len(b_tokens))\n",
    "\n",
    "\n",
    "def get_best_supplier_match(extracted_supplier: str):\n",
    "    \"\"\"\n",
    "    ‚úÖ FINAL Supplier Name MUST be from SUPPLIER_LIST (suppliers.json)\n",
    "    Returns:\n",
    "      (best_supplier_name, best_score)\n",
    "    \"\"\"\n",
    "    if not extracted_supplier:\n",
    "        return \"Unknown\", 0.0\n",
    "\n",
    "    extracted_supplier = normalize_supplier_text(extracted_supplier)\n",
    "    low = extracted_supplier.lower()\n",
    "\n",
    "    if low in [\"unknown\", \"n/a\", \"not applicable\"]:\n",
    "        return \"Unknown\", 0.0\n",
    "\n",
    "    # 1) Exact match\n",
    "    supplier_map = {s.lower(): s for s in SUPPLIER_LIST}\n",
    "    if low in supplier_map:\n",
    "        return supplier_map[low], 1.0\n",
    "\n",
    "    # 2) Containment match (best practical for long extracted)\n",
    "    containment_hits = [s for s in SUPPLIER_LIST if s.lower() in low]\n",
    "    if containment_hits:\n",
    "        containment_hits.sort(key=len, reverse=True)  # longest = most specific\n",
    "        return containment_hits[0], 0.95\n",
    "\n",
    "    # 3) Hybrid fuzzy match over supplier list\n",
    "    best_name = \"Unknown\"\n",
    "    best_score = 0.0\n",
    "\n",
    "    for s in SUPPLIER_LIST:\n",
    "        s_clean = normalize_supplier_text(s)\n",
    "\n",
    "        seq = SequenceMatcher(None, low, s_clean.lower()).ratio()\n",
    "        tok = token_overlap_score(extracted_supplier, s_clean)\n",
    "\n",
    "        final = (0.65 * tok) + (0.35 * seq)\n",
    "\n",
    "        if final > best_score:\n",
    "            best_score = final\n",
    "            best_name = s\n",
    "\n",
    "    # strict cutoff: avoid wrong match\n",
    "    if best_score < 0.45:\n",
    "        return \"Unknown\", best_score\n",
    "\n",
    "    return best_name, best_score\n",
    "\n",
    "\n",
    "def calculate_mro_months(start_date_str, end_date_text, program_type):\n",
    "    \"\"\"Calculates duration only if Program Type is MRO/Support.\"\"\"\n",
    "    if program_type != \"MRO/Support\":\n",
    "        return \"Not Applicable\"\n",
    "\n",
    "    try:\n",
    "        if not start_date_str or not end_date_text or str(end_date_text).lower() in [\"unknown\", \"n/a\"]:\n",
    "            return \"Not Applicable\"\n",
    "\n",
    "        start = pd.to_datetime(start_date_str, dayfirst=True)\n",
    "        end = parser.parse(end_date_text, fuzzy=True)\n",
    "\n",
    "        diff = relativedelta(end, start)\n",
    "        total_months = (diff.years * 12) + diff.months\n",
    "        return str(max(0, int(total_months)))\n",
    "    except:\n",
    "        return \"Not Applicable\"\n",
    "\n",
    "\n",
    "def get_region_for_country(country_name):\n",
    "    \"\"\"Robust lookup handling casing/whitespace.\"\"\"\n",
    "    if not country_name or country_name.lower() in [\"unknown\", \"n/a\", \"not applicable\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    clean = country_name.strip().lower()\n",
    "\n",
    "    if clean in [\"us\", \"usa\", \"united states\", \"united states of america\"]:\n",
    "        return \"North America\"\n",
    "    if clean in [\"uk\", \"britain\", \"great britain\"]:\n",
    "        return \"Europe\"\n",
    "\n",
    "    for region, countries in GEOGRAPHY_MAPPING.items():\n",
    "        if any(c.lower() == clean for c in countries):\n",
    "            return region\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ 6. Designators (System Name + Piloting)\n",
    "# ==============================================================================\n",
    "\n",
    "DESIGNATOR_PATTERNS = [\n",
    "    r\"\\bDDG[-\\s]?\\d+\\b\", r\"\\bCVN[-\\s]?\\d+\\b\", r\"\\bSSN[-\\s]?\\d+\\b\",\n",
    "    r\"\\bLCS[-\\s]?\\d+\\b\", r\"\\bLPD[-\\s]?\\d+\\b\", r\"\\bLHA[-\\s]?\\d+\\b\", r\"\\bLHD[-\\s]?\\d+\\b\",\n",
    "    r\"\\bF-\\d+\\b\", r\"\\bB-\\d+\\b\", r\"\\bC-\\d+\\b\", r\"\\bA-\\d+\\b\",\n",
    "    r\"\\bMQ-\\d+\\b\", r\"\\bRQ-\\d+\\b\",\n",
    "    r\"\\bAN\\/[A-Z0-9\\-]+\\b\",\n",
    "    r\"\\b(AIM|AGM|SM|RIM|MIM)-\\d+\\b\",\n",
    "]\n",
    "\n",
    "def extract_designators(text: str):\n",
    "    text = str(text)\n",
    "    found = []\n",
    "    for pat in DESIGNATOR_PATTERNS:\n",
    "        found.extend(re.findall(pat, text, flags=re.IGNORECASE))\n",
    "\n",
    "    cleaned = []\n",
    "    for f in found:\n",
    "        cleaned.append(f.upper().replace(\" \", \"\").replace(\"--\", \"-\"))\n",
    "\n",
    "    seen = set()\n",
    "    final = []\n",
    "    for x in cleaned:\n",
    "        if x not in seen:\n",
    "            final.append(x)\n",
    "            seen.add(x)\n",
    "    return final\n",
    "\n",
    "\n",
    "def detect_piloting_rule_based(text: str, designators: List[str]) -> str:\n",
    "    t = str(text).lower()\n",
    "\n",
    "    if any(d.startswith((\"MQ-\", \"RQ-\")) for d in designators):\n",
    "        return \"Uncrewed\"\n",
    "    if any(k in t for k in [\"unmanned\", \"uav\", \"drone\", \"autonomous\"]):\n",
    "        return \"Uncrewed\"\n",
    "\n",
    "    if any(d.startswith((\"DDG\", \"CVN\", \"SSN\", \"LCS\", \"LPD\", \"LHA\", \"LHD\")) for d in designators):\n",
    "        return \"Crewed\"\n",
    "    if \"uss \" in t:\n",
    "        return \"Crewed\"\n",
    "\n",
    "    return \"Not Applicable\"\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ 7. TOOL DEFINITIONS (Agents)\n",
    "# ==============================================================================\n",
    "\n",
    "# --- AGENT 1: SOURCING ---\n",
    "class SourcingInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "    url: str = Field(description=\"Source URL.\")\n",
    "    date: str = Field(description=\"Contract Date.\")\n",
    "\n",
    "@tool(\"sourcing_extractor\")\n",
    "def sourcing_extractor(paragraph: str, url: str, date: str):\n",
    "    reported_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    notes = \"Standard extraction.\"\n",
    "    if \"modification\" in paragraph.lower():\n",
    "        notes = \"Contract Modification.\"\n",
    "    if \"split\" in paragraph.lower():\n",
    "        notes = \"Split award detected.\"\n",
    "\n",
    "    return {\n",
    "        \"Description of Contract\": paragraph,\n",
    "        \"Additional Notes (Internal Only)\": notes,\n",
    "        \"Source Link(s)\": url,\n",
    "        \"Contract Date\": date,\n",
    "        \"Reported Date (By SGA)\": reported_date\n",
    "    }\n",
    "\n",
    "\n",
    "# --- AGENT 2: GEOGRAPHY ---\n",
    "class GeographyInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "\n",
    "@tool(\"geography_extractor\")\n",
    "def geography_extractor(paragraph: str):\n",
    "    sys_prompt = \"\"\"\n",
    "Extract: Customer Country, Supplier Country, Customer Operator.\n",
    "Logic: If 'Navy awarded...', Operator is Navy.\n",
    "Return JSON:\n",
    "{\n",
    "  \"Customer Country\": \"...\",\n",
    "  \"Customer Operator\": \"...\",\n",
    "  \"Supplier Country\": \"...\"\n",
    "}\n",
    "\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": paragraph}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "    except Exception:\n",
    "        raw = {}\n",
    "\n",
    "    cust = raw.get(\"Customer Country\", \"Unknown\")\n",
    "    supp = raw.get(\"Supplier Country\", \"Unknown\")\n",
    "\n",
    "    domestic = \"Indigenous\" if cust.lower() == supp.lower() else \"Imported\"\n",
    "    if \"united states\" in cust.lower() and \"usa\" in supp.lower():\n",
    "        domestic = \"Indigenous\"\n",
    "\n",
    "    return {\n",
    "        \"Customer Region\": get_region_for_country(cust),\n",
    "        \"Customer Country\": cust,\n",
    "        \"Customer Operator\": raw.get(\"Customer Operator\", \"Unknown\"),\n",
    "        \"Supplier Region\": get_region_for_country(supp),\n",
    "        \"Supplier Country\": supp,\n",
    "        \"Domestic Content\": domestic\n",
    "    }\n",
    "\n",
    "\n",
    "# --- AGENT 3: SYSTEM (RAG + Evidence + Reason) ---\n",
    "class SystemInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "\n",
    "@tool(\"system_classifier\")\n",
    "def system_classifier(paragraph: str):\n",
    "    paragraph = str(paragraph).strip()\n",
    "    if not paragraph:\n",
    "        return {}\n",
    "\n",
    "    lower_text = paragraph.lower()\n",
    "\n",
    "    hints = [\n",
    "        f\"RULE: {v['guidance']}\"\n",
    "        for _, v in RULE_BOOK.items()\n",
    "        if any(t in lower_text for t in v[\"triggers\"])\n",
    "    ]\n",
    "    hint_str = \"\\n\".join(hints) if hints else \"No special override rules triggered.\"\n",
    "\n",
    "    designators = extract_designators(paragraph)\n",
    "    piloting_rule = detect_piloting_rule_based(paragraph, designators)\n",
    "\n",
    "    rag_hits = retriever.retrieve(paragraph, top_k=3)\n",
    "\n",
    "    rag_examples = []\n",
    "    for hit in rag_hits:\n",
    "        meta = hit[\"meta\"]\n",
    "        rag_examples.append({\n",
    "            \"score\": round(hit[\"score\"], 4),\n",
    "            \"Market Segment\": meta.get(\"Market Segment\", \"\"),\n",
    "            \"System Type (General)\": meta.get(\"System Type (General)\", \"\"),\n",
    "            \"System Type (Specific)\": meta.get(\"System Type (Specific)\", \"\"),\n",
    "            \"System Name (General)\": meta.get(\"System Name (General)\", \"\"),\n",
    "            \"System Name (Specific)\": meta.get(\"System Name (Specific)\", \"\"),\n",
    "            \"System Piloting\": meta.get(\"System Piloting\", \"\"),\n",
    "            \"Supplier Name\": meta.get(\"Supplier Name\", \"\"),\n",
    "            \"Customer Operator\": meta.get(\"Customer Operator\", \"\"),\n",
    "            \"Snippet\": meta.get(\"Description of Contract\", \"\")[:220] + \"...\"\n",
    "        })\n",
    "\n",
    "    sys_prompt = f\"\"\"\n",
    "You are a Senior Defense System Classification Analyst.\n",
    "\n",
    "Use these inputs:\n",
    "1) RAG Similar Examples (top 3)\n",
    "2) Rule Book Overrides\n",
    "3) Extracted Designators\n",
    "\n",
    "RULE BOOK OVERRIDES:\n",
    "{hint_str}\n",
    "\n",
    "OUTPUT RULES:\n",
    "- Return ONLY a FLAT JSON object.\n",
    "- Every value must be a STRING.\n",
    "- Do NOT return nested JSON or lists.\n",
    "- Evidence must be copied EXACTLY from paragraph.\n",
    "- If evidence not present, use \"Not Found\".\n",
    "\n",
    "Return JSON exactly:\n",
    "{{\n",
    "  \"Market Segment\": \"\",\n",
    "  \"Market Segment Evidence\": \"\",\n",
    "  \"Market Segment Reason\": \"\",\n",
    "\n",
    "  \"System Type (General)\": \"\",\n",
    "  \"System Type (General) Evidence\": \"\",\n",
    "  \"System Type (General) Reason\": \"\",\n",
    "\n",
    "  \"System Type (Specific)\": \"\",\n",
    "  \"System Type (Specific) Evidence\": \"\",\n",
    "  \"System Type (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Name (General)\": \"\",\n",
    "  \"System Name (General) Evidence\": \"\",\n",
    "  \"System Name (General) Reason\": \"\",\n",
    "\n",
    "  \"System Name (Specific)\": \"\",\n",
    "  \"System Name (Specific) Evidence\": \"\",\n",
    "  \"System Name (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Piloting\": \"\",\n",
    "  \"System Piloting Evidence\": \"\",\n",
    "  \"System Piloting Reason\": \"\",\n",
    "\n",
    "  \"Confidence\": \"High/Medium/Low\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "INPUT PARAGRAPH:\n",
    "{paragraph}\n",
    "\n",
    "DESIGNATORS (regex extracted):\n",
    "{designators if designators else \"None\"}\n",
    "\n",
    "RULE-BASED PILOTING:\n",
    "{piloting_rule}\n",
    "\n",
    "RAG SIMILAR EXAMPLES:\n",
    "{json.dumps(rag_examples, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        result = json.loads(completion.choices[0].message.content)\n",
    "\n",
    "        # Piloting override\n",
    "        result[\"System Piloting\"] = piloting_rule\n",
    "        if not result.get(\"System Piloting Reason\"):\n",
    "            result[\"System Piloting Reason\"] = \"Piloting derived using deterministic rules.\"\n",
    "        if not result.get(\"System Piloting Evidence\"):\n",
    "            result[\"System Piloting Evidence\"] = \"Not Found\"\n",
    "\n",
    "        # Ensure flat\n",
    "        for k, v in result.items():\n",
    "            if isinstance(v, (dict, list)):\n",
    "                result[k] = str(v)\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"Market Segment\": \"\",\n",
    "            \"System Type (General)\": \"\",\n",
    "            \"System Type (Specific)\": \"\",\n",
    "            \"System Name (General)\": \"\",\n",
    "            \"System Name (Specific)\": \"\",\n",
    "            \"System Piloting\": piloting_rule,\n",
    "            \"Market Segment Evidence\": \"Not Found\",\n",
    "            \"System Type (General) Evidence\": \"Not Found\",\n",
    "            \"System Type (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Name (General) Evidence\": \"Not Found\",\n",
    "            \"System Name (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Piloting Evidence\": \"Not Found\",\n",
    "            \"Market Segment Reason\": \"\",\n",
    "            \"System Type (General) Reason\": \"\",\n",
    "            \"System Type (Specific) Reason\": \"\",\n",
    "            \"System Name (General) Reason\": \"\",\n",
    "            \"System Name (Specific) Reason\": \"\",\n",
    "            \"System Piloting Reason\": \"Piloting derived using deterministic rules.\",\n",
    "            \"Confidence\": \"Low\",\n",
    "            \"Error\": str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "# --- AGENT 4: CONTRACT (Supplier Match FIXED ‚úÖ‚úÖ‚úÖ) ---\n",
    "class ContractInfoInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "    contract_date: str = Field(description=\"Signed date.\")\n",
    "\n",
    "@tool(\"contract_extractor\")\n",
    "def contract_extractor(paragraph: str, contract_date: str):\n",
    "    system_instruction = \"\"\"\n",
    "You are a Defense Contract Financial Analyst. Extract data strictly following these SOP rules:\n",
    "\n",
    "1) Supplier Name: Extract exact company name as written in paragraph.\n",
    "2) Program Type: Procurement / Training / MRO/Support / RDT&E / Upgrade / Other Service\n",
    "3) Value Certainty:\n",
    "   - Confirmed: fixed price/obligated stated\n",
    "   - Estimated: ceiling/potential/IDIQ/multi-award\n",
    "4) Quantity: number or Not Applicable\n",
    "5) G2G/B2G:\n",
    "   - G2G only if Foreign Military Sales (FMS)\n",
    "   - else B2G\n",
    "6) Completion Date: only needed for MRO duration calc\n",
    "\n",
    "Return JSON only.\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "Analyze contract:\n",
    "\"{paragraph}\"\n",
    "\n",
    "Signed Date: {contract_date}\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"raw_supplier_name\": \"\",\n",
    "  \"program_type\": \"\",\n",
    "  \"value_million_raw\": \"\",\n",
    "  \"currency_code\": \"\",\n",
    "  \"value_certainty\": \"\",\n",
    "  \"quantity\": \"\",\n",
    "  \"completion_date_text\": \"\",\n",
    "  \"g2g_b2g\": \"\",\n",
    "  \"value_note\": \"\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_instruction},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        return {\"Error\": str(e)}\n",
    "\n",
    "    raw_supplier = str(raw.get(\"raw_supplier_name\", \"\")).strip()\n",
    "\n",
    "    # ‚úÖ Fallback supplier extraction if LLM returns blank\n",
    "    if not raw_supplier:\n",
    "        m = re.search(r\"^(.*?)( is awarded| is being awarded)\", paragraph, flags=re.IGNORECASE)\n",
    "        if m:\n",
    "            raw_supplier = m.group(1).strip()\n",
    "\n",
    "    # ‚úÖ FINAL supplier must come from suppliers.json best match\n",
    "    final_supplier, supplier_match_score = get_best_supplier_match(raw_supplier)\n",
    "\n",
    "    prog_type = raw.get(\"program_type\", \"Unknown\")\n",
    "    mro_months = calculate_mro_months(contract_date, raw.get(\"completion_date_text\"), prog_type)\n",
    "\n",
    "    try:\n",
    "        val_str = str(raw.get(\"value_million_raw\", \"0\")).replace(\",\", \"\").replace(\"$\", \"\")\n",
    "        val_float = float(val_str)\n",
    "        val_formatted = \"{:.3f}\".format(val_float)\n",
    "    except:\n",
    "        val_formatted = \"0.000\"\n",
    "\n",
    "    try:\n",
    "        dt = pd.to_datetime(contract_date)\n",
    "        sign_month = dt.strftime(\"%B\")\n",
    "        sign_year = str(dt.year)\n",
    "    except:\n",
    "        sign_month, sign_year = \"Unknown\", \"Unknown\"\n",
    "\n",
    "    val_note = raw.get(\"value_note\", \"Not Applicable\")\n",
    "    if \"split\" in paragraph.lower() and val_note == \"Not Applicable\":\n",
    "        val_note = \"Split contract; value distribution unclear.\"\n",
    "\n",
    "    return {\n",
    "        # ‚úÖ Final output supplier from JSON\n",
    "        \"Supplier Name\": final_supplier,\n",
    "\n",
    "        # ‚úÖ Debug (optional but VERY useful)\n",
    "        \"Supplier Name Raw (LLM)\": raw_supplier,\n",
    "        \"Supplier Match Score\": round(float(supplier_match_score), 3),\n",
    "\n",
    "        \"Program Type\": prog_type,\n",
    "        \"Expected MRO Contract Duration (Months)\": mro_months,\n",
    "        \"Quantity\": raw.get(\"quantity\", \"Not Applicable\"),\n",
    "        \"Value Certainty\": raw.get(\"value_certainty\", \"Confirmed\"),\n",
    "        \"Value (Million)\": val_formatted,\n",
    "        \"Currency\": raw.get(\"currency_code\", \"USD$\"),\n",
    "        \"Value (USD$ Million)\": val_formatted,\n",
    "        \"Value Note (If Any)\": val_note,\n",
    "        \"G2G/B2G\": raw.get(\"g2g_b2g\", \"B2G\"),\n",
    "        \"Signing Month\": sign_month,\n",
    "        \"Signing Year\": sign_year\n",
    "    }\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ 8. LANGGRAPH PIPELINE\n",
    "# ==============================================================================\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input_text: str\n",
    "    input_date: str\n",
    "    input_url: str\n",
    "    final_data: dict\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "\n",
    "def stage_1_sourcing(state: AgentState):\n",
    "    res = sourcing_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"url\": state[\"input_url\"],\n",
    "        \"date\": state[\"input_date\"]\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "def stage_2_geography(state: AgentState):\n",
    "    res = geography_extractor.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "def stage_3_system(state: AgentState):\n",
    "    res = system_classifier.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "def stage_4_contract(state: AgentState):\n",
    "    res = contract_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"contract_date\": state[\"input_date\"]\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Stage1\", stage_1_sourcing)\n",
    "workflow.add_node(\"Stage2\", stage_2_geography)\n",
    "workflow.add_node(\"Stage3\", stage_3_system)\n",
    "workflow.add_node(\"Stage4\", stage_4_contract)\n",
    "\n",
    "workflow.add_edge(START, \"Stage1\")\n",
    "workflow.add_edge(\"Stage1\", \"Stage2\")\n",
    "workflow.add_edge(\"Stage2\", \"Stage3\")\n",
    "workflow.add_edge(\"Stage3\", \"Stage4\")\n",
    "workflow.add_edge(\"Stage4\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ‚úÖ 9. EXECUTION & OUTPUT FORMAT\n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(f\"üìÇ Loading Input File: {INPUT_EXCEL_PATH}...\")\n",
    "\n",
    "    try:\n",
    "        df_input = pd.read_excel(INPUT_EXCEL_PATH)\n",
    "\n",
    "        required_cols = [\"Source URL\", \"Contract Date\", \"Contract Description\"]\n",
    "        if not all(col in df_input.columns for col in required_cols):\n",
    "            raise ValueError(f\"Excel file must contain columns: {required_cols}\")\n",
    "\n",
    "        print(f\"üöÄ Processing {len(df_input)} rows...\")\n",
    "        results = []\n",
    "\n",
    "        for index, row in df_input.iterrows():\n",
    "            print(f\"   -> Row {index + 1}...\")\n",
    "\n",
    "            desc = str(row[\"Contract Description\"]) if pd.notna(row[\"Contract Description\"]) else \"\"\n",
    "            c_date = str(row[\"Contract Date\"]) if pd.notna(row[\"Contract Date\"]) else str(datetime.date.today())\n",
    "            c_url = str(row[\"Source URL\"]) if pd.notna(row[\"Source URL\"]) else \"\"\n",
    "\n",
    "            initial_state = {\n",
    "                \"input_text\": desc,\n",
    "                \"input_date\": c_date,\n",
    "                \"input_url\": c_url,\n",
    "                \"final_data\": {},\n",
    "                \"messages\": []\n",
    "            }\n",
    "\n",
    "            output_state = app.invoke(initial_state)\n",
    "            results.append(output_state[\"final_data\"])\n",
    "\n",
    "        df_final = pd.DataFrame(results)\n",
    "\n",
    "        FINAL_COLUMNS = [\n",
    "            \"Customer Region\", \"Customer Country\", \"Customer Operator\",\n",
    "            \"Supplier Region\", \"Supplier Country\", \"Domestic Content\",\n",
    "\n",
    "            \"Market Segment\", \"Market Segment Evidence\", \"Market Segment Reason\",\n",
    "            \"System Type (General)\", \"System Type (General) Evidence\", \"System Type (General) Reason\",\n",
    "            \"System Type (Specific)\", \"System Type (Specific) Evidence\", \"System Type (Specific) Reason\",\n",
    "            \"System Name (General)\", \"System Name (General) Evidence\", \"System Name (General) Reason\",\n",
    "            \"System Name (Specific)\", \"System Name (Specific) Evidence\", \"System Name (Specific) Reason\",\n",
    "            \"System Piloting\", \"System Piloting Evidence\", \"System Piloting Reason\",\n",
    "            \"Confidence\",\n",
    "\n",
    "            # ‚úÖ Supplier Debug (optional but recommended)\n",
    "            \"Supplier Name Raw (LLM)\",\n",
    "            \"Supplier Match Score\",\n",
    "\n",
    "            \"Supplier Name\", \"Program Type\", \"Expected MRO Contract Duration (Months)\",\n",
    "            \"Quantity\", \"Value Certainty\", \"Value (Million)\", \"Currency\",\n",
    "            \"Value (USD$ Million)\", \"Value Note (If Any)\", \"G2G/B2G\",\n",
    "            \"Signing Month\", \"Signing Year\",\n",
    "\n",
    "            \"Description of Contract\",\n",
    "            \"Additional Notes (Internal Only)\",\n",
    "            \"Source Link(s)\",\n",
    "            \"Contract Date\",\n",
    "            \"Reported Date (By SGA)\"\n",
    "        ]\n",
    "\n",
    "        df_final = df_final.reindex(columns=FINAL_COLUMNS, fill_value=\"\")\n",
    "        df_final.to_excel(OUTPUT_EXCEL_PATH, index=False)\n",
    "\n",
    "        print(\"\\n‚úÖ Processing Complete!\")\n",
    "        print(f\"üíæ File saved to: {OUTPUT_EXCEL_PATH}\")\n",
    "        print(df_final.head().to_string())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ca495b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import difflib\n",
    "import pickle\n",
    "import datetime\n",
    "from typing import Annotated, TypedDict, List, Dict, Any\n",
    "\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import getpass\n",
    "\n",
    "# LangGraph / LangChain\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "\n",
    "# Excel formatting\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill, Font\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 0) DEBUG LOGGING HELPERS\n",
    "# ==============================================================================\n",
    "\n",
    "def log_block(title: str, content: str):\n",
    "    \"\"\"\n",
    "    Prints a clearly separated block in console logs.\n",
    "\n",
    "    Why this matters:\n",
    "    - You want to validate LLM extraction decisions row-by-row.\n",
    "    - Helps debugging issues in specific stages like System Classification or Split logic.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(title)\n",
    "    print(\"=\" * 100)\n",
    "    print(content)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 1) RAG RETRIEVER (FAISS + Metadata)\n",
    "# ==============================================================================\n",
    "\n",
    "class SystemKBRetriever:\n",
    "    \"\"\"\n",
    "    RAG Retriever for Defense System Classification.\n",
    "\n",
    "    Purpose:\n",
    "    - Loads FAISS vector index (system_kb.faiss)\n",
    "    - Loads metadata rows (system_kb_meta.pkl)\n",
    "    - Retrieves top-k similar historical examples\n",
    "      using semantic embeddings over \"Description of Contract\".\n",
    "\n",
    "    Why this improves accuracy:\n",
    "    - Your taxonomy-based system classification becomes consistent\n",
    "      because the model sees \"known-good labeled examples\" from your excel KB.\n",
    "\n",
    "    Output:\n",
    "    retrieve(query_text) returns:\n",
    "      [\n",
    "        {\"score\": float, \"meta\": {all KB columns}},\n",
    "        ...\n",
    "      ]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kb_dir: str, embed_model: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self.kb_dir = kb_dir\n",
    "        self.embed_model = embed_model\n",
    "\n",
    "        index_path = os.path.join(kb_dir, \"system_kb.faiss\")\n",
    "        meta_path = os.path.join(kb_dir, \"system_kb_meta.pkl\")\n",
    "\n",
    "        if not os.path.exists(index_path) or not os.path.exists(meta_path):\n",
    "            raise FileNotFoundError(\n",
    "                f\"‚ùå KB files not found in: {kb_dir}\\n\"\n",
    "                f\"Expected:\\n- {index_path}\\n- {meta_path}\\n\\n\"\n",
    "                f\"Build the KB first using your KB builder script.\"\n",
    "            )\n",
    "\n",
    "        print(f\"‚úÖ Loading FAISS Index: {index_path}\")\n",
    "        self.index = faiss.read_index(index_path)\n",
    "\n",
    "        print(f\"‚úÖ Loading KB Metadata: {meta_path}\")\n",
    "        with open(meta_path, \"rb\") as f:\n",
    "            self.meta = pickle.load(f)\n",
    "\n",
    "        print(f\"‚úÖ KB Loaded rows: {len(self.meta)}\")\n",
    "\n",
    "        self.embedder = None\n",
    "\n",
    "    def _lazy_load_embedder(self):\n",
    "        \"\"\"\n",
    "        Lazy-load the embedding model only when needed.\n",
    "\n",
    "        Why:\n",
    "        - Faster pipeline startup\n",
    "        - Avoids memory overhead until the first retrieval call\n",
    "        \"\"\"\n",
    "        if self.embedder is None:\n",
    "            from sentence_transformers import SentenceTransformer\n",
    "            self.embedder = SentenceTransformer(self.embed_model)\n",
    "\n",
    "    def retrieve(self, query_text: str, top_k: int = 3):\n",
    "        \"\"\"\n",
    "        Retrieves top-k semantic matches from the KB.\n",
    "\n",
    "        Parameters:\n",
    "        - query_text: input paragraph\n",
    "        - top_k: number of examples\n",
    "\n",
    "        Returns:\n",
    "        - List of dicts with score + metadata row.\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "\n",
    "        query_text = str(query_text).strip()\n",
    "        if not query_text:\n",
    "            return []\n",
    "\n",
    "        self._lazy_load_embedder()\n",
    "\n",
    "        q_emb = self.embedder.encode([query_text], normalize_embeddings=True).astype(\"float32\")\n",
    "        scores, idxs = self.index.search(q_emb, top_k)\n",
    "\n",
    "        results = []\n",
    "        for score, idx in zip(scores[0], idxs[0]):\n",
    "            if idx < 0:\n",
    "                continue\n",
    "            results.append({\"score\": float(score), \"meta\": self.meta[idx]})\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2) CONFIGURATION & FILE PATHS\n",
    "# ==============================================================================\n",
    "\n",
    "TAXONOMY_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\taxonomy.json\"\n",
    "SUPPLIERS_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\suppliers.json\"\n",
    "INPUT_EXCEL_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\data\\source_file.xlsx\"\n",
    "OUTPUT_EXCEL_PATH = \"Processed_Defense_Data.xlsx\"\n",
    "\n",
    "RAG_KB_DIR = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\system_kb_store\"\n",
    "\n",
    "\n",
    "# Setup API key once\n",
    "if \"LLMFOUNDRY_TOKEN\" not in os.environ:\n",
    "    os.environ[\"LLMFOUNDRY_TOKEN\"] = getpass.getpass(\"Enter the LLM Foundry API Key: \")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=f'{os.environ.get(\"LLMFOUNDRY_TOKEN\")}:my-test-project',\n",
    "    base_url=\"https://llmfoundry.straive.com/openai/v1/\",\n",
    ")\n",
    "\n",
    "retriever = SystemKBRetriever(kb_dir=RAG_KB_DIR)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3) LOAD JSON HELPERS\n",
    "# ==============================================================================\n",
    "\n",
    "def load_json_file(filename, default_value):\n",
    "    \"\"\"\n",
    "    Loads a JSON file safely.\n",
    "\n",
    "    Why:\n",
    "    - Your taxonomy and supplier list must load reliably\n",
    "    - Prevents pipeline crash if the file is missing\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            print(f\"‚úÖ Loaded: {filename}\")\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Warning: Could not load {filename} ({e}). Using default.\")\n",
    "        return default_value\n",
    "\n",
    "\n",
    "raw_taxonomy = load_json_file(TAXONOMY_PATH, {})\n",
    "TAXONOMY_STR = json.dumps(raw_taxonomy, separators=(\",\", \":\"))\n",
    "\n",
    "SUPPLIER_LIST = load_json_file(SUPPLIERS_PATH, [\n",
    "    \"Dell Inc\", \"Boeing\", \"Lockheed Martin\", \"Raytheon Technologies\",\n",
    "    \"Northrop Grumman\", \"L3Harris\", \"BAE Systems\", \"General Dynamics\"\n",
    "])\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4) RULE BOOK + GEOGRAPHY\n",
    "# ==============================================================================\n",
    "\n",
    "RULE_BOOK = {\n",
    "    \"defensive_countermeasures\": {\n",
    "        \"triggers\": [\"flare\", \"chaff\", \"countermeasure\", \"decoy\", \"mju-\", \"ale-\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Defensive Systems', Specific: 'Defensive Aid Suite'\"\n",
    "    },\n",
    "    \"radars_and_sensors\": {\n",
    "        \"triggers\": [\"radar\", \"sonar\", \"sensor\", \"an/apy\", \"an/tpy\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Sensors'\"\n",
    "    },\n",
    "    \"ammunition\": {\n",
    "        \"triggers\": [\"cartridge\", \"round\", \"projectile\", \" 5.56\", \" 7.62\", \"ammo\"],\n",
    "        \"guidance\": \"Market Segment: 'Weapon Systems', System Type (General): 'Ammunition'\"\n",
    "    }\n",
    "}\n",
    "\n",
    "GEOGRAPHY_MAPPING = {\n",
    "    \"North America\": [\"USA\", \"United States\", \"US\", \"United States of America\", \"Canada\", \"America\"],\n",
    "    \"Europe\": [\"UK\", \"United Kingdom\", \"Ukraine\", \"Germany\", \"France\", \"Italy\", \"Spain\", \"Poland\", \"Netherlands\",\n",
    "               \"Norway\", \"Sweden\", \"Finland\", \"Denmark\", \"Belgium\"],\n",
    "    \"Asia-Pacific\": [\"Australia\", \"Japan\", \"South Korea\", \"Taiwan\", \"India\", \"Singapore\", \"New Zealand\"],\n",
    "    \"Middle East and North Africa\": [\"Israel\", \"Saudi Arabia\", \"UAE\", \"United Arab Emirates\", \"Egypt\", \"Qatar\", \"Kuwait\", \"Iraq\"],\n",
    "    \"International Organisations\": [\"NATO\", \"EU\", \"IFU\", \"UN\", \"NSPA\"]\n",
    "}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 5) BASE HELPERS (Supplier + Dates + Region + Designators)\n",
    "# ==============================================================================\n",
    "\n",
    "def get_best_supplier_match(extracted_name: str):\n",
    "    \"\"\"\n",
    "    Supplier standardization function.\n",
    "\n",
    "    Steps:\n",
    "    1) Exact match with suppliers.json\n",
    "    2) Fuzzy match (difflib) to find best candidate\n",
    "    3) If no match, return extracted text\n",
    "\n",
    "    Goal:\n",
    "    - Ensure supplier name output matches \"standard supplier taxonomy\"\n",
    "      used by your client.\n",
    "    \"\"\"\n",
    "    if not extracted_name or str(extracted_name).strip().lower() in [\"unknown\", \"n/a\", \"not applicable\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    clean_name = str(extracted_name).strip()\n",
    "\n",
    "    supplier_map = {s.lower(): s for s in SUPPLIER_LIST}\n",
    "    if clean_name.lower() in supplier_map:\n",
    "        return supplier_map[clean_name.lower()]\n",
    "\n",
    "    matches = difflib.get_close_matches(clean_name, SUPPLIER_LIST, n=1, cutoff=0.6)\n",
    "    return matches[0] if matches else clean_name\n",
    "\n",
    "\n",
    "def calculate_mro_months(start_date_str, end_date_text, program_type):\n",
    "    \"\"\"\n",
    "    Calculates MRO duration in months.\n",
    "\n",
    "    Rule:\n",
    "    - ONLY valid if program_type == \"MRO/Support\"\n",
    "    \"\"\"\n",
    "    if program_type != \"MRO/Support\":\n",
    "        return \"Not Applicable\"\n",
    "    try:\n",
    "        if not start_date_str or not end_date_text:\n",
    "            return \"Not Applicable\"\n",
    "\n",
    "        start = pd.to_datetime(start_date_str, dayfirst=True)\n",
    "        end = parser.parse(str(end_date_text), fuzzy=True)\n",
    "\n",
    "        diff = relativedelta(end, start)\n",
    "        total_months = diff.years * 12 + diff.months\n",
    "        return str(max(0, int(total_months)))\n",
    "    except:\n",
    "        return \"Not Applicable\"\n",
    "\n",
    "\n",
    "def get_region_for_country(country_name):\n",
    "    \"\"\"\n",
    "    Maps country name -> region string.\n",
    "    Uses GEOGRAPHY_MAPPING.\n",
    "    \"\"\"\n",
    "    if not country_name or str(country_name).strip().lower() in [\"unknown\", \"n/a\", \"not applicable\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    clean = str(country_name).strip().lower()\n",
    "\n",
    "    if clean in [\"us\", \"usa\", \"u.s.\", \"united states\", \"united states of america\"]:\n",
    "        return \"North America\"\n",
    "    if clean in [\"uk\", \"u.k.\", \"britain\", \"great britain\"]:\n",
    "        return \"Europe\"\n",
    "\n",
    "    for region, countries in GEOGRAPHY_MAPPING.items():\n",
    "        if any(c.lower() == clean for c in countries):\n",
    "            return region\n",
    "\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "DESIGNATOR_PATTERNS = [\n",
    "    r\"\\bDDG[-\\s]?\\d+\\b\", r\"\\bCVN[-\\s]?\\d+\\b\", r\"\\bSSN[-\\s]?\\d+\\b\",\n",
    "    r\"\\bLCS[-\\s]?\\d+\\b\", r\"\\bLPD[-\\s]?\\d+\\b\", r\"\\bLHA[-\\s]?\\d+\\b\", r\"\\bLHD[-\\s]?\\d+\\b\",\n",
    "    r\"\\bF-\\d+\\b\", r\"\\bB-\\d+\\b\", r\"\\bC-\\d+\\b\", r\"\\bA-\\d+\\b\",\n",
    "    r\"\\bMQ-\\d+\\b\", r\"\\bRQ-\\d+\\b\",\n",
    "    r\"\\bAN\\/[A-Z0-9\\-]+\\b\",\n",
    "    r\"\\b(AIM|AGM|SM|RIM|MIM)-\\d+\\b\",\n",
    "]\n",
    "\n",
    "def extract_designators(text: str):\n",
    "    \"\"\"\n",
    "    Extracts common defense platform designators from paragraph.\n",
    "\n",
    "    Examples:\n",
    "    - DDG-51, CVN-78\n",
    "    - MQ-9, RQ-4\n",
    "    - AIM-9X\n",
    "    - AN/APY-10\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    found = []\n",
    "    for pat in DESIGNATOR_PATTERNS:\n",
    "        found.extend(re.findall(pat, text, flags=re.IGNORECASE))\n",
    "    cleaned = []\n",
    "    for f in found:\n",
    "        cleaned.append(f.upper().replace(\" \", \"\").replace(\"--\", \"-\"))\n",
    "    final = []\n",
    "    seen = set()\n",
    "    for x in cleaned:\n",
    "        if x not in seen:\n",
    "            final.append(x)\n",
    "            seen.add(x)\n",
    "    return final\n",
    "\n",
    "\n",
    "def detect_piloting_rule_based(text: str, designators: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Deterministic piloting classification to reduce model errors.\n",
    "\n",
    "    Output:\n",
    "    - \"Crewed\"\n",
    "    - \"Uncrewed\"\n",
    "    - \"Not Applicable\"\n",
    "    \"\"\"\n",
    "    t = str(text).lower()\n",
    "\n",
    "    if any(d.startswith((\"MQ-\", \"RQ-\")) for d in designators):\n",
    "        return \"Uncrewed\"\n",
    "    if any(k in t for k in [\"unmanned\", \"uav\", \"drone\", \"autonomous\"]):\n",
    "        return \"Uncrewed\"\n",
    "\n",
    "    if any(d.startswith((\"DDG\", \"CVN\", \"SSN\", \"LCS\", \"LPD\", \"LHA\", \"LHD\")) for d in designators):\n",
    "        return \"Crewed\"\n",
    "    if \"uss \" in t:\n",
    "        return \"Crewed\"\n",
    "\n",
    "    return \"Not Applicable\"\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 6) ENHANCED SPLIT ENGINE (Multi-operator / Multi-country / Multi-supplier / Multi-value)\n",
    "# ==============================================================================\n",
    "\n",
    "def parse_operator_quantity_allocations(paragraph: str):\n",
    "    \"\"\"\n",
    "    Detects quantity allocations by operator.\n",
    "\n",
    "    Example patterns:\n",
    "      - \"212 for the Navy\"\n",
    "      - \"187 for the Air Force\"\n",
    "      - \"84 for Foreign Military Sales (FMS) customers\"\n",
    "\n",
    "    Output:\n",
    "      [\n",
    "        {\"operator\": \"Navy\", \"quantity\": \"212\", \"g2g_b2g\": \"B2G\"},\n",
    "        {\"operator\": \"Foreign Assistance\", \"quantity\": \"84\", \"g2g_b2g\": \"G2G\"}\n",
    "      ]\n",
    "    \"\"\"\n",
    "    text = str(paragraph)\n",
    "    allocations = []\n",
    "\n",
    "    pattern = r\"(\\d+)\\s+for\\s+the\\s+(Navy|Air Force|Army|Marine Corps)\"\n",
    "    matches = re.findall(pattern, text, flags=re.IGNORECASE)\n",
    "    for qty, op in matches:\n",
    "        allocations.append({\"operator\": op.title(), \"quantity\": qty, \"g2g_b2g\": \"B2G\"})\n",
    "\n",
    "    fms_pattern = r\"(\\d+)\\s+for\\s+(?:Foreign Military Sales\\s*\\(FMS\\)\\s*customers|FMS\\s*customers|a\\s*FMS\\s*customer|FMS)\"\n",
    "    fms_matches = re.findall(fms_pattern, text, flags=re.IGNORECASE)\n",
    "    for qty in fms_matches:\n",
    "        allocations.append({\"operator\": \"Foreign Assistance\", \"quantity\": qty, \"g2g_b2g\": \"G2G\"})\n",
    "\n",
    "    unique = []\n",
    "    seen = set()\n",
    "    for a in allocations:\n",
    "        key = (a[\"operator\"], a[\"quantity\"], a[\"g2g_b2g\"])\n",
    "        if key not in seen:\n",
    "            unique.append(a)\n",
    "            seen.add(key)\n",
    "\n",
    "    return unique\n",
    "\n",
    "\n",
    "def parse_fms_countries(paragraph: str):\n",
    "    \"\"\"\n",
    "    Extracts FMS customer country list.\n",
    "\n",
    "    Looks for:\n",
    "      'governments of Australia, Bahrain, Belgium...'\n",
    "\n",
    "    Output: [\"Australia\", \"Bahrain\", ...]\n",
    "    \"\"\"\n",
    "    text = str(paragraph)\n",
    "\n",
    "    m = re.search(\n",
    "        r\"governments of (.+?)(?:\\.\\s| Work will be performed| Fiscal| This contract|$)\",\n",
    "        text,\n",
    "        flags=re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "    if not m:\n",
    "        return []\n",
    "\n",
    "    block = m.group(1)\n",
    "    raw = re.split(r\",|\\band\\b\", block)\n",
    "\n",
    "    countries = []\n",
    "    for c in raw:\n",
    "        c = c.strip()\n",
    "        if 2 < len(c) <= 40:\n",
    "            countries.append(c)\n",
    "\n",
    "    final = []\n",
    "    seen = set()\n",
    "    for c in countries:\n",
    "        if c.lower() not in seen:\n",
    "            final.append(c)\n",
    "            seen.add(c.lower())\n",
    "\n",
    "    return final\n",
    "\n",
    "\n",
    "def parse_multiple_suppliers(paragraph: str):\n",
    "    \"\"\"\n",
    "    Attempts to detect multi-supplier contract statements.\n",
    "\n",
    "    Examples:\n",
    "    - \"Lockheed Martin and Raytheon were awarded...\"\n",
    "    - \"Boeing, Northrop Grumman, and General Dynamics...\"\n",
    "    - \"multiple awardees include...\"\n",
    "\n",
    "    Output:\n",
    "      [\"Lockheed Martin\", \"Raytheon\"]\n",
    "    \"\"\"\n",
    "    text = str(paragraph)\n",
    "    lower = text.lower()\n",
    "\n",
    "    if \" and \" not in lower and \",\" not in lower:\n",
    "        return []\n",
    "\n",
    "    candidates = []\n",
    "    for supplier in SUPPLIER_LIST:\n",
    "        if supplier.lower() in lower:\n",
    "            candidates.append(supplier)\n",
    "\n",
    "    # If multiple suppliers found ‚Üí split required\n",
    "    candidates = list(dict.fromkeys(candidates))\n",
    "    return candidates if len(candidates) >= 2 else []\n",
    "\n",
    "\n",
    "def parse_multiple_values(paragraph: str):\n",
    "    \"\"\"\n",
    "    Detects multiple financial values in paragraph.\n",
    "\n",
    "    Examples:\n",
    "    - \"$328,156,454\"\n",
    "    - \"ceiling value of $500 million\"\n",
    "    - \"base value $20 million and option value $10 million\"\n",
    "\n",
    "    Output:\n",
    "      [\"328,156,454\", \"500\", ...] (raw strings)\n",
    "    \"\"\"\n",
    "    text = str(paragraph)\n",
    "\n",
    "    # $328,156,454\n",
    "    money_pattern = r\"\\$([\\d,]+(?:\\.\\d+)?)\"\n",
    "    vals = re.findall(money_pattern, text)\n",
    "\n",
    "    # remove duplicates\n",
    "    vals = list(dict.fromkeys(vals))\n",
    "    return vals\n",
    "\n",
    "\n",
    "def parse_share_percentages(paragraph: str):\n",
    "    \"\"\"\n",
    "    Detects share splits like:\n",
    "      '60% for Company A and 40% for Company B'\n",
    "\n",
    "    Output:\n",
    "      [\n",
    "        {\"supplier\": \"Company A\", \"percentage\": \"60\"},\n",
    "        {\"supplier\": \"Company B\", \"percentage\": \"40\"}\n",
    "      ]\n",
    "    \"\"\"\n",
    "    text = str(paragraph)\n",
    "    result = []\n",
    "\n",
    "    percent_pattern = r\"(\\d+)\\s?%\\s+(?:for\\s+)?([A-Z][A-Za-z0-9&\\-\\.\\s]+)\"\n",
    "    matches = re.findall(percent_pattern, text)\n",
    "\n",
    "    for pct, name in matches:\n",
    "        name = name.strip()\n",
    "        # Try to best-match supplier name list\n",
    "        supplier_std = get_best_supplier_match(name)\n",
    "        result.append({\"supplier\": supplier_std, \"percentage\": pct})\n",
    "\n",
    "    # keep only valid multi splits\n",
    "    if len(result) >= 2:\n",
    "        return result\n",
    "    return []\n",
    "\n",
    "\n",
    "def detect_multi_country_presence(paragraph: str):\n",
    "    \"\"\"\n",
    "    Lightweight country scan from mapping lists to detect multi-country mention.\n",
    "    \"\"\"\n",
    "    text = str(paragraph).lower()\n",
    "    countries_found = set()\n",
    "\n",
    "    for region, countries in GEOGRAPHY_MAPPING.items():\n",
    "        for c in countries:\n",
    "            if c.lower() in text:\n",
    "                countries_found.add(c)\n",
    "\n",
    "    return list(countries_found)\n",
    "\n",
    "\n",
    "def split_rows_engine(base_row: dict, paragraph: str):\n",
    "    \"\"\"\n",
    "    MASTER SPLIT ENGINE.\n",
    "\n",
    "    Goal:\n",
    "    - Takes one extracted row (base_row)\n",
    "    - Produces 1..N output rows depending on split conditions\n",
    "\n",
    "    Split triggers supported:\n",
    "    1) Operator allocation splits (Navy/Air Force/FMS)\n",
    "    2) Multi-country FMS customer lists\n",
    "    3) Multi supplier mentions\n",
    "    4) Multi values inside same paragraph\n",
    "    5) Percent share splits\n",
    "    6) Multi-country region scan\n",
    "\n",
    "    Important:\n",
    "    - Only split-driving columns should change.\n",
    "    - Shared columns remain consistent.\n",
    "    \"\"\"\n",
    "    paragraph = str(paragraph)\n",
    "\n",
    "    allocations = parse_operator_quantity_allocations(paragraph)\n",
    "    fms_countries = parse_fms_countries(paragraph)\n",
    "    multi_suppliers = parse_multiple_suppliers(paragraph)\n",
    "    multi_values = parse_multiple_values(paragraph)\n",
    "    share_splits = parse_share_percentages(paragraph)\n",
    "    multi_countries = detect_multi_country_presence(paragraph)\n",
    "\n",
    "    split_reasons = []\n",
    "\n",
    "    if allocations:\n",
    "        split_reasons.append(\"Multi-operator allocation found\")\n",
    "    if fms_countries:\n",
    "        split_reasons.append(\"FMS multi-country list found\")\n",
    "    if multi_suppliers:\n",
    "        split_reasons.append(\"Multi-supplier mention found\")\n",
    "    if len(multi_values) >= 2:\n",
    "        split_reasons.append(\"Multiple financial values found\")\n",
    "    if share_splits:\n",
    "        split_reasons.append(\"Percentage share split found\")\n",
    "    if len(multi_countries) >= 2:\n",
    "        split_reasons.append(\"Multiple countries detected in text\")\n",
    "\n",
    "    if not split_reasons:\n",
    "        base_row[\"Split Flag\"] = \"No\"\n",
    "        base_row[\"Split Reason\"] = \"No split condition found\"\n",
    "        return [base_row]\n",
    "\n",
    "    # Start with one base row\n",
    "    rows = [base_row.copy()]\n",
    "    base_reason = \" | \".join(split_reasons)\n",
    "\n",
    "    # 1) Multi supplier split\n",
    "    if multi_suppliers:\n",
    "        new_rows = []\n",
    "        for r in rows:\n",
    "            for s in multi_suppliers:\n",
    "                rr = r.copy()\n",
    "                rr[\"Supplier Name\"] = s\n",
    "                rr[\"Split Flag\"] = \"Yes\"\n",
    "                rr[\"Split Reason\"] = f\"{base_reason} (Supplier split)\"\n",
    "                new_rows.append(rr)\n",
    "        rows = new_rows\n",
    "\n",
    "    # 2) Operator split\n",
    "    if allocations:\n",
    "        new_rows = []\n",
    "        for r in rows:\n",
    "            for alloc in allocations:\n",
    "                rr = r.copy()\n",
    "                rr[\"Customer Operator\"] = alloc[\"operator\"]\n",
    "                rr[\"Quantity\"] = alloc[\"quantity\"]\n",
    "                rr[\"G2G/B2G\"] = alloc[\"g2g_b2g\"]\n",
    "                rr[\"Split Flag\"] = \"Yes\"\n",
    "                rr[\"Split Reason\"] = f\"{base_reason} (Operator/Quantity split)\"\n",
    "                new_rows.append(rr)\n",
    "        rows = new_rows\n",
    "\n",
    "    # 3) Share split ‚Üí can modify Value Note\n",
    "    if share_splits:\n",
    "        new_rows = []\n",
    "        for r in rows:\n",
    "            for sh in share_splits:\n",
    "                rr = r.copy()\n",
    "                rr[\"Supplier Name\"] = sh[\"supplier\"]\n",
    "                rr[\"Value Note (If Any)\"] = f\"Share split detected: {sh['percentage']}%\"\n",
    "                rr[\"Split Flag\"] = \"Yes\"\n",
    "                rr[\"Split Reason\"] = f\"{base_reason} (Share % split)\"\n",
    "                new_rows.append(rr)\n",
    "        rows = new_rows\n",
    "\n",
    "    # 4) Multi financial values split (optional)\n",
    "    # Here we do NOT override your Value (Million) because that comes from contract_extractor,\n",
    "    # but we store in Value Note as cross-reference.\n",
    "    if len(multi_values) >= 2:\n",
    "        for r in rows:\n",
    "            note = r.get(\"Value Note (If Any)\", \"Not Applicable\")\n",
    "            r[\"Value Note (If Any)\"] = f\"{note} | Multiple values detected: {multi_values[:5]}\"\n",
    "\n",
    "    # 5) FMS country split applied ONLY when G2G rows exist\n",
    "    if fms_countries:\n",
    "        final_rows = []\n",
    "        for r in rows:\n",
    "            if r.get(\"G2G/B2G\") == \"G2G\":\n",
    "                for c in fms_countries:\n",
    "                    rr = r.copy()\n",
    "                    rr[\"Customer Country\"] = c\n",
    "                    rr[\"Customer Region\"] = get_region_for_country(c)\n",
    "                    rr[\"Split Flag\"] = \"Yes\"\n",
    "                    rr[\"Split Reason\"] = f\"{base_reason} (FMS country split)\"\n",
    "                    final_rows.append(rr)\n",
    "            else:\n",
    "                final_rows.append(r)\n",
    "        rows = final_rows\n",
    "\n",
    "    # Always ensure flags exist\n",
    "    for r in rows:\n",
    "        r.setdefault(\"Split Flag\", \"Yes\")\n",
    "        r.setdefault(\"Split Reason\", base_reason)\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 7) AGENTS / TOOLS\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Stage 1: Sourcing ---\n",
    "class SourcingInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    url: str = Field(description=\"Source URL of the contract announcement/news.\")\n",
    "    date: str = Field(description=\"Contract date in Excel (string).\")\n",
    "\n",
    "@tool(\"sourcing_extractor\")\n",
    "def sourcing_extractor(paragraph: str, url: str, date: str):\n",
    "    \"\"\"\n",
    "    Stage 1: SOURCING EXTRACTOR\n",
    "\n",
    "    Goal:\n",
    "    - Build the base skeleton row containing:\n",
    "      - Description of Contract (raw paragraph)\n",
    "      - Source Link(s)\n",
    "      - Contract Date\n",
    "      - Reported Date (By SGA)\n",
    "      - Additional Notes (Internal Only)\n",
    "\n",
    "    Why needed:\n",
    "    - These columns remain SAME even if contract splits into multiple rows.\n",
    "    \"\"\"\n",
    "    reported_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    notes = \"Standard extraction.\"\n",
    "    if \"modification\" in str(paragraph).lower():\n",
    "        notes = \"Contract Modification.\"\n",
    "    if \"split\" in str(paragraph).lower():\n",
    "        notes = \"Split award detected.\"\n",
    "\n",
    "    return {\n",
    "        \"Description of Contract\": paragraph,\n",
    "        \"Additional Notes (Internal Only)\": notes,\n",
    "        \"Source Link(s)\": url,\n",
    "        \"Contract Date\": date,\n",
    "        \"Reported Date (By SGA)\": reported_date\n",
    "    }\n",
    "\n",
    "\n",
    "# --- Stage 2: Geography ---\n",
    "class GeographyInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "\n",
    "@tool(\"geography_extractor\")\n",
    "def geography_extractor(paragraph: str):\n",
    "    \"\"\"\n",
    "    Stage 2: GEOGRAPHY EXTRACTOR\n",
    "\n",
    "    Goal:\n",
    "    - Identify:\n",
    "      - Customer Country\n",
    "      - Customer Operator\n",
    "      - Supplier Country\n",
    "    - Derive:\n",
    "      - Customer Region\n",
    "      - Supplier Region\n",
    "      - Domestic Content (Indigenous vs Imported)\n",
    "\n",
    "    Why needed:\n",
    "    - Geography can be split-driving when multiple customer countries exist.\n",
    "    \"\"\"\n",
    "    sys_prompt = \"\"\"\n",
    "Extract: Customer Country, Supplier Country, Customer Operator.\n",
    "Logic: If 'Navy awarded...', operator is Navy.\n",
    "Return JSON:\n",
    "{\n",
    "  \"Customer Country\": \"...\",\n",
    "  \"Customer Operator\": \"...\",\n",
    "  \"Supplier Country\": \"...\"\n",
    "}\n",
    "\"\"\"\n",
    "    log_block(\"HUMAN MESSAGE (Stage2 - Geography)\", paragraph)\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"system\", \"content\": sys_prompt},\n",
    "                      {\"role\": \"user\", \"content\": paragraph}],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "        log_block(\"AI RESPONSE (Stage2 - Geography)\", json.dumps(raw, indent=2))\n",
    "    except Exception as e:\n",
    "        raw = {}\n",
    "        log_block(\"AI ERROR (Stage2 - Geography)\", str(e))\n",
    "\n",
    "    cust = raw.get(\"Customer Country\", \"Unknown\")\n",
    "    supp = raw.get(\"Supplier Country\", \"Unknown\")\n",
    "\n",
    "    domestic = \"Indigenous\" if str(cust).lower() == str(supp).lower() else \"Imported\"\n",
    "\n",
    "    return {\n",
    "        \"Customer Region\": get_region_for_country(cust),\n",
    "        \"Customer Country\": cust,\n",
    "        \"Customer Operator\": raw.get(\"Customer Operator\", \"Unknown\"),\n",
    "        \"Supplier Region\": get_region_for_country(supp),\n",
    "        \"Supplier Country\": supp,\n",
    "        \"Domestic Content\": domestic\n",
    "    }\n",
    "\n",
    "\n",
    "# --- Stage 3: System Classification (RAG + Evidence + Reason) ---\n",
    "class SystemInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "\n",
    "@tool(\"system_classifier\")\n",
    "def system_classifier(paragraph: str):\n",
    "    \"\"\"\n",
    "    Stage 3: SYSTEM CLASSIFIER (RAG-ENHANCED)\n",
    "\n",
    "    Goal:\n",
    "    - Extract system-level labels using:\n",
    "      ‚úÖ Taxonomy reference\n",
    "      ‚úÖ Rule book triggers\n",
    "      ‚úÖ RAG similar examples\n",
    "      ‚úÖ Deterministic piloting override\n",
    "\n",
    "    Output:\n",
    "    - Adds Evidence + Reason for:\n",
    "      - Market Segment\n",
    "      - System Type (General)\n",
    "      - System Type (Specific)\n",
    "      - System Name (General)\n",
    "      - System Name (Specific)\n",
    "      - System Piloting\n",
    "\n",
    "    Why this matters:\n",
    "    - Your biggest accuracy issues were in:\n",
    "      Market, System Type, System Name, System Piloting\n",
    "    - RAG makes results consistent with your labeled history dataset\n",
    "    \"\"\"\n",
    "    paragraph = str(paragraph).strip()\n",
    "    if not paragraph:\n",
    "        return {}\n",
    "\n",
    "    log_block(\"HUMAN MESSAGE (Stage3 - System)\", paragraph)\n",
    "\n",
    "    lower_text = paragraph.lower()\n",
    "    hints = [\n",
    "        f\"RULE: {v['guidance']}\"\n",
    "        for _, v in RULE_BOOK.items()\n",
    "        if any(t in lower_text for t in v[\"triggers\"])\n",
    "    ]\n",
    "    hint_str = \"\\n\".join(hints) if hints else \"No special override rules triggered.\"\n",
    "\n",
    "    designators = extract_designators(paragraph)\n",
    "    piloting_rule = detect_piloting_rule_based(paragraph, designators)\n",
    "\n",
    "    rag_hits = retriever.retrieve(paragraph, top_k=3)\n",
    "    rag_examples = []\n",
    "    for hit in rag_hits:\n",
    "        meta = hit[\"meta\"]\n",
    "        rag_examples.append({\n",
    "            \"score\": round(hit[\"score\"], 4),\n",
    "            \"Market Segment\": meta.get(\"Market Segment\", \"\"),\n",
    "            \"System Type (General)\": meta.get(\"System Type (General)\", \"\"),\n",
    "            \"System Type (Specific)\": meta.get(\"System Type (Specific)\", \"\"),\n",
    "            \"System Name (General)\": meta.get(\"System Name (General)\", \"\"),\n",
    "            \"System Name (Specific)\": meta.get(\"System Name (Specific)\", \"\"),\n",
    "            \"System Piloting\": meta.get(\"System Piloting\", \"\"),\n",
    "            \"Snippet\": meta.get(\"Description of Contract\", \"\")[:220] + \"...\"\n",
    "        })\n",
    "\n",
    "    sys_prompt = f\"\"\"\n",
    "You are a Senior Defense System Classification Analyst.\n",
    "\n",
    "REFERENCE TAXONOMY:\n",
    "{TAXONOMY_STR}\n",
    "\n",
    "RULE BOOK OVERRIDES:\n",
    "{hint_str}\n",
    "\n",
    "OUTPUT RULES:\n",
    "- Return ONLY a FLAT JSON object.\n",
    "- Every value must be a STRING.\n",
    "- Do NOT return nested objects or lists.\n",
    "- Evidence must be copied EXACTLY from paragraph text.\n",
    "- If evidence not present, output \"Not Found\".\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"Market Segment\": \"\",\n",
    "  \"Market Segment Evidence\": \"\",\n",
    "  \"Market Segment Reason\": \"\",\n",
    "\n",
    "  \"System Type (General)\": \"\",\n",
    "  \"System Type (General) Evidence\": \"\",\n",
    "  \"System Type (General) Reason\": \"\",\n",
    "\n",
    "  \"System Type (Specific)\": \"\",\n",
    "  \"System Type (Specific) Evidence\": \"\",\n",
    "  \"System Type (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Name (General)\": \"\",\n",
    "  \"System Name (General) Evidence\": \"\",\n",
    "  \"System Name (General) Reason\": \"\",\n",
    "\n",
    "  \"System Name (Specific)\": \"\",\n",
    "  \"System Name (Specific) Evidence\": \"\",\n",
    "  \"System Name (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Piloting\": \"\",\n",
    "  \"System Piloting Evidence\": \"\",\n",
    "  \"System Piloting Reason\": \"\",\n",
    "\n",
    "  \"Confidence\": \"High/Medium/Low\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "PARAGRAPH:\n",
    "{paragraph}\n",
    "\n",
    "DESIGNATORS (regex extracted):\n",
    "{designators if designators else \"None\"}\n",
    "\n",
    "RULE BASED PILOTING:\n",
    "{piloting_rule}\n",
    "\n",
    "RAG EXAMPLES:\n",
    "{json.dumps(rag_examples, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"system\", \"content\": sys_prompt},\n",
    "                      {\"role\": \"user\", \"content\": user_prompt}],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        result = json.loads(completion.choices[0].message.content)\n",
    "        log_block(\"AI RESPONSE (Stage3 - System)\", json.dumps(result, indent=2))\n",
    "\n",
    "        # Hard override piloting (best accuracy)\n",
    "        result[\"System Piloting\"] = piloting_rule\n",
    "        result.setdefault(\"System Piloting Evidence\", \"Not Found\")\n",
    "        result.setdefault(\"System Piloting Reason\", \"Derived from deterministic piloting rules.\")\n",
    "\n",
    "        # Ensure flat\n",
    "        for k, v in result.items():\n",
    "            if isinstance(v, (dict, list)):\n",
    "                result[k] = str(v)\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        log_block(\"AI ERROR (Stage3 - System)\", str(e))\n",
    "        return {\n",
    "            \"Market Segment\": \"\",\n",
    "            \"Market Segment Evidence\": \"Not Found\",\n",
    "            \"Market Segment Reason\": \"\",\n",
    "\n",
    "            \"System Type (General)\": \"\",\n",
    "            \"System Type (General) Evidence\": \"Not Found\",\n",
    "            \"System Type (General) Reason\": \"\",\n",
    "\n",
    "            \"System Type (Specific)\": \"\",\n",
    "            \"System Type (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Type (Specific) Reason\": \"\",\n",
    "\n",
    "            \"System Name (General)\": \"\",\n",
    "            \"System Name (General) Evidence\": \"Not Found\",\n",
    "            \"System Name (General) Reason\": \"\",\n",
    "\n",
    "            \"System Name (Specific)\": \"\",\n",
    "            \"System Name (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Name (Specific) Reason\": \"\",\n",
    "\n",
    "            \"System Piloting\": piloting_rule,\n",
    "            \"System Piloting Evidence\": \"Not Found\",\n",
    "            \"System Piloting Reason\": \"Derived from deterministic piloting rules.\",\n",
    "\n",
    "            \"Confidence\": \"Low\",\n",
    "            \"Error\": str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "# --- Stage 4: Contract Extractor ---\n",
    "class ContractInfoInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    contract_date: str = Field(description=\"Contract date as string.\")\n",
    "\n",
    "@tool(\"contract_extractor\")\n",
    "def contract_extractor(paragraph: str, contract_date: str):\n",
    "    \"\"\"\n",
    "    Stage 4: CONTRACT EXTRACTOR\n",
    "\n",
    "    Goal:\n",
    "    - Extract the contract financial + program details:\n",
    "      - Supplier Name (raw)\n",
    "      - Program Type\n",
    "      - Quantity\n",
    "      - Value (Million)\n",
    "      - Currency\n",
    "      - Value Certainty\n",
    "      - G2G/B2G\n",
    "      - Completion Date Text\n",
    "\n",
    "    Critical improvement:\n",
    "    - Supplier Name returned from model is ALWAYS standardized\n",
    "      using suppliers.json fuzzy match.\n",
    "    \"\"\"\n",
    "    system_instruction = \"\"\"\n",
    "You are a Defense Contract Financial Analyst.\n",
    "\n",
    "Rules:\n",
    "1) raw_supplier_name: extract exact supplier from paragraph\n",
    "2) program_type: Procurement/Training/MRO/Support/RDT&E/Upgrade/Other Service\n",
    "3) value_certainty: Confirmed vs Estimated\n",
    "4) quantity: extract numeric units if found else Not Applicable\n",
    "5) g2g_b2g: G2G only if FMS mentioned else B2G\n",
    "6) completion_date_text: for MRO calc only\n",
    "\n",
    "Return JSON only.\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "PARAGRAPH:\n",
    "{paragraph}\n",
    "\n",
    "SIGNED DATE:\n",
    "{contract_date}\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"raw_supplier_name\": \"\",\n",
    "  \"program_type\": \"\",\n",
    "  \"value_million_raw\": \"\",\n",
    "  \"currency_code\": \"\",\n",
    "  \"value_certainty\": \"\",\n",
    "  \"quantity\": \"\",\n",
    "  \"completion_date_text\": \"\",\n",
    "  \"g2g_b2g\": \"\",\n",
    "  \"value_note\": \"\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    log_block(\"HUMAN MESSAGE (Stage4 - Contract)\", paragraph)\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"system\", \"content\": system_instruction},\n",
    "                      {\"role\": \"user\", \"content\": user_prompt}],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "        log_block(\"AI RESPONSE (Stage4 - Contract)\", json.dumps(raw, indent=2))\n",
    "    except Exception as e:\n",
    "        log_block(\"AI ERROR (Stage4 - Contract)\", str(e))\n",
    "        return {\"Error\": str(e)}\n",
    "\n",
    "    final_supplier = get_best_supplier_match(raw.get(\"raw_supplier_name\"))\n",
    "\n",
    "    prog_type = raw.get(\"program_type\", \"Unknown\")\n",
    "    mro_months = calculate_mro_months(contract_date, raw.get(\"completion_date_text\"), prog_type)\n",
    "\n",
    "    try:\n",
    "        val_str = str(raw.get(\"value_million_raw\", \"0\")).replace(\",\", \"\").replace(\"$\", \"\")\n",
    "        val_float = float(val_str)\n",
    "        val_formatted = \"{:.3f}\".format(val_float)\n",
    "    except:\n",
    "        val_formatted = \"0.000\"\n",
    "\n",
    "    try:\n",
    "        dt = pd.to_datetime(contract_date)\n",
    "        sign_month = dt.strftime(\"%B\")\n",
    "        sign_year = str(dt.year)\n",
    "    except:\n",
    "        sign_month, sign_year = \"Unknown\", \"Unknown\"\n",
    "\n",
    "    return {\n",
    "        \"Supplier Name\": final_supplier,\n",
    "        \"Program Type\": prog_type,\n",
    "        \"Expected MRO Contract Duration (Months)\": mro_months,\n",
    "        \"Quantity\": raw.get(\"quantity\", \"Not Applicable\"),\n",
    "        \"Value Certainty\": raw.get(\"value_certainty\", \"Confirmed\"),\n",
    "        \"Value (Million)\": val_formatted,\n",
    "        \"Currency\": raw.get(\"currency_code\", \"USD$\"),\n",
    "        \"Value (USD$ Million)\": val_formatted,\n",
    "        \"Value Note (If Any)\": raw.get(\"value_note\", \"Not Applicable\"),\n",
    "        \"G2G/B2G\": raw.get(\"g2g_b2g\", \"B2G\"),\n",
    "        \"Signing Month\": sign_month,\n",
    "        \"Signing Year\": sign_year\n",
    "    }\n",
    "\n",
    "\n",
    "# --- Stage 5: Split Agent ---\n",
    "class SplitterInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    base_row: dict = Field(description=\"Final extracted row after Stage1-4.\")\n",
    "\n",
    "@tool(\"splitter_agent\")\n",
    "def splitter_agent(paragraph: str, base_row: dict):\n",
    "    \"\"\"\n",
    "    Stage 5: SPLITTER AGENT\n",
    "\n",
    "    Goal:\n",
    "    - Detect whether the extracted row must be split into multiple output rows.\n",
    "    - Uses split_rows_engine() to apply deterministic split logic.\n",
    "    - Ensures the split matches patterns found in your sample_data.\n",
    "\n",
    "    Output:\n",
    "    - Returns {\"rows\": [row1, row2, ...]}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        rows = split_rows_engine(base_row, paragraph)\n",
    "        for r in rows:\n",
    "            r.setdefault(\"Split Flag\", \"No\")\n",
    "            r.setdefault(\"Split Reason\", \"\")\n",
    "        return {\"rows\": rows}\n",
    "    except Exception as e:\n",
    "        base_row[\"Split Flag\"] = \"Error\"\n",
    "        base_row[\"Split Reason\"] = f\"Split failed: {str(e)}\"\n",
    "        return {\"rows\": [base_row]}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 8) LANGGRAPH PIPELINE\n",
    "# ==============================================================================\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    State object passed between LangGraph stages.\n",
    "\n",
    "    Contains:\n",
    "    - Raw inputs (text, date, url)\n",
    "    - Aggregated extraction dict (final_data)\n",
    "    - Final output rows (final_rows) after splitting\n",
    "    \"\"\"\n",
    "    input_text: str\n",
    "    input_date: str\n",
    "    input_url: str\n",
    "    final_data: dict\n",
    "    final_rows: list\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "def stage_1_sourcing(state: AgentState):\n",
    "    \"\"\"\n",
    "    Node Stage1: Runs sourcing_extractor tool and updates final_data.\n",
    "    \"\"\"\n",
    "    res = sourcing_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"url\": state[\"input_url\"],\n",
    "        \"date\": state[\"input_date\"],\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_2_geography(state: AgentState):\n",
    "    \"\"\"\n",
    "    Node Stage2: Extracts geography fields and updates final_data.\n",
    "    \"\"\"\n",
    "    res = geography_extractor.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_3_system(state: AgentState):\n",
    "    \"\"\"\n",
    "    Node Stage3: System classification using RAG + evidence + reason.\n",
    "    \"\"\"\n",
    "    res = system_classifier.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_4_contract(state: AgentState):\n",
    "    \"\"\"\n",
    "    Node Stage4: Extracts supplier/program/financial/quantity.\n",
    "    Supplier name is standardized via suppliers.json fuzzy match.\n",
    "    \"\"\"\n",
    "    res = contract_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"contract_date\": state[\"input_date\"]\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_5_split(state: AgentState):\n",
    "    \"\"\"\n",
    "    Node Stage5: Applies split logic to create 1..N rows based on paragraph.\n",
    "    \"\"\"\n",
    "    res = splitter_agent.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"base_row\": state[\"final_data\"]\n",
    "    })\n",
    "    return {\"final_rows\": res.get(\"rows\", [state[\"final_data\"]])}\n",
    "\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Stage1\", stage_1_sourcing)\n",
    "workflow.add_node(\"Stage2\", stage_2_geography)\n",
    "workflow.add_node(\"Stage3\", stage_3_system)\n",
    "workflow.add_node(\"Stage4\", stage_4_contract)\n",
    "workflow.add_node(\"Stage5\", stage_5_split)\n",
    "\n",
    "workflow.add_edge(START, \"Stage1\")\n",
    "workflow.add_edge(\"Stage1\", \"Stage2\")\n",
    "workflow.add_edge(\"Stage2\", \"Stage3\")\n",
    "workflow.add_edge(\"Stage3\", \"Stage4\")\n",
    "workflow.add_edge(\"Stage4\", \"Stage5\")\n",
    "workflow.add_edge(\"Stage5\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 9) GRAPH VISUALIZATION (OFFLINE SAFE)\n",
    "# ==============================================================================\n",
    "\n",
    "def export_workflow_mermaid(app_obj, out_file=\"workflow.mmd\"):\n",
    "    \"\"\"\n",
    "    Exports Mermaid graph as TEXT locally (no mermaid.ink required).\n",
    "\n",
    "    Why:\n",
    "    - Office laptops often block mermaid.ink API calls\n",
    "    - You still need graph visualization / documentation\n",
    "\n",
    "    Output:\n",
    "    - A workflow.mmd file (Mermaid format)\n",
    "    \"\"\"\n",
    "    mmd = app_obj.get_graph().draw_mermaid()\n",
    "    with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(mmd)\n",
    "    print(f\"‚úÖ Workflow Mermaid saved locally: {out_file}\")\n",
    "    return out_file\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 10) EXCEL HIGHLIGHTING FEATURE\n",
    "# ==============================================================================\n",
    "\n",
    "def highlight_evidence_reason_columns(excel_path: str):\n",
    "    \"\"\"\n",
    "    Highlights Evidence + Reason columns in output Excel.\n",
    "\n",
    "    Evidence Columns:\n",
    "    - colored light yellow\n",
    "    Reason Columns:\n",
    "    - colored light blue\n",
    "\n",
    "    Goal:\n",
    "    - Your team can validate 'why this label was chosen'\n",
    "      without confusion.\n",
    "    \"\"\"\n",
    "    wb = load_workbook(excel_path)\n",
    "    ws = wb.active\n",
    "\n",
    "    header = [cell.value for cell in ws[1]]\n",
    "\n",
    "    evidence_cols = []\n",
    "    reason_cols = []\n",
    "\n",
    "    for idx, col_name in enumerate(header, start=1):\n",
    "        if isinstance(col_name, str) and \"Evidence\" in col_name:\n",
    "            evidence_cols.append(idx)\n",
    "        if isinstance(col_name, str) and \"Reason\" in col_name:\n",
    "            reason_cols.append(idx)\n",
    "\n",
    "    evidence_fill = PatternFill(start_color=\"FFF2CC\", end_color=\"FFF2CC\", fill_type=\"solid\")  # Yellow\n",
    "    reason_fill = PatternFill(start_color=\"D9E1F2\", end_color=\"D9E1F2\", fill_type=\"solid\")    # Blue\n",
    "    header_font = Font(bold=True)\n",
    "\n",
    "    for col_idx in evidence_cols:\n",
    "        ws.cell(row=1, column=col_idx).fill = evidence_fill\n",
    "        ws.cell(row=1, column=col_idx).font = header_font\n",
    "\n",
    "    for col_idx in reason_cols:\n",
    "        ws.cell(row=1, column=col_idx).fill = reason_fill\n",
    "        ws.cell(row=1, column=col_idx).font = header_font\n",
    "\n",
    "    for row in range(2, ws.max_row + 1):\n",
    "        for col_idx in evidence_cols:\n",
    "            ws.cell(row=row, column=col_idx).fill = evidence_fill\n",
    "        for col_idx in reason_cols:\n",
    "            ws.cell(row=row, column=col_idx).fill = reason_fill\n",
    "\n",
    "    wb.save(excel_path)\n",
    "    print(\"‚úÖ Evidence + Reason columns highlighted successfully.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 11) MAIN EXECUTION\n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(f\"\\nüìå Loading Input File: {INPUT_EXCEL_PATH}\")\n",
    "\n",
    "    # Offline safe workflow graph\n",
    "    export_workflow_mermaid(app, out_file=\"workflow.mmd\")\n",
    "\n",
    "    try:\n",
    "        df_input = pd.read_excel(INPUT_EXCEL_PATH)\n",
    "\n",
    "        required_cols = [\"Source URL\", \"Contract Date\", \"Contract Description\"]\n",
    "        if not all(col in df_input.columns for col in required_cols):\n",
    "            raise ValueError(f\"Excel file must contain columns: {required_cols}\")\n",
    "\n",
    "        print(f\"üöÄ Processing {len(df_input)} rows...\")\n",
    "        results = []\n",
    "\n",
    "        for index, row in df_input.iterrows():\n",
    "            print(f\"\\nüîπ Row {index + 1}/{len(df_input)}\")\n",
    "\n",
    "            desc = str(row[\"Contract Description\"]) if pd.notna(row[\"Contract Description\"]) else \"\"\n",
    "            c_date = str(row[\"Contract Date\"]) if pd.notna(row[\"Contract Date\"]) else str(datetime.date.today())\n",
    "            c_url = str(row[\"Source URL\"]) if pd.notna(row[\"Source URL\"]) else \"\"\n",
    "\n",
    "            initial_state = {\n",
    "                \"input_text\": desc,\n",
    "                \"input_date\": c_date,\n",
    "                \"input_url\": c_url,\n",
    "                \"final_data\": {},\n",
    "                \"final_rows\": [],\n",
    "                \"messages\": []\n",
    "            }\n",
    "\n",
    "            output_state = app.invoke(initial_state)\n",
    "\n",
    "            rows = output_state.get(\"final_rows\", [])\n",
    "            if not rows:\n",
    "                rows = [output_state.get(\"final_data\", {})]\n",
    "\n",
    "            results.extend(rows)\n",
    "\n",
    "        df_final = pd.DataFrame(results)\n",
    "\n",
    "        FINAL_COLUMNS = [\n",
    "            \"Customer Region\", \"Customer Country\", \"Customer Operator\",\n",
    "            \"Supplier Region\", \"Supplier Country\", \"Domestic Content\",\n",
    "\n",
    "            \"Split Flag\", \"Split Reason\",\n",
    "\n",
    "            \"Market Segment\", \"Market Segment Evidence\", \"Market Segment Reason\",\n",
    "            \"System Type (General)\", \"System Type (General) Evidence\", \"System Type (General) Reason\",\n",
    "            \"System Type (Specific)\", \"System Type (Specific) Evidence\", \"System Type (Specific) Reason\",\n",
    "            \"System Name (General)\", \"System Name (General) Evidence\", \"System Name (General) Reason\",\n",
    "            \"System Name (Specific)\", \"System Name (Specific) Evidence\", \"System Name (Specific) Reason\",\n",
    "            \"System Piloting\", \"System Piloting Evidence\", \"System Piloting Reason\",\n",
    "            \"Confidence\",\n",
    "\n",
    "            \"Supplier Name\", \"Program Type\", \"Expected MRO Contract Duration (Months)\",\n",
    "            \"Quantity\", \"Value Certainty\", \"Value (Million)\", \"Currency\",\n",
    "            \"Value (USD$ Million)\", \"Value Note (If Any)\", \"G2G/B2G\",\n",
    "            \"Signing Month\", \"Signing Year\",\n",
    "\n",
    "            \"Description of Contract\",\n",
    "            \"Additional Notes (Internal Only)\",\n",
    "            \"Source Link(s)\",\n",
    "            \"Contract Date\",\n",
    "            \"Reported Date (By SGA)\"\n",
    "        ]\n",
    "\n",
    "        df_final = df_final.reindex(columns=FINAL_COLUMNS, fill_value=\"\")\n",
    "        df_final.to_excel(OUTPUT_EXCEL_PATH, index=False)\n",
    "\n",
    "        # Highlight Evidence + Reason\n",
    "        highlight_evidence_reason_columns(OUTPUT_EXCEL_PATH)\n",
    "\n",
    "        print(\"\\n‚úÖ Processing Complete!\")\n",
    "        print(f\"üíæ Output File Saved: {OUTPUT_EXCEL_PATH}\")\n",
    "        print(df_final.head(3).to_string(index=False))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec28bd1e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import difflib\n",
    "import pickle\n",
    "import datetime\n",
    "from typing import Annotated, TypedDict, List, Dict, Any, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import getpass\n",
    "\n",
    "# LangGraph / LangChain\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "\n",
    "# Excel formatting\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill, Font\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 0) DEBUG LOGGING HELPERS\n",
    "# ==============================================================================\n",
    "\n",
    "def log_block(title: str, content: str):\n",
    "    \"\"\"\n",
    "    Prints a clean and separated debug block in the console.\n",
    "\n",
    "    WHY THIS IS IMPORTANT:\n",
    "    - This pipeline is multi-stage and agentic (Stage1 -> Stage6).\n",
    "    - If any stage fails, debugging becomes hard without clear logs.\n",
    "    - This helps validate extraction decisions row-by-row.\n",
    "\n",
    "    OUTPUT:\n",
    "    - A titled separator\n",
    "    - The content text (prompt / response / error)\n",
    "\n",
    "    NOTE:\n",
    "    - Does NOT affect output Excel.\n",
    "    - Only prints to console.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 130)\n",
    "    print(title)\n",
    "    print(\"=\" * 130)\n",
    "    print(content)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 1) RAG RETRIEVER (FAISS + Metadata)\n",
    "# ==============================================================================\n",
    "\n",
    "class SystemKBRetriever:\n",
    "    \"\"\"\n",
    "    RAG Retriever for Defense System Classification.\n",
    "\n",
    "    PURPOSE:\n",
    "    This retriever provides semantic retrieval over a historical labeled dataset\n",
    "    stored inside a FAISS index + metadata pickle.\n",
    "\n",
    "    EXPECTED FILES INSIDE kb_dir:\n",
    "    ‚úÖ system_kb.faiss       -> FAISS index\n",
    "    ‚úÖ system_kb_meta.pkl    -> list[dict] metadata rows\n",
    "\n",
    "    WHY RAG IMPROVES ACCURACY:\n",
    "    - System taxonomy classification becomes inconsistent if the LLM guesses.\n",
    "    - RAG provides labeled examples similar to the current paragraph.\n",
    "    - This improves consistency for:\n",
    "      Market Segment, System Types, System Names, Piloting, etc.\n",
    "\n",
    "    RETURN FORMAT:\n",
    "    retrieve(query_text, top_k=3) returns:\n",
    "      [\n",
    "        {\n",
    "          \"score\": float,\n",
    "          \"meta\": {... column values from KB ...}\n",
    "        },\n",
    "        ...\n",
    "      ]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kb_dir: str, embed_model: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initializes and loads FAISS + metadata.\n",
    "\n",
    "        PARAMETERS:\n",
    "        - kb_dir: directory where FAISS + metadata exist\n",
    "        - embed_model: sentence-transformers model name\n",
    "\n",
    "        IMPORTANT:\n",
    "        - embedder is lazy-loaded so script startup is fast.\n",
    "        \"\"\"\n",
    "        self.kb_dir = kb_dir\n",
    "        self.embed_model = embed_model\n",
    "\n",
    "        index_path = os.path.join(kb_dir, \"system_kb.faiss\")\n",
    "        meta_path = os.path.join(kb_dir, \"system_kb_meta.pkl\")\n",
    "\n",
    "        if not os.path.exists(index_path) or not os.path.exists(meta_path):\n",
    "            raise FileNotFoundError(\n",
    "                f\"‚ùå KB files not found in: {kb_dir}\\n\"\n",
    "                f\"Expected:\\n- {index_path}\\n- {meta_path}\\n\\n\"\n",
    "                f\"Build the KB first before running this pipeline.\"\n",
    "            )\n",
    "\n",
    "        print(f\"‚úÖ Loading FAISS Index: {index_path}\")\n",
    "        self.index = faiss.read_index(index_path)\n",
    "\n",
    "        print(f\"‚úÖ Loading KB Metadata: {meta_path}\")\n",
    "        with open(meta_path, \"rb\") as f:\n",
    "            self.meta = pickle.load(f)\n",
    "\n",
    "        print(f\"‚úÖ KB Loaded rows: {len(self.meta)}\")\n",
    "\n",
    "        self.embedder = None\n",
    "\n",
    "    def _lazy_load_embedder(self):\n",
    "        \"\"\"\n",
    "        Lazy-load the embedding model only on demand.\n",
    "\n",
    "        WHY:\n",
    "        - Avoid memory overhead at script startup\n",
    "        - Faster pipeline initialization\n",
    "        \"\"\"\n",
    "        if self.embedder is None:\n",
    "            from sentence_transformers import SentenceTransformer\n",
    "            self.embedder = SentenceTransformer(self.embed_model)\n",
    "\n",
    "    def retrieve(self, query_text: str, top_k: int = 3):\n",
    "        \"\"\"\n",
    "        Retrieve top-k semantically similar KB examples.\n",
    "\n",
    "        INPUT:\n",
    "        - query_text: contract paragraph (string)\n",
    "        - top_k: number of similar KB rows to retrieve\n",
    "\n",
    "        OUTPUT:\n",
    "        - list of dicts: [{\"score\":..., \"meta\":...}, ...]\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "\n",
    "        query_text = str(query_text).strip()\n",
    "        if not query_text:\n",
    "            return []\n",
    "\n",
    "        self._lazy_load_embedder()\n",
    "\n",
    "        q_emb = self.embedder.encode([query_text], normalize_embeddings=True).astype(\"float32\")\n",
    "        scores, idxs = self.index.search(q_emb, top_k)\n",
    "\n",
    "        results = []\n",
    "        for score, idx in zip(scores[0], idxs[0]):\n",
    "            if idx < 0:\n",
    "                continue\n",
    "            results.append({\"score\": float(score), \"meta\": self.meta[idx]})\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2) CONFIGURATION & FILE PATHS\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"\n",
    "PATH CONFIGURATION\n",
    "\n",
    "Update these paths based on your system.\n",
    "\n",
    "IMPORTANT:\n",
    "- taxonomy.json is your classification constraints\n",
    "- suppliers.json is your supplier normalization list\n",
    "- input excel must have the required columns:\n",
    "    [\"Source URL\", \"Contract Date\", \"Contract Description\"]\n",
    "\"\"\"\n",
    "\n",
    "TAXONOMY_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\taxonomy.json\"\n",
    "SUPPLIERS_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\suppliers.json\"\n",
    "INPUT_EXCEL_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\data\\source_file.xlsx\"\n",
    "OUTPUT_EXCEL_PATH = \"Processed_Defense_Data.xlsx\"\n",
    "\n",
    "RAG_KB_DIR = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\system_kb_store\"\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3) SETUP LLM CLIENT\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"\n",
    "LLM Client Setup Notes:\n",
    "\n",
    "You are using LLM Foundry OpenAI-compatible endpoint.\n",
    "\n",
    "IMPORTANT:\n",
    "- Key must be passed properly: api_key=\"TOKEN:project\"\n",
    "- base_url is Foundry endpoint\n",
    "\"\"\"\n",
    "\n",
    "if \"LLMFOUNDRY_TOKEN\" not in os.environ:\n",
    "    os.environ[\"LLMFOUNDRY_TOKEN\"] = getpass.getpass(\"Enter the LLM Foundry API Key: \")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=f'{os.environ.get(\"LLMFOUNDRY_TOKEN\")}:my-test-project',\n",
    "    base_url=\"https://llmfoundry.straive.com/openai/v1/\",\n",
    ")\n",
    "\n",
    "retriever = SystemKBRetriever(kb_dir=RAG_KB_DIR)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4) LOAD JSON HELPERS\n",
    "# ==============================================================================\n",
    "\n",
    "def load_json_file(filename, default_value):\n",
    "    \"\"\"\n",
    "    Loads a JSON file safely with fallback.\n",
    "\n",
    "    WHY:\n",
    "    - taxonomy.json and suppliers.json are critical\n",
    "    - pipeline must not crash if JSON file is missing/corrupt\n",
    "\n",
    "    RETURNS:\n",
    "    - json object (dict/list) if loaded successfully\n",
    "    - default_value otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            print(f\"‚úÖ Loaded: {filename}\")\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Warning: Could not load {filename} ({e}). Using default.\")\n",
    "        return default_value\n",
    "\n",
    "\n",
    "raw_taxonomy = load_json_file(TAXONOMY_PATH, {})\n",
    "TAXONOMY_STR = json.dumps(raw_taxonomy, separators=(\",\", \":\"))\n",
    "\n",
    "SUPPLIER_LIST = load_json_file(SUPPLIERS_PATH, [\n",
    "    \"Dell Inc\", \"Boeing\", \"Lockheed Martin\", \"Raytheon Technologies\",\n",
    "    \"Northrop Grumman\", \"L3Harris\", \"BAE Systems\", \"General Dynamics\"\n",
    "])\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 5) RULE BOOK + GEOGRAPHY\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"\n",
    "RULE_BOOK\n",
    "\n",
    "This is deterministic \"hint injection\" logic to reduce misclassification\n",
    "for very frequent patterns (radars, countermeasures, ammo).\n",
    "\n",
    "If any triggers match the paragraph text, we provide a guidance string\n",
    "inside system prompt for Stage3 classifier.\n",
    "\"\"\"\n",
    "\n",
    "RULE_BOOK = {\n",
    "    \"defensive_countermeasures\": {\n",
    "        \"triggers\": [\"flare\", \"chaff\", \"countermeasure\", \"decoy\", \"mju-\", \"ale-\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Defensive Systems', Specific: 'Defensive Aid Suite'\"\n",
    "    },\n",
    "    \"radars_and_sensors\": {\n",
    "        \"triggers\": [\"radar\", \"sonar\", \"sensor\", \"an/apy\", \"an/tpy\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Sensors'\"\n",
    "    },\n",
    "    \"ammunition\": {\n",
    "        \"triggers\": [\"cartridge\", \"round\", \"projectile\", \" 5.56\", \" 7.62\", \"ammo\"],\n",
    "        \"guidance\": \"Market Segment: 'Weapon Systems', System Type (General): 'Ammunition'\"\n",
    "    }\n",
    "}\n",
    "\n",
    "GEOGRAPHY_MAPPING = {\n",
    "    \"North America\": [\"USA\", \"United States\", \"US\", \"United States of America\", \"Canada\", \"America\"],\n",
    "    \"Europe\": [\"UK\", \"United Kingdom\", \"Ukraine\", \"Germany\", \"France\", \"Italy\", \"Spain\", \"Poland\", \"Netherlands\",\n",
    "               \"Norway\", \"Sweden\", \"Finland\", \"Denmark\", \"Belgium\"],\n",
    "    \"Asia-Pacific\": [\"Australia\", \"Japan\", \"South Korea\", \"Taiwan\", \"India\", \"Singapore\", \"New Zealand\"],\n",
    "    \"Middle East and North Africa\": [\"Israel\", \"Saudi Arabia\", \"UAE\", \"United Arab Emirates\", \"Egypt\", \"Qatar\", \"Kuwait\", \"Iraq\"],\n",
    "    \"International Organisations\": [\"NATO\", \"EU\", \"IFU\", \"UN\", \"NSPA\"]\n",
    "}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 6) BASE HELPERS (Supplier + Dates + Region + Designators)\n",
    "# ==============================================================================\n",
    "\n",
    "def get_best_supplier_match(extracted_name: str):\n",
    "    \"\"\"\n",
    "    Standardizes supplier names using suppliers.json.\n",
    "\n",
    "    WHY:\n",
    "    - LLM outputs inconsistent supplier strings\n",
    "    - Your final Excel must match standardized naming\n",
    "\n",
    "    MATCH STRATEGY:\n",
    "    1) If blank/unknown -> \"Unknown\"\n",
    "    2) Exact match ignoring case\n",
    "    3) Fuzzy match using difflib\n",
    "    4) Otherwise return cleaned extracted string\n",
    "    \"\"\"\n",
    "    if not extracted_name or str(extracted_name).strip().lower() in [\"unknown\", \"n/a\", \"not applicable\", \"\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    clean_name = str(extracted_name).strip()\n",
    "    supplier_map = {s.lower(): s for s in SUPPLIER_LIST}\n",
    "\n",
    "    if clean_name.lower() in supplier_map:\n",
    "        return supplier_map[clean_name.lower()]\n",
    "\n",
    "    matches = difflib.get_close_matches(clean_name, SUPPLIER_LIST, n=1, cutoff=0.6)\n",
    "    return matches[0] if matches else clean_name\n",
    "\n",
    "\n",
    "def calculate_mro_months(start_date_str, end_date_text, program_type):\n",
    "    \"\"\"\n",
    "    Calculates MRO duration in months.\n",
    "\n",
    "    RULE:\n",
    "    - Only valid for program_type == \"MRO/Support\"\n",
    "    - otherwise return \"Not Applicable\"\n",
    "\n",
    "    OUTPUT:\n",
    "    - month count as string OR \"Not Applicable\"\n",
    "    \"\"\"\n",
    "    if program_type != \"MRO/Support\":\n",
    "        return \"Not Applicable\"\n",
    "    try:\n",
    "        if not start_date_str or not end_date_text:\n",
    "            return \"Not Applicable\"\n",
    "\n",
    "        start = pd.to_datetime(start_date_str, dayfirst=True)\n",
    "        end = parser.parse(str(end_date_text), fuzzy=True)\n",
    "\n",
    "        diff = relativedelta(end, start)\n",
    "        total_months = diff.years * 12 + diff.months\n",
    "        return str(max(0, int(total_months)))\n",
    "    except:\n",
    "        return \"Not Applicable\"\n",
    "\n",
    "\n",
    "def get_region_for_country(country_name):\n",
    "    \"\"\"\n",
    "    Maps a country name into a region bucket using GEOGRAPHY_MAPPING.\n",
    "\n",
    "    IMPORTANT:\n",
    "    - If unknown -> \"Unknown\"\n",
    "    - Handles US/USA/UK common strings\n",
    "    \"\"\"\n",
    "    if not country_name or str(country_name).strip().lower() in [\"unknown\", \"n/a\", \"not applicable\", \"\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    clean = str(country_name).strip().lower()\n",
    "\n",
    "    if clean in [\"us\", \"usa\", \"u.s.\", \"united states\", \"united states of america\"]:\n",
    "        return \"North America\"\n",
    "    if clean in [\"uk\", \"u.k.\", \"britain\", \"great britain\"]:\n",
    "        return \"Europe\"\n",
    "\n",
    "    for region, countries in GEOGRAPHY_MAPPING.items():\n",
    "        if any(c.lower() == clean for c in countries):\n",
    "            return region\n",
    "\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "DESIGNATOR_PATTERNS = [\n",
    "    r\"\\bDDG[-\\s]?\\d+\\b\", r\"\\bCVN[-\\s]?\\d+\\b\", r\"\\bSSN[-\\s]?\\d+\\b\",\n",
    "    r\"\\bLCS[-\\s]?\\d+\\b\", r\"\\bLPD[-\\s]?\\d+\\b\", r\"\\bLHA[-\\s]?\\d+\\b\", r\"\\bLHD[-\\s]?\\d+\\b\",\n",
    "    r\"\\bF-\\d+\\b\", r\"\\bB-\\d+\\b\", r\"\\bC-\\d+\\b\", r\"\\bA-\\d+\\b\",\n",
    "    r\"\\bMQ-\\d+\\b\", r\"\\bRQ-\\d+\\b\",\n",
    "    r\"\\bAN\\/[A-Z0-9\\-]+\\b\",\n",
    "    r\"\\b(AIM|AGM|SM|RIM|MIM)-\\d+\\b\",\n",
    "]\n",
    "\n",
    "def extract_designators(text: str):\n",
    "    \"\"\"\n",
    "    Extracts defense platform identifiers/designators from contract text.\n",
    "\n",
    "    WHY:\n",
    "    - Helps classify system piloting deterministically\n",
    "    - Helps identify platform family quickly\n",
    "\n",
    "    OUTPUT:\n",
    "    - list[str] of unique designators found in paragraph\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    found = []\n",
    "    for pat in DESIGNATOR_PATTERNS:\n",
    "        found.extend(re.findall(pat, text, flags=re.IGNORECASE))\n",
    "\n",
    "    cleaned = []\n",
    "    for f in found:\n",
    "        cleaned.append(f.upper().replace(\" \", \"\").replace(\"--\", \"-\"))\n",
    "\n",
    "    final = []\n",
    "    seen = set()\n",
    "    for x in cleaned:\n",
    "        if x not in seen:\n",
    "            final.append(x)\n",
    "            seen.add(x)\n",
    "\n",
    "    return final\n",
    "\n",
    "\n",
    "def detect_piloting_rule_based(text: str, designators: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Deterministic piloting classifier.\n",
    "\n",
    "    OUTPUT MUST BE ONE OF:\n",
    "    - \"Crewed\"\n",
    "    - \"Uncrewed\"\n",
    "    - \"Not Applicable\"\n",
    "\n",
    "    RULES:\n",
    "    - MQ-/RQ- or unmanned/UAV/drone/autonomous -> Uncrewed\n",
    "    - DDG/CVN/SSN/USS -> Crewed\n",
    "    - Else -> Not Applicable\n",
    "    \"\"\"\n",
    "    t = str(text).lower()\n",
    "\n",
    "    if any(d.startswith((\"MQ-\", \"RQ-\")) for d in designators):\n",
    "        return \"Uncrewed\"\n",
    "    if any(k in t for k in [\"unmanned\", \"uav\", \"drone\", \"autonomous\"]):\n",
    "        return \"Uncrewed\"\n",
    "\n",
    "    if any(d.startswith((\"DDG\", \"CVN\", \"SSN\", \"LCS\", \"LPD\", \"LHA\", \"LHD\")) for d in designators):\n",
    "        return \"Crewed\"\n",
    "    if \"uss \" in t:\n",
    "        return \"Crewed\"\n",
    "\n",
    "    return \"Not Applicable\"\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 7) SPLIT ENGINE (DETERMINISTIC)\n",
    "# ==============================================================================\n",
    "\n",
    "def _normalize_spaces(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalizes whitespace to simplify parsing.\n",
    "\n",
    "    WHY:\n",
    "    - DoD contract paragraphs often contain newlines, multiple spaces.\n",
    "    - Regex extraction becomes more stable.\n",
    "    \"\"\"\n",
    "    return re.sub(r\"\\s+\", \" \", str(text or \"\")).strip()\n",
    "\n",
    "def _safe_int(value: str):\n",
    "    \"\"\"\n",
    "    Safely converts string -> integer.\n",
    "    Returns None if conversion fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(str(value).replace(\",\", \"\").strip())\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _extract_supplier_from_description(paragraph: str) -> str:\n",
    "    \"\"\"\n",
    "    Fallback supplier extraction from DoD style contracts.\n",
    "\n",
    "    EXAMPLE:\n",
    "    \"Raytheon Technologies, Tucson, Arizona, is awarded $XYZ...\"\n",
    "\n",
    "    We extract the leading entity before first comma if sentence matches.\n",
    "    \"\"\"\n",
    "    p = _normalize_spaces(paragraph)\n",
    "    m = re.match(r\"^(.*?),\\s+.*?\\s+is awarded\", p, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return m.group(1).strip()\n",
    "    return \"Unknown\"\n",
    "\n",
    "def parse_line_items(paragraph: str):\n",
    "    \"\"\"\n",
    "    Extracts line-item splits when paragraph contains \"as follows:\" and semicolons.\n",
    "\n",
    "    EXAMPLE:\n",
    "      \"as follows: 212 for the Navy; 187 for the Air Force; 84 for FMS customers\"\n",
    "\n",
    "    OUTPUT:\n",
    "      [\n",
    "        {\n",
    "          \"item_total_qty\": 212,\n",
    "          \"item_name\": \"for the Navy\",\n",
    "          \"allocation_text\": \"\"\n",
    "        }\n",
    "      ]\n",
    "\n",
    "    NOTE:\n",
    "    - Best-effort parsing; not perfect.\n",
    "    - If no chunks found, returns [].\n",
    "    \"\"\"\n",
    "    paragraph = _normalize_spaces(paragraph)\n",
    "\n",
    "    if \"as follows:\" in paragraph.lower():\n",
    "        idx = paragraph.lower().find(\"as follows:\")\n",
    "        split_part = paragraph[idx + len(\"as follows:\"):].strip()\n",
    "    else:\n",
    "        split_part = paragraph\n",
    "\n",
    "    chunks = [c.strip() for c in split_part.split(\";\") if c.strip()]\n",
    "\n",
    "    items = []\n",
    "    for ch in chunks:\n",
    "        m = re.match(r\"^(\\d{1,6}(?:,\\d{3})*)\\s+(.*)$\", ch)\n",
    "        if not m:\n",
    "            continue\n",
    "\n",
    "        qty = _safe_int(m.group(1))\n",
    "        rest = m.group(2).strip()\n",
    "\n",
    "        allocation_text = \"\"\n",
    "        item_name = rest\n",
    "\n",
    "        paren = re.search(r\"\\((.*?)\\)\", rest)\n",
    "        if paren:\n",
    "            allocation_text = paren.group(0).strip()\n",
    "            item_name = re.sub(r\"\\(.*?\\)\", \"\", rest).strip()\n",
    "\n",
    "        items.append(\n",
    "            {\n",
    "                \"item_total_qty\": qty,\n",
    "                \"item_name\": item_name,\n",
    "                \"allocation_text\": allocation_text,\n",
    "            }\n",
    "        )\n",
    "    return items\n",
    "\n",
    "def parse_operator_allocations(allocation_text: str):\n",
    "    \"\"\"\n",
    "    Detects allocations inside a text fragment like:\n",
    "    - \"212 for the Navy\"\n",
    "    - \"187 for the Air Force\"\n",
    "    - \"84 for FMS customers\"\n",
    "\n",
    "    OUTPUT:\n",
    "      [\n",
    "        {\"allocation_type\":\"operator\",\"operator\":\"Navy\",\"qty\":212,\"g2g_b2g\":\"B2G\"},\n",
    "        {\"allocation_type\":\"fms_bucket\",\"operator\":\"Foreign Assistance\",\"qty\":84,\"g2g_b2g\":\"G2G\"}\n",
    "      ]\n",
    "\n",
    "    RULES:\n",
    "    - Navy/Air Force/Army/Marine => B2G\n",
    "    - FMS => G2G + operator=Foreign Assistance\n",
    "    \"\"\"\n",
    "    if not allocation_text:\n",
    "        return []\n",
    "\n",
    "    txt = allocation_text.lower()\n",
    "\n",
    "    allocations = []\n",
    "    ops = re.findall(r\"(\\d{1,6}(?:,\\d{3})*)\\s+for\\s+the\\s+(navy|air force|army|marine corps)\", txt)\n",
    "    for qty_word, op in ops:\n",
    "        qty = _safe_int(qty_word)\n",
    "        if qty is None:\n",
    "            continue\n",
    "        op_norm = \"Air Force\" if op == \"air force\" else op.title()\n",
    "        allocations.append({\n",
    "            \"allocation_type\": \"operator\",\n",
    "            \"operator\": op_norm,\n",
    "            \"qty\": qty,\n",
    "            \"g2g_b2g\": \"B2G\"\n",
    "        })\n",
    "\n",
    "    fms = re.findall(\n",
    "        r\"(\\d{1,6}(?:,\\d{3})*)\\s+for\\s+(?:foreign military sales\\s*\\(fms\\)\\s*customers|fms\\s*customers|fms)\",\n",
    "        txt\n",
    "    )\n",
    "    for qty_word in fms:\n",
    "        qty = _safe_int(qty_word)\n",
    "        if qty is None:\n",
    "            continue\n",
    "        allocations.append({\n",
    "            \"allocation_type\": \"fms_bucket\",\n",
    "            \"operator\": \"Foreign Assistance\",\n",
    "            \"qty\": qty,\n",
    "            \"g2g_b2g\": \"G2G\"\n",
    "        })\n",
    "\n",
    "    uniq, seen = [], set()\n",
    "    for a in allocations:\n",
    "        key = (a[\"allocation_type\"], a[\"operator\"], a[\"qty\"], a[\"g2g_b2g\"])\n",
    "        if key not in seen:\n",
    "            uniq.append(a)\n",
    "            seen.add(key)\n",
    "\n",
    "    return uniq\n",
    "\n",
    "def parse_fms_countries(paragraph: str):\n",
    "    \"\"\"\n",
    "    Extracts multi-country list for FMS.\n",
    "\n",
    "    PATTERN:\n",
    "      \"governments of Australia, Bahrain, Belgium...\"\n",
    "\n",
    "    OUTPUT:\n",
    "      [\"Australia\",\"Bahrain\",\"Belgium\",...]\n",
    "    \"\"\"\n",
    "    text = str(paragraph)\n",
    "\n",
    "    m = re.search(\n",
    "        r\"governments of (.+?)(?:\\.\\s| Work will be performed| Fiscal| This contract|$)\",\n",
    "        text,\n",
    "        flags=re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "    if not m:\n",
    "        return []\n",
    "\n",
    "    block = m.group(1)\n",
    "    raw = re.split(r\",|\\band\\b\", block)\n",
    "\n",
    "    countries = []\n",
    "    for c in raw:\n",
    "        c = c.strip()\n",
    "        if 2 < len(c) <= 50:\n",
    "            countries.append(c)\n",
    "\n",
    "    final, seen = [], set()\n",
    "    for c in countries:\n",
    "        if c.lower() not in seen:\n",
    "            final.append(c)\n",
    "            seen.add(c.lower())\n",
    "\n",
    "    return final\n",
    "\n",
    "def split_rows_engine(base_row: dict, paragraph: str):\n",
    "    \"\"\"\n",
    "    MASTER SPLIT ENGINE (DETERMINISTIC)\n",
    "\n",
    "    INPUTS:\n",
    "    - base_row: dict output after Stage1-4\n",
    "    - paragraph: contract paragraph text\n",
    "\n",
    "    OUTPUT:\n",
    "    - list of rows (1..N)\n",
    "\n",
    "    SPLIT RULES:\n",
    "    ‚úÖ Operator allocations:\n",
    "       - \"212 for the Navy\"\n",
    "       - \"187 for the Air Force\"\n",
    "       => Creates one row per operator allocation\n",
    "\n",
    "    ‚úÖ FMS allocations:\n",
    "       - \"84 for FMS customers\"\n",
    "       => Creates one row with operator \"Foreign Assistance\" and G2G\n",
    "\n",
    "    ‚úÖ Multi-country FMS:\n",
    "       - \"governments of Australia, Bahrain, Belgium\"\n",
    "       => creates one row per country (Quantity=1 each)\n",
    "\n",
    "    VALIDATION COLUMNS:\n",
    "    - Split Flag\n",
    "    - Split Reason\n",
    "    - Split Evidence\n",
    "    - Split Line Item\n",
    "    \"\"\"\n",
    "    paragraph = _normalize_spaces(paragraph)\n",
    "    base_row = base_row.copy()\n",
    "\n",
    "    # Supplier fallback (important)\n",
    "    if not base_row.get(\"Supplier Name\") or base_row.get(\"Supplier Name\") in [\"\", \"Unknown\"]:\n",
    "        extracted = _extract_supplier_from_description(paragraph)\n",
    "        base_row[\"Supplier Name\"] = get_best_supplier_match(extracted)\n",
    "\n",
    "    line_items = parse_line_items(paragraph)\n",
    "    fms_countries = parse_fms_countries(paragraph)\n",
    "\n",
    "    # fallback as one chunk\n",
    "    if not line_items:\n",
    "        line_items = [{\n",
    "            \"item_total_qty\": base_row.get(\"Quantity\", \"Not Applicable\"),\n",
    "            \"item_name\": base_row.get(\"System Name (Specific)\", \"Unknown Deliverable\"),\n",
    "            \"allocation_text\": \"\"\n",
    "        }]\n",
    "\n",
    "    final_rows = []\n",
    "    any_split = False\n",
    "\n",
    "    for item in line_items:\n",
    "        item_total_qty = item.get(\"item_total_qty\")\n",
    "        item_name = item.get(\"item_name\", \"Unknown Deliverable\")\n",
    "        allocation_text = item.get(\"allocation_text\", \"\")\n",
    "\n",
    "        allocations = parse_operator_allocations(item_name)\n",
    "\n",
    "        # if no allocations, return as is\n",
    "        if not allocations:\n",
    "            r = base_row.copy()\n",
    "            r[\"Split Flag\"] = \"No\"\n",
    "            r[\"Split Reason\"] = \"No operator/FMS allocation detected.\"\n",
    "            r[\"Split Evidence\"] = \"Not Found\"\n",
    "            r[\"Split Line Item\"] = str(item_name)\n",
    "            if item_total_qty is not None:\n",
    "                r[\"Quantity\"] = str(item_total_qty)\n",
    "            final_rows.append(r)\n",
    "            continue\n",
    "\n",
    "        any_split = True\n",
    "\n",
    "        for alloc in allocations:\n",
    "            if alloc[\"allocation_type\"] == \"operator\":\n",
    "                rr = base_row.copy()\n",
    "                rr[\"Customer Operator\"] = alloc[\"operator\"]\n",
    "                rr[\"Quantity\"] = str(alloc[\"qty\"])\n",
    "                rr[\"G2G/B2G\"] = alloc[\"g2g_b2g\"]\n",
    "\n",
    "                rr[\"Split Flag\"] = \"Yes\"\n",
    "                rr[\"Split Reason\"] = \"Operator allocation split detected.\"\n",
    "                rr[\"Split Evidence\"] = item_name\n",
    "                rr[\"Split Line Item\"] = str(item_name)\n",
    "                final_rows.append(rr)\n",
    "\n",
    "            elif alloc[\"allocation_type\"] == \"fms_bucket\":\n",
    "                fms_qty = alloc[\"qty\"]\n",
    "\n",
    "                if fms_countries:\n",
    "                    for c in fms_countries:\n",
    "                        rr = base_row.copy()\n",
    "                        rr[\"Customer Country\"] = c\n",
    "                        rr[\"Customer Region\"] = get_region_for_country(c)\n",
    "                        rr[\"Customer Operator\"] = \"Foreign Assistance\"\n",
    "                        rr[\"Quantity\"] = \"1\"\n",
    "                        rr[\"G2G/B2G\"] = \"G2G\"\n",
    "\n",
    "                        rr[\"Split Flag\"] = \"Yes\"\n",
    "                        rr[\"Split Reason\"] = \"FMS multi-country detected -> 1 row per country\"\n",
    "                        rr[\"Split Evidence\"] = f\"Countries: {', '.join(fms_countries)}\"\n",
    "                        rr[\"Split Line Item\"] = str(item_name)\n",
    "                        final_rows.append(rr)\n",
    "                else:\n",
    "                    rr = base_row.copy()\n",
    "                    rr[\"Customer Operator\"] = \"Foreign Assistance\"\n",
    "                    rr[\"Quantity\"] = str(fms_qty)\n",
    "                    rr[\"G2G/B2G\"] = \"G2G\"\n",
    "\n",
    "                    rr[\"Split Flag\"] = \"Yes\"\n",
    "                    rr[\"Split Reason\"] = \"FMS quantity detected but no explicit countries\"\n",
    "                    rr[\"Split Evidence\"] = item_name\n",
    "                    rr[\"Split Line Item\"] = str(item_name)\n",
    "                    final_rows.append(rr)\n",
    "\n",
    "    if not final_rows:\n",
    "        base_row[\"Split Flag\"] = \"No\"\n",
    "        base_row[\"Split Reason\"] = \"Split fallback (no rows created)\"\n",
    "        base_row[\"Split Evidence\"] = \"Not Found\"\n",
    "        base_row[\"Split Line Item\"] = \"Not Found\"\n",
    "        return [base_row]\n",
    "\n",
    "    for r in final_rows:\n",
    "        r.setdefault(\"Split Flag\", \"Yes\" if any_split else \"No\")\n",
    "        r.setdefault(\"Split Reason\", \"Not Found\")\n",
    "        r.setdefault(\"Split Evidence\", \"Not Found\")\n",
    "        r.setdefault(\"Split Line Item\", \"Not Found\")\n",
    "\n",
    "    return final_rows\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 8) TOOLS / AGENTS (Stage1 -> Stage6)\n",
    "# ==============================================================================\n",
    "\n",
    "class SourcingInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    url: str = Field(description=\"Source URL of the contract announcement/news.\")\n",
    "    date: str = Field(description=\"Contract date string.\")\n",
    "\n",
    "@tool(\"sourcing_extractor\")\n",
    "def sourcing_extractor(paragraph: str, url: str, date: str):\n",
    "    \"\"\"\n",
    "    STAGE 1 TOOL: SOURCING EXTRACTOR\n",
    "\n",
    "    GOAL:\n",
    "    Build base row skeleton metadata fields which remain constant across splits.\n",
    "\n",
    "    OUTPUT FIELDS:\n",
    "    - Description of Contract\n",
    "    - Additional Notes (Internal Only)\n",
    "    - Source Link(s)\n",
    "    - Contract Date\n",
    "    - Reported Date (By SGA)\n",
    "\n",
    "    RULES:\n",
    "    ‚úÖ Must not guess/modify system classification\n",
    "    ‚úÖ Must not guess financial values\n",
    "    ‚úÖ Only sourcing metadata is allowed here\n",
    "    \"\"\"\n",
    "    reported_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    notes = \"Standard extraction.\"\n",
    "    if \"modification\" in str(paragraph).lower():\n",
    "        notes = \"Contract Modification.\"\n",
    "    if \"split\" in str(paragraph).lower():\n",
    "        notes = \"Split award detected.\"\n",
    "\n",
    "    return {\n",
    "        \"Description of Contract\": paragraph,\n",
    "        \"Additional Notes (Internal Only)\": notes,\n",
    "        \"Source Link(s)\": url,\n",
    "        \"Contract Date\": date,\n",
    "        \"Reported Date (By SGA)\": reported_date\n",
    "    }\n",
    "\n",
    "\n",
    "class GeographyInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "\n",
    "@tool(\"geography_extractor\")\n",
    "def geography_extractor(paragraph: str):\n",
    "    \"\"\"\n",
    "    STAGE 2 TOOL: GEOGRAPHY EXTRACTOR\n",
    "\n",
    "    GOAL:\n",
    "    Extract and derive geography information:\n",
    "    - Customer Country\n",
    "    - Customer Operator\n",
    "    - Supplier Country\n",
    "    - Customer Region (derived)\n",
    "    - Supplier Region (derived)\n",
    "    - Domestic Content (derived)\n",
    "\n",
    "    RULES FOR LLM:\n",
    "    ‚úÖ Return JSON only\n",
    "    ‚úÖ Keep short and clean values\n",
    "    ‚úÖ If missing -> \"Unknown\"\n",
    "    \"\"\"\n",
    "    sys_prompt = \"\"\"\n",
    "You are a Defense Contract Geography Analyst.\n",
    "\n",
    "Extract ONLY:\n",
    "1) Customer Country\n",
    "2) Customer Operator\n",
    "3) Supplier Country\n",
    "\n",
    "Return JSON ONLY:\n",
    "{\n",
    "  \"Customer Country\": \"...\",\n",
    "  \"Customer Operator\": \"...\",\n",
    "  \"Supplier Country\": \"...\"\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- If missing -> \"Unknown\"\n",
    "- Keep values short and clean\n",
    "\"\"\"\n",
    "\n",
    "    log_block(\"HUMAN MESSAGE (Stage2 - Geography)\", paragraph)\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": paragraph}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "        log_block(\"AI RESPONSE (Stage2 - Geography)\", json.dumps(raw, indent=2))\n",
    "    except Exception as e:\n",
    "        raw = {}\n",
    "        log_block(\"AI ERROR (Stage2 - Geography)\", str(e))\n",
    "\n",
    "    cust = raw.get(\"Customer Country\", \"Unknown\")\n",
    "    supp = raw.get(\"Supplier Country\", \"Unknown\")\n",
    "    domestic = \"Indigenous\" if str(cust).lower() == str(supp).lower() else \"Imported\"\n",
    "\n",
    "    return {\n",
    "        \"Customer Region\": get_region_for_country(cust),\n",
    "        \"Customer Country\": cust,\n",
    "        \"Customer Operator\": raw.get(\"Customer Operator\", \"Unknown\"),\n",
    "        \"Supplier Region\": get_region_for_country(supp),\n",
    "        \"Supplier Country\": supp,\n",
    "        \"Domestic Content\": domestic\n",
    "    }\n",
    "\n",
    "\n",
    "class SystemInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "\n",
    "@tool(\"system_classifier\")\n",
    "def system_classifier(paragraph: str):\n",
    "    \"\"\"\n",
    "    STAGE 3 TOOL: SYSTEM CLASSIFIER (RAG + TAXONOMY + EVIDENCE/REASON)\n",
    "\n",
    "    GOAL:\n",
    "    Assign system classification fields using:\n",
    "    ‚úÖ taxonomy.json\n",
    "    ‚úÖ deterministic rule-book triggers\n",
    "    ‚úÖ RAG examples from FAISS KB\n",
    "    ‚úÖ deterministic piloting override\n",
    "\n",
    "    REQUIRED OUTPUT (FLAT JSON):\n",
    "    - Market Segment\n",
    "    - System Type (General)\n",
    "    - System Type (Specific)\n",
    "    - System Name (General)\n",
    "    - System Name (Specific)\n",
    "    - System Piloting (overridden in python)\n",
    "    - Confidence\n",
    "\n",
    "    REQUIRED SUPPORT FIELDS:\n",
    "    - Evidence fields must match EXACT paragraph text\n",
    "    - Reason fields are short and logical\n",
    "\n",
    "    STRICT RULES:\n",
    "    ‚úÖ Output FLAT JSON ONLY\n",
    "    ‚úÖ All values must be STRING\n",
    "    ‚úÖ Evidence must be EXACT substring from paragraph\n",
    "    ‚úÖ If evidence not found -> \"Not Found\"\n",
    "    \"\"\"\n",
    "    paragraph = str(paragraph).strip()\n",
    "    if not paragraph:\n",
    "        return {}\n",
    "\n",
    "    log_block(\"HUMAN MESSAGE (Stage3 - System)\", paragraph)\n",
    "\n",
    "    lower_text = paragraph.lower()\n",
    "    hints = [\n",
    "        f\"RULE: {v['guidance']}\"\n",
    "        for _, v in RULE_BOOK.items()\n",
    "        if any(t in lower_text for t in v[\"triggers\"])\n",
    "    ]\n",
    "    hint_str = \"\\n\".join(hints) if hints else \"No special override rules triggered.\"\n",
    "\n",
    "    designators = extract_designators(paragraph)\n",
    "    piloting_rule = detect_piloting_rule_based(paragraph, designators)\n",
    "\n",
    "    rag_hits = retriever.retrieve(paragraph, top_k=3)\n",
    "    rag_examples = []\n",
    "    for hit in rag_hits:\n",
    "        meta = hit[\"meta\"]\n",
    "        rag_examples.append({\n",
    "            \"score\": round(hit[\"score\"], 4),\n",
    "            \"Market Segment\": meta.get(\"Market Segment\", \"\"),\n",
    "            \"System Type (General)\": meta.get(\"System Type (General)\", \"\"),\n",
    "            \"System Type (Specific)\": meta.get(\"System Type (Specific)\", \"\"),\n",
    "            \"System Name (General)\": meta.get(\"System Name (General)\", \"\"),\n",
    "            \"System Name (Specific)\": meta.get(\"System Name (Specific)\", \"\"),\n",
    "            \"System Piloting\": meta.get(\"System Piloting\", \"\"),\n",
    "            \"Snippet\": meta.get(\"Description of Contract\", \"\")[:200] + \"...\"\n",
    "        })\n",
    "\n",
    "    sys_prompt = f\"\"\"\n",
    "You are a Senior Defense System Classification Analyst.\n",
    "\n",
    "REFERENCE TAXONOMY:\n",
    "{TAXONOMY_STR}\n",
    "\n",
    "RULE BOOK OVERRIDES:\n",
    "{hint_str}\n",
    "\n",
    "STRICT OUTPUT RULES:\n",
    "- Return ONLY a FLAT JSON object\n",
    "- Every value MUST be a STRING\n",
    "- Evidence MUST be copied EXACTLY from paragraph\n",
    "- If evidence not found -> \"Not Found\"\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"Market Segment\": \"\",\n",
    "  \"Market Segment Evidence\": \"\",\n",
    "  \"Market Segment Reason\": \"\",\n",
    "\n",
    "  \"System Type (General)\": \"\",\n",
    "  \"System Type (General) Evidence\": \"\",\n",
    "  \"System Type (General) Reason\": \"\",\n",
    "\n",
    "  \"System Type (Specific)\": \"\",\n",
    "  \"System Type (Specific) Evidence\": \"\",\n",
    "  \"System Type (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Name (General)\": \"\",\n",
    "  \"System Name (General) Evidence\": \"\",\n",
    "  \"System Name (General) Reason\": \"\",\n",
    "\n",
    "  \"System Name (Specific)\": \"\",\n",
    "  \"System Name (Specific) Evidence\": \"\",\n",
    "  \"System Name (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Piloting\": \"\",\n",
    "  \"System Piloting Evidence\": \"\",\n",
    "  \"System Piloting Reason\": \"\",\n",
    "\n",
    "  \"Confidence\": \"High/Medium/Low\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "PARAGRAPH:\n",
    "{paragraph}\n",
    "\n",
    "DESIGNATORS:\n",
    "{designators if designators else \"None\"}\n",
    "\n",
    "RULE PILOTING OVERRIDE:\n",
    "{piloting_rule}\n",
    "\n",
    "RAG EXAMPLES:\n",
    "{json.dumps(rag_examples, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        result = json.loads(completion.choices[0].message.content)\n",
    "        log_block(\"AI RESPONSE (Stage3 - System)\", json.dumps(result, indent=2))\n",
    "\n",
    "        result[\"System Piloting\"] = piloting_rule\n",
    "        result.setdefault(\"System Piloting Evidence\", \"Not Found\")\n",
    "        result.setdefault(\"System Piloting Reason\", \"Derived using deterministic piloting rules.\")\n",
    "\n",
    "        # enforce flat\n",
    "        for k, v in result.items():\n",
    "            if isinstance(v, (dict, list)):\n",
    "                result[k] = str(v)\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        log_block(\"AI ERROR (Stage3 - System)\", str(e))\n",
    "        return {\n",
    "            \"Market Segment\": \"\",\n",
    "            \"Market Segment Evidence\": \"Not Found\",\n",
    "            \"Market Segment Reason\": \"\",\n",
    "\n",
    "            \"System Type (General)\": \"\",\n",
    "            \"System Type (General) Evidence\": \"Not Found\",\n",
    "            \"System Type (General) Reason\": \"\",\n",
    "\n",
    "            \"System Type (Specific)\": \"\",\n",
    "            \"System Type (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Type (Specific) Reason\": \"\",\n",
    "\n",
    "            \"System Name (General)\": \"\",\n",
    "            \"System Name (General) Evidence\": \"Not Found\",\n",
    "            \"System Name (General) Reason\": \"\",\n",
    "\n",
    "            \"System Name (Specific)\": \"\",\n",
    "            \"System Name (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Name (Specific) Reason\": \"\",\n",
    "\n",
    "            \"System Piloting\": piloting_rule,\n",
    "            \"System Piloting Evidence\": \"Not Found\",\n",
    "            \"System Piloting Reason\": \"Derived using deterministic piloting rules (fallback).\",\n",
    "\n",
    "            \"Confidence\": \"Low\",\n",
    "            \"Error\": str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "class ContractInfoInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    contract_date: str = Field(description=\"Contract date string.\")\n",
    "\n",
    "@tool(\"contract_extractor\")\n",
    "def contract_extractor(paragraph: str, contract_date: str):\n",
    "    \"\"\"\n",
    "    STAGE 4 TOOL: CONTRACT EXTRACTOR (Financial + Program)\n",
    "\n",
    "    GOAL:\n",
    "    Extract supplier/program/financial fields in a structured JSON output.\n",
    "\n",
    "    REQUIRED OUTPUT KEYS:\n",
    "    - raw_supplier_name\n",
    "    - program_type\n",
    "    - value_million_raw\n",
    "    - currency_code\n",
    "    - value_certainty\n",
    "    - quantity\n",
    "    - completion_date_text\n",
    "    - g2g_b2g\n",
    "    - value_note\n",
    "\n",
    "    RULES:\n",
    "    ‚úÖ Supplier name must come EXACTLY from paragraph\n",
    "    ‚úÖ program_type must be one of:\n",
    "       Procurement/Training/MRO/Support/RDT&E/Upgrade/Other Service\n",
    "    ‚úÖ g2g_b2g: if FMS -> G2G else B2G\n",
    "    ‚úÖ quantity numeric else \"Not Applicable\"\n",
    "\n",
    "    POST-PROCESSING:\n",
    "    - supplier standardized using suppliers.json\n",
    "    - values formatted to 3 decimals\n",
    "    - signing month/year derived from contract_date\n",
    "    \"\"\"\n",
    "    system_instruction = \"\"\"\n",
    "You are a Defense Contract Financial Analyst.\n",
    "\n",
    "Return JSON ONLY.\n",
    "\n",
    "Rules:\n",
    "1) raw_supplier_name: extract exact supplier from paragraph text\n",
    "2) program_type: Procurement/Training/MRO/Support/RDT&E/Upgrade/Other Service\n",
    "3) value_certainty: Confirmed vs Estimated\n",
    "4) quantity: numeric if found else Not Applicable\n",
    "5) g2g_b2g: G2G only if FMS mentioned else B2G\n",
    "6) completion_date_text: end date if mentioned\n",
    "7) value_million_raw: numeric only\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "PARAGRAPH:\n",
    "{paragraph}\n",
    "\n",
    "SIGNED DATE:\n",
    "{contract_date}\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"raw_supplier_name\": \"\",\n",
    "  \"program_type\": \"\",\n",
    "  \"value_million_raw\": \"\",\n",
    "  \"currency_code\": \"\",\n",
    "  \"value_certainty\": \"\",\n",
    "  \"quantity\": \"\",\n",
    "  \"completion_date_text\": \"\",\n",
    "  \"g2g_b2g\": \"\",\n",
    "  \"value_note\": \"\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    log_block(\"HUMAN MESSAGE (Stage4 - Contract)\", paragraph)\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_instruction},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "        log_block(\"AI RESPONSE (Stage4 - Contract)\", json.dumps(raw, indent=2))\n",
    "    except Exception as e:\n",
    "        log_block(\"AI ERROR (Stage4 - Contract)\", str(e))\n",
    "        return {\"Error\": str(e)}\n",
    "\n",
    "    final_supplier = get_best_supplier_match(raw.get(\"raw_supplier_name\"))\n",
    "\n",
    "    prog_type = raw.get(\"program_type\", \"Unknown\")\n",
    "    mro_months = calculate_mro_months(contract_date, raw.get(\"completion_date_text\"), prog_type)\n",
    "\n",
    "    try:\n",
    "        val_str = str(raw.get(\"value_million_raw\", \"0\")).replace(\",\", \"\").replace(\"$\", \"\")\n",
    "        val_float = float(val_str)\n",
    "        val_formatted = \"{:.3f}\".format(val_float)\n",
    "    except:\n",
    "        val_formatted = \"0.000\"\n",
    "\n",
    "    try:\n",
    "        dt = pd.to_datetime(contract_date)\n",
    "        sign_month = dt.strftime(\"%B\")\n",
    "        sign_year = str(dt.year)\n",
    "    except:\n",
    "        sign_month, sign_year = \"Unknown\", \"Unknown\"\n",
    "\n",
    "    return {\n",
    "        \"Supplier Name\": final_supplier,\n",
    "        \"Program Type\": prog_type,\n",
    "        \"Expected MRO Contract Duration (Months)\": mro_months,\n",
    "        \"Quantity\": raw.get(\"quantity\", \"Not Applicable\"),\n",
    "        \"Value Certainty\": raw.get(\"value_certainty\", \"Confirmed\"),\n",
    "        \"Value (Million)\": val_formatted,\n",
    "        \"Currency\": raw.get(\"currency_code\", \"USD$\"),\n",
    "        \"Value (USD$ Million)\": val_formatted,\n",
    "        \"Value Note (If Any)\": raw.get(\"value_note\", \"Not Applicable\"),\n",
    "        \"G2G/B2G\": raw.get(\"g2g_b2g\", \"B2G\"),\n",
    "        \"Signing Month\": sign_month,\n",
    "        \"Signing Year\": sign_year\n",
    "    }\n",
    "\n",
    "\n",
    "class SplitterInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    base_row: dict = Field(description=\"Final extracted row after Stage1-4.\")\n",
    "\n",
    "@tool(\"splitter_agent\")\n",
    "def splitter_agent(paragraph: str, base_row: dict):\n",
    "    \"\"\"\n",
    "    STAGE 5 TOOL: SPLITTER AGENT (DETERMINISTIC)\n",
    "\n",
    "    GOAL:\n",
    "    Apply deterministic row split logic to handle:\n",
    "    - Multi-operator allocations (Navy/Air Force/etc)\n",
    "    - FMS allocations (G2G)\n",
    "    - Multi-country FMS list\n",
    "\n",
    "    OUTPUT:\n",
    "    Returns:\n",
    "    {\n",
    "      \"rows\": [row1, row2, ...]\n",
    "    }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        rows = split_rows_engine(base_row, paragraph)\n",
    "        for r in rows:\n",
    "            r.setdefault(\"Split Flag\", \"No\")\n",
    "            r.setdefault(\"Split Reason\", \"\")\n",
    "            r.setdefault(\"Split Evidence\", \"Not Found\")\n",
    "            r.setdefault(\"Split Line Item\", \"Not Found\")\n",
    "        return {\"rows\": rows}\n",
    "    except Exception as e:\n",
    "        base_row = base_row.copy()\n",
    "        base_row[\"Split Flag\"] = \"Error\"\n",
    "        base_row[\"Split Reason\"] = f\"Split failed: {str(e)}\"\n",
    "        base_row[\"Split Evidence\"] = \"Not Found\"\n",
    "        base_row[\"Split Line Item\"] = \"Not Found\"\n",
    "        return {\"rows\": [base_row]}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 9) STAGE 6 QUALITY VALIDATOR (RULE-BASED + LIGHT AUTO-FIX)\n",
    "# ==============================================================================\n",
    "\n",
    "def _contains_any(text: str, keywords: List[str]) -> bool:\n",
    "    \"\"\"Returns True if any keyword appears in text (case-insensitive).\"\"\"\n",
    "    t = str(text or \"\").lower()\n",
    "    return any(k.lower() in t for k in keywords)\n",
    "\n",
    "def _supplier_appears_in_paragraph(supplier: str, paragraph: str) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if standardized supplier appears in paragraph text.\n",
    "\n",
    "    WHY:\n",
    "    - After standardization, supplier text might not match exactly\n",
    "      but partial match should still be detected.\n",
    "\n",
    "    RULE:\n",
    "    - If supplier == Unknown -> return False\n",
    "    \"\"\"\n",
    "    supplier = str(supplier or \"\").strip()\n",
    "    if not supplier or supplier.lower() == \"unknown\":\n",
    "        return False\n",
    "\n",
    "    p = str(paragraph or \"\").lower()\n",
    "    s = supplier.lower()\n",
    "\n",
    "    # try direct match\n",
    "    if s in p:\n",
    "        return True\n",
    "\n",
    "    # try partial token match (first 2 words)\n",
    "    parts = s.split()\n",
    "    if len(parts) >= 2:\n",
    "        key = \" \".join(parts[:2])\n",
    "        return key in p\n",
    "\n",
    "    return False\n",
    "\n",
    "def validate_single_row(row: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    VALIDATOR FUNCTION (RULE-BASED)\n",
    "\n",
    "    GOAL:\n",
    "    Validate one extracted output row for common errors like:\n",
    "    1) Supplier mismatch (supplier not present in paragraph)\n",
    "    2) Piloting mismatch (UAV but crewed)\n",
    "    3) Segment mismatch (radar but wrong Market Segment)\n",
    "    4) Value mismatch (Value missing but paragraph has $)\n",
    "    5) G2G/B2G mismatch (FMS but B2G)\n",
    "\n",
    "    OUTPUT:\n",
    "    Adds these fields:\n",
    "    - Validation Flag: PASS/FAIL/WARN\n",
    "    - Validation Issues: string summary\n",
    "    - AutoFix Applied: Yes/No\n",
    "    - AutoFix Notes: explanation\n",
    "\n",
    "    AUTOFIX POLICY (SAFE FIXES ONLY):\n",
    "    ‚úÖ Fix G2G/B2G to G2G if paragraph contains \"FMS\"\n",
    "    ‚úÖ Fix System Piloting using deterministic rules\n",
    "    ‚úÖ Fix Supplier Name if unknown using fallback extraction\n",
    "    ‚úÖ Fix Value Certainty = Estimated if paragraph contains \"estimated\"\n",
    "    ‚ùå Never modify Market Segment / System Name based on validator (too risky)\n",
    "    \"\"\"\n",
    "    updated = row.copy()\n",
    "    issues = []\n",
    "    autofix_notes = []\n",
    "    autofix_applied = False\n",
    "\n",
    "    paragraph = updated.get(\"Description of Contract\", \"\")\n",
    "    supplier = updated.get(\"Supplier Name\", \"Unknown\")\n",
    "\n",
    "    # 1) Supplier mismatch\n",
    "    if supplier and supplier != \"Unknown\":\n",
    "        if not _supplier_appears_in_paragraph(supplier, paragraph):\n",
    "            issues.append(\"Supplier Name not found in paragraph (possible wrong supplier extraction).\")\n",
    "\n",
    "    # 2) Piloting mismatch\n",
    "    designators = extract_designators(paragraph)\n",
    "    piloting_expected = detect_piloting_rule_based(paragraph, designators)\n",
    "    piloting_current = updated.get(\"System Piloting\", \"Not Applicable\")\n",
    "\n",
    "    if piloting_expected != \"Not Applicable\":\n",
    "        if piloting_current != piloting_expected:\n",
    "            issues.append(f\"System Piloting mismatch (expected={piloting_expected}, got={piloting_current}).\")\n",
    "            updated[\"System Piloting\"] = piloting_expected\n",
    "            updated[\"System Piloting Reason\"] = \"Validator override: deterministic piloting rules applied.\"\n",
    "            autofix_applied = True\n",
    "            autofix_notes.append(\"Corrected System Piloting using deterministic rules.\")\n",
    "\n",
    "    # 3) FMS mismatch\n",
    "    if _contains_any(paragraph, [\"fms\", \"foreign military sales\"]):\n",
    "        if updated.get(\"G2G/B2G\", \"B2G\") != \"G2G\":\n",
    "            issues.append(\"Paragraph mentions FMS but row marked as B2G.\")\n",
    "            updated[\"G2G/B2G\"] = \"G2G\"\n",
    "            autofix_applied = True\n",
    "            autofix_notes.append(\"Fixed G2G/B2G to G2G due to FMS keyword.\")\n",
    "\n",
    "    # 4) Value mismatch (simple)\n",
    "    if \"$\" in str(paragraph) and str(updated.get(\"Value (Million)\", \"\")).strip() in [\"\", \"0.000\", \"0\", \"Not Applicable\"]:\n",
    "        issues.append(\"Paragraph contains $ value but Value (Million) is missing/zero.\")\n",
    "\n",
    "    # 5) Segment sanity hint (warn only)\n",
    "    if _contains_any(paragraph, [\"radar\", \"an/apy\", \"an/tpy\"]) and updated.get(\"Market Segment\", \"\"):\n",
    "        if updated.get(\"Market Segment\") not in [\"C4ISR Systems\", \"C4ISR\"]:\n",
    "            issues.append(\"Radar keyword detected but Market Segment not C4ISR (check classification).\")\n",
    "\n",
    "    # 6) Supplier unknown autofix\n",
    "    if supplier in [\"Unknown\", \"\", None]:\n",
    "        fallback_supplier = _extract_supplier_from_description(paragraph)\n",
    "        if fallback_supplier != \"Unknown\":\n",
    "            updated[\"Supplier Name\"] = get_best_supplier_match(fallback_supplier)\n",
    "            autofix_applied = True\n",
    "            autofix_notes.append(\"Filled Supplier Name from DoD sentence fallback extraction.\")\n",
    "\n",
    "    updated[\"AutoFix Applied\"] = \"Yes\" if autofix_applied else \"No\"\n",
    "    updated[\"AutoFix Notes\"] = \" | \".join(autofix_notes) if autofix_notes else \"Not Applicable\"\n",
    "\n",
    "    if not issues:\n",
    "        updated[\"Validation Flag\"] = \"PASS\"\n",
    "        updated[\"Validation Issues\"] = \"No issues detected.\"\n",
    "    else:\n",
    "        # FAIL if supplier mismatch or value mismatch\n",
    "        severe = any(\n",
    "            \"Supplier Name not found\" in x or \"Value (Million) is missing\" in x\n",
    "            for x in issues\n",
    "        )\n",
    "        updated[\"Validation Flag\"] = \"FAIL\" if severe else \"WARN\"\n",
    "        updated[\"Validation Issues\"] = \" | \".join(issues)\n",
    "\n",
    "    return updated\n",
    "\n",
    "\n",
    "class ValidatorInput(BaseModel):\n",
    "    rows: list = Field(description=\"List of extracted rows AFTER splitting. Each row is a dict.\")\n",
    "\n",
    "@tool(\"quality_validator_agent\")\n",
    "def quality_validator_agent(rows: list):\n",
    "    \"\"\"\n",
    "    STAGE 6 TOOL: QUALITY VALIDATOR AGENT\n",
    "\n",
    "    GOAL:\n",
    "    Validate final output rows AFTER split logic.\n",
    "\n",
    "    INPUT:\n",
    "    - rows: list of extracted row dicts\n",
    "\n",
    "    OUTPUT:\n",
    "    - {\"validated_rows\": [row1, row2, ...]}\n",
    "\n",
    "    THIS TOOL:\n",
    "    ‚úÖ Detects likely extraction errors\n",
    "    ‚úÖ Applies SAFE auto-fixes only\n",
    "    ‚úÖ Adds validation columns\n",
    "\n",
    "    IT MUST NEVER:\n",
    "    ‚ùå Re-run system classification with LLM (expensive + unstable)\n",
    "    ‚ùå Override Market Segment/System Name based only on heuristic\n",
    "    \"\"\"\n",
    "    validated = []\n",
    "    for r in rows:\n",
    "        validated.append(validate_single_row(r))\n",
    "    return {\"validated_rows\": validated}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 10) LANGGRAPH PIPELINE\n",
    "# ==============================================================================\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    LangGraph pipeline shared state structure.\n",
    "\n",
    "    INPUTS:\n",
    "    - input_text: contract paragraph\n",
    "    - input_date: contract date string\n",
    "    - input_url: source url\n",
    "\n",
    "    INTERNAL:\n",
    "    - final_data: merged dict after Stage1-4\n",
    "    - final_rows: list after Stage5 split\n",
    "\n",
    "    FINAL:\n",
    "    - validated_rows: list after Stage6 quality validation\n",
    "\n",
    "    messages:\n",
    "    - reserved for message tracing\n",
    "    \"\"\"\n",
    "    input_text: str\n",
    "    input_date: str\n",
    "    input_url: str\n",
    "    final_data: dict\n",
    "    final_rows: list\n",
    "    validated_rows: list\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "def stage_1_sourcing(state: AgentState):\n",
    "    \"\"\"\n",
    "    LANGGRAPH NODE Stage1:\n",
    "    Runs sourcing_extractor and updates final_data.\n",
    "    \"\"\"\n",
    "    res = sourcing_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"url\": state[\"input_url\"],\n",
    "        \"date\": state[\"input_date\"],\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_2_geography(state: AgentState):\n",
    "    \"\"\"\n",
    "    LANGGRAPH NODE Stage2:\n",
    "    Runs geography_extractor and updates final_data.\n",
    "    \"\"\"\n",
    "    res = geography_extractor.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_3_system(state: AgentState):\n",
    "    \"\"\"\n",
    "    LANGGRAPH NODE Stage3:\n",
    "    Runs system_classifier and updates final_data.\n",
    "    \"\"\"\n",
    "    res = system_classifier.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_4_contract(state: AgentState):\n",
    "    \"\"\"\n",
    "    LANGGRAPH NODE Stage4:\n",
    "    Runs contract_extractor and updates final_data.\n",
    "    \"\"\"\n",
    "    res = contract_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"contract_date\": state[\"input_date\"]\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_5_split(state: AgentState):\n",
    "    \"\"\"\n",
    "    LANGGRAPH NODE Stage5:\n",
    "    Runs splitter_agent and outputs final_rows.\n",
    "    \"\"\"\n",
    "    res = splitter_agent.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"base_row\": state[\"final_data\"]\n",
    "    })\n",
    "    return {\"final_rows\": res.get(\"rows\", [state[\"final_data\"]])}\n",
    "\n",
    "\n",
    "def stage_6_validate(state: AgentState):\n",
    "    \"\"\"\n",
    "    LANGGRAPH NODE Stage6:\n",
    "    Runs quality_validator_agent on Stage5 output rows.\n",
    "\n",
    "    OUTPUT:\n",
    "    - validated_rows: list of post-validated rows\n",
    "    \"\"\"\n",
    "    res = quality_validator_agent.invoke({\n",
    "        \"rows\": state.get(\"final_rows\", [])\n",
    "    })\n",
    "    return {\"validated_rows\": res.get(\"validated_rows\", state.get(\"final_rows\", []))}\n",
    "\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Stage1\", stage_1_sourcing)\n",
    "workflow.add_node(\"Stage2\", stage_2_geography)\n",
    "workflow.add_node(\"Stage3\", stage_3_system)\n",
    "workflow.add_node(\"Stage4\", stage_4_contract)\n",
    "workflow.add_node(\"Stage5\", stage_5_split)\n",
    "workflow.add_node(\"Stage6\", stage_6_validate)\n",
    "\n",
    "workflow.add_edge(START, \"Stage1\")\n",
    "workflow.add_edge(\"Stage1\", \"Stage2\")\n",
    "workflow.add_edge(\"Stage2\", \"Stage3\")\n",
    "workflow.add_edge(\"Stage3\", \"Stage4\")\n",
    "workflow.add_edge(\"Stage4\", \"Stage5\")\n",
    "workflow.add_edge(\"Stage5\", \"Stage6\")\n",
    "workflow.add_edge(\"Stage6\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 11) GRAPH VISUALIZATION\n",
    "# ==============================================================================\n",
    "\n",
    "def export_workflow_mermaid(app_obj, out_file=\"workflow.mmd\"):\n",
    "    \"\"\"\n",
    "    Exports LangGraph workflow graph to Mermaid format (.mmd).\n",
    "\n",
    "    WHY:\n",
    "    - Helps document the agentic pipeline\n",
    "    - Offline-safe (no API calls to mermaid.ink)\n",
    "    \"\"\"\n",
    "    mmd = app_obj.get_graph().draw_mermaid()\n",
    "    with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(mmd)\n",
    "    print(f\"‚úÖ Workflow Mermaid saved locally: {out_file}\")\n",
    "    return out_file\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 12) EXCEL HIGHLIGHTING FEATURE\n",
    "# ==============================================================================\n",
    "\n",
    "def highlight_evidence_reason_columns(excel_path: str):\n",
    "    \"\"\"\n",
    "    Highlights Evidence + Reason columns in output Excel.\n",
    "\n",
    "    Evidence Columns -> Yellow\n",
    "    Reason Columns   -> Blue\n",
    "\n",
    "    WHY:\n",
    "    - Makes validation easy for reviewers\n",
    "    - Improves interpretability\n",
    "\n",
    "    NOTE:\n",
    "    - Applies to the active sheet\n",
    "    \"\"\"\n",
    "    wb = load_workbook(excel_path)\n",
    "    ws = wb.active\n",
    "\n",
    "    header = [cell.value for cell in ws[1]]\n",
    "\n",
    "    evidence_cols = []\n",
    "    reason_cols = []\n",
    "\n",
    "    for idx, col_name in enumerate(header, start=1):\n",
    "        if isinstance(col_name, str) and \"Evidence\" in col_name:\n",
    "            evidence_cols.append(idx)\n",
    "        if isinstance(col_name, str) and \"Reason\" in col_name:\n",
    "            reason_cols.append(idx)\n",
    "\n",
    "    evidence_fill = PatternFill(start_color=\"FFF2CC\", end_color=\"FFF2CC\", fill_type=\"solid\")\n",
    "    reason_fill = PatternFill(start_color=\"D9E1F2\", end_color=\"D9E1F2\", fill_type=\"solid\")\n",
    "    header_font = Font(bold=True)\n",
    "\n",
    "    for col_idx in evidence_cols:\n",
    "        ws.cell(row=1, column=col_idx).fill = evidence_fill\n",
    "        ws.cell(row=1, column=col_idx).font = header_font\n",
    "\n",
    "    for col_idx in reason_cols:\n",
    "        ws.cell(row=1, column=col_idx).fill = reason_fill\n",
    "        ws.cell(row=1, column=col_idx).font = header_font\n",
    "\n",
    "    for row in range(2, ws.max_row + 1):\n",
    "        for col_idx in evidence_cols:\n",
    "            ws.cell(row=row, column=col_idx).fill = evidence_fill\n",
    "        for col_idx in reason_cols:\n",
    "            ws.cell(row=row, column=col_idx).fill = reason_fill\n",
    "\n",
    "    wb.save(excel_path)\n",
    "    print(\"‚úÖ Evidence + Reason columns highlighted successfully.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 13) MAIN EXECUTION\n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(f\"\\nüìå Loading Input File: {INPUT_EXCEL_PATH}\")\n",
    "\n",
    "    # Offline-safe workflow graph output\n",
    "    export_workflow_mermaid(app, out_file=\"workflow.mmd\")\n",
    "\n",
    "    try:\n",
    "        df_input = pd.read_excel(INPUT_EXCEL_PATH)\n",
    "\n",
    "        required_cols = [\"Source URL\", \"Contract Date\", \"Contract Description\"]\n",
    "        if not all(col in df_input.columns for col in required_cols):\n",
    "            raise ValueError(f\"Excel file must contain columns: {required_cols}\")\n",
    "\n",
    "        print(f\"üöÄ Processing {len(df_input)} rows...\")\n",
    "        results = []\n",
    "\n",
    "        for index, row in df_input.iterrows():\n",
    "            print(f\"\\nüîπ Row {index + 1}/{len(df_input)}\")\n",
    "\n",
    "            desc = str(row[\"Contract Description\"]) if pd.notna(row[\"Contract Description\"]) else \"\"\n",
    "            c_date = str(row[\"Contract Date\"]) if pd.notna(row[\"Contract Date\"]) else str(datetime.date.today())\n",
    "            c_url = str(row[\"Source URL\"]) if pd.notna(row[\"Source URL\"]) else \"\"\n",
    "\n",
    "            initial_state = {\n",
    "                \"input_text\": desc,\n",
    "                \"input_date\": c_date,\n",
    "                \"input_url\": c_url,\n",
    "                \"final_data\": {},\n",
    "                \"final_rows\": [],\n",
    "                \"validated_rows\": [],\n",
    "                \"messages\": []\n",
    "            }\n",
    "\n",
    "            output_state = app.invoke(initial_state)\n",
    "\n",
    "            rows = output_state.get(\"validated_rows\", [])\n",
    "            if not rows:\n",
    "                rows = output_state.get(\"final_rows\", [])\n",
    "            if not rows:\n",
    "                rows = [output_state.get(\"final_data\", {})]\n",
    "\n",
    "            results.extend(rows)\n",
    "\n",
    "        df_final = pd.DataFrame(results)\n",
    "\n",
    "        FINAL_COLUMNS = [\n",
    "            \"Customer Region\", \"Customer Country\", \"Customer Operator\",\n",
    "            \"Supplier Region\", \"Supplier Country\", \"Domestic Content\",\n",
    "\n",
    "            \"Split Flag\", \"Split Reason\", \"Split Evidence\", \"Split Line Item\",\n",
    "\n",
    "            \"Market Segment\", \"Market Segment Evidence\", \"Market Segment Reason\",\n",
    "            \"System Type (General)\", \"System Type (General) Evidence\", \"System Type (General) Reason\",\n",
    "            \"System Type (Specific)\", \"System Type (Specific) Evidence\", \"System Type (Specific) Reason\",\n",
    "            \"System Name (General)\", \"System Name (General) Evidence\", \"System Name (General) Reason\",\n",
    "            \"System Name (Specific)\", \"System Name (Specific) Evidence\", \"System Name (Specific) Reason\",\n",
    "            \"System Piloting\", \"System Piloting Evidence\", \"System Piloting Reason\",\n",
    "            \"Confidence\",\n",
    "\n",
    "            \"Supplier Name\", \"Program Type\", \"Expected MRO Contract Duration (Months)\",\n",
    "            \"Quantity\", \"Value Certainty\", \"Value (Million)\", \"Currency\",\n",
    "            \"Value (USD$ Million)\", \"Value Note (If Any)\", \"G2G/B2G\",\n",
    "            \"Signing Month\", \"Signing Year\",\n",
    "\n",
    "            # Stage 6 validation columns\n",
    "            \"Validation Flag\", \"Validation Issues\",\n",
    "            \"AutoFix Applied\", \"AutoFix Notes\",\n",
    "\n",
    "            \"Description of Contract\",\n",
    "            \"Additional Notes (Internal Only)\",\n",
    "            \"Source Link(s)\",\n",
    "            \"Contract Date\",\n",
    "            \"Reported Date (By SGA)\"\n",
    "        ]\n",
    "\n",
    "        df_final = df_final.reindex(columns=FINAL_COLUMNS, fill_value=\"\")\n",
    "        df_final.to_excel(OUTPUT_EXCEL_PATH, index=False)\n",
    "\n",
    "        highlight_evidence_reason_columns(OUTPUT_EXCEL_PATH)\n",
    "\n",
    "        print(\"\\n‚úÖ Processing Complete!\")\n",
    "        print(f\"üíæ Output File Saved: {OUTPUT_EXCEL_PATH}\")\n",
    "        print(df_final.head(3).to_string(index=False))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511a61ab",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import difflib\n",
    "import pickle\n",
    "import datetime\n",
    "from typing import Annotated, TypedDict, List, Dict, Any, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import getpass\n",
    "\n",
    "# LangGraph / LangChain\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "\n",
    "# Excel formatting\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill, Font\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 0) DEBUG LOGGING HELPERS\n",
    "# ==============================================================================\n",
    "\n",
    "def log_block(title: str, content: str):\n",
    "    \"\"\"\n",
    "    Prints a clean and separated debug block in the console.\n",
    "\n",
    "    WHY THIS MATTERS:\n",
    "    - You have multiple stages: Stage1 -> Stage6\n",
    "    - When a value is wrong, you must inspect prompts + responses per stage\n",
    "    - Helps debugging extraction + validation decisions row-by-row\n",
    "\n",
    "    OUTPUT:\n",
    "    - Clearly separated logs (title + content)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 130)\n",
    "    print(title)\n",
    "    print(\"=\" * 130)\n",
    "    print(content)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 1) RAG RETRIEVER (FAISS + Metadata)\n",
    "# ==============================================================================\n",
    "\n",
    "class SystemKBRetriever:\n",
    "    \"\"\"\n",
    "    RAG Retriever for Defense System Classification.\n",
    "\n",
    "    PURPOSE:\n",
    "    - Loads FAISS index and metadata from kb_dir\n",
    "    - Retrieves top-k similar labeled examples\n",
    "\n",
    "    WHY:\n",
    "    - Makes system classification consistent against your labeled KB dataset\n",
    "    - Reduces hallucination and random taxonomy mapping\n",
    "\n",
    "    EXPECTED FILES:\n",
    "    - system_kb.faiss\n",
    "    - system_kb_meta.pkl\n",
    "\n",
    "    OUTPUT:\n",
    "    retrieve(query_text) returns:\n",
    "      [\n",
    "        {\"score\": float, \"meta\": dict_of_kb_row},\n",
    "        ...\n",
    "      ]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kb_dir: str, embed_model: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initializes retriever:\n",
    "        - loads FAISS index\n",
    "        - loads metadata rows list\n",
    "        - lazy-loads sentence-transformer embedder\n",
    "        \"\"\"\n",
    "        self.kb_dir = kb_dir\n",
    "        self.embed_model = embed_model\n",
    "\n",
    "        index_path = os.path.join(kb_dir, \"system_kb.faiss\")\n",
    "        meta_path = os.path.join(kb_dir, \"system_kb_meta.pkl\")\n",
    "\n",
    "        if not os.path.exists(index_path) or not os.path.exists(meta_path):\n",
    "            raise FileNotFoundError(\n",
    "                f\"‚ùå KB files not found in: {kb_dir}\\n\"\n",
    "                f\"Expected:\\n- {index_path}\\n- {meta_path}\\n\\n\"\n",
    "                f\"Build the KB first before running this pipeline.\"\n",
    "            )\n",
    "\n",
    "        print(f\"‚úÖ Loading FAISS Index: {index_path}\")\n",
    "        self.index = faiss.read_index(index_path)\n",
    "\n",
    "        print(f\"‚úÖ Loading KB Metadata: {meta_path}\")\n",
    "        with open(meta_path, \"rb\") as f:\n",
    "            self.meta = pickle.load(f)\n",
    "\n",
    "        print(f\"‚úÖ KB Loaded rows: {len(self.meta)}\")\n",
    "        self.embedder = None\n",
    "\n",
    "    def _lazy_load_embedder(self):\n",
    "        \"\"\"\n",
    "        Loads embedding model only when needed.\n",
    "\n",
    "        WHY:\n",
    "        - Faster script startup\n",
    "        - Saves memory until retrieval is actually requested\n",
    "        \"\"\"\n",
    "        if self.embedder is None:\n",
    "            from sentence_transformers import SentenceTransformer\n",
    "            self.embedder = SentenceTransformer(self.embed_model)\n",
    "\n",
    "    def retrieve(self, query_text: str, top_k: int = 3):\n",
    "        \"\"\"\n",
    "        Retrieve top-k nearest semantic matches from FAISS.\n",
    "\n",
    "        INPUT:\n",
    "        - query_text: paragraph string\n",
    "        - top_k: number of matches\n",
    "\n",
    "        OUTPUT:\n",
    "        - list of {score, meta}\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "\n",
    "        query_text = str(query_text).strip()\n",
    "        if not query_text:\n",
    "            return []\n",
    "\n",
    "        self._lazy_load_embedder()\n",
    "\n",
    "        q_emb = self.embedder.encode([query_text], normalize_embeddings=True).astype(\"float32\")\n",
    "        scores, idxs = self.index.search(q_emb, top_k)\n",
    "\n",
    "        results = []\n",
    "        for score, idx in zip(scores[0], idxs[0]):\n",
    "            if idx < 0:\n",
    "                continue\n",
    "            results.append({\"score\": float(score), \"meta\": self.meta[idx]})\n",
    "        return results\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2) CONFIGURATION & FILE PATHS\n",
    "# ==============================================================================\n",
    "\n",
    "TAXONOMY_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\taxonomy.json\"\n",
    "SUPPLIERS_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\suppliers.json\"\n",
    "INPUT_EXCEL_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\data\\source_file.xlsx\"\n",
    "OUTPUT_EXCEL_PATH = \"Processed_Defense_Data.xlsx\"\n",
    "RAG_KB_DIR = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\system_kb_store\"\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3) SETUP LLM CLIENT\n",
    "# ==============================================================================\n",
    "\n",
    "if \"LLMFOUNDRY_TOKEN\" not in os.environ:\n",
    "    os.environ[\"LLMFOUNDRY_TOKEN\"] = getpass.getpass(\"Enter the LLM Foundry API Key: \")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=f'{os.environ.get(\"LLMFOUNDRY_TOKEN\")}:my-test-project',\n",
    "    base_url=\"https://llmfoundry.straive.com/openai/v1/\",\n",
    ")\n",
    "\n",
    "retriever = SystemKBRetriever(kb_dir=RAG_KB_DIR)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4) LOAD JSON HELPERS\n",
    "# ==============================================================================\n",
    "\n",
    "def load_json_file(filename, default_value):\n",
    "    \"\"\"\n",
    "    Safe JSON loader.\n",
    "\n",
    "    WHY:\n",
    "    - taxonomy.json / suppliers.json are required for extraction + normalization\n",
    "    - pipeline should not crash if missing; should fallback\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            print(f\"‚úÖ Loaded: {filename}\")\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Warning: Could not load {filename} ({e}). Using default.\")\n",
    "        return default_value\n",
    "\n",
    "\n",
    "raw_taxonomy = load_json_file(TAXONOMY_PATH, {})\n",
    "TAXONOMY_STR = json.dumps(raw_taxonomy, separators=(\",\", \":\"))\n",
    "\n",
    "SUPPLIER_LIST = load_json_file(SUPPLIERS_PATH, [\n",
    "    \"Dell Inc\", \"Boeing\", \"Lockheed Martin\", \"Raytheon Technologies\",\n",
    "    \"Northrop Grumman\", \"L3Harris\", \"BAE Systems\", \"General Dynamics\"\n",
    "])\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 5) RULE BOOK + GEOGRAPHY\n",
    "# ==============================================================================\n",
    "\n",
    "RULE_BOOK = {\n",
    "    \"defensive_countermeasures\": {\n",
    "        \"triggers\": [\"flare\", \"chaff\", \"countermeasure\", \"decoy\", \"mju-\", \"ale-\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Defensive Systems', Specific: 'Defensive Aid Suite'\"\n",
    "    },\n",
    "    \"radars_and_sensors\": {\n",
    "        \"triggers\": [\"radar\", \"sonar\", \"sensor\", \"an/apy\", \"an/tpy\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Sensors'\"\n",
    "    },\n",
    "    \"ammunition\": {\n",
    "        \"triggers\": [\"cartridge\", \"round\", \"projectile\", \" 5.56\", \" 7.62\", \"ammo\"],\n",
    "        \"guidance\": \"Market Segment: 'Weapon Systems', System Type (General): 'Ammunition'\"\n",
    "    }\n",
    "}\n",
    "\n",
    "GEOGRAPHY_MAPPING = {\n",
    "    \"North America\": [\"USA\", \"United States\", \"US\", \"United States of America\", \"Canada\", \"America\"],\n",
    "    \"Europe\": [\"UK\", \"United Kingdom\", \"Ukraine\", \"Germany\", \"France\", \"Italy\", \"Spain\", \"Poland\", \"Netherlands\",\n",
    "               \"Norway\", \"Sweden\", \"Finland\", \"Denmark\", \"Belgium\"],\n",
    "    \"Asia-Pacific\": [\"Australia\", \"Japan\", \"South Korea\", \"Taiwan\", \"India\", \"Singapore\", \"New Zealand\"],\n",
    "    \"Middle East and North Africa\": [\"Israel\", \"Saudi Arabia\", \"UAE\", \"United Arab Emirates\", \"Egypt\", \"Qatar\", \"Kuwait\", \"Iraq\"],\n",
    "    \"International Organisations\": [\"NATO\", \"EU\", \"IFU\", \"UN\", \"NSPA\"]\n",
    "}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 6) BASE HELPERS (Supplier + Dates + Region + Designators)\n",
    "# ==============================================================================\n",
    "\n",
    "def get_best_supplier_match(extracted_name: str):\n",
    "    \"\"\"\n",
    "    Standardizes supplier names using suppliers.json.\n",
    "\n",
    "    STRATEGY:\n",
    "    1) Unknown/blank -> \"Unknown\"\n",
    "    2) Exact match ignoring case\n",
    "    3) Fuzzy match with difflib\n",
    "    4) fallback to cleaned extracted string\n",
    "    \"\"\"\n",
    "    if not extracted_name or str(extracted_name).strip().lower() in [\"unknown\", \"n/a\", \"not applicable\", \"\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    clean_name = str(extracted_name).strip()\n",
    "    supplier_map = {s.lower(): s for s in SUPPLIER_LIST}\n",
    "\n",
    "    if clean_name.lower() in supplier_map:\n",
    "        return supplier_map[clean_name.lower()]\n",
    "\n",
    "    matches = difflib.get_close_matches(clean_name, SUPPLIER_LIST, n=1, cutoff=0.6)\n",
    "    return matches[0] if matches else clean_name\n",
    "\n",
    "\n",
    "def calculate_mro_months(start_date_str, end_date_text, program_type):\n",
    "    \"\"\"\n",
    "    Calculates MRO duration in months.\n",
    "\n",
    "    RULE:\n",
    "    - Only valid when program_type == \"MRO/Support\"\n",
    "    \"\"\"\n",
    "    if program_type != \"MRO/Support\":\n",
    "        return \"Not Applicable\"\n",
    "    try:\n",
    "        if not start_date_str or not end_date_text:\n",
    "            return \"Not Applicable\"\n",
    "\n",
    "        start = pd.to_datetime(start_date_str, dayfirst=True)\n",
    "        end = parser.parse(str(end_date_text), fuzzy=True)\n",
    "\n",
    "        diff = relativedelta(end, start)\n",
    "        total_months = diff.years * 12 + diff.months\n",
    "        return str(max(0, int(total_months)))\n",
    "    except:\n",
    "        return \"Not Applicable\"\n",
    "\n",
    "\n",
    "def get_region_for_country(country_name):\n",
    "    \"\"\"\n",
    "    Maps country name to region bucket.\n",
    "\n",
    "    OUTPUT:\n",
    "    - region string OR \"Unknown\"\n",
    "    \"\"\"\n",
    "    if not country_name or str(country_name).strip().lower() in [\"unknown\", \"n/a\", \"not applicable\", \"\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    clean = str(country_name).strip().lower()\n",
    "\n",
    "    if clean in [\"us\", \"usa\", \"u.s.\", \"united states\", \"united states of america\"]:\n",
    "        return \"North America\"\n",
    "    if clean in [\"uk\", \"u.k.\", \"britain\", \"great britain\"]:\n",
    "        return \"Europe\"\n",
    "\n",
    "    for region, countries in GEOGRAPHY_MAPPING.items():\n",
    "        if any(c.lower() == clean for c in countries):\n",
    "            return region\n",
    "\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "DESIGNATOR_PATTERNS = [\n",
    "    r\"\\bDDG[-\\s]?\\d+\\b\", r\"\\bCVN[-\\s]?\\d+\\b\", r\"\\bSSN[-\\s]?\\d+\\b\",\n",
    "    r\"\\bLCS[-\\s]?\\d+\\b\", r\"\\bLPD[-\\s]?\\d+\\b\", r\"\\bLHA[-\\s]?\\d+\\b\", r\"\\bLHD[-\\s]?\\d+\\b\",\n",
    "    r\"\\bF-\\d+\\b\", r\"\\bB-\\d+\\b\", r\"\\bC-\\d+\\b\", r\"\\bA-\\d+\\b\",\n",
    "    r\"\\bMQ-\\d+\\b\", r\"\\bRQ-\\d+\\b\",\n",
    "    r\"\\bAN\\/[A-Z0-9\\-]+\\b\",\n",
    "    r\"\\b(AIM|AGM|SM|RIM|MIM)-\\d+\\b\",\n",
    "]\n",
    "\n",
    "def extract_designators(text: str):\n",
    "    \"\"\"\n",
    "    Extracts defense platform designators.\n",
    "\n",
    "    EXAMPLES:\n",
    "    - DDG-51, CVN-78\n",
    "    - MQ-9, RQ-4\n",
    "    - AN/APY-10\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    found = []\n",
    "    for pat in DESIGNATOR_PATTERNS:\n",
    "        found.extend(re.findall(pat, text, flags=re.IGNORECASE))\n",
    "\n",
    "    cleaned = []\n",
    "    for f in found:\n",
    "        cleaned.append(f.upper().replace(\" \", \"\").replace(\"--\", \"-\"))\n",
    "\n",
    "    final = []\n",
    "    seen = set()\n",
    "    for x in cleaned:\n",
    "        if x not in seen:\n",
    "            final.append(x)\n",
    "            seen.add(x)\n",
    "\n",
    "    return final\n",
    "\n",
    "\n",
    "def detect_piloting_rule_based(text: str, designators: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Determines System Piloting using deterministic rules.\n",
    "\n",
    "    OUTPUT:\n",
    "    - \"Crewed\"\n",
    "    - \"Uncrewed\"\n",
    "    - \"Not Applicable\"\n",
    "    \"\"\"\n",
    "    t = str(text).lower()\n",
    "\n",
    "    if any(d.startswith((\"MQ-\", \"RQ-\")) for d in designators):\n",
    "        return \"Uncrewed\"\n",
    "    if any(k in t for k in [\"unmanned\", \"uav\", \"drone\", \"autonomous\"]):\n",
    "        return \"Uncrewed\"\n",
    "\n",
    "    if any(d.startswith((\"DDG\", \"CVN\", \"SSN\", \"LCS\", \"LPD\", \"LHA\", \"LHD\")) for d in designators):\n",
    "        return \"Crewed\"\n",
    "    if \"uss \" in t:\n",
    "        return \"Crewed\"\n",
    "\n",
    "    return \"Not Applicable\"\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 7) SPLIT ENGINE (DETERMINISTIC)\n",
    "# ==============================================================================\n",
    "\n",
    "def _normalize_spaces(text: str) -> str:\n",
    "    \"\"\"Normalizes whitespace for stable regex parsing.\"\"\"\n",
    "    return re.sub(r\"\\s+\", \" \", str(text or \"\")).strip()\n",
    "\n",
    "def _safe_int(value: str):\n",
    "    \"\"\"Safely converts string to int; returns None if conversion fails.\"\"\"\n",
    "    try:\n",
    "        return int(str(value).replace(\",\", \"\").strip())\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _extract_supplier_from_description(paragraph: str) -> str:\n",
    "    \"\"\"\n",
    "    Fallback supplier extraction from typical DoD contract format.\n",
    "\n",
    "    Example:\n",
    "    \"Raytheon Technologies, Tucson, Arizona, is awarded $X...\"\n",
    "\n",
    "    Extraction:\n",
    "    - take text before first comma, if \"is awarded\" exists\n",
    "    \"\"\"\n",
    "    p = _normalize_spaces(paragraph)\n",
    "    m = re.match(r\"^(.*?),\\s+.*?\\s+is awarded\", p, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return m.group(1).strip()\n",
    "    return \"Unknown\"\n",
    "\n",
    "def parse_fms_countries(paragraph: str):\n",
    "    \"\"\"\n",
    "    Extracts FMS countries if paragraph contains:\n",
    "      \"governments of Australia, Bahrain, Belgium...\"\n",
    "\n",
    "    OUTPUT:\n",
    "    - list[str]\n",
    "    \"\"\"\n",
    "    text = str(paragraph)\n",
    "\n",
    "    m = re.search(\n",
    "        r\"governments of (.+?)(?:\\.\\s| Work will be performed| Fiscal| This contract|$)\",\n",
    "        text,\n",
    "        flags=re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "    if not m:\n",
    "        return []\n",
    "\n",
    "    block = m.group(1)\n",
    "    raw = re.split(r\",|\\band\\b\", block)\n",
    "\n",
    "    countries = []\n",
    "    for c in raw:\n",
    "        c = c.strip()\n",
    "        if 2 < len(c) <= 50:\n",
    "            countries.append(c)\n",
    "\n",
    "    final, seen = [], set()\n",
    "    for c in countries:\n",
    "        if c.lower() not in seen:\n",
    "            final.append(c)\n",
    "            seen.add(c.lower())\n",
    "\n",
    "    return final\n",
    "\n",
    "def parse_operator_allocations(text: str):\n",
    "    \"\"\"\n",
    "    Detects operator allocations like:\n",
    "    \"212 for the Navy\"\n",
    "    \"187 for the Air Force\"\n",
    "    \"84 for FMS customers\"\n",
    "\n",
    "    OUTPUT:\n",
    "      [\n",
    "        {\"operator\": \"Navy\", \"qty\": 212, \"g2g_b2g\": \"B2G\"},\n",
    "        {\"operator\": \"Foreign Assistance\", \"qty\": 84, \"g2g_b2g\": \"G2G\"}\n",
    "      ]\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "\n",
    "    txt = str(text).lower()\n",
    "    allocations = []\n",
    "\n",
    "    ops = re.findall(r\"(\\d{1,6}(?:,\\d{3})*)\\s+for\\s+the\\s+(navy|air force|army|marine corps)\", txt)\n",
    "    for qty_word, op in ops:\n",
    "        qty = _safe_int(qty_word)\n",
    "        if qty is None:\n",
    "            continue\n",
    "        op_norm = \"Air Force\" if op == \"air force\" else op.title()\n",
    "        allocations.append({\"operator\": op_norm, \"qty\": qty, \"g2g_b2g\": \"B2G\"})\n",
    "\n",
    "    fms = re.findall(\n",
    "        r\"(\\d{1,6}(?:,\\d{3})*)\\s+for\\s+(?:foreign military sales\\s*\\(fms\\)\\s*customers|fms\\s*customers|fms)\",\n",
    "        txt\n",
    "    )\n",
    "    for qty_word in fms:\n",
    "        qty = _safe_int(qty_word)\n",
    "        if qty is None:\n",
    "            continue\n",
    "        allocations.append({\"operator\": \"Foreign Assistance\", \"qty\": qty, \"g2g_b2g\": \"G2G\"})\n",
    "\n",
    "    uniq, seen = [], set()\n",
    "    for a in allocations:\n",
    "        key = (a[\"operator\"], a[\"qty\"], a[\"g2g_b2g\"])\n",
    "        if key not in seen:\n",
    "            uniq.append(a)\n",
    "            seen.add(key)\n",
    "\n",
    "    return uniq\n",
    "\n",
    "def split_rows_engine(base_row: dict, paragraph: str):\n",
    "    \"\"\"\n",
    "    Split engine that expands rows when multi-operator allocations exist.\n",
    "\n",
    "    Splits supported:\n",
    "    ‚úÖ Navy/Air Force/Army/Marine allocations\n",
    "    ‚úÖ FMS allocations (G2G)\n",
    "    ‚úÖ FMS countries -> 1 row per country\n",
    "\n",
    "    Adds:\n",
    "    - Split Flag\n",
    "    - Split Reason\n",
    "    - Split Evidence\n",
    "    - Split Line Item\n",
    "    \"\"\"\n",
    "    paragraph = _normalize_spaces(paragraph)\n",
    "    base_row = base_row.copy()\n",
    "\n",
    "    # Supplier fallback (critical)\n",
    "    if not base_row.get(\"Supplier Name\") or base_row.get(\"Supplier Name\") in [\"\", \"Unknown\"]:\n",
    "        extracted = _extract_supplier_from_description(paragraph)\n",
    "        base_row[\"Supplier Name\"] = get_best_supplier_match(extracted)\n",
    "\n",
    "    fms_countries = parse_fms_countries(paragraph)\n",
    "    allocations = parse_operator_allocations(paragraph)\n",
    "\n",
    "    if not allocations:\n",
    "        base_row[\"Split Flag\"] = \"No\"\n",
    "        base_row[\"Split Reason\"] = \"No allocation split detected.\"\n",
    "        base_row[\"Split Evidence\"] = \"Not Found\"\n",
    "        base_row[\"Split Line Item\"] = \"Not Found\"\n",
    "        return [base_row]\n",
    "\n",
    "    rows = []\n",
    "    for alloc in allocations:\n",
    "        if alloc[\"g2g_b2g\"] == \"G2G\" and fms_countries:\n",
    "            for c in fms_countries:\n",
    "                rr = base_row.copy()\n",
    "                rr[\"Customer Country\"] = c\n",
    "                rr[\"Customer Region\"] = get_region_for_country(c)\n",
    "                rr[\"Customer Operator\"] = \"Foreign Assistance\"\n",
    "                rr[\"Quantity\"] = \"1\"\n",
    "                rr[\"G2G/B2G\"] = \"G2G\"\n",
    "\n",
    "                rr[\"Split Flag\"] = \"Yes\"\n",
    "                rr[\"Split Reason\"] = \"FMS multi-country split\"\n",
    "                rr[\"Split Evidence\"] = f\"Countries: {', '.join(fms_countries)}\"\n",
    "                rr[\"Split Line Item\"] = \"FMS countries\"\n",
    "                rows.append(rr)\n",
    "        else:\n",
    "            rr = base_row.copy()\n",
    "            rr[\"Customer Operator\"] = alloc[\"operator\"]\n",
    "            rr[\"Quantity\"] = str(alloc[\"qty\"])\n",
    "            rr[\"G2G/B2G\"] = alloc[\"g2g_b2g\"]\n",
    "\n",
    "            rr[\"Split Flag\"] = \"Yes\"\n",
    "            rr[\"Split Reason\"] = \"Operator allocation split\"\n",
    "            rr[\"Split Evidence\"] = paragraph[:250] + (\"...\" if len(paragraph) > 250 else \"\")\n",
    "            rr[\"Split Line Item\"] = alloc[\"operator\"]\n",
    "            rows.append(rr)\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 8) TOOLS / AGENTS (Stage1 -> Stage6)\n",
    "# ==============================================================================\n",
    "\n",
    "class SourcingInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    url: str = Field(description=\"Source URL of the contract announcement/news.\")\n",
    "    date: str = Field(description=\"Contract date string.\")\n",
    "\n",
    "@tool(\"sourcing_extractor\")\n",
    "def sourcing_extractor(paragraph: str, url: str, date: str):\n",
    "    \"\"\"\n",
    "    Stage 1: Sourcing Extractor\n",
    "\n",
    "    Produces base metadata fields that stay constant:\n",
    "    - Description of Contract\n",
    "    - Source Link(s)\n",
    "    - Contract Date\n",
    "    - Reported Date (By SGA)\n",
    "    - Additional Notes (Internal Only)\n",
    "    \"\"\"\n",
    "    reported_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    notes = \"Standard extraction.\"\n",
    "    if \"modification\" in str(paragraph).lower():\n",
    "        notes = \"Contract Modification.\"\n",
    "    if \"split\" in str(paragraph).lower():\n",
    "        notes = \"Split award detected.\"\n",
    "\n",
    "    return {\n",
    "        \"Description of Contract\": paragraph,\n",
    "        \"Additional Notes (Internal Only)\": notes,\n",
    "        \"Source Link(s)\": url,\n",
    "        \"Contract Date\": date,\n",
    "        \"Reported Date (By SGA)\": reported_date\n",
    "    }\n",
    "\n",
    "\n",
    "class GeographyInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "\n",
    "@tool(\"geography_extractor\")\n",
    "def geography_extractor(paragraph: str):\n",
    "    \"\"\"\n",
    "    Stage 2: Geography Extractor\n",
    "\n",
    "    Extract:\n",
    "    - Customer Country\n",
    "    - Customer Operator\n",
    "    - Supplier Country\n",
    "\n",
    "    Derive:\n",
    "    - Customer Region\n",
    "    - Supplier Region\n",
    "    - Domestic Content\n",
    "    \"\"\"\n",
    "    sys_prompt = \"\"\"\n",
    "You are a Defense Contract Geography Analyst.\n",
    "\n",
    "Extract ONLY:\n",
    "1) Customer Country\n",
    "2) Customer Operator\n",
    "3) Supplier Country\n",
    "\n",
    "Return JSON ONLY:\n",
    "{\n",
    "  \"Customer Country\": \"...\",\n",
    "  \"Customer Operator\": \"...\",\n",
    "  \"Supplier Country\": \"...\"\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- If missing -> \"Unknown\"\n",
    "- Keep values short and clean\n",
    "\"\"\"\n",
    "\n",
    "    log_block(\"HUMAN MESSAGE (Stage2 - Geography)\", paragraph)\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": paragraph}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "        log_block(\"AI RESPONSE (Stage2 - Geography)\", json.dumps(raw, indent=2))\n",
    "    except Exception as e:\n",
    "        raw = {}\n",
    "        log_block(\"AI ERROR (Stage2 - Geography)\", str(e))\n",
    "\n",
    "    cust = raw.get(\"Customer Country\", \"Unknown\")\n",
    "    supp = raw.get(\"Supplier Country\", \"Unknown\")\n",
    "\n",
    "    domestic = \"Indigenous\" if str(cust).lower() == str(supp).lower() else \"Imported\"\n",
    "\n",
    "    return {\n",
    "        \"Customer Region\": get_region_for_country(cust),\n",
    "        \"Customer Country\": cust,\n",
    "        \"Customer Operator\": raw.get(\"Customer Operator\", \"Unknown\"),\n",
    "        \"Supplier Region\": get_region_for_country(supp),\n",
    "        \"Supplier Country\": supp,\n",
    "        \"Domestic Content\": domestic\n",
    "    }\n",
    "\n",
    "\n",
    "class SystemInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "\n",
    "@tool(\"system_classifier\")\n",
    "def system_classifier(paragraph: str):\n",
    "    \"\"\"\n",
    "    Stage 3: System Classifier (RAG enhanced)\n",
    "\n",
    "    Output fields (flat):\n",
    "    - Market Segment (+Evidence+Reason)\n",
    "    - System Type General (+Evidence+Reason)\n",
    "    - System Type Specific (+Evidence+Reason)\n",
    "    - System Name General (+Evidence+Reason)\n",
    "    - System Name Specific (+Evidence+Reason)\n",
    "    - System Piloting (overridden deterministically)\n",
    "    - Confidence\n",
    "    \"\"\"\n",
    "    paragraph = str(paragraph).strip()\n",
    "    if not paragraph:\n",
    "        return {}\n",
    "\n",
    "    log_block(\"HUMAN MESSAGE (Stage3 - System)\", paragraph)\n",
    "\n",
    "    lower_text = paragraph.lower()\n",
    "    hints = [\n",
    "        f\"RULE: {v['guidance']}\"\n",
    "        for _, v in RULE_BOOK.items()\n",
    "        if any(t in lower_text for t in v[\"triggers\"])\n",
    "    ]\n",
    "    hint_str = \"\\n\".join(hints) if hints else \"No special override rules triggered.\"\n",
    "\n",
    "    designators = extract_designators(paragraph)\n",
    "    piloting_rule = detect_piloting_rule_based(paragraph, designators)\n",
    "\n",
    "    rag_hits = retriever.retrieve(paragraph, top_k=3)\n",
    "    rag_examples = []\n",
    "    for hit in rag_hits:\n",
    "        meta = hit[\"meta\"]\n",
    "        rag_examples.append({\n",
    "            \"score\": round(hit[\"score\"], 4),\n",
    "            \"Market Segment\": meta.get(\"Market Segment\", \"\"),\n",
    "            \"System Type (General)\": meta.get(\"System Type (General)\", \"\"),\n",
    "            \"System Type (Specific)\": meta.get(\"System Type (Specific)\", \"\"),\n",
    "            \"System Name (General)\": meta.get(\"System Name (General)\", \"\"),\n",
    "            \"System Name (Specific)\": meta.get(\"System Name (Specific)\", \"\"),\n",
    "            \"System Piloting\": meta.get(\"System Piloting\", \"\"),\n",
    "            \"Snippet\": meta.get(\"Description of Contract\", \"\")[:200] + \"...\"\n",
    "        })\n",
    "\n",
    "    sys_prompt = f\"\"\"\n",
    "You are a Senior Defense System Classification Analyst.\n",
    "\n",
    "REFERENCE TAXONOMY:\n",
    "{TAXONOMY_STR}\n",
    "\n",
    "RULE BOOK OVERRIDES:\n",
    "{hint_str}\n",
    "\n",
    "STRICT OUTPUT RULES:\n",
    "- Return ONLY a FLAT JSON object\n",
    "- Every value MUST be a STRING\n",
    "- Evidence MUST be copied EXACTLY from paragraph\n",
    "- If evidence not found -> \"Not Found\"\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"Market Segment\": \"\",\n",
    "  \"Market Segment Evidence\": \"\",\n",
    "  \"Market Segment Reason\": \"\",\n",
    "\n",
    "  \"System Type (General)\": \"\",\n",
    "  \"System Type (General) Evidence\": \"\",\n",
    "  \"System Type (General) Reason\": \"\",\n",
    "\n",
    "  \"System Type (Specific)\": \"\",\n",
    "  \"System Type (Specific) Evidence\": \"\",\n",
    "  \"System Type (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Name (General)\": \"\",\n",
    "  \"System Name (General) Evidence\": \"\",\n",
    "  \"System Name (General) Reason\": \"\",\n",
    "\n",
    "  \"System Name (Specific)\": \"\",\n",
    "  \"System Name (Specific) Evidence\": \"\",\n",
    "  \"System Name (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Piloting\": \"\",\n",
    "  \"System Piloting Evidence\": \"\",\n",
    "  \"System Piloting Reason\": \"\",\n",
    "\n",
    "  \"Confidence\": \"High/Medium/Low\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "PARAGRAPH:\n",
    "{paragraph}\n",
    "\n",
    "DESIGNATORS:\n",
    "{designators if designators else \"None\"}\n",
    "\n",
    "RULE PILOTING OVERRIDE:\n",
    "{piloting_rule}\n",
    "\n",
    "RAG EXAMPLES:\n",
    "{json.dumps(rag_examples, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        result = json.loads(completion.choices[0].message.content)\n",
    "        log_block(\"AI RESPONSE (Stage3 - System)\", json.dumps(result, indent=2))\n",
    "\n",
    "        # hard override piloting\n",
    "        result[\"System Piloting\"] = piloting_rule\n",
    "        result.setdefault(\"System Piloting Evidence\", \"Not Found\")\n",
    "        result.setdefault(\"System Piloting Reason\", \"Derived using deterministic piloting rules.\")\n",
    "\n",
    "        for k, v in result.items():\n",
    "            if isinstance(v, (dict, list)):\n",
    "                result[k] = str(v)\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        log_block(\"AI ERROR (Stage3 - System)\", str(e))\n",
    "        return {\n",
    "            \"Market Segment\": \"\",\n",
    "            \"Market Segment Evidence\": \"Not Found\",\n",
    "            \"Market Segment Reason\": \"\",\n",
    "\n",
    "            \"System Type (General)\": \"\",\n",
    "            \"System Type (General) Evidence\": \"Not Found\",\n",
    "            \"System Type (General) Reason\": \"\",\n",
    "\n",
    "            \"System Type (Specific)\": \"\",\n",
    "            \"System Type (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Type (Specific) Reason\": \"\",\n",
    "\n",
    "            \"System Name (General)\": \"\",\n",
    "            \"System Name (General) Evidence\": \"Not Found\",\n",
    "            \"System Name (General) Reason\": \"\",\n",
    "\n",
    "            \"System Name (Specific)\": \"\",\n",
    "            \"System Name (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Name (Specific) Reason\": \"\",\n",
    "\n",
    "            \"System Piloting\": piloting_rule,\n",
    "            \"System Piloting Evidence\": \"Not Found\",\n",
    "            \"System Piloting Reason\": \"Derived using deterministic piloting rules (fallback).\",\n",
    "\n",
    "            \"Confidence\": \"Low\",\n",
    "            \"Error\": str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "class ContractInfoInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    contract_date: str = Field(description=\"Contract date string.\")\n",
    "\n",
    "@tool(\"contract_extractor\")\n",
    "def contract_extractor(paragraph: str, contract_date: str):\n",
    "    \"\"\"\n",
    "    Stage 4: Contract Extractor\n",
    "\n",
    "    Extract:\n",
    "    - Supplier Name (raw -> standardized)\n",
    "    - Program Type\n",
    "    - Quantity\n",
    "    - Value (Million)\n",
    "    - Currency\n",
    "    - Value Certainty\n",
    "    - G2G/B2G\n",
    "    - Completion date text (for MRO)\n",
    "    \"\"\"\n",
    "    system_instruction = \"\"\"\n",
    "You are a Defense Contract Financial Analyst.\n",
    "\n",
    "Return JSON ONLY.\n",
    "\n",
    "Rules:\n",
    "1) raw_supplier_name: exact supplier as in paragraph\n",
    "2) program_type: Procurement/Training/MRO/Support/RDT&E/Upgrade/Other Service\n",
    "3) value_certainty: Confirmed vs Estimated\n",
    "4) quantity: numeric if available else Not Applicable\n",
    "5) g2g_b2g: G2G only if FMS mentioned else B2G\n",
    "6) completion_date_text: end date if mentioned\n",
    "7) value_million_raw: numeric only\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "PARAGRAPH:\n",
    "{paragraph}\n",
    "\n",
    "SIGNED DATE:\n",
    "{contract_date}\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"raw_supplier_name\": \"\",\n",
    "  \"program_type\": \"\",\n",
    "  \"value_million_raw\": \"\",\n",
    "  \"currency_code\": \"\",\n",
    "  \"value_certainty\": \"\",\n",
    "  \"quantity\": \"\",\n",
    "  \"completion_date_text\": \"\",\n",
    "  \"g2g_b2g\": \"\",\n",
    "  \"value_note\": \"\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    log_block(\"HUMAN MESSAGE (Stage4 - Contract)\", paragraph)\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_instruction},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "        log_block(\"AI RESPONSE (Stage4 - Contract)\", json.dumps(raw, indent=2))\n",
    "    except Exception as e:\n",
    "        log_block(\"AI ERROR (Stage4 - Contract)\", str(e))\n",
    "        return {\"Error\": str(e)}\n",
    "\n",
    "    final_supplier = get_best_supplier_match(raw.get(\"raw_supplier_name\"))\n",
    "    prog_type = raw.get(\"program_type\", \"Unknown\")\n",
    "    mro_months = calculate_mro_months(contract_date, raw.get(\"completion_date_text\"), prog_type)\n",
    "\n",
    "    try:\n",
    "        val_str = str(raw.get(\"value_million_raw\", \"0\")).replace(\",\", \"\").replace(\"$\", \"\")\n",
    "        val_float = float(val_str)\n",
    "        val_formatted = \"{:.3f}\".format(val_float)\n",
    "    except:\n",
    "        val_formatted = \"0.000\"\n",
    "\n",
    "    try:\n",
    "        dt = pd.to_datetime(contract_date)\n",
    "        sign_month = dt.strftime(\"%B\")\n",
    "        sign_year = str(dt.year)\n",
    "    except:\n",
    "        sign_month, sign_year = \"Unknown\", \"Unknown\"\n",
    "\n",
    "    return {\n",
    "        \"Supplier Name\": final_supplier,\n",
    "        \"Program Type\": prog_type,\n",
    "        \"Expected MRO Contract Duration (Months)\": mro_months,\n",
    "        \"Quantity\": raw.get(\"quantity\", \"Not Applicable\"),\n",
    "        \"Value Certainty\": raw.get(\"value_certainty\", \"Confirmed\"),\n",
    "        \"Value (Million)\": val_formatted,\n",
    "        \"Currency\": raw.get(\"currency_code\", \"USD$\"),\n",
    "        \"Value (USD$ Million)\": val_formatted,\n",
    "        \"Value Note (If Any)\": raw.get(\"value_note\", \"Not Applicable\"),\n",
    "        \"G2G/B2G\": raw.get(\"g2g_b2g\", \"B2G\"),\n",
    "        \"Signing Month\": sign_month,\n",
    "        \"Signing Year\": sign_year\n",
    "    }\n",
    "\n",
    "\n",
    "class SplitterInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    base_row: dict = Field(description=\"Final extracted row after Stage1-4.\")\n",
    "\n",
    "@tool(\"splitter_agent\")\n",
    "def splitter_agent(paragraph: str, base_row: dict):\n",
    "    \"\"\"\n",
    "    Stage 5: Splitter Agent\n",
    "\n",
    "    Splits row using deterministic engine:\n",
    "    - operator allocations\n",
    "    - FMS multi-countries\n",
    "    \"\"\"\n",
    "    try:\n",
    "        rows = split_rows_engine(base_row, paragraph)\n",
    "        for r in rows:\n",
    "            r.setdefault(\"Split Flag\", \"No\")\n",
    "            r.setdefault(\"Split Reason\", \"\")\n",
    "            r.setdefault(\"Split Evidence\", \"Not Found\")\n",
    "            r.setdefault(\"Split Line Item\", \"Not Found\")\n",
    "        return {\"rows\": rows}\n",
    "    except Exception as e:\n",
    "        base_row = base_row.copy()\n",
    "        base_row[\"Split Flag\"] = \"Error\"\n",
    "        base_row[\"Split Reason\"] = f\"Split failed: {str(e)}\"\n",
    "        base_row[\"Split Evidence\"] = \"Not Found\"\n",
    "        base_row[\"Split Line Item\"] = \"Not Found\"\n",
    "        return {\"rows\": [base_row]}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 9) STAGE 6 QUALITY VALIDATOR (RULE-BASED + FAIL-ONLY LLM VALIDATION)\n",
    "# ==============================================================================\n",
    "\n",
    "def _contains_any(text: str, keywords: List[str]) -> bool:\n",
    "    \"\"\"True if any keyword appears in text (case-insensitive).\"\"\"\n",
    "    t = str(text or \"\").lower()\n",
    "    return any(k.lower() in t for k in keywords)\n",
    "\n",
    "def _supplier_appears_in_paragraph(supplier: str, paragraph: str) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if supplier appears in paragraph text.\n",
    "\n",
    "    NOTE:\n",
    "    - Works on standardized supplier (may not match exactly)\n",
    "    - Also tries first 2 tokens partial match\n",
    "    \"\"\"\n",
    "    supplier = str(supplier or \"\").strip()\n",
    "    if not supplier or supplier.lower() == \"unknown\":\n",
    "        return False\n",
    "\n",
    "    p = str(paragraph or \"\").lower()\n",
    "    s = supplier.lower()\n",
    "\n",
    "    if s in p:\n",
    "        return True\n",
    "\n",
    "    parts = s.split()\n",
    "    if len(parts) >= 2:\n",
    "        key = \" \".join(parts[:2])\n",
    "        return key in p\n",
    "\n",
    "    return False\n",
    "\n",
    "def validate_single_row_rule_based(row: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    RULE-BASED VALIDATION (Stage6.1)\n",
    "\n",
    "    Adds:\n",
    "    - Validation Flag: PASS/WARN/FAIL\n",
    "    - Validation Issues\n",
    "    - AutoFix Applied\n",
    "    - AutoFix Notes\n",
    "\n",
    "    SAFE FIXES:\n",
    "    ‚úÖ fix piloting by deterministic rules\n",
    "    ‚úÖ fix G2G/B2G if FMS exists\n",
    "    ‚úÖ fill supplier if unknown using fallback supplier extraction\n",
    "\n",
    "    DOES NOT:\n",
    "    ‚ùå overwrite Market Segment / System Names\n",
    "    \"\"\"\n",
    "    updated = row.copy()\n",
    "    issues = []\n",
    "    autofix_notes = []\n",
    "    autofix_applied = False\n",
    "\n",
    "    paragraph = updated.get(\"Description of Contract\", \"\")\n",
    "    supplier = updated.get(\"Supplier Name\", \"Unknown\")\n",
    "\n",
    "    # supplier mismatch\n",
    "    if supplier and supplier != \"Unknown\":\n",
    "        if not _supplier_appears_in_paragraph(supplier, paragraph):\n",
    "            issues.append(\"Supplier Name not found in paragraph (possible wrong supplier extraction).\")\n",
    "\n",
    "    # piloting mismatch\n",
    "    designators = extract_designators(paragraph)\n",
    "    piloting_expected = detect_piloting_rule_based(paragraph, designators)\n",
    "    piloting_current = updated.get(\"System Piloting\", \"Not Applicable\")\n",
    "\n",
    "    if piloting_expected != \"Not Applicable\" and piloting_current != piloting_expected:\n",
    "        issues.append(f\"System Piloting mismatch (expected={piloting_expected}, got={piloting_current}).\")\n",
    "        updated[\"System Piloting\"] = piloting_expected\n",
    "        updated[\"System Piloting Reason\"] = \"Validator override: deterministic piloting rules applied.\"\n",
    "        autofix_applied = True\n",
    "        autofix_notes.append(\"Corrected System Piloting using deterministic rules.\")\n",
    "\n",
    "    # FMS mismatch\n",
    "    if _contains_any(paragraph, [\"fms\", \"foreign military sales\"]):\n",
    "        if updated.get(\"G2G/B2G\", \"B2G\") != \"G2G\":\n",
    "            issues.append(\"Paragraph mentions FMS but row marked as B2G.\")\n",
    "            updated[\"G2G/B2G\"] = \"G2G\"\n",
    "            autofix_applied = True\n",
    "            autofix_notes.append(\"Fixed G2G/B2G to G2G due to FMS keyword.\")\n",
    "\n",
    "    # Value mismatch\n",
    "    if \"$\" in str(paragraph) and str(updated.get(\"Value (Million)\", \"\")).strip() in [\"\", \"0.000\", \"0\"]:\n",
    "        issues.append(\"Paragraph contains $ value but Value (Million) is missing/zero.\")\n",
    "\n",
    "    # segment heuristic warn\n",
    "    if _contains_any(paragraph, [\"radar\", \"an/apy\", \"an/tpy\"]) and updated.get(\"Market Segment\", \"\"):\n",
    "        if updated.get(\"Market Segment\") not in [\"C4ISR Systems\", \"C4ISR\"]:\n",
    "            issues.append(\"Radar keyword detected but Market Segment not C4ISR (check classification).\")\n",
    "\n",
    "    # Supplier unknown autofix\n",
    "    if supplier in [\"Unknown\", \"\", None]:\n",
    "        fallback_supplier = _extract_supplier_from_description(paragraph)\n",
    "        if fallback_supplier != \"Unknown\":\n",
    "            updated[\"Supplier Name\"] = get_best_supplier_match(fallback_supplier)\n",
    "            autofix_applied = True\n",
    "            autofix_notes.append(\"Filled Supplier Name from DoD fallback extraction.\")\n",
    "\n",
    "    updated[\"AutoFix Applied\"] = \"Yes\" if autofix_applied else \"No\"\n",
    "    updated[\"AutoFix Notes\"] = \" | \".join(autofix_notes) if autofix_notes else \"Not Applicable\"\n",
    "\n",
    "    if not issues:\n",
    "        updated[\"Validation Flag\"] = \"PASS\"\n",
    "        updated[\"Validation Issues\"] = \"No issues detected.\"\n",
    "    else:\n",
    "        severe = any(\n",
    "            \"Supplier Name not found\" in x or \"Value (Million) is missing\" in x\n",
    "            for x in issues\n",
    "        )\n",
    "        updated[\"Validation Flag\"] = \"FAIL\" if severe else \"WARN\"\n",
    "        updated[\"Validation Issues\"] = \" | \".join(issues)\n",
    "\n",
    "    return updated\n",
    "\n",
    "\n",
    "def llm_validate_fail_row(row: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    LLM VALIDATION (Stage6.2) - RUN ONLY FOR FAIL ROWS\n",
    "\n",
    "    WHY THIS IS IMPORTANT:\n",
    "    - Some FAIL rows require semantic judgment:\n",
    "      Supplier confusion, wrong system label, wrong G2G/B2G logic.\n",
    "\n",
    "    INPUT:\n",
    "    - Row dict (already extracted) including paragraph in Description of Contract.\n",
    "\n",
    "    OUTPUT:\n",
    "    Adds:\n",
    "    - LLM Validation Run: Yes/No\n",
    "    - LLM Validation Verdict: CONFIRMED / WRONG / NEEDS_REVIEW\n",
    "    - LLM Validation Notes: explanation\n",
    "    - LLM Suggested Fixes: JSON string (flat)\n",
    "    - LLM Fix Applied: Yes/No\n",
    "\n",
    "    SAFE APPLICATION RULES:\n",
    "    - We only apply these fixes automatically:\n",
    "      ‚úÖ Supplier Name (only if suggested supplier appears in paragraph)\n",
    "      ‚úÖ G2G/B2G\n",
    "      ‚úÖ Value Certainty (if estimated)\n",
    "      ‚úÖ Program Type (only if suggested value in allowed list)\n",
    "    - We NEVER auto-override:\n",
    "      ‚ùå Market Segment / System Types / System Names (only suggest, do not apply)\n",
    "    \"\"\"\n",
    "    updated = row.copy()\n",
    "    paragraph = updated.get(\"Description of Contract\", \"\")\n",
    "\n",
    "    updated[\"LLM Validation Run\"] = \"Yes\"\n",
    "    updated.setdefault(\"LLM Fix Applied\", \"No\")\n",
    "    updated.setdefault(\"LLM Suggested Fixes\", \"Not Applicable\")\n",
    "    updated.setdefault(\"LLM Validation Verdict\", \"NEEDS_REVIEW\")\n",
    "    updated.setdefault(\"LLM Validation Notes\", \"Not Applicable\")\n",
    "\n",
    "    sys_prompt = \"\"\"\n",
    "You are a Defense Contract Quality Auditor.\n",
    "\n",
    "Your job:\n",
    "- Validate if the extracted row fields match the contract paragraph.\n",
    "- Detect mismatches or hallucinations.\n",
    "- Suggest corrected fields ONLY when strongly supported by paragraph text.\n",
    "\n",
    "IMPORTANT RULES:\n",
    "1) NEVER fabricate any supplier/system/value not present in paragraph.\n",
    "2) Output must be a FLAT JSON object only (no nesting).\n",
    "3) You must include a verdict:\n",
    "   - \"CONFIRMED\" (row looks correct)\n",
    "   - \"WRONG\" (row clearly incorrect)\n",
    "   - \"NEEDS_REVIEW\" (unclear)\n",
    "4) If suggesting a fix, give corrected values.\n",
    "\n",
    "Return JSON:\n",
    "{\n",
    "  \"verdict\": \"CONFIRMED/WRONG/NEEDS_REVIEW\",\n",
    "  \"notes\": \"short explanation\",\n",
    "  \"suggest_supplier_name\": \"\",\n",
    "  \"suggest_g2g_b2g\": \"\",\n",
    "  \"suggest_program_type\": \"\",\n",
    "  \"suggest_value_certainty\": \"\",\n",
    "  \"suggest_customer_operator\": \"\",\n",
    "  \"suggest_quantity\": \"\"\n",
    "}\n",
    "\n",
    "Allowed program_type values:\n",
    "Procurement / Training / MRO/Support / RDT&E / Upgrade / Other Service\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "PARAGRAPH:\n",
    "{paragraph}\n",
    "\n",
    "CURRENT EXTRACTED ROW:\n",
    "Supplier Name: {updated.get(\"Supplier Name\")}\n",
    "Market Segment: {updated.get(\"Market Segment\")}\n",
    "System Type (General): {updated.get(\"System Type (General)\")}\n",
    "System Type (Specific): {updated.get(\"System Type (Specific)\")}\n",
    "System Name (General): {updated.get(\"System Name (General)\")}\n",
    "System Name (Specific): {updated.get(\"System Name (Specific)\")}\n",
    "Program Type: {updated.get(\"Program Type\")}\n",
    "Quantity: {updated.get(\"Quantity\")}\n",
    "Value (Million): {updated.get(\"Value (Million)\")}\n",
    "Currency: {updated.get(\"Currency\")}\n",
    "G2G/B2G: {updated.get(\"G2G/B2G\")}\n",
    "Customer Operator: {updated.get(\"Customer Operator\")}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "        log_block(\"AI RESPONSE (Stage6.2 - LLM FAIL VALIDATOR)\", json.dumps(raw, indent=2))\n",
    "\n",
    "        verdict = str(raw.get(\"verdict\", \"NEEDS_REVIEW\")).strip().upper()\n",
    "        notes = str(raw.get(\"notes\", \"Not Applicable\")).strip()\n",
    "\n",
    "        updated[\"LLM Validation Verdict\"] = verdict\n",
    "        updated[\"LLM Validation Notes\"] = notes\n",
    "\n",
    "        # suggested fixes\n",
    "        suggested = {\n",
    "            \"suggest_supplier_name\": raw.get(\"suggest_supplier_name\", \"\"),\n",
    "            \"suggest_g2g_b2g\": raw.get(\"suggest_g2g_b2g\", \"\"),\n",
    "            \"suggest_program_type\": raw.get(\"suggest_program_type\", \"\"),\n",
    "            \"suggest_value_certainty\": raw.get(\"suggest_value_certainty\", \"\"),\n",
    "            \"suggest_customer_operator\": raw.get(\"suggest_customer_operator\", \"\"),\n",
    "            \"suggest_quantity\": raw.get(\"suggest_quantity\", \"\")\n",
    "        }\n",
    "        updated[\"LLM Suggested Fixes\"] = json.dumps(suggested, ensure_ascii=False)\n",
    "\n",
    "        # ===== APPLY SAFE FIXES ONLY =====\n",
    "        applied_any = False\n",
    "\n",
    "        # Supplier\n",
    "        sug_supplier = str(raw.get(\"suggest_supplier_name\", \"\")).strip()\n",
    "        if sug_supplier:\n",
    "            sug_std = get_best_supplier_match(sug_supplier)\n",
    "            if _supplier_appears_in_paragraph(sug_std, paragraph):\n",
    "                updated[\"Supplier Name\"] = sug_std\n",
    "                applied_any = True\n",
    "\n",
    "        # G2G/B2G\n",
    "        sug_g2g = str(raw.get(\"suggest_g2g_b2g\", \"\")).strip()\n",
    "        if sug_g2g in [\"G2G\", \"B2G\"]:\n",
    "            updated[\"G2G/B2G\"] = sug_g2g\n",
    "            applied_any = True\n",
    "\n",
    "        # Program Type (strict allowed list)\n",
    "        allowed_programs = {\"Procurement\", \"Training\", \"MRO/Support\", \"RDT&E\", \"Upgrade\", \"Other Service\"}\n",
    "        sug_prog = str(raw.get(\"suggest_program_type\", \"\")).strip()\n",
    "        if sug_prog in allowed_programs:\n",
    "            updated[\"Program Type\"] = sug_prog\n",
    "            applied_any = True\n",
    "\n",
    "        # Value certainty\n",
    "        sug_cert = str(raw.get(\"suggest_value_certainty\", \"\")).strip()\n",
    "        if sug_cert in [\"Confirmed\", \"Estimated\"]:\n",
    "            updated[\"Value Certainty\"] = sug_cert\n",
    "            applied_any = True\n",
    "\n",
    "        # Operator\n",
    "        sug_op = str(raw.get(\"suggest_customer_operator\", \"\")).strip()\n",
    "        if sug_op and sug_op.lower() != \"unknown\":\n",
    "            updated[\"Customer Operator\"] = sug_op\n",
    "            applied_any = True\n",
    "\n",
    "        # Quantity (only if numeric)\n",
    "        sug_qty = str(raw.get(\"suggest_quantity\", \"\")).strip()\n",
    "        if sug_qty and sug_qty.isdigit():\n",
    "            updated[\"Quantity\"] = sug_qty\n",
    "            applied_any = True\n",
    "\n",
    "        updated[\"LLM Fix Applied\"] = \"Yes\" if applied_any else \"No\"\n",
    "        return updated\n",
    "\n",
    "    except Exception as e:\n",
    "        log_block(\"AI ERROR (Stage6.2 - LLM FAIL VALIDATOR)\", str(e))\n",
    "        updated[\"LLM Validation Verdict\"] = \"NEEDS_REVIEW\"\n",
    "        updated[\"LLM Validation Notes\"] = f\"LLM validator failed: {str(e)}\"\n",
    "        updated[\"LLM Suggested Fixes\"] = \"Not Applicable\"\n",
    "        updated[\"LLM Fix Applied\"] = \"No\"\n",
    "        return updated\n",
    "\n",
    "\n",
    "class ValidatorInput(BaseModel):\n",
    "    rows: list = Field(description=\"List of extracted rows AFTER splitting. Each row is a dict.\")\n",
    "\n",
    "@tool(\"quality_validator_agent\")\n",
    "def quality_validator_agent(rows: list):\n",
    "    \"\"\"\n",
    "    Stage 6: Quality Validator Agent (Hybrid)\n",
    "\n",
    "    PIPELINE:\n",
    "    Stage 6.1 -> Rule-based validator for all rows\n",
    "    Stage 6.2 -> LLM validator ONLY for FAIL rows\n",
    "\n",
    "    WHY:\n",
    "    - Cost controlled (LLM only when needed)\n",
    "    - Increases accuracy for tricky mismatches\n",
    "\n",
    "    OUTPUT:\n",
    "    - {\"validated_rows\": [validated_row1, validated_row2, ...]}\n",
    "    \"\"\"\n",
    "    validated = []\n",
    "    for r in rows:\n",
    "        rb = validate_single_row_rule_based(r)\n",
    "\n",
    "        # default LLM fields\n",
    "        rb.setdefault(\"LLM Validation Run\", \"No\")\n",
    "        rb.setdefault(\"LLM Validation Verdict\", \"Not Applicable\")\n",
    "        rb.setdefault(\"LLM Validation Notes\", \"Not Applicable\")\n",
    "        rb.setdefault(\"LLM Suggested Fixes\", \"Not Applicable\")\n",
    "        rb.setdefault(\"LLM Fix Applied\", \"No\")\n",
    "\n",
    "        if rb.get(\"Validation Flag\") == \"FAIL\":\n",
    "            rb = llm_validate_fail_row(rb)\n",
    "\n",
    "        validated.append(rb)\n",
    "\n",
    "    return {\"validated_rows\": validated}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 10) LANGGRAPH PIPELINE\n",
    "# ==============================================================================\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    Shared state between LangGraph nodes.\n",
    "    \"\"\"\n",
    "    input_text: str\n",
    "    input_date: str\n",
    "    input_url: str\n",
    "    final_data: dict\n",
    "    final_rows: list\n",
    "    validated_rows: list\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "def stage_1_sourcing(state: AgentState):\n",
    "    \"\"\"Stage1 node\"\"\"\n",
    "    res = sourcing_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"url\": state[\"input_url\"],\n",
    "        \"date\": state[\"input_date\"],\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_2_geography(state: AgentState):\n",
    "    \"\"\"Stage2 node\"\"\"\n",
    "    res = geography_extractor.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_3_system(state: AgentState):\n",
    "    \"\"\"Stage3 node\"\"\"\n",
    "    res = system_classifier.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_4_contract(state: AgentState):\n",
    "    \"\"\"Stage4 node\"\"\"\n",
    "    res = contract_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"contract_date\": state[\"input_date\"]\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_5_split(state: AgentState):\n",
    "    \"\"\"Stage5 node\"\"\"\n",
    "    res = splitter_agent.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"base_row\": state[\"final_data\"]\n",
    "    })\n",
    "    return {\"final_rows\": res.get(\"rows\", [state[\"final_data\"]])}\n",
    "\n",
    "\n",
    "def stage_6_validate(state: AgentState):\n",
    "    \"\"\"Stage6 node\"\"\"\n",
    "    res = quality_validator_agent.invoke({\n",
    "        \"rows\": state.get(\"final_rows\", [])\n",
    "    })\n",
    "    return {\"validated_rows\": res.get(\"validated_rows\", state.get(\"final_rows\", []))}\n",
    "\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Stage1\", stage_1_sourcing)\n",
    "workflow.add_node(\"Stage2\", stage_2_geography)\n",
    "workflow.add_node(\"Stage3\", stage_3_system)\n",
    "workflow.add_node(\"Stage4\", stage_4_contract)\n",
    "workflow.add_node(\"Stage5\", stage_5_split)\n",
    "workflow.add_node(\"Stage6\", stage_6_validate)\n",
    "\n",
    "workflow.add_edge(START, \"Stage1\")\n",
    "workflow.add_edge(\"Stage1\", \"Stage2\")\n",
    "workflow.add_edge(\"Stage2\", \"Stage3\")\n",
    "workflow.add_edge(\"Stage3\", \"Stage4\")\n",
    "workflow.add_edge(\"Stage4\", \"Stage5\")\n",
    "workflow.add_edge(\"Stage5\", \"Stage6\")\n",
    "workflow.add_edge(\"Stage6\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 11) WORKFLOW GRAPH EXPORT (OFFLINE SAFE)\n",
    "# ==============================================================================\n",
    "\n",
    "def export_workflow_mermaid(app_obj, out_file=\"workflow.mmd\"):\n",
    "    \"\"\"\n",
    "    Exports LangGraph workflow diagram in Mermaid format.\n",
    "\n",
    "    WHY:\n",
    "    - Documentation for your workflow\n",
    "    - Offline safe (no external API call)\n",
    "    \"\"\"\n",
    "    mmd = app_obj.get_graph().draw_mermaid()\n",
    "    with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(mmd)\n",
    "    print(f\"‚úÖ Workflow Mermaid saved locally: {out_file}\")\n",
    "    return out_file\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 12) EXCEL HIGHLIGHTING FEATURE\n",
    "# ==============================================================================\n",
    "\n",
    "def highlight_evidence_reason_columns(excel_path: str):\n",
    "    \"\"\"\n",
    "    Highlights Evidence + Reason columns in output Excel.\n",
    "\n",
    "    Evidence Columns -> Yellow\n",
    "    Reason Columns   -> Blue\n",
    "    \"\"\"\n",
    "    wb = load_workbook(excel_path)\n",
    "    ws = wb.active\n",
    "\n",
    "    header = [cell.value for cell in ws[1]]\n",
    "\n",
    "    evidence_cols = []\n",
    "    reason_cols = []\n",
    "\n",
    "    for idx, col_name in enumerate(header, start=1):\n",
    "        if isinstance(col_name, str) and \"Evidence\" in col_name:\n",
    "            evidence_cols.append(idx)\n",
    "        if isinstance(col_name, str) and \"Reason\" in col_name:\n",
    "            reason_cols.append(idx)\n",
    "\n",
    "    evidence_fill = PatternFill(start_color=\"FFF2CC\", end_color=\"FFF2CC\", fill_type=\"solid\")\n",
    "    reason_fill = PatternFill(start_color=\"D9E1F2\", end_color=\"D9E1F2\", fill_type=\"solid\")\n",
    "    header_font = Font(bold=True)\n",
    "\n",
    "    for col_idx in evidence_cols:\n",
    "        ws.cell(row=1, column=col_idx).fill = evidence_fill\n",
    "        ws.cell(row=1, column=col_idx).font = header_font\n",
    "\n",
    "    for col_idx in reason_cols:\n",
    "        ws.cell(row=1, column=col_idx).fill = reason_fill\n",
    "        ws.cell(row=1, column=col_idx).font = header_font\n",
    "\n",
    "    for row in range(2, ws.max_row + 1):\n",
    "        for col_idx in evidence_cols:\n",
    "            ws.cell(row=row, column=col_idx).fill = evidence_fill\n",
    "        for col_idx in reason_cols:\n",
    "            ws.cell(row=row, column=col_idx).fill = reason_fill\n",
    "\n",
    "    wb.save(excel_path)\n",
    "    print(\"‚úÖ Evidence + Reason columns highlighted successfully.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 13) MAIN EXECUTION\n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(f\"\\nüìå Loading Input File: {INPUT_EXCEL_PATH}\")\n",
    "\n",
    "    export_workflow_mermaid(app, out_file=\"workflow.mmd\")\n",
    "\n",
    "    try:\n",
    "        df_input = pd.read_excel(INPUT_EXCEL_PATH)\n",
    "\n",
    "        required_cols = [\"Source URL\", \"Contract Date\", \"Contract Description\"]\n",
    "        if not all(col in df_input.columns for col in required_cols):\n",
    "            raise ValueError(f\"Excel file must contain columns: {required_cols}\")\n",
    "\n",
    "        print(f\"üöÄ Processing {len(df_input)} rows...\")\n",
    "        results = []\n",
    "\n",
    "        for index, row in df_input.iterrows():\n",
    "            print(f\"\\nüîπ Row {index + 1}/{len(df_input)}\")\n",
    "\n",
    "            desc = str(row[\"Contract Description\"]) if pd.notna(row[\"Contract Description\"]) else \"\"\n",
    "            c_date = str(row[\"Contract Date\"]) if pd.notna(row[\"Contract Date\"]) else str(datetime.date.today())\n",
    "            c_url = str(row[\"Source URL\"]) if pd.notna(row[\"Source URL\"]) else \"\"\n",
    "\n",
    "            initial_state = {\n",
    "                \"input_text\": desc,\n",
    "                \"input_date\": c_date,\n",
    "                \"input_url\": c_url,\n",
    "                \"final_data\": {},\n",
    "                \"final_rows\": [],\n",
    "                \"validated_rows\": [],\n",
    "                \"messages\": []\n",
    "            }\n",
    "\n",
    "            output_state = app.invoke(initial_state)\n",
    "\n",
    "            rows = output_state.get(\"validated_rows\", [])\n",
    "            if not rows:\n",
    "                rows = output_state.get(\"final_rows\", [])\n",
    "            if not rows:\n",
    "                rows = [output_state.get(\"final_data\", {})]\n",
    "\n",
    "            results.extend(rows)\n",
    "\n",
    "        df_final = pd.DataFrame(results)\n",
    "\n",
    "        FINAL_COLUMNS = [\n",
    "            \"Customer Region\", \"Customer Country\", \"Customer Operator\",\n",
    "            \"Supplier Region\", \"Supplier Country\", \"Domestic Content\",\n",
    "\n",
    "            \"Split Flag\", \"Split Reason\", \"Split Evidence\", \"Split Line Item\",\n",
    "\n",
    "            \"Market Segment\", \"Market Segment Evidence\", \"Market Segment Reason\",\n",
    "            \"System Type (General)\", \"System Type (General) Evidence\", \"System Type (General) Reason\",\n",
    "            \"System Type (Specific)\", \"System Type (Specific) Evidence\", \"System Type (Specific) Reason\",\n",
    "            \"System Name (General)\", \"System Name (General) Evidence\", \"System Name (General) Reason\",\n",
    "            \"System Name (Specific)\", \"System Name (Specific) Evidence\", \"System Name (Specific) Reason\",\n",
    "            \"System Piloting\", \"System Piloting Evidence\", \"System Piloting Reason\",\n",
    "            \"Confidence\",\n",
    "\n",
    "            \"Supplier Name\", \"Program Type\", \"Expected MRO Contract Duration (Months)\",\n",
    "            \"Quantity\", \"Value Certainty\", \"Value (Million)\", \"Currency\",\n",
    "            \"Value (USD$ Million)\", \"Value Note (If Any)\", \"G2G/B2G\",\n",
    "            \"Signing Month\", \"Signing Year\",\n",
    "\n",
    "            # Stage6 rule validation\n",
    "            \"Validation Flag\", \"Validation Issues\",\n",
    "            \"AutoFix Applied\", \"AutoFix Notes\",\n",
    "\n",
    "            # Stage6 FAIL-only LLM validator\n",
    "            \"LLM Validation Run\", \"LLM Validation Verdict\", \"LLM Validation Notes\",\n",
    "            \"LLM Suggested Fixes\", \"LLM Fix Applied\",\n",
    "\n",
    "            \"Description of Contract\",\n",
    "            \"Additional Notes (Internal Only)\",\n",
    "            \"Source Link(s)\",\n",
    "            \"Contract Date\",\n",
    "            \"Reported Date (By SGA)\"\n",
    "        ]\n",
    "\n",
    "        df_final = df_final.reindex(columns=FINAL_COLUMNS, fill_value=\"\")\n",
    "        df_final.to_excel(OUTPUT_EXCEL_PATH, index=False)\n",
    "\n",
    "        highlight_evidence_reason_columns(OUTPUT_EXCEL_PATH)\n",
    "\n",
    "        print(\"\\n‚úÖ Processing Complete!\")\n",
    "        print(f\"üíæ Output File Saved: {OUTPUT_EXCEL_PATH}\")\n",
    "        print(df_final.head(3).to_string(index=False))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f717379",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Final Version \n",
    "\n",
    "# ======================================================================================\n",
    "# DEFENSE CONTRACT DATA EXTRACTION PIPELINE (AGENTIC + RAG + SPLIT + QA VALIDATION)\n",
    "# ======================================================================================\n",
    "# Author: Mukesh Kumar Sharma (Customized Agentic Pipeline)\n",
    "# Maintained by: ChatGPT\n",
    "#\n",
    "# GOAL:\n",
    "# - Read contract paragraphs from Excel\n",
    "# - Extract structured fields (supplier/program/value/system/etc.)\n",
    "# - Apply split logic for multi-operator / multi-supplier / multi-country cases\n",
    "# - Validate outputs using deterministic + LLM validator (ONLY FAIL rows)\n",
    "# - Export final Excel with evidence/reason highlighted\n",
    "#\n",
    "# ======================================================================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import difflib\n",
    "import pickle\n",
    "import datetime\n",
    "import getpass\n",
    "from typing import Annotated, TypedDict, List, Dict, Any, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# LangGraph / LangChain\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "\n",
    "# Excel formatting\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill, Font\n",
    "\n",
    "# ======================================================================================\n",
    "# 0) DEBUG LOGGING HELPERS\n",
    "# ======================================================================================\n",
    "\n",
    "def log_block(title: str, content: str):\n",
    "    \"\"\"\n",
    "    Print a separated log block in console output.\n",
    "\n",
    "    WHY THIS EXISTS:\n",
    "    - This pipeline is multi-stage and deeply agentic.\n",
    "    - Debugging becomes hard when you don't know which stage produced a wrong value.\n",
    "    - This function prints stage-wise logs so you can track:\n",
    "      * What paragraph went to LLM\n",
    "      * What response came back\n",
    "      * What transformation happened after extraction\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 110)\n",
    "    print(title)\n",
    "    print(\"=\" * 110)\n",
    "    print(content)\n",
    "\n",
    "\n",
    "def _normalize_spaces(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize whitespace spacing for safer regex and matching.\n",
    "\n",
    "    Example:\n",
    "    \"Lockheed   Martin,   Fort Worth , TX\" -> \"Lockheed Martin, Fort Worth , TX\"\n",
    "    \"\"\"\n",
    "    return re.sub(r\"\\s+\", \" \", str(text or \"\")).strip()\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# 1) RAG RETRIEVER (FAISS + Metadata)\n",
    "# ======================================================================================\n",
    "\n",
    "class SystemKBRetriever:\n",
    "    \"\"\"\n",
    "    RAG Retriever for defense system classification (FAISS + metadata).\n",
    "\n",
    "    PURPOSE:\n",
    "    - Loads FAISS index and metadata created from your labeled KB dataset\n",
    "      (system_kb.faiss + system_kb_meta.pkl)\n",
    "    - Retrieves top-k similar examples using semantic embedding similarity\n",
    "\n",
    "    WHY THIS IMPROVES ACCURACY:\n",
    "    - Defense system classification is highly taxonomy-driven.\n",
    "    - Your KB contains \"known correct\" historical labeled examples.\n",
    "    - RAG reduces random hallucinations and increases classification stability.\n",
    "\n",
    "    OUTPUT:\n",
    "    retrieve(query_text) returns:\n",
    "      [\n",
    "        {\"score\": float, \"meta\": {...KB row columns...}},\n",
    "        ...\n",
    "      ]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kb_dir: str, embed_model: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self.kb_dir = kb_dir\n",
    "        self.embed_model = embed_model\n",
    "\n",
    "        index_path = os.path.join(kb_dir, \"system_kb.faiss\")\n",
    "        meta_path = os.path.join(kb_dir, \"system_kb_meta.pkl\")\n",
    "\n",
    "        if not os.path.exists(index_path) or not os.path.exists(meta_path):\n",
    "            raise FileNotFoundError(\n",
    "                f\"‚ùå KB files not found in: {kb_dir}\\n\"\n",
    "                f\"Expected:\\n- {index_path}\\n- {meta_path}\\n\"\n",
    "                f\"Build KB first using your KB builder script.\"\n",
    "            )\n",
    "\n",
    "        print(f\"‚úÖ Loading FAISS Index: {index_path}\")\n",
    "        self.index = faiss.read_index(index_path)\n",
    "\n",
    "        print(f\"‚úÖ Loading KB Metadata: {meta_path}\")\n",
    "        with open(meta_path, \"rb\") as f:\n",
    "            self.meta = pickle.load(f)\n",
    "\n",
    "        print(f\"‚úÖ KB Loaded rows: {len(self.meta)}\")\n",
    "\n",
    "        self.embedder = None\n",
    "\n",
    "    def _lazy_load_embedder(self):\n",
    "        \"\"\"\n",
    "        Lazy-load embedder only when retrieval is actually requested.\n",
    "\n",
    "        WHY:\n",
    "        - Speeds up pipeline startup\n",
    "        - Avoids heavy RAM usage until needed\n",
    "        \"\"\"\n",
    "        if self.embedder is None:\n",
    "            from sentence_transformers import SentenceTransformer\n",
    "            self.embedder = SentenceTransformer(self.embed_model)\n",
    "\n",
    "    def retrieve(self, query_text: str, top_k: int = 3):\n",
    "        \"\"\"\n",
    "        Retrieve top-k semantic matches from KB.\n",
    "\n",
    "        Args:\n",
    "            query_text: contract paragraph\n",
    "            top_k: number of examples returned\n",
    "\n",
    "        Returns:\n",
    "            list of dict {score, meta}\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "\n",
    "        query_text = str(query_text).strip()\n",
    "        if not query_text:\n",
    "            return []\n",
    "\n",
    "        self._lazy_load_embedder()\n",
    "\n",
    "        q_emb = self.embedder.encode([query_text], normalize_embeddings=True).astype(\"float32\")\n",
    "        scores, idxs = self.index.search(q_emb, top_k)\n",
    "\n",
    "        results = []\n",
    "        for score, idx in zip(scores[0], idxs[0]):\n",
    "            if idx < 0:\n",
    "                continue\n",
    "            results.append({\"score\": float(score), \"meta\": self.meta[idx]})\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# 2) CONFIGURATION (PATHS + MODELS)\n",
    "# ======================================================================================\n",
    "\n",
    "TAXONOMY_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\taxonomy.json\"\n",
    "SUPPLIERS_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\suppliers.json\"\n",
    "INPUT_EXCEL_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\data\\source_file.xlsx\"\n",
    "OUTPUT_EXCEL_PATH = \"Processed_Defense_Data.xlsx\"\n",
    "\n",
    "RAG_KB_DIR = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\system_kb_store\"\n",
    "\n",
    "# Program Type must be EXACTLY this set (enforced globally)\n",
    "ALLOWED_PROGRAM_TYPES = {\n",
    "    \"Procurement\",\n",
    "    \"Training\",\n",
    "    \"MRO/Support\",\n",
    "    \"RDT&E\",\n",
    "    \"Upgrade\",\n",
    "    \"Other Service\"\n",
    "}\n",
    "\n",
    "# Setup API key\n",
    "if \"LLMFOUNDRY_TOKEN\" not in os.environ:\n",
    "    os.environ[\"LLMFOUNDRY_TOKEN\"] = getpass.getpass(\"Enter the LLM Foundry API Key: \")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=f'{os.environ.get(\"LLMFOUNDRY_TOKEN\")}:my-test-project',\n",
    "    base_url=\"https://llmfoundry.straive.com/openai/v1/\",\n",
    ")\n",
    "\n",
    "retriever = SystemKBRetriever(kb_dir=RAG_KB_DIR)\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# 3) JSON LOADERS\n",
    "# ======================================================================================\n",
    "\n",
    "def load_json_file(filename, default_value):\n",
    "    \"\"\"\n",
    "    Load a JSON file safely.\n",
    "\n",
    "    WHY:\n",
    "    - Taxonomy + suppliers list are critical to the pipeline.\n",
    "    - This prevents full crash if file missing during deployment.\n",
    "\n",
    "    Returns:\n",
    "        dict or list (based on file)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            print(f\"‚úÖ Loaded JSON: {filename}\")\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Warning: Could not load {filename} ({e}). Using default.\")\n",
    "        return default_value\n",
    "\n",
    "\n",
    "raw_taxonomy = load_json_file(TAXONOMY_PATH, {})\n",
    "TAXONOMY_STR = json.dumps(raw_taxonomy, separators=(\",\", \":\"))\n",
    "\n",
    "SUPPLIER_LIST = load_json_file(SUPPLIERS_PATH, [\n",
    "    \"Dell Inc\", \"Boeing\", \"Lockheed Martin\", \"Raytheon Technologies\",\n",
    "    \"Northrop Grumman\", \"L3Harris\", \"BAE Systems\", \"General Dynamics\"\n",
    "])\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# 4) RULE BOOK + GEOGRAPHY\n",
    "# ======================================================================================\n",
    "\n",
    "RULE_BOOK = {\n",
    "    \"defensive_countermeasures\": {\n",
    "        \"triggers\": [\"flare\", \"chaff\", \"countermeasure\", \"decoy\", \"mju-\", \"ale-\"],\n",
    "        \"guidance\": \"Market Segment='C4ISR Systems', System Type (General)='Defensive Systems', Specific='Defensive Aid Suite'\"\n",
    "    },\n",
    "    \"radars_and_sensors\": {\n",
    "        \"triggers\": [\"radar\", \"sonar\", \"sensor\", \"an/apy\", \"an/tpy\"],\n",
    "        \"guidance\": \"Market Segment='C4ISR Systems', System Type (General)='Sensors'\"\n",
    "    },\n",
    "    \"ammunition\": {\n",
    "        \"triggers\": [\"cartridge\", \"round\", \"projectile\", \" 5.56\", \" 7.62\", \"ammo\"],\n",
    "        \"guidance\": \"Market Segment='Weapon Systems', System Type (General)='Ammunition'\"\n",
    "    }\n",
    "}\n",
    "\n",
    "GEOGRAPHY_MAPPING = {\n",
    "    \"North America\": [\"USA\", \"United States\", \"US\", \"United States of America\", \"Canada\", \"America\"],\n",
    "    \"Europe\": [\"UK\", \"United Kingdom\", \"Ukraine\", \"Germany\", \"France\", \"Italy\", \"Spain\", \"Poland\", \"Netherlands\",\n",
    "               \"Norway\", \"Sweden\", \"Finland\", \"Denmark\", \"Belgium\"],\n",
    "    \"Asia-Pacific\": [\"Australia\", \"Japan\", \"South Korea\", \"Taiwan\", \"India\", \"Singapore\", \"New Zealand\"],\n",
    "    \"Middle East and North Africa\": [\"Israel\", \"Saudi Arabia\", \"UAE\", \"United Arab Emirates\", \"Egypt\", \"Qatar\", \"Kuwait\", \"Iraq\"],\n",
    "    \"International Organisations\": [\"NATO\", \"EU\", \"IFU\", \"UN\", \"NSPA\"]\n",
    "}\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# 5) BASE HELPERS (Supplier + Dates + Region + Designators)\n",
    "# ======================================================================================\n",
    "\n",
    "def get_region_for_country(country_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Maps country name -> region using GEOGRAPHY_MAPPING.\n",
    "\n",
    "    Returns:\n",
    "        region string (example \"Europe\") or \"Unknown\"\n",
    "    \"\"\"\n",
    "    if not country_name or str(country_name).strip().lower() in [\"unknown\", \"n/a\", \"not applicable\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    clean = str(country_name).strip().lower()\n",
    "\n",
    "    if clean in [\"us\", \"usa\", \"u.s.\", \"united states\", \"united states of america\"]:\n",
    "        return \"North America\"\n",
    "    if clean in [\"uk\", \"u.k.\", \"britain\", \"great britain\"]:\n",
    "        return \"Europe\"\n",
    "\n",
    "    for region, countries in GEOGRAPHY_MAPPING.items():\n",
    "        if any(c.lower() == clean for c in countries):\n",
    "            return region\n",
    "\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "def calculate_mro_months(start_date_str: str, end_date_text: str, program_type: str) -> str:\n",
    "    \"\"\"\n",
    "    Calculate MRO duration in months.\n",
    "\n",
    "    IMPORTANT RULE:\n",
    "    - Only compute when program_type == \"MRO/Support\"\n",
    "    - For all other program types return \"Not Applicable\"\n",
    "\n",
    "    Args:\n",
    "        start_date_str: signed date from Excel\n",
    "        end_date_text: completion date text extracted from paragraph\n",
    "        program_type: must be normalized program type\n",
    "\n",
    "    Returns:\n",
    "        months as string OR \"Not Applicable\"\n",
    "    \"\"\"\n",
    "    if program_type != \"MRO/Support\":\n",
    "        return \"Not Applicable\"\n",
    "\n",
    "    try:\n",
    "        if not start_date_str or not end_date_text:\n",
    "            return \"Not Applicable\"\n",
    "\n",
    "        start = pd.to_datetime(start_date_str, dayfirst=True)\n",
    "        end = parser.parse(str(end_date_text), fuzzy=True)\n",
    "\n",
    "        diff = relativedelta(end, start)\n",
    "        total_months = diff.years * 12 + diff.months\n",
    "        return str(max(0, int(total_months)))\n",
    "    except:\n",
    "        return \"Not Applicable\"\n",
    "\n",
    "\n",
    "# ----------------------------- SUPPLIER HELPERS (CRITICAL FIX) -----------------------------\n",
    "\n",
    "def _extract_supplier_from_description(paragraph: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract supplier name from typical DoD award structure using regex.\n",
    "\n",
    "    WHY THIS EXISTS:\n",
    "    - LLM sometimes returns incomplete supplier names (\"Lockheed\", \"Raytheon Co.\")\n",
    "    - Fuzzy match can accidentally map to wrong supplier\n",
    "    - DoD structure is VERY consistent: first entity before comma is supplier\n",
    "\n",
    "    Supported patterns:\n",
    "    1) \"Company Name, City, State, is awarded...\"\n",
    "    2) \"Company Name, City, State, was awarded...\"\n",
    "\n",
    "    Returns:\n",
    "        extracted supplier string OR \"Unknown\"\n",
    "    \"\"\"\n",
    "    p = _normalize_spaces(paragraph)\n",
    "\n",
    "    m = re.match(r\"^(.*?),\\s+.*?\\s+is awarded\", p, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        supplier = m.group(1).strip()\n",
    "        if len(supplier) >= 3:\n",
    "            return supplier\n",
    "\n",
    "    m2 = re.match(r\"^(.*?),\\s+.*?\\s+was awarded\", p, flags=re.IGNORECASE)\n",
    "    if m2:\n",
    "        supplier = m2.group(1).strip()\n",
    "        if len(supplier) >= 3:\n",
    "            return supplier\n",
    "\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "def get_best_supplier_match(extracted_name: str, paragraph: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Robust supplier standardization (SAFE LOGIC).\n",
    "\n",
    "    STRICT PRIORITY ORDER:\n",
    "    1) If extracted supplier is empty -> \"Unknown\"\n",
    "    2) If extracted supplier appears in paragraph -> accept it (minimal modification)\n",
    "    3) Exact match with suppliers.json list\n",
    "    4) If exactly one known supplier appears inside paragraph -> use that\n",
    "    5) Fuzzy match ONLY if high confidence (cutoff >= 0.75)\n",
    "    6) Else keep extracted text (do NOT hallucinate)\n",
    "\n",
    "    WHY THIS IS IMPORTANT:\n",
    "    - Your previous supplier issue happened because fuzzy match was too aggressive.\n",
    "    - This logic prevents wrong overrides (example: \"Lockheed\" -> \"Lockheed Martin\"\n",
    "      only when it's safe).\n",
    "    \"\"\"\n",
    "    if not extracted_name or str(extracted_name).strip().lower() in [\"unknown\", \"n/a\", \"not applicable\", \"\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    extracted_clean = str(extracted_name).strip()\n",
    "    para_lower = str(paragraph or \"\").lower()\n",
    "\n",
    "    # If supplier already appears in paragraph -> safest (keep it)\n",
    "    if extracted_clean.lower() in para_lower:\n",
    "        return extracted_clean\n",
    "\n",
    "    # Exact match\n",
    "    supplier_map = {s.lower(): s for s in SUPPLIER_LIST}\n",
    "    if extracted_clean.lower() in supplier_map:\n",
    "        return supplier_map[extracted_clean.lower()]\n",
    "\n",
    "    # Paragraph scan match (best evidence-based)\n",
    "    paragraph_hits = []\n",
    "    for s in SUPPLIER_LIST:\n",
    "        if s.lower() in para_lower:\n",
    "            paragraph_hits.append(s)\n",
    "    paragraph_hits = list(dict.fromkeys(paragraph_hits))\n",
    "\n",
    "    if len(paragraph_hits) == 1:\n",
    "        return paragraph_hits[0]\n",
    "\n",
    "    # Fuzzy match only if strong\n",
    "    matches = difflib.get_close_matches(extracted_clean, SUPPLIER_LIST, n=1, cutoff=0.75)\n",
    "    if matches:\n",
    "        return matches[0]\n",
    "\n",
    "    return extracted_clean\n",
    "\n",
    "\n",
    "def normalize_program_type(program_type_raw: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize program type into strict allowed values.\n",
    "\n",
    "    IMPORTANT:\n",
    "    - NEVER output \"MRO\"\n",
    "    - If maintenance/sustainment/support -> MUST be \"MRO/Support\"\n",
    "\n",
    "    Returns:\n",
    "        Strict program type string from ALLOWED_PROGRAM_TYPES\n",
    "    \"\"\"\n",
    "    prog_type = str(program_type_raw or \"\").strip()\n",
    "\n",
    "    prog_type_map = {\n",
    "        \"mro\": \"MRO/Support\",\n",
    "        \"support\": \"MRO/Support\",\n",
    "        \"mro/support\": \"MRO/Support\",\n",
    "        \"maintenance\": \"MRO/Support\",\n",
    "        \"sustainment\": \"MRO/Support\",\n",
    "        \"logistics\": \"MRO/Support\",\n",
    "        \"repair\": \"MRO/Support\",\n",
    "        \"spares\": \"MRO/Support\",\n",
    "        \"procurements\": \"Procurement\",\n",
    "        \"rdte\": \"RDT&E\",\n",
    "        \"r&d\": \"RDT&E\"\n",
    "    }\n",
    "\n",
    "    prog_type_norm = prog_type_map.get(prog_type.lower(), prog_type)\n",
    "\n",
    "    if prog_type_norm not in ALLOWED_PROGRAM_TYPES:\n",
    "        return \"Other Service\"\n",
    "\n",
    "    return prog_type_norm\n",
    "\n",
    "\n",
    "# ----------------------------- DESIGNATORS + PILOTING RULES -----------------------------\n",
    "\n",
    "DESIGNATOR_PATTERNS = [\n",
    "    r\"\\bDDG[-\\s]?\\d+\\b\", r\"\\bCVN[-\\s]?\\d+\\b\", r\"\\bSSN[-\\s]?\\d+\\b\",\n",
    "    r\"\\bLCS[-\\s]?\\d+\\b\", r\"\\bLPD[-\\s]?\\d+\\b\", r\"\\bLHA[-\\s]?\\d+\\b\", r\"\\bLHD[-\\s]?\\d+\\b\",\n",
    "    r\"\\bF-\\d+\\b\", r\"\\bB-\\d+\\b\", r\"\\bC-\\d+\\b\", r\"\\bA-\\d+\\b\",\n",
    "    r\"\\bMQ-\\d+\\b\", r\"\\bRQ-\\d+\\b\",\n",
    "    r\"\\bAN\\/[A-Z0-9\\-]+\\b\",\n",
    "    r\"\\b(AIM|AGM|SM|RIM|MIM)-\\d+\\b\",\n",
    "]\n",
    "\n",
    "\n",
    "def extract_designators(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract defense platform designators from paragraph.\n",
    "\n",
    "    Examples:\n",
    "    - DDG-51, CVN-78, SSN-774\n",
    "    - MQ-9, RQ-4\n",
    "    - AIM-9X, SM-6\n",
    "    - AN/APY-10\n",
    "\n",
    "    Returns:\n",
    "        list of unique designator tokens (standardized to uppercase)\n",
    "    \"\"\"\n",
    "    text = str(text or \"\")\n",
    "    found = []\n",
    "    for pat in DESIGNATOR_PATTERNS:\n",
    "        found.extend(re.findall(pat, text, flags=re.IGNORECASE))\n",
    "\n",
    "    cleaned = [f.upper().replace(\" \", \"\").replace(\"--\", \"-\") for f in found]\n",
    "\n",
    "    final = []\n",
    "    seen = set()\n",
    "    for x in cleaned:\n",
    "        if x not in seen:\n",
    "            final.append(x)\n",
    "            seen.add(x)\n",
    "    return final\n",
    "\n",
    "\n",
    "def detect_piloting_rule_based(text: str, designators: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Deterministic piloting classification.\n",
    "\n",
    "    WHY:\n",
    "    - System Piloting is often wrongly inferred by LLM\n",
    "    - Designators MQ- / RQ- strongly indicate UAV/uncrewed systems\n",
    "\n",
    "    Output:\n",
    "        \"Crewed\" | \"Uncrewed\" | \"Not Applicable\"\n",
    "    \"\"\"\n",
    "    t = str(text).lower()\n",
    "\n",
    "    if any(d.startswith((\"MQ-\", \"RQ-\")) for d in designators):\n",
    "        return \"Uncrewed\"\n",
    "    if any(k in t for k in [\"unmanned\", \"uav\", \"drone\", \"autonomous\"]):\n",
    "        return \"Uncrewed\"\n",
    "\n",
    "    if any(d.startswith((\"DDG\", \"CVN\", \"SSN\", \"LCS\", \"LPD\", \"LHA\", \"LHD\")) for d in designators):\n",
    "        return \"Crewed\"\n",
    "    if \"uss \" in t:\n",
    "        return \"Crewed\"\n",
    "\n",
    "    return \"Not Applicable\"\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# 6) ENHANCED SPLIT ENGINE\n",
    "# ======================================================================================\n",
    "\n",
    "def parse_operator_quantity_allocations(paragraph: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Detect quantity allocations by operator.\n",
    "\n",
    "    Example:\n",
    "      \"212 for the Navy, 187 for the Air Force, and 84 for FMS customers\"\n",
    "\n",
    "    Returns:\n",
    "      [\n",
    "        {\"operator\": \"Navy\", \"quantity\": \"212\", \"g2g_b2g\": \"B2G\"},\n",
    "        {\"operator\": \"Foreign Assistance\", \"quantity\": \"84\", \"g2g_b2g\": \"G2G\"}\n",
    "      ]\n",
    "    \"\"\"\n",
    "    text = str(paragraph or \"\")\n",
    "    allocations = []\n",
    "\n",
    "    pattern = r\"(\\d+)\\s+for\\s+the\\s+(Navy|Air Force|Army|Marine Corps)\"\n",
    "    matches = re.findall(pattern, text, flags=re.IGNORECASE)\n",
    "    for qty, op in matches:\n",
    "        allocations.append({\"operator\": op.title(), \"quantity\": qty, \"g2g_b2g\": \"B2G\"})\n",
    "\n",
    "    fms_pattern = r\"(\\d+)\\s+for\\s+(?:Foreign Military Sales\\s*\\(FMS\\)\\s*customers|FMS\\s*customers|a\\s*FMS\\s*customer|FMS)\"\n",
    "    fms_matches = re.findall(fms_pattern, text, flags=re.IGNORECASE)\n",
    "    for qty in fms_matches:\n",
    "        allocations.append({\"operator\": \"Foreign Assistance\", \"quantity\": qty, \"g2g_b2g\": \"G2G\"})\n",
    "\n",
    "    unique = []\n",
    "    seen = set()\n",
    "    for a in allocations:\n",
    "        key = (a[\"operator\"], a[\"quantity\"], a[\"g2g_b2g\"])\n",
    "        if key not in seen:\n",
    "            unique.append(a)\n",
    "            seen.add(key)\n",
    "\n",
    "    return unique\n",
    "\n",
    "\n",
    "def parse_fms_countries(paragraph: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract FMS customer countries list.\n",
    "\n",
    "    Looks for patterns like:\n",
    "      \"governments of Australia, Bahrain, Belgium...\"\n",
    "\n",
    "    Returns:\n",
    "      [\"Australia\", \"Bahrain\", ...]\n",
    "    \"\"\"\n",
    "    text = str(paragraph or \"\")\n",
    "\n",
    "    m = re.search(\n",
    "        r\"governments of (.+?)(?:\\.\\s| Work will be performed| Fiscal| This contract|$)\",\n",
    "        text,\n",
    "        flags=re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "    if not m:\n",
    "        return []\n",
    "\n",
    "    block = m.group(1)\n",
    "    raw = re.split(r\",|\\band\\b\", block)\n",
    "\n",
    "    countries = []\n",
    "    for c in raw:\n",
    "        c = c.strip()\n",
    "        if 2 < len(c) <= 40:\n",
    "            countries.append(c)\n",
    "\n",
    "    final = []\n",
    "    seen = set()\n",
    "    for c in countries:\n",
    "        if c.lower() not in seen:\n",
    "            final.append(c)\n",
    "            seen.add(c.lower())\n",
    "\n",
    "    return final\n",
    "\n",
    "\n",
    "def parse_multiple_suppliers(paragraph: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Detect multi-supplier mention using supplier taxonomy list.\n",
    "\n",
    "    Example:\n",
    "    - \"Lockheed Martin and Raytheon...\"\n",
    "    - \"multiple awardees include...\"\n",
    "\n",
    "    Returns:\n",
    "      list of supplier names from SUPPLIER_LIST found in paragraph.\n",
    "      Returns [] if only one or none.\n",
    "    \"\"\"\n",
    "    text = str(paragraph or \"\")\n",
    "    lower = text.lower()\n",
    "\n",
    "    if \" and \" not in lower and \",\" not in lower:\n",
    "        return []\n",
    "\n",
    "    candidates = []\n",
    "    for supplier in SUPPLIER_LIST:\n",
    "        if supplier.lower() in lower:\n",
    "            candidates.append(supplier)\n",
    "\n",
    "    candidates = list(dict.fromkeys(candidates))\n",
    "    return candidates if len(candidates) >= 2 else []\n",
    "\n",
    "\n",
    "def parse_multiple_values(paragraph: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Detect multiple financial values in paragraph.\n",
    "\n",
    "    Examples:\n",
    "    - \"$328,156,454\"\n",
    "    - \"ceiling value of $500 million\"\n",
    "    - \"base value $20 million and option value $10 million\"\n",
    "\n",
    "    Returns:\n",
    "      [\"328,156,454\", \"500\", ...] raw numbers only\n",
    "    \"\"\"\n",
    "    text = str(paragraph or \"\")\n",
    "    money_pattern = r\"\\$([\\d,]+(?:\\.\\d+)?)\"\n",
    "    vals = re.findall(money_pattern, text)\n",
    "    return list(dict.fromkeys(vals))\n",
    "\n",
    "\n",
    "def split_rows_engine(base_row: dict, paragraph: str) -> List[dict]:\n",
    "    \"\"\"\n",
    "    MASTER SPLIT ENGINE\n",
    "\n",
    "    PURPOSE:\n",
    "    - Convert 1 extracted base_row into 1..N final output rows\n",
    "      depending on split conditions.\n",
    "\n",
    "    SUPPORTED SPLITS:\n",
    "    1) Multi supplier mentions (if paragraph contains 2+ known suppliers)\n",
    "    2) Operator quantity allocation (Navy/Air Force + qty)\n",
    "    3) FMS multi-country split (only applied for G2G rows)\n",
    "    4) Multi financial values -> added only as Value Note (no overwrite)\n",
    "\n",
    "    IMPORTANT:\n",
    "    - Shared columns remain same\n",
    "    - Split-driven columns are modified\n",
    "    - Split Flag + Split Reason are always filled\n",
    "    \"\"\"\n",
    "    paragraph = str(paragraph or \"\")\n",
    "\n",
    "    allocations = parse_operator_quantity_allocations(paragraph)\n",
    "    fms_countries = parse_fms_countries(paragraph)\n",
    "    multi_suppliers = parse_multiple_suppliers(paragraph)\n",
    "    multi_values = parse_multiple_values(paragraph)\n",
    "\n",
    "    split_reasons = []\n",
    "\n",
    "    if multi_suppliers:\n",
    "        split_reasons.append(\"Multi-supplier mention found\")\n",
    "    if allocations:\n",
    "        split_reasons.append(\"Multi-operator allocation found\")\n",
    "    if fms_countries:\n",
    "        split_reasons.append(\"FMS multi-country list found\")\n",
    "    if len(multi_values) >= 2:\n",
    "        split_reasons.append(\"Multiple financial values found\")\n",
    "\n",
    "    if not split_reasons:\n",
    "        base_row[\"Split Flag\"] = \"No\"\n",
    "        base_row[\"Split Reason\"] = \"No split condition found\"\n",
    "        return [base_row]\n",
    "\n",
    "    base_reason = \" | \".join(split_reasons)\n",
    "    rows = [base_row.copy()]\n",
    "\n",
    "    # Supplier split\n",
    "    if multi_suppliers:\n",
    "        new_rows = []\n",
    "        for r in rows:\n",
    "            for s in multi_suppliers:\n",
    "                rr = r.copy()\n",
    "                rr[\"Supplier Name\"] = s\n",
    "                rr[\"Split Flag\"] = \"Yes\"\n",
    "                rr[\"Split Reason\"] = f\"{base_reason} (Supplier split)\"\n",
    "                new_rows.append(rr)\n",
    "        rows = new_rows\n",
    "\n",
    "    # Operator split\n",
    "    if allocations:\n",
    "        new_rows = []\n",
    "        for r in rows:\n",
    "            for alloc in allocations:\n",
    "                rr = r.copy()\n",
    "                rr[\"Customer Operator\"] = alloc[\"operator\"]\n",
    "                rr[\"Quantity\"] = alloc[\"quantity\"]\n",
    "                rr[\"G2G/B2G\"] = alloc[\"g2g_b2g\"]\n",
    "                rr[\"Split Flag\"] = \"Yes\"\n",
    "                rr[\"Split Reason\"] = f\"{base_reason} (Operator/Quantity split)\"\n",
    "                new_rows.append(rr)\n",
    "        rows = new_rows\n",
    "\n",
    "    # Multi values note\n",
    "    if len(multi_values) >= 2:\n",
    "        for r in rows:\n",
    "            note = r.get(\"Value Note (If Any)\", \"Not Applicable\")\n",
    "            r[\"Value Note (If Any)\"] = f\"{note} | Multiple values detected: {multi_values[:5]}\"\n",
    "\n",
    "    # FMS country split\n",
    "    if fms_countries:\n",
    "        final_rows = []\n",
    "        for r in rows:\n",
    "            if r.get(\"G2G/B2G\") == \"G2G\":\n",
    "                for c in fms_countries:\n",
    "                    rr = r.copy()\n",
    "                    rr[\"Customer Country\"] = c\n",
    "                    rr[\"Customer Region\"] = get_region_for_country(c)\n",
    "                    rr[\"Split Flag\"] = \"Yes\"\n",
    "                    rr[\"Split Reason\"] = f\"{base_reason} (FMS country split)\"\n",
    "                    final_rows.append(rr)\n",
    "            else:\n",
    "                final_rows.append(r)\n",
    "        rows = final_rows\n",
    "\n",
    "    for r in rows:\n",
    "        r.setdefault(\"Split Flag\", \"Yes\")\n",
    "        r.setdefault(\"Split Reason\", base_reason)\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# 7) AGENTS / TOOLS\n",
    "# ======================================================================================\n",
    "\n",
    "# ---------------------------------- Stage 1: Sourcing ----------------------------------\n",
    "\n",
    "class SourcingInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    url: str = Field(description=\"Source URL of the contract announcement/news.\")\n",
    "    date: str = Field(description=\"Contract date in Excel (string).\")\n",
    "\n",
    "\n",
    "@tool(\"sourcing_extractor\")\n",
    "def sourcing_extractor(paragraph: str, url: str, date: str):\n",
    "    \"\"\"\n",
    "    STAGE 1 TOOL: SOURCING EXTRACTOR\n",
    "\n",
    "    GOAL:\n",
    "    - Build the base skeleton row of the dataset with sourcing fields.\n",
    "    - These fields MUST remain unchanged even when row split happens later.\n",
    "\n",
    "    OUTPUT COLUMNS:\n",
    "    - Description of Contract\n",
    "    - Source Link(s)\n",
    "    - Contract Date\n",
    "    - Reported Date (By SGA)\n",
    "    - Additional Notes (Internal Only)\n",
    "\n",
    "    WHY IMPORTANT:\n",
    "    - Split engine later will duplicate rows.\n",
    "    - Without this stage, split rows lose traceability to paragraph and URL.\n",
    "    \"\"\"\n",
    "    reported_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    notes = \"Standard extraction.\"\n",
    "    if \"modification\" in str(paragraph).lower():\n",
    "        notes = \"Contract Modification.\"\n",
    "    if \"multiple award\" in str(paragraph).lower() or \"split\" in str(paragraph).lower():\n",
    "        notes = \"Potential split award detected.\"\n",
    "\n",
    "    return {\n",
    "        \"Description of Contract\": paragraph,\n",
    "        \"Additional Notes (Internal Only)\": notes,\n",
    "        \"Source Link(s)\": url,\n",
    "        \"Contract Date\": date,\n",
    "        \"Reported Date (By SGA)\": reported_date\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------------------------------- Stage 2: Geography ----------------------------------\n",
    "\n",
    "class GeographyInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "\n",
    "\n",
    "@tool(\"geography_extractor\")\n",
    "def geography_extractor(paragraph: str):\n",
    "    \"\"\"\n",
    "    STAGE 2 TOOL: GEOGRAPHY EXTRACTOR\n",
    "\n",
    "    GOAL:\n",
    "    - Extract geography context (buyer + supplier location).\n",
    "\n",
    "    OUTPUT:\n",
    "    - Customer Country\n",
    "    - Customer Operator\n",
    "    - Supplier Country\n",
    "    - Customer Region (derived)\n",
    "    - Supplier Region (derived)\n",
    "    - Domestic Content (derived)\n",
    "\n",
    "    RULES:\n",
    "    - Customer Operator is the defense branch / customer body:\n",
    "      Navy, Air Force, Army, Marine Corps, Foreign Assistance etc.\n",
    "    - Domestic Content:\n",
    "      Indigenous if Customer Country == Supplier Country\n",
    "      else Imported\n",
    "    \"\"\"\n",
    "    sys_prompt = \"\"\"\n",
    "Extract: Customer Country, Supplier Country, Customer Operator.\n",
    "\n",
    "STRICT RULES:\n",
    "- Return JSON only.\n",
    "- If not found, return \"Unknown\".\n",
    "- Operator examples:\n",
    "  \"Navy\", \"Air Force\", \"Army\", \"Marine Corps\", \"Foreign Assistance\"\n",
    "\n",
    "Return JSON:\n",
    "{\n",
    "  \"Customer Country\": \"...\",\n",
    "  \"Customer Operator\": \"...\",\n",
    "  \"Supplier Country\": \"...\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "    log_block(\"HUMAN MESSAGE (Stage2 - Geography)\", paragraph)\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": paragraph}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "        log_block(\"AI RESPONSE (Stage2 - Geography)\", json.dumps(raw, indent=2))\n",
    "    except Exception as e:\n",
    "        raw = {}\n",
    "        log_block(\"AI ERROR (Stage2 - Geography)\", str(e))\n",
    "\n",
    "    cust = raw.get(\"Customer Country\", \"Unknown\")\n",
    "    supp = raw.get(\"Supplier Country\", \"Unknown\")\n",
    "\n",
    "    domestic = \"Indigenous\" if str(cust).lower() == str(supp).lower() else \"Imported\"\n",
    "\n",
    "    return {\n",
    "        \"Customer Region\": get_region_for_country(cust),\n",
    "        \"Customer Country\": cust,\n",
    "        \"Customer Operator\": raw.get(\"Customer Operator\", \"Unknown\"),\n",
    "        \"Supplier Region\": get_region_for_country(supp),\n",
    "        \"Supplier Country\": supp,\n",
    "        \"Domestic Content\": domestic\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------------------------------- Stage 3: System Classifier (RAG) ---------------------\n",
    "\n",
    "class SystemInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "\n",
    "\n",
    "@tool(\"system_classifier\")\n",
    "def system_classifier(paragraph: str):\n",
    "    \"\"\"\n",
    "    STAGE 3 TOOL: SYSTEM CLASSIFIER (RAG + RULE BOOK + EVIDENCE/REASON)\n",
    "\n",
    "    GOAL:\n",
    "    - Identify taxonomy-based defense system classification fields with evidence + reasoning.\n",
    "\n",
    "    OUTPUT FIELDS:\n",
    "    - Market Segment (+ Evidence + Reason)\n",
    "    - System Type (General) (+ Evidence + Reason)\n",
    "    - System Type (Specific) (+ Evidence + Reason)\n",
    "    - System Name (General) (+ Evidence + Reason)\n",
    "    - System Name (Specific) (+ Evidence + Reason)\n",
    "    - System Piloting (+ Evidence + Reason)\n",
    "    - Confidence\n",
    "\n",
    "    ACCURACY ENHANCEMENTS:\n",
    "    ‚úÖ RULE_BOOK triggers add hard guidance for known keyword patterns\n",
    "    ‚úÖ RAG examples provide consistent \"known good\" labeled references\n",
    "    ‚úÖ Deterministic System Piloting overrides model errors:\n",
    "       MQ-/RQ- -> Uncrewed, USS/DDG/CVN -> Crewed\n",
    "\n",
    "    STRICT RULES:\n",
    "    - Evidence text must be copied EXACTLY from paragraph if present.\n",
    "    - If not found -> \"Not Found\"\n",
    "    - Return flat JSON only (no nested dict/list).\n",
    "    \"\"\"\n",
    "    paragraph = str(paragraph or \"\").strip()\n",
    "    if not paragraph:\n",
    "        return {}\n",
    "\n",
    "    log_block(\"HUMAN MESSAGE (Stage3 - System)\", paragraph)\n",
    "\n",
    "    lower_text = paragraph.lower()\n",
    "    hints = [\n",
    "        f\"RULE: {v['guidance']}\"\n",
    "        for _, v in RULE_BOOK.items()\n",
    "        if any(t in lower_text for t in v[\"triggers\"])\n",
    "    ]\n",
    "    hint_str = \"\\n\".join(hints) if hints else \"No special override rules triggered.\"\n",
    "\n",
    "    designators = extract_designators(paragraph)\n",
    "    piloting_rule = detect_piloting_rule_based(paragraph, designators)\n",
    "\n",
    "    rag_hits = retriever.retrieve(paragraph, top_k=3)\n",
    "    rag_examples = []\n",
    "    for hit in rag_hits:\n",
    "        meta = hit[\"meta\"]\n",
    "        rag_examples.append({\n",
    "            \"score\": round(hit[\"score\"], 4),\n",
    "            \"Market Segment\": meta.get(\"Market Segment\", \"\"),\n",
    "            \"System Type (General)\": meta.get(\"System Type (General)\", \"\"),\n",
    "            \"System Type (Specific)\": meta.get(\"System Type (Specific)\", \"\"),\n",
    "            \"System Name (General)\": meta.get(\"System Name (General)\", \"\"),\n",
    "            \"System Name (Specific)\": meta.get(\"System Name (Specific)\", \"\"),\n",
    "            \"System Piloting\": meta.get(\"System Piloting\", \"\"),\n",
    "            \"Snippet\": (meta.get(\"Description of Contract\", \"\")[:220] + \"...\") if meta.get(\"Description of Contract\") else \"\"\n",
    "        })\n",
    "\n",
    "    sys_prompt = f\"\"\"\n",
    "You are a Senior Defense System Classification Analyst.\n",
    "\n",
    "REFERENCE TAXONOMY (JSON):\n",
    "{TAXONOMY_STR}\n",
    "\n",
    "RULE BOOK OVERRIDES:\n",
    "{hint_str}\n",
    "\n",
    "OUTPUT RULES:\n",
    "- Return ONLY a FLAT JSON object.\n",
    "- Every value must be a STRING.\n",
    "- Do NOT return nested objects or lists.\n",
    "- Evidence must be copied EXACTLY from paragraph.\n",
    "- If evidence not present, output \"Not Found\".\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"Market Segment\": \"\",\n",
    "  \"Market Segment Evidence\": \"\",\n",
    "  \"Market Segment Reason\": \"\",\n",
    "\n",
    "  \"System Type (General)\": \"\",\n",
    "  \"System Type (General) Evidence\": \"\",\n",
    "  \"System Type (General) Reason\": \"\",\n",
    "\n",
    "  \"System Type (Specific)\": \"\",\n",
    "  \"System Type (Specific) Evidence\": \"\",\n",
    "  \"System Type (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Name (General)\": \"\",\n",
    "  \"System Name (General) Evidence\": \"\",\n",
    "  \"System Name (General) Reason\": \"\",\n",
    "\n",
    "  \"System Name (Specific)\": \"\",\n",
    "  \"System Name (Specific) Evidence\": \"\",\n",
    "  \"System Name (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Piloting\": \"\",\n",
    "  \"System Piloting Evidence\": \"\",\n",
    "  \"System Piloting Reason\": \"\",\n",
    "\n",
    "  \"Confidence\": \"High/Medium/Low\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "PARAGRAPH:\n",
    "{paragraph}\n",
    "\n",
    "DESIGNATORS (regex extracted):\n",
    "{designators if designators else \"None\"}\n",
    "\n",
    "RULE BASED PILOTING:\n",
    "{piloting_rule}\n",
    "\n",
    "RAG EXAMPLES (top matches):\n",
    "{json.dumps(rag_examples, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        result = json.loads(completion.choices[0].message.content)\n",
    "        log_block(\"AI RESPONSE (Stage3 - System)\", json.dumps(result, indent=2))\n",
    "\n",
    "        # Hard override piloting\n",
    "        result[\"System Piloting\"] = piloting_rule\n",
    "        result.setdefault(\"System Piloting Evidence\", \"Not Found\")\n",
    "        result.setdefault(\"System Piloting Reason\", \"Derived from deterministic piloting rules (designator + keywords).\")\n",
    "\n",
    "        # ensure flat values\n",
    "        for k, v in result.items():\n",
    "            if isinstance(v, (dict, list)):\n",
    "                result[k] = str(v)\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        log_block(\"AI ERROR (Stage3 - System)\", str(e))\n",
    "        return {\n",
    "            \"Market Segment\": \"\",\n",
    "            \"Market Segment Evidence\": \"Not Found\",\n",
    "            \"Market Segment Reason\": \"\",\n",
    "\n",
    "            \"System Type (General)\": \"\",\n",
    "            \"System Type (General) Evidence\": \"Not Found\",\n",
    "            \"System Type (General) Reason\": \"\",\n",
    "\n",
    "            \"System Type (Specific)\": \"\",\n",
    "            \"System Type (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Type (Specific) Reason\": \"\",\n",
    "\n",
    "            \"System Name (General)\": \"\",\n",
    "            \"System Name (General) Evidence\": \"Not Found\",\n",
    "            \"System Name (General) Reason\": \"\",\n",
    "\n",
    "            \"System Name (Specific)\": \"\",\n",
    "            \"System Name (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Name (Specific) Reason\": \"\",\n",
    "\n",
    "            \"System Piloting\": piloting_rule,\n",
    "            \"System Piloting Evidence\": \"Not Found\",\n",
    "            \"System Piloting Reason\": \"Derived from deterministic piloting rules.\",\n",
    "\n",
    "            \"Confidence\": \"Low\",\n",
    "            \"Error\": str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "# ---------------------------------- Stage 4: Contract Extractor --------------------------\n",
    "\n",
    "class ContractInfoInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    contract_date: str = Field(description=\"Contract signed date (string from Excel).\")\n",
    "\n",
    "\n",
    "@tool(\"contract_extractor\")\n",
    "def contract_extractor(paragraph: str, contract_date: str):\n",
    "    \"\"\"\n",
    "    STAGE 4 TOOL: CONTRACT EXTRACTOR (SUPPLIER + FINANCIAL + PROGRAM)\n",
    "\n",
    "    GOAL:\n",
    "    Extract financial + contract fields from paragraph:\n",
    "\n",
    "    OUTPUT FIELDS:\n",
    "    - Supplier Name  ‚úÖ (fixed logic + safe matching)\n",
    "    - Program Type   ‚úÖ (STRICT: must be exactly one of allowed types)\n",
    "    - Quantity\n",
    "    - Value (Million)\n",
    "    - Currency\n",
    "    - Value Certainty\n",
    "    - G2G/B2G\n",
    "    - Completion Date Text\n",
    "    - Value Note\n",
    "\n",
    "    SUPPLIER NAME LOGIC (VERY IMPORTANT FIX):\n",
    "    - LLM raw supplier is not trusted blindly\n",
    "    - We compute a fallback supplier using DoD regex structure:\n",
    "      \"Company Name, City, ST, is awarded...\"\n",
    "    - Then we standardize with safe logic:\n",
    "      * Exact/paragraph based match first\n",
    "      * Fuzzy ONLY at high cutoff\n",
    "      * Never hallucinate supplier\n",
    "\n",
    "    PROGRAM TYPE STRICT RULE:\n",
    "    - Must be EXACTLY one of:\n",
    "      Procurement / Training / MRO/Support / RDT&E / Upgrade / Other Service\n",
    "    - NEVER output \"MRO\"\n",
    "    \"\"\"\n",
    "    system_instruction = f\"\"\"\n",
    "You are a Defense Contract Financial Analyst.\n",
    "\n",
    "Return JSON ONLY.\n",
    "\n",
    "STRICT RULES:\n",
    "1) raw_supplier_name:\n",
    "   - Extract EXACT supplier company name as written in paragraph (no guessing).\n",
    "   - If not found, return \"\" (empty string).\n",
    "\n",
    "2) program_type MUST be EXACTLY one of:\n",
    "   - Procurement\n",
    "   - Training\n",
    "   - MRO/Support\n",
    "   - RDT&E\n",
    "   - Upgrade\n",
    "   - Other Service\n",
    "\n",
    "   IMPORTANT:\n",
    "   - Do NOT return \"MRO\"\n",
    "   - Do NOT return \"Support\"\n",
    "   - It MUST be \"MRO/Support\" exactly for sustainment/maintenance/support/spares.\n",
    "\n",
    "3) value_certainty MUST be one of:\n",
    "   - Confirmed\n",
    "   - Estimated\n",
    "\n",
    "4) quantity:\n",
    "   - Extract numeric quantity if present else \"Not Applicable\"\n",
    "\n",
    "5) g2g_b2g:\n",
    "   - \"G2G\" ONLY if paragraph mentions FMS/Foreign Military Sales\n",
    "   - Else \"B2G\"\n",
    "\n",
    "6) value_million_raw:\n",
    "   - numeric only, may contain comma or decimal\n",
    "   - DO NOT include \"$\"\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"raw_supplier_name\": \"\",\n",
    "  \"program_type\": \"\",\n",
    "  \"value_million_raw\": \"\",\n",
    "  \"currency_code\": \"\",\n",
    "  \"value_certainty\": \"\",\n",
    "  \"quantity\": \"\",\n",
    "  \"completion_date_text\": \"\",\n",
    "  \"g2g_b2g\": \"\",\n",
    "  \"value_note\": \"\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "PARAGRAPH:\n",
    "{paragraph}\n",
    "\n",
    "SIGNED DATE:\n",
    "{contract_date}\n",
    "\"\"\"\n",
    "\n",
    "    log_block(\"HUMAN MESSAGE (Stage4 - Contract)\", paragraph)\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_instruction},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "        log_block(\"AI RESPONSE (Stage4 - Contract)\", json.dumps(raw, indent=2))\n",
    "    except Exception as e:\n",
    "        log_block(\"AI ERROR (Stage4 - Contract)\", str(e))\n",
    "        return {\"Error\": str(e)}\n",
    "\n",
    "    # ------------------ Supplier Fix: do NOT break supplier name ------------------\n",
    "\n",
    "    raw_supplier = raw.get(\"raw_supplier_name\", \"\")\n",
    "    fallback_supplier = _extract_supplier_from_description(paragraph)\n",
    "    candidate_supplier = raw_supplier if raw_supplier else fallback_supplier\n",
    "\n",
    "    final_supplier = get_best_supplier_match(candidate_supplier, paragraph=paragraph)\n",
    "\n",
    "    # ------------------ Program Type Fix: must be EXACT ------------------\n",
    "\n",
    "    prog_type = normalize_program_type(raw.get(\"program_type\", \"\"))\n",
    "\n",
    "    # ------------------ MRO months only when MRO/Support ------------------\n",
    "\n",
    "    mro_months = calculate_mro_months(contract_date, raw.get(\"completion_date_text\"), prog_type)\n",
    "\n",
    "    # ------------------ Value formatting ------------------\n",
    "\n",
    "    try:\n",
    "        val_str = str(raw.get(\"value_million_raw\", \"0\")).replace(\",\", \"\").replace(\"$\", \"\").strip()\n",
    "        val_float = float(val_str)\n",
    "        val_formatted = \"{:.3f}\".format(val_float)\n",
    "    except:\n",
    "        val_formatted = \"0.000\"\n",
    "\n",
    "    # ------------------ Signing Month/Year ------------------\n",
    "\n",
    "    try:\n",
    "        dt = pd.to_datetime(contract_date)\n",
    "        sign_month = dt.strftime(\"%B\")\n",
    "        sign_year = str(dt.year)\n",
    "    except:\n",
    "        sign_month, sign_year = \"Unknown\", \"Unknown\"\n",
    "\n",
    "    return {\n",
    "        \"Supplier Name\": final_supplier,\n",
    "        \"Program Type\": prog_type,\n",
    "        \"Expected MRO Contract Duration (Months)\": mro_months,\n",
    "        \"Quantity\": raw.get(\"quantity\", \"Not Applicable\"),\n",
    "        \"Value Certainty\": raw.get(\"value_certainty\", \"Confirmed\"),\n",
    "        \"Value (Million)\": val_formatted,\n",
    "        \"Currency\": raw.get(\"currency_code\", \"USD$\"),\n",
    "        \"Value (USD$ Million)\": val_formatted,\n",
    "        \"Value Note (If Any)\": raw.get(\"value_note\", \"Not Applicable\"),\n",
    "        \"G2G/B2G\": raw.get(\"g2g_b2g\", \"B2G\"),\n",
    "        \"Signing Month\": sign_month,\n",
    "        \"Signing Year\": sign_year\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------------------------------- Stage 5: Split Agent --------------------------------\n",
    "\n",
    "class SplitterInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    base_row: dict = Field(description=\"Final extracted row after Stage1-4.\")\n",
    "\n",
    "\n",
    "@tool(\"splitter_agent\")\n",
    "def splitter_agent(paragraph: str, base_row: dict):\n",
    "    \"\"\"\n",
    "    STAGE 5 TOOL: SPLITTER AGENT\n",
    "\n",
    "    GOAL:\n",
    "    - Identify if one extracted row must be split into multiple rows\n",
    "      using deterministic split logic.\n",
    "\n",
    "    WHEN SPLIT HAPPENS:\n",
    "    - Multiple suppliers in one paragraph\n",
    "    - Operator-wise quantity allocation (Navy/Air Force split)\n",
    "    - FMS multi-country list (only for G2G rows)\n",
    "    - Multiple values -> stored in Value Note\n",
    "\n",
    "    OUTPUT:\n",
    "    Returns JSON:\n",
    "    {\n",
    "      \"rows\": [row1, row2, ...]\n",
    "    }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        rows = split_rows_engine(base_row, paragraph)\n",
    "        for r in rows:\n",
    "            r.setdefault(\"Split Flag\", \"No\")\n",
    "            r.setdefault(\"Split Reason\", \"\")\n",
    "        return {\"rows\": rows}\n",
    "    except Exception as e:\n",
    "        base_row[\"Split Flag\"] = \"Error\"\n",
    "        base_row[\"Split Reason\"] = f\"Split failed: {str(e)}\"\n",
    "        return {\"rows\": [base_row]}\n",
    "\n",
    "\n",
    "# ---------------------------------- Stage 6: Quality Validator (Rule-Based) --------------\n",
    "\n",
    "class QualityValidatorInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    row: dict = Field(description=\"One fully extracted row after splitting.\")\n",
    "\n",
    "\n",
    "@tool(\"quality_validator\")\n",
    "def quality_validator(paragraph: str, row: dict):\n",
    "    \"\"\"\n",
    "    STAGE 6 TOOL: QUALITY VALIDATOR (RULE-BASED)\n",
    "\n",
    "    GOAL:\n",
    "    - Detect obviously wrong output rows and flag them.\n",
    "\n",
    "    THIS VALIDATOR DOES NOT \"FIX\" DATA.\n",
    "    It ONLY flags with:\n",
    "    - QA Status = PASS/FAIL\n",
    "    - QA Flags = list of issues\n",
    "    - QA Notes = explanation\n",
    "\n",
    "    IMPORTANT VALIDATIONS:\n",
    "    ‚úÖ Supplier mismatch:\n",
    "       - If Supplier Name NOT mentioned anywhere in paragraph -> FAIL\n",
    "\n",
    "    ‚úÖ Program Type format:\n",
    "       - If Program Type not in allowed strict list -> FAIL\n",
    "       - If Program Type == \"MRO\" -> FAIL (disallowed)\n",
    "\n",
    "    ‚úÖ System mismatch signals:\n",
    "       - If Market Segment/System Type empty -> FAIL\n",
    "\n",
    "    OUTPUT:\n",
    "    - QA Status\n",
    "    - QA Flags\n",
    "    - QA Notes\n",
    "    \"\"\"\n",
    "    paragraph_l = str(paragraph or \"\").lower()\n",
    "\n",
    "    supplier = str(row.get(\"Supplier Name\", \"\")).strip()\n",
    "    program_type = str(row.get(\"Program Type\", \"\")).strip()\n",
    "\n",
    "    flags = []\n",
    "\n",
    "    # Supplier validation\n",
    "    if supplier in [\"\", \"Unknown\"]:\n",
    "        flags.append(\"Supplier missing or Unknown\")\n",
    "    else:\n",
    "        # if supplier does not appear in paragraph -> very suspicious\n",
    "        if supplier.lower() not in paragraph_l:\n",
    "            # allow short fallback check: maybe supplier appears as partial token\n",
    "            partial_hit = any(tok.lower() in paragraph_l for tok in supplier.split() if len(tok) >= 4)\n",
    "            if not partial_hit:\n",
    "                flags.append(\"Supplier does not match paragraph evidence\")\n",
    "\n",
    "    # Program type validation\n",
    "    if program_type not in ALLOWED_PROGRAM_TYPES:\n",
    "        flags.append(\"Program Type not in allowed list\")\n",
    "    if program_type.strip().lower() == \"mro\":\n",
    "        flags.append(\"Program Type invalid: must be 'MRO/Support' not 'MRO'\")\n",
    "\n",
    "    # System sanity\n",
    "    market = str(row.get(\"Market Segment\", \"\")).strip()\n",
    "    sys_type = str(row.get(\"System Type (General)\", \"\")).strip()\n",
    "    sys_name = str(row.get(\"System Name (General)\", \"\")).strip()\n",
    "\n",
    "    if market == \"\":\n",
    "        flags.append(\"Market Segment missing\")\n",
    "    if sys_type == \"\":\n",
    "        flags.append(\"System Type (General) missing\")\n",
    "    if sys_name == \"\":\n",
    "        flags.append(\"System Name (General) missing\")\n",
    "\n",
    "    status = \"PASS\" if len(flags) == 0 else \"FAIL\"\n",
    "\n",
    "    return {\n",
    "        \"QA Status\": status,\n",
    "        \"QA Flags\": \"; \".join(flags) if flags else \"None\",\n",
    "        \"QA Notes\": \"Rule-based QA validation applied.\"\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------------------------------- Stage 6B: LLM Validator (ONLY FAIL rows) -------------\n",
    "\n",
    "class LLMValidatorInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    row: dict = Field(description=\"Row that failed rule-based QA and requires LLM validation.\")\n",
    "\n",
    "\n",
    "@tool(\"llm_fail_validator\")\n",
    "def llm_fail_validator(paragraph: str, row: dict):\n",
    "    \"\"\"\n",
    "    STAGE 6B TOOL: LLM FAIL VALIDATOR (ONLY RUNS WHEN QA STATUS = FAIL)\n",
    "\n",
    "    WHY THIS EXISTS:\n",
    "    - Rule-based QA catches false positives sometimes.\n",
    "    - LLM can reason better if supplier is acceptable even if not literally present.\n",
    "      (Example: \"Lockheed Martin Corp.\" vs \"Lockheed Martin\")\n",
    "\n",
    "    WHAT IT DOES:\n",
    "    - It reviews the paragraph + extracted row\n",
    "    - It decides:\n",
    "        * should this row still be FAIL?\n",
    "        * OR upgrade to PASS with justification?\n",
    "\n",
    "    OUTPUT:\n",
    "    {\n",
    "      \"QA Status Final\": \"PASS\" or \"FAIL\",\n",
    "      \"QA LLM Notes\": \"short reason\",\n",
    "      \"Supplier Fix Suggestion\": \"...\",\n",
    "      \"Program Type Fix Suggestion\": \"...\"\n",
    "    }\n",
    "\n",
    "    IMPORTANT:\n",
    "    - It does NOT overwrite the row automatically.\n",
    "    - It provides suggestions only for debugging + manual review.\n",
    "    \"\"\"\n",
    "    sys_prompt = \"\"\"\n",
    "You are a Defense Contract QA Auditor.\n",
    "\n",
    "You will receive:\n",
    "1) Contract paragraph text\n",
    "2) Extracted output row data\n",
    "\n",
    "TASK:\n",
    "- Validate if supplier and program type make sense based on paragraph.\n",
    "- If supplier seems wrong -> suggest correction (if possible).\n",
    "- If program type seems wrong -> suggest correction.\n",
    "\n",
    "STRICT RULES:\n",
    "- Do NOT hallucinate suppliers that are not evidenced in the paragraph.\n",
    "- Program Type must be exactly one of:\n",
    "  Procurement, Training, MRO/Support, RDT&E, Upgrade, Other Service\n",
    "\n",
    "Return JSON only:\n",
    "{\n",
    "  \"QA Status Final\": \"PASS/FAIL\",\n",
    "  \"QA LLM Notes\": \"\",\n",
    "  \"Supplier Fix Suggestion\": \"\",\n",
    "  \"Program Type Fix Suggestion\": \"\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "PARAGRAPH:\n",
    "{paragraph}\n",
    "\n",
    "ROW:\n",
    "{json.dumps(row, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "        return raw\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"QA Status Final\": \"FAIL\",\n",
    "            \"QA LLM Notes\": f\"LLM validator failed: {str(e)}\",\n",
    "            \"Supplier Fix Suggestion\": \"\",\n",
    "            \"Program Type Fix Suggestion\": \"\"\n",
    "        }\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# 8) LANGGRAPH PIPELINE\n",
    "# ======================================================================================\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    LangGraph Agent State container.\n",
    "\n",
    "    Fields:\n",
    "    - input_text: contract paragraph\n",
    "    - input_date: signing date from Excel\n",
    "    - input_url: source URL from Excel\n",
    "\n",
    "    - final_data: dict containing extracted fields before splitting\n",
    "    - final_rows: list of rows after split applied\n",
    "\n",
    "    - messages: internal message channel (LangGraph requirement)\n",
    "    \"\"\"\n",
    "    input_text: str\n",
    "    input_date: str\n",
    "    input_url: str\n",
    "    final_data: dict\n",
    "    final_rows: list\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "def stage_1_sourcing(state: AgentState):\n",
    "    \"\"\"\n",
    "    NODE Stage1: Sourcing Extractor\n",
    "\n",
    "    PURPOSE:\n",
    "    - Populate paragraph-level traceability fields:\n",
    "      Description, Source link, dates, internal notes\n",
    "\n",
    "    IMPORTANT:\n",
    "    - These fields MUST remain same even after split happens.\n",
    "    \"\"\"\n",
    "    res = sourcing_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"url\": state[\"input_url\"],\n",
    "        \"date\": state[\"input_date\"],\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_2_geography(state: AgentState):\n",
    "    \"\"\"\n",
    "    NODE Stage2: Geography Extractor\n",
    "\n",
    "    PURPOSE:\n",
    "    - Identify Customer Country/Operator + Supplier Country\n",
    "    - Derive regions + domestic content\n",
    "    \"\"\"\n",
    "    res = geography_extractor.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_3_system(state: AgentState):\n",
    "    \"\"\"\n",
    "    NODE Stage3: System Classifier\n",
    "\n",
    "    PURPOSE:\n",
    "    - Classify defense contract into taxonomy fields using:\n",
    "      - TAXONOMY JSON reference\n",
    "      - RULE BOOK keyword guidance\n",
    "      - RAG examples\n",
    "      - Deterministic piloting override\n",
    "\n",
    "    OUTPUT:\n",
    "    - Market Segment + evidence/reason\n",
    "    - System fields + evidence/reason\n",
    "    \"\"\"\n",
    "    res = system_classifier.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_4_contract(state: AgentState):\n",
    "    \"\"\"\n",
    "    NODE Stage4: Contract Extractor\n",
    "\n",
    "    PURPOSE:\n",
    "    - Extract supplier/program type/value/quantity and normalize.\n",
    "\n",
    "    ENHANCED SUPPLIER LOGIC:\n",
    "    - Uses regex-based fallback supplier extraction for DoD structured paragraphs\n",
    "    - Uses evidence-based matching (paragraph scan) BEFORE fuzzy matching\n",
    "    - Prevents wrong supplier assignments\n",
    "\n",
    "    PROGRAM TYPE FIX:\n",
    "    - Program Type must be one of allowed list\n",
    "    - \"MRO\" is forbidden; must be \"MRO/Support\"\n",
    "    \"\"\"\n",
    "    res = contract_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"contract_date\": state[\"input_date\"]\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_5_split(state: AgentState):\n",
    "    \"\"\"\n",
    "    NODE Stage5: Split Engine\n",
    "\n",
    "    PURPOSE:\n",
    "    - Convert 1 extracted row -> N rows if paragraph describes:\n",
    "      multi suppliers, multi operators/qty allocation, multi FMS countries.\n",
    "\n",
    "    OUTPUT:\n",
    "    - final_rows list used downstream for validation + export\n",
    "    \"\"\"\n",
    "    res = splitter_agent.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"base_row\": state[\"final_data\"]\n",
    "    })\n",
    "    return {\"final_rows\": res.get(\"rows\", [state[\"final_data\"]])}\n",
    "\n",
    "\n",
    "def stage_6_quality_validation(state: AgentState):\n",
    "    \"\"\"\n",
    "    NODE Stage6: Quality Validation (Rule-based + Optional LLM on FAIL)\n",
    "\n",
    "    PURPOSE:\n",
    "    - Evaluate each output row AFTER splitting.\n",
    "    - Assign QA Status = PASS/FAIL.\n",
    "    - If FAIL:\n",
    "        Run LLM validator (Stage6B) ONLY for FAIL rows.\n",
    "\n",
    "    WHY IMPORTANT:\n",
    "    - This catches broken supplier extraction or program type issues.\n",
    "    - Prevents bad rows from silently going into output Excel.\n",
    "    \"\"\"\n",
    "    paragraph = state[\"input_text\"]\n",
    "    validated_rows = []\n",
    "\n",
    "    for row in state.get(\"final_rows\", []):\n",
    "        qa = quality_validator.invoke({\"paragraph\": paragraph, \"row\": row})\n",
    "        merged = row.copy()\n",
    "        merged.update(qa)\n",
    "\n",
    "        # Only run LLM validator if FAIL\n",
    "        if merged.get(\"QA Status\") == \"FAIL\":\n",
    "            llm_q = llm_fail_validator.invoke({\"paragraph\": paragraph, \"row\": merged})\n",
    "            merged[\"QA Status Final\"] = llm_q.get(\"QA Status Final\", \"FAIL\")\n",
    "            merged[\"QA LLM Notes\"] = llm_q.get(\"QA LLM Notes\", \"\")\n",
    "            merged[\"Supplier Fix Suggestion\"] = llm_q.get(\"Supplier Fix Suggestion\", \"\")\n",
    "            merged[\"Program Type Fix Suggestion\"] = llm_q.get(\"Program Type Fix Suggestion\", \"\")\n",
    "        else:\n",
    "            merged[\"QA Status Final\"] = \"PASS\"\n",
    "            merged[\"QA LLM Notes\"] = \"Not Applicable\"\n",
    "            merged[\"Supplier Fix Suggestion\"] = \"Not Applicable\"\n",
    "            merged[\"Program Type Fix Suggestion\"] = \"Not Applicable\"\n",
    "\n",
    "        validated_rows.append(merged)\n",
    "\n",
    "    return {\"final_rows\": validated_rows}\n",
    "\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Stage1\", stage_1_sourcing)\n",
    "workflow.add_node(\"Stage2\", stage_2_geography)\n",
    "workflow.add_node(\"Stage3\", stage_3_system)\n",
    "workflow.add_node(\"Stage4\", stage_4_contract)\n",
    "workflow.add_node(\"Stage5\", stage_5_split)\n",
    "workflow.add_node(\"Stage6\", stage_6_quality_validation)\n",
    "\n",
    "workflow.add_edge(START, \"Stage1\")\n",
    "workflow.add_edge(\"Stage1\", \"Stage2\")\n",
    "workflow.add_edge(\"Stage2\", \"Stage3\")\n",
    "workflow.add_edge(\"Stage3\", \"Stage4\")\n",
    "workflow.add_edge(\"Stage4\", \"Stage5\")\n",
    "workflow.add_edge(\"Stage5\", \"Stage6\")\n",
    "workflow.add_edge(\"Stage6\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# 9) GRAPH VISUALIZATION (OFFLINE SAFE)\n",
    "# ======================================================================================\n",
    "\n",
    "def export_workflow_mermaid(app_obj, out_file=\"workflow.mmd\"):\n",
    "    \"\"\"\n",
    "    Export Mermaid graph text locally (no external API call).\n",
    "\n",
    "    WHY:\n",
    "    - Office or Streamlit cloud might block mermaid.ink\n",
    "    - Still useful for documenting your agent pipeline\n",
    "\n",
    "    Output:\n",
    "    - workflow.mmd file\n",
    "    \"\"\"\n",
    "    mmd = app_obj.get_graph().draw_mermaid()\n",
    "    with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(mmd)\n",
    "    print(f\"‚úÖ Workflow Mermaid saved locally: {out_file}\")\n",
    "    return out_file\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# 10) EXCEL HIGHLIGHTING FEATURE\n",
    "# ======================================================================================\n",
    "\n",
    "def highlight_evidence_reason_columns(excel_path: str):\n",
    "    \"\"\"\n",
    "    Highlight Evidence + Reason columns in output Excel.\n",
    "\n",
    "    Evidence Columns:\n",
    "      - Light Yellow\n",
    "    Reason Columns:\n",
    "      - Light Blue\n",
    "\n",
    "    This makes review very easy for business users.\n",
    "    \"\"\"\n",
    "    wb = load_workbook(excel_path)\n",
    "    ws = wb.active\n",
    "\n",
    "    header = [cell.value for cell in ws[1]]\n",
    "\n",
    "    evidence_cols = []\n",
    "    reason_cols = []\n",
    "\n",
    "    for idx, col_name in enumerate(header, start=1):\n",
    "        if isinstance(col_name, str) and \"Evidence\" in col_name:\n",
    "            evidence_cols.append(idx)\n",
    "        if isinstance(col_name, str) and \"Reason\" in col_name:\n",
    "            reason_cols.append(idx)\n",
    "\n",
    "    evidence_fill = PatternFill(start_color=\"FFF2CC\", end_color=\"FFF2CC\", fill_type=\"solid\")\n",
    "    reason_fill = PatternFill(start_color=\"D9E1F2\", end_color=\"D9E1F2\", fill_type=\"solid\")\n",
    "    header_font = Font(bold=True)\n",
    "\n",
    "    for col_idx in evidence_cols:\n",
    "        ws.cell(row=1, column=col_idx).fill = evidence_fill\n",
    "        ws.cell(row=1, column=col_idx).font = header_font\n",
    "\n",
    "    for col_idx in reason_cols:\n",
    "        ws.cell(row=1, column=col_idx).fill = reason_fill\n",
    "        ws.cell(row=1, column=col_idx).font = header_font\n",
    "\n",
    "    for row in range(2, ws.max_row + 1):\n",
    "        for col_idx in evidence_cols:\n",
    "            ws.cell(row=row, column=col_idx).fill = evidence_fill\n",
    "        for col_idx in reason_cols:\n",
    "            ws.cell(row=row, column=col_idx).fill = reason_fill\n",
    "\n",
    "    wb.save(excel_path)\n",
    "    print(\"‚úÖ Evidence + Reason columns highlighted successfully.\")\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# 11) MAIN EXECUTION\n",
    "# ======================================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(f\"\\nüìå Loading Input File: {INPUT_EXCEL_PATH}\")\n",
    "\n",
    "    # Offline safe workflow graph\n",
    "    export_workflow_mermaid(app, out_file=\"workflow.mmd\")\n",
    "\n",
    "    try:\n",
    "        df_input = pd.read_excel(INPUT_EXCEL_PATH)\n",
    "\n",
    "        required_cols = [\"Source URL\", \"Contract Date\", \"Contract Description\"]\n",
    "        if not all(col in df_input.columns for col in required_cols):\n",
    "            raise ValueError(f\"Excel file must contain columns: {required_cols}\")\n",
    "\n",
    "        print(f\"üöÄ Processing {len(df_input)} rows...\")\n",
    "        results = []\n",
    "\n",
    "        for index, row in df_input.iterrows():\n",
    "            print(f\"\\nüîπ Row {index + 1}/{len(df_input)}\")\n",
    "\n",
    "            desc = str(row[\"Contract Description\"]) if pd.notna(row[\"Contract Description\"]) else \"\"\n",
    "            c_date = str(row[\"Contract Date\"]) if pd.notna(row[\"Contract Date\"]) else str(datetime.date.today())\n",
    "            c_url = str(row[\"Source URL\"]) if pd.notna(row[\"Source URL\"]) else \"\"\n",
    "\n",
    "            initial_state = {\n",
    "                \"input_text\": desc,\n",
    "                \"input_date\": c_date,\n",
    "                \"input_url\": c_url,\n",
    "                \"final_data\": {},\n",
    "                \"final_rows\": [],\n",
    "                \"messages\": []\n",
    "            }\n",
    "\n",
    "            output_state = app.invoke(initial_state)\n",
    "\n",
    "            rows = output_state.get(\"final_rows\", [])\n",
    "            if not rows:\n",
    "                rows = [output_state.get(\"final_data\", {})]\n",
    "\n",
    "            results.extend(rows)\n",
    "\n",
    "        df_final = pd.DataFrame(results)\n",
    "\n",
    "        FINAL_COLUMNS = [\n",
    "            \"QA Status\", \"QA Flags\", \"QA Notes\",\n",
    "            \"QA Status Final\", \"QA LLM Notes\",\n",
    "            \"Supplier Fix Suggestion\", \"Program Type Fix Suggestion\",\n",
    "\n",
    "            \"Customer Region\", \"Customer Country\", \"Customer Operator\",\n",
    "            \"Supplier Region\", \"Supplier Country\", \"Domestic Content\",\n",
    "\n",
    "            \"Split Flag\", \"Split Reason\",\n",
    "\n",
    "            \"Market Segment\", \"Market Segment Evidence\", \"Market Segment Reason\",\n",
    "            \"System Type (General)\", \"System Type (General) Evidence\", \"System Type (General) Reason\",\n",
    "            \"System Type (Specific)\", \"System Type (Specific) Evidence\", \"System Type (Specific) Reason\",\n",
    "            \"System Name (General)\", \"System Name (General) Evidence\", \"System Name (General) Reason\",\n",
    "            \"System Name (Specific)\", \"System Name (Specific) Evidence\", \"System Name (Specific) Reason\",\n",
    "            \"System Piloting\", \"System Piloting Evidence\", \"System Piloting Reason\",\n",
    "            \"Confidence\",\n",
    "\n",
    "            \"Supplier Name\", \"Program Type\", \"Expected MRO Contract Duration (Months)\",\n",
    "            \"Quantity\", \"Value Certainty\", \"Value (Million)\", \"Currency\",\n",
    "            \"Value (USD$ Million)\", \"Value Note (If Any)\", \"G2G/B2G\",\n",
    "            \"Signing Month\", \"Signing Year\",\n",
    "\n",
    "            \"Description of Contract\",\n",
    "            \"Additional Notes (Internal Only)\",\n",
    "            \"Source Link(s)\",\n",
    "            \"Contract Date\",\n",
    "            \"Reported Date (By SGA)\"\n",
    "        ]\n",
    "\n",
    "        df_final = df_final.reindex(columns=FINAL_COLUMNS, fill_value=\"\")\n",
    "        df_final.to_excel(OUTPUT_EXCEL_PATH, index=False)\n",
    "\n",
    "        # Highlight Evidence + Reason columns\n",
    "        highlight_evidence_reason_columns(OUTPUT_EXCEL_PATH)\n",
    "\n",
    "        print(\"\\n‚úÖ Processing Complete!\")\n",
    "        print(f\"üíæ Output File Saved: {OUTPUT_EXCEL_PATH}\")\n",
    "        print(df_final.head(3).to_string(index=False))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
