{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3283d23b",
   "metadata": {},
   "source": [
    "# **Stage-1:- Creating a Knowledge Base**\n",
    "\n",
    "- **Problem Statement**\n",
    "  - Contract / defense data is stored in Excel but it‚Äôs hard to search intelligently\n",
    "  - Traditional keyword search fails when the query wording is different (synonyms / rephrasing)\n",
    "  - Finding the most relevant past contract descriptions takes too much manual effort\n",
    "  - Even if you find a match, getting the full context (supplier, program, amount, etc.) from the correct row is difficult\n",
    "  - A scalable system is needed to support quick retrieval + future AI extraction workflows\n",
    "\n",
    "- **Proposed Solution**\n",
    "  - Build a Vector Knowledge Base (KB) from the Excel dataset\n",
    "  - Convert contract descriptions into semantic embeddings using a transformer model\n",
    "  - Store embeddings in a FAISS vector index for fast similarity-based retrieval\n",
    "  - Store all original Excel columns as metadata to return complete structured information\n",
    "  - Enable searching based on meaning, not only exact words\n",
    "\n",
    "- **Outcome**\n",
    "  * Your Excel knowledge base will become **searchable by meaning (semantic search)** instead of only keywords\n",
    "  * When you give a **new contract description/query**, the system will return the **most similar past contracts** instantly\n",
    "  * You will be able to retrieve the **best-matching row** even if the words are different (synonyms, rephrasing, short forms)\n",
    "  * Along with the match, you will also get the **complete row details** (Supplier, Program, Amount, Dates, etc.) because metadata is stored\n",
    "  * Your extraction pipeline will become **more accurate**, since the LLM can be grounded with relevant historical examples\n",
    "  * It will reduce **manual lookup time**, improve consistency, and make the process scalable as data grows\n",
    "  * You will have a reusable **system KB (FAISS + metadata files)** that can be loaded anytime without rebuilding every time\n",
    "  * This becomes a strong base for building an **agentic workflow** like: Retrieve ‚Üí Validate ‚Üí Extract ‚Üí Store ‚Üí Report\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf543cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Loading Knowledge Base: C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\data\\sample_data.xlsx\n",
      "   Loaded rows=2979 cols=29\n",
      "‚ú® Enriching text with important columns...\n",
      "   Prepared 2979 rows for embedding.\n",
      "üß† Loading Model: sentence-transformers/all-mpnet-base-v2\n",
      "   Creating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 94/94 [25:48<00:00, 16.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ System KB Created Successfully!\n",
      "\n",
      "üöÄ Loading Retriever...\n",
      "\n",
      "============================================================\n",
      "QUERY: Lockheed Martin fighter jets for the US Navy\n",
      "============================================================\n",
      "\n",
      "üîπ Rank: 1 (Score: 0.7450)\n",
      "   Context Used: Market: Air Platforms. System: Ancillary mission equipment (Fighter). Supplier: Lockheed Martin. Customer: USA. Program: Procurement. Certainty: Confirmed. Details: Lockheed Martin Corp., Lockheed Mar...\n",
      "\n",
      "üîπ Rank: 2 (Score: 0.7448)\n",
      "   Context Used: Market: Air Platforms. System: Ancillary Mission Equipment (Fighter). Supplier: Lockheed Martin Aeronautics. Customer: Unknown. Program: Procurement. Certainty: Confirmed. Details: Lockheed Martin Cor...\n",
      "\n",
      "üîπ Rank: 3 (Score: 0.7445)\n",
      "   Context Used: Market: Air Platforms. System: Ancillary Mission Equipment (Fighter). Supplier: Lockheed Martin Aeronautics. Customer: USA. Program: Procurement. Certainty: Confirmed. Details: Lockheed Martin Corp., ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# We use a better model for detailed context\n",
    "DEFAULT_MODEL_NAME = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    if pd.isna(text) or text is None:\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "def safe_to_str(x):\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    return str(x).strip()\n",
    "\n",
    "def build_system_kb_store_enriched(\n",
    "    excel_path: str,\n",
    "    save_dir: str = \"system_kb_store\",\n",
    "    model_name: str = DEFAULT_MODEL_NAME,\n",
    "    batch_size: int = 32,\n",
    "    embed_column: str = \"Description of Contract\",\n",
    "):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"\\nüìÇ Loading Knowledge Base: {excel_path}\")\n",
    "    # Auto-detect file type\n",
    "    if excel_path.endswith(\".csv\"):\n",
    "        df = pd.read_csv(excel_path)\n",
    "    else:\n",
    "        df = pd.read_excel(excel_path)\n",
    "        \n",
    "    # Normalize column names\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    print(f\"   Loaded rows={len(df)} cols={len(df.columns)}\")\n",
    "\n",
    "    kb_texts = []\n",
    "    kb_meta = []\n",
    "\n",
    "    print(\"‚ú® Enriching text with important columns...\")\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        # 1. Get the base description\n",
    "        desc = clean_text(row.get(embed_column, \"\"))\n",
    "\n",
    "        # 2. Extract Important Columns\n",
    "        # We use .get() so the code doesn't crash if a column is missing\n",
    "        market = safe_to_str(row.get(\"Market Segment\", \"\"))\n",
    "        sys_type = safe_to_str(row.get(\"System Type (Specific)\", \"\"))\n",
    "        sys_name = safe_to_str(row.get(\"System Name (Specific)\", \"\"))\n",
    "        supplier = safe_to_str(row.get(\"Supplier Name\", \"\"))\n",
    "        customer = safe_to_str(row.get(\"Customer Country\", \"\"))\n",
    "        program = safe_to_str(row.get(\"Program Type\", \"\"))\n",
    "        value_cert = safe_to_str(row.get(\"Value Certainty\", \"\"))\n",
    "\n",
    "        # 3. Fallback: If description is empty, build one from metadata\n",
    "        if not desc:\n",
    "            desc = f\"Contract for {sys_name} ({sys_type}) supplied by {supplier}.\"\n",
    "\n",
    "        # 4. Create the \"Rich Context\" String\n",
    "        # This is what gets embedded. The model will now \"know\" these fields.\n",
    "        enriched_text = (\n",
    "            f\"Market: {market}. \"\n",
    "            f\"System: {sys_name} ({sys_type}). \"\n",
    "            f\"Supplier: {supplier}. \"\n",
    "            f\"Customer: {customer}. \"\n",
    "            f\"Program: {program}. \"\n",
    "            f\"Certainty: {value_cert}. \"\n",
    "            f\"Details: {desc}\"\n",
    "        )\n",
    "\n",
    "        # 5. Save Metadata\n",
    "        meta = {\"row_id\": int(idx), \"original_text\": desc, \"enriched_text\": enriched_text}\n",
    "        \n",
    "        # Save all columns to metadata for retrieval later\n",
    "        for col in df.columns:\n",
    "            meta[col] = safe_to_str(row[col])\n",
    "\n",
    "        kb_texts.append(enriched_text)\n",
    "        kb_meta.append(meta)\n",
    "\n",
    "    print(f\"   Prepared {len(kb_texts)} rows for embedding.\")\n",
    "\n",
    "    print(f\"üß† Loading Model: {model_name}\")\n",
    "    embedder = SentenceTransformer(model_name)\n",
    "\n",
    "    print(\"   Creating embeddings...\")\n",
    "    embeddings = embedder.encode(\n",
    "        kb_texts, \n",
    "        batch_size=batch_size, \n",
    "        show_progress_bar=True, \n",
    "        normalize_embeddings=True\n",
    "    )\n",
    "\n",
    "    embeddings = np.vstack(embeddings).astype(\"float32\")\n",
    "    dim = embeddings.shape[1]\n",
    "\n",
    "    # Indexing\n",
    "    index = faiss.IndexFlatIP(dim)\n",
    "    index.add(embeddings)\n",
    "\n",
    "    index_path = os.path.join(save_dir, \"system_kb.faiss\")\n",
    "    meta_path = os.path.join(save_dir, \"system_kb_meta.pkl\")\n",
    "\n",
    "    faiss.write_index(index, index_path)\n",
    "    with open(meta_path, \"wb\") as f:\n",
    "        pickle.dump(kb_meta, f)\n",
    "\n",
    "    print(\"\\n‚úÖ System KB Created Successfully!\")\n",
    "    return index_path, meta_path\n",
    "\n",
    "# Part 2: Retriever (Updated to use Enriched Text)\n",
    "\n",
    "class SystemKBRetriever:\n",
    "    def __init__(self, kb_dir=\"system_kb_store\", model_name=DEFAULT_MODEL_NAME):\n",
    "        index_path = os.path.join(kb_dir, \"system_kb.faiss\")\n",
    "        meta_path = os.path.join(kb_dir, \"system_kb_meta.pkl\")\n",
    "\n",
    "        if not os.path.exists(index_path):\n",
    "            raise FileNotFoundError(\"‚ùå KB missing. Build it first.\")\n",
    "\n",
    "        print(f\"\\nüöÄ Loading Retriever...\")\n",
    "        self.index = faiss.read_index(index_path)\n",
    "        with open(meta_path, \"rb\") as f:\n",
    "            self.meta = pickle.load(f)\n",
    "\n",
    "        self.embedder = SentenceTransformer(model_name)\n",
    "\n",
    "    def retrieve(self, query_text: str, top_k: int = 5):\n",
    "        query_text = clean_text(query_text)\n",
    "        if not query_text: return []\n",
    "\n",
    "        q_emb = self.embedder.encode([query_text], normalize_embeddings=True).astype(\"float32\")\n",
    "        scores, idxs = self.index.search(q_emb, top_k)\n",
    "        \n",
    "        results = []\n",
    "        for score, idx in zip(scores[0], idxs[0]):\n",
    "            if idx < 0: continue\n",
    "            results.append({\"score\": float(score), \"meta\": self.meta[idx]})\n",
    "\n",
    "        return results\n",
    "\n",
    "# Run Pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    # UPDATE THIS PATH TO YOUR FILE\n",
    "    EXCEL_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\data\\sample_data.xlsx\"\n",
    "    KB_DIR = \"system_kb_store\"\n",
    "\n",
    "    # 1. Build KB with Enriched Columns\n",
    "    build_system_kb_store_enriched(\n",
    "        excel_path=EXCEL_PATH,\n",
    "        save_dir=KB_DIR,\n",
    "        embed_column=\"Description of Contract\"\n",
    "    )\n",
    "\n",
    "    # 2. Test Search\n",
    "    r = SystemKBRetriever(kb_dir=KB_DIR)\n",
    "\n",
    "    # Test query that relies on the columns we just added\n",
    "    query = \"Lockheed Martin fighter jets for the US Navy\"\n",
    "    \n",
    "    hits = r.retrieve(query, top_k=3)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for i, h in enumerate(hits, start=1):\n",
    "        m = h[\"meta\"]\n",
    "        print(f\"\\nüîπ Rank: {i} (Score: {h['score']:.4f})\")\n",
    "        # Print the Enriched text to prove it's working\n",
    "        print(f\"   Context Used: {m['enriched_text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27531d34",
   "metadata": {},
   "source": [
    "## **Stage 2**\n",
    "\n",
    "In this stage I will be creating AI agest that can help in extraction of data based on the input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab4a89bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import difflib\n",
    "import datetime\n",
    "from typing import Annotated, TypedDict, List, Dict, Any, Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import getpass\n",
    "\n",
    "# LangGraph / LangChain\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "\n",
    "# Excel formatting\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill, Font\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from prompts import (\n",
    "    GEOGRAPHY_PROMPT, \n",
    "    SYSTEM_CLASSIFIER_PROMPT, \n",
    "    CONTRACT_EXTRACTOR_PROMPT, \n",
    "    VALIDATOR_FIX_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bbac0c",
   "metadata": {},
   "source": [
    "**Configurations and Supporting File Path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b5cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LLM CLIENT SETUP (OpenRouter)\n",
    "\n",
    "if \"LLMFOUNDRY_TOKEN\" not in os.environ:\n",
    "    os.environ[\"LLMFOUNDRY_TOKEN\"] = getpass.getpass(\"Enter the LLM Foundry API Key: \")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=f'{os.environ.get(\"LLMFOUNDRY_TOKEN\")}:my-test-project',\n",
    "    base_url=\"https://llmfoundry.straive.com/openai/v1/\",\n",
    ")\n",
    "OPENROUTER_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "# CONFIGURATION & FILE PATHS\n",
    "TAXONOMY_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\taxonomy.json\"\n",
    "SUPPLIERS_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\suppliers.json\"\n",
    "INPUT_EXCEL_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\data\\source_file.xlsx\"\n",
    "OUTPUT_CSV_PATH = \"Processed_Defense_Data.csv\"\n",
    "RAG_KB_DIR = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\system_kb_store\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2af0ae7",
   "metadata": {},
   "source": [
    "**Helper Functions for Stage-2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c743241",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RULE BOOK + GEOGRAPHY\n",
    "\n",
    "# CORRECTED: Guidance values now strictly match standard Taxonomy keys\n",
    "RULE_BOOK = {\n",
    "    \"defensive_countermeasures\": {\n",
    "        \"triggers\": [\"flare\", \"chaff\", \"countermeasure\", \"decoy\", \"mju-\", \"ale-\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Defensive Systems', Specific: 'Defensive Aid Suite'\"\n",
    "    },\n",
    "    \"radars_and_sensors\": {\n",
    "        \"triggers\": [\"radar\", \"sonar\", \"sensor\", \"an/apy\", \"an/tpy\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Sensors'\"\n",
    "    },\n",
    "    \"ammunition\": {\n",
    "        \"triggers\": [\"cartridge\", \"round\", \"projectile\", \" 5.56\", \" 7.62\", \"ammo\"],\n",
    "        \"guidance\": \"Market Segment: 'Weapon Systems', System Type (General): 'Ammunition'\"\n",
    "    },\n",
    "    \"infrastructure_labs\": {\n",
    "        \"triggers\": [\n",
    "            \"lab hardware\", \n",
    "            \"laboratory\", \n",
    "            \"test bed\", \n",
    "            \"facility\", \n",
    "            \"infrastructure\", \n",
    "            \"test environment\"\n",
    "        ],\n",
    "        # FIXED: \"Infrastructure\" -> \"Infrastructure & Construction\" to match Category 1 below\n",
    "        \"guidance\": \"Market Segment: 'Infrastructure & Construction', System Type (General): 'RDT&E Facilities', System Type (Specific): 'Not Applicable'. Priority Override: Ignore platform mentions (like DDG, F-35) if the deliverable is clearly for a lab or facility.\"\n",
    "    },\n",
    "\n",
    "    # --- Category 1: Construction & Facilities (High Confidence) ---\n",
    "    \"construction_projects\": {\n",
    "        \"triggers\": [\n",
    "            \"construction of\", \"design and construction\", \"paving\", \"dredging\", \n",
    "            \"renovation of\", \"roof repair\", \"hvac\", \"hangar\", \"architect-engineer\"\n",
    "        ],\n",
    "        \"guidance\": {\n",
    "            \"Market Segment\": \"Infrastructure & Construction\",\n",
    "            \"Program Type\": \"Construction/Facilities\",\n",
    "            \"Value Certainty\": \"Confirmed\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # --- Category 2: IT & Software (ESA/ESI/Licensing) ---\n",
    "    \"it_software_licensing\": {\n",
    "        \"triggers\": [\n",
    "            \"microsoft\", \"cisco\", \"software licensing\", \"perpetual licenses\", \n",
    "            \"enterprise software initiative\", \"dod esi\", \"cloud services\", \"aws\", \"azure\"\n",
    "        ],\n",
    "        \"guidance\": {\n",
    "            \"Market Segment\": \"ICT & Cyber\",\n",
    "            \"System Type (General)\": \"Software & Licensing\",\n",
    "            \"Program Type\": \"Procurement (Software)\",\n",
    "            \"System Piloting\": \"Not Applicable\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # --- Category 3: R&D and Engineering Services ---\n",
    "    \"research_development\": {\n",
    "        \"triggers\": [\n",
    "            \"research\", \"developing\", \"studies\", \"analysis\", \"modeling and simulation\",\n",
    "            \"prototyping\", \"sbir\", \"sttr\", \"darpa\", \"demonstration\"\n",
    "        ],\n",
    "        \"guidance\": {\n",
    "            \"Program Type\": \"RDT&E\",\n",
    "            \"Value Certainty\": \"Estimated\" # R&D is often cost-plus and varies\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # --- Category 4: Logistics & Sustainment ---\n",
    "    \"logistics_support\": {\n",
    "        \"triggers\": [\n",
    "            \"contractor logistics support\", \"cls\", \"sustainment\", \"supply chain management\",\n",
    "            \"performance based logistics\", \"depot maintenance\", \"obsolescence\"\n",
    "        ],\n",
    "        \"guidance\": {\n",
    "            \"Program Type\": \"MRO/Support\",\n",
    "            \"System Piloting\": \"Not Applicable\" # The service itself is N/A\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # --- Category 5: Specific Weapon System Overrides ---\n",
    "    \"missile_production\": {\n",
    "        \"triggers\": [\"production of lot\", \"all up round\", \"guidance units\", \"tail caps\"],\n",
    "        \"guidance\": {\n",
    "            \"Program Type\": \"Procurement\",\n",
    "            \"System Piloting\": \"Not Applicable\" # Missiles are not piloted vehicles\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "GEOGRAPHY_MAPPING = {\n",
    "    \"Sub-Saharan Africa\": [\n",
    "        \"Angola\", \"Benin\", \"Botswana\", \"Burkina Faso\", \"Burundi\", \"Cameroon\", \"Cape Verde\",\n",
    "        \"Central African Republic\", \"Chad\", \"Congo, Democratic Republic of\", \"Congo, Republic of\",\n",
    "        \"Djibouti\", \"Equatorial Guinea\", \"Eritrea\", \"Eswatini\", \"Ethiopia\", \"Gabon\", \"Gambia\",\n",
    "        \"Ghana\", \"Guinea\", \"Guinea-Bissau\", \"Ivory Coast\", \"Kenya\", \"Lesotho\", \"Liberia\",\n",
    "        \"Madagascar\", \"Malawi\", \"Mali\", \"Mauritius\", \"Mozambique\", \"Namibia\", \"Niger\",\n",
    "        \"Nigeria\", \"Rwanda\", \"Senegal\", \"Seychelles\", \"Sierra Leone\", \"Somalia\", \"South Africa\",\n",
    "        \"South Sudan\", \"Sudan\", \"Tanzania\", \"Togo\", \"Uganda\", \"Zambia\", \"Zimbabwe\"\n",
    "    ],\n",
    "    \"Asia-Pacific\": [\n",
    "        \"Australia\", \"Brunei\", \"Cambodia\", \"China\", \"Hong Kong\", \"Indonesia\", \"Japan\", \"Laos\",\n",
    "        \"Malaysia\", \"Mongolia\", \"Myanmar\", \"New Zealand\", \"North Korea\", \"Papua New Guinea\",\n",
    "        \"Philippines\", \"Singapore\", \"South Korea\", \"Taiwan\", \"Thailand\", \"Vietnam\"\n",
    "    ],\n",
    "    \"Europe\": [\n",
    "        \"Albania\", \"Austria\", \"Belgium\", \"Bosnia and Herzegovina\", \"Bulgaria\", \"Croatia\", \"Cyprus\",\n",
    "        \"Czech Republic\", \"Denmark\", \"Estonia\", \"Finland\", \"France\", \"Georgia\", \"Germany\", \"Greece\",\n",
    "        \"Hungary\", \"Iceland\", \"Ireland\", \"Italy\", \"Kosovo\", \"Latvia\", \"Lithuania\", \"Luxembourg\",\n",
    "        \"Malta\", \"Montenegro\", \"Netherlands\", \"North Macedonia\", \"Norway\", \"Poland\", \"Portugal\",\n",
    "        \"Romania\", \"Serbia\", \"Slovakia\", \"Slovenia\", \"Spain\", \"Sweden\", \"Switzerland\", \"Turkey\",\n",
    "        \"Ukraine\", \"United Kingdom\"\n",
    "    ],\n",
    "    \"Latin America\": [\n",
    "        \"Argentina\", \"Bahamas\", \"Barbados\", \"Belize\", \"Bolivia\", \"Brazil\", \"Chile\", \"Colombia\",\n",
    "        \"Costa Rica\", \"Cuba\", \"Curacao\", \"Dominican Republic\", \"Ecuador\", \"El Salvador\", \"Guatemala\",\n",
    "        \"Guyana\", \"Haiti\", \"Honduras\", \"Jamaica\", \"Mexico\", \"Nicaragua\", \"Panama\", \"Paraguay\",\n",
    "        \"Peru\", \"Suriname\", \"Trinidad and Tobago\", \"Uruguay\", \"Venezuela\"\n",
    "    ],\n",
    "    \"Middle East and North Africa\": [\n",
    "        \"Algeria\", \"Bahrain\", \"Egypt\", \"Iran\", \"Iraq\", \"Israel\", \"Jordan\", \"Kuwait\", \"Lebanon\",\n",
    "        \"Libya\", \"Mauritania\", \"Morocco\", \"Oman\", \"Qatar\", \"Saudi Arabia\", \"Syria\", \"Tunisia\",\n",
    "        \"United Arab Emirates\", \"Yemen\"\n",
    "    ],\n",
    "    \"North America\": [\"Canada\", \"USA\"],\n",
    "    \"Russia & CIS\": [\n",
    "        \"Armenia\", \"Azerbaijan\", \"Belarus\", \"Kazakhstan\", \"Kyrgyzstan\", \"Moldova\", \"Russia\",\n",
    "        \"Tajikistan\", \"Turkmenistan\", \"Uzbekistan\"\n",
    "    ],\n",
    "    \"South Asia\": [\n",
    "        \"Afghanistan\", \"Bangladesh\", \"India\", \"Maldives\", \"Nepal\", \"Pakistan\", \"Sri Lanka\"\n",
    "    ],\n",
    "    \"Unknown\": [\n",
    "        \"Andorra\", \"Antigua and Barbuda\", \"Bhutan\", \"Comoros\", \"Dominica\", \"Federated States of Micronesia\",\n",
    "        \"Fiji\", \"Grenada\", \"Kiribati\", \"Liechtenstein\", \"Marshall Islands\", \"Monaco\", \"Nauru\", \"Palau\",\n",
    "        \"Palestine\", \"Puerto Rico\", \"Saint Kitts and Nevis\", \"Saint Lucia\", \"Saint Vincent and the Grenadines\",\n",
    "        \"Samoa\", \"San Marino\", \"Sao Tom and Principe\", \"Solomon Islands\", \"Timor-Leste\", \"Tonga\", \"Tuvalu\",\n",
    "        \"Unknown\", \"Vanuatu\", \"Vatican City\", \"Western Sahara\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "ALLOWED_OPERATORS = [\n",
    "    \"Army\",\n",
    "    \"Navy\",\n",
    "    \"Air Force\",\n",
    "    \"Defence Wide\",\n",
    "    \"Ukraine (Assistance)\",\n",
    "    \"Foreign Assistance\",\n",
    "    \"Other\"\n",
    "]\n",
    "\n",
    "PROGRAM_TYPE_ALLOWED = [\n",
    "    \"Procurement\",\n",
    "    \"Training\",\n",
    "    \"MRO/Support\",\n",
    "    \"RDT&E\",\n",
    "    \"Upgrade\",\n",
    "    \"Other Service\"\n",
    "]\n",
    "\n",
    "DESIGNATOR_PATTERNS = [\n",
    "    r\"\\bDDG[-\\s]?\\d+\\b\", r\"\\bCVN[-\\s]?\\d+\\\\b\", r\"\\bSSN[-\\s]?\\d+\\b\",\n",
    "    r\"\\bLCS[-\\s]?\\d+\\b\", r\"\\bLPD[-\\s]?\\d+\\b\", r\"\\bLHA[-\\s]?\\d+\\b\", r\"\\bLHD[-\\s]?\\d+\\b\",\n",
    "    r\"\\bF-\\d+\\b\", r\"\\bB-\\d+\\b\", r\"\\bC-\\d+\\b\", r\"\\bA-\\d+\\b\",\n",
    "    r\"\\bMQ-\\d+\\b\", r\"\\bRQ-\\d+\\b\",\n",
    "    r\"\\bAN\\/[A-Z0-9\\-]+\\b\",\n",
    "    r\"\\b(AIM|AGM|SM|RIM|MIM)-\\d+\\b\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "637b5de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\taxonomy.json\n",
      "Loaded: C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\suppliers.json\n",
      "['22nd Century Tech', 'A&P Group', 'A&R Pacific -Garney Federal', 'AAR Supply Chain Inc.', 'Aardvark Clear', 'AASKI Technology', 'AAVCO', 'Abacus Tech Corp', 'Abdallah Al-Faris', 'Abeking Rasmuss', 'ABG Shipyards', 'ABM Shipyard', 'Absher Construction Co.', 'Abu Dhabi MAR', 'Abu Dhabi SB', 'ACC Construction Co.', 'Accenture', 'Accurate Energetic Systems', 'ACE Technology', 'Aceinfo Solutions', 'ACHILE Consortium', 'Achleitner', 'ACMI', 'ACT-Corp', 'ActioNet', 'ADCOM Systems', 'ADI Group', 'Admiralty Ship', 'Advanced Navigation and Positioning Corp.', 'Advanced Technology International', 'AdvElect Co (AEC)', 'AECOM', 'Aegis Technologies', 'Aeraccess', 'Aero Def Systems', 'Aero Synergie', 'Aero Vodochody', 'Aerodata AG', 'Aerodyca', 'Aerojet Rocketdyne', 'Aeromaritime Grp', 'Aeromot', 'Aeronautical Development Establishment', 'Aeronautics Defense Systems', 'Aerospace Corp', 'Aerostar', 'Aerostar S.A.', 'Aerotree', 'AeroVironment', 'AeroVolga', 'Affigent', 'Africa Automotive Distribution Service', 'Agat', 'AgEagle', 'Agiliti Health', 'AICI-Archirodon JV', 'AIDC', 'AIM Defence', 'Air Center Helicopters', 'Air Tractor', 'Airbus', 'Airbus-Rheinmetall', 'Airborne Tactical Advantage Co.', 'Aircell', 'Aircraft Readiness Alliance', 'AirRobot', 'AIS Engineering', 'Akkodis', 'Albadeey', 'Albatross Industria Aeronautica Ltd.', 'Alcatel-Lucent', 'Alcock Ashdown', 'Alexandria Ship', 'Alion Science', 'Allen-Vanguard', 'Alliant Techsystems Operations', 'Allison Transmission', 'Alpha Marine', 'Alpine Armoring Inc.', 'Altawest', 'Altec Industries', 'ALTECH Services', 'Aleut Federal', 'Alzchem Trostberg', 'AM General', 'Amazon', 'Amentum Services', 'American International Contractors', 'American States Utilities Services', 'American SysCorp', 'American Systems Corp', 'AMESYS', 'AMI Industries', 'AMO ZIL', 'Amper Group', 'AMSL Aero', 'AMTEC Corp.', 'AMX International', 'Amyx Inc', 'AMZ-Kutno', 'Anadolu Shipyard', 'Analytic Services', 'Ananda Shipyard', 'Andrea Systems', 'Andritz Hydro Corp.', 'Anduril Industries', 'Antonov', 'ANVL', 'AOI', 'Apogee Engeineering', 'Applied Mechanics', 'Applied Technology', 'Applied Visual Technology', 'APS', 'Aquacopters', 'Aquila Aerospace', 'Arab Contractors', 'Arcfield Canada', 'Archer Aviation', 'Archer Western', 'Arcturus UAV', 'ARES Shipyard', 'Aresa Shipyard', 'ARGE K-130', 'ARGE NNbS Consortium', 'Argon ST Inc.', 'ARGE DiNa 155', 'ARIS', 'Arma', 'Armenian Air Force Institute', 'American Electronics Warfare Associates', 'American Ordnance', 'Armour International', 'Armoured Car Sys', 'ARMSCOR', 'Armtec Defense Products', 'Arnold Defense and Elec', 'ARO SA', 'Arotech Corp', 'Arquus', 'Array Information', 'Arrow Edge LLC', 'AR-SAT', \"Arsenal d' Marinha\", 'Arsenal JSCO', 'ARTEC', 'ARTEL, Inc', 'ASC Pty Ltd', 'Ascent Flight Training Consotium', 'Ascom Group', 'Aselsan', 'ASENAV', 'Asian ArmoredVeh', 'ASIMAR', 'ASISGUARD', 'Ashot Ashkelon', 'ASL Group', 'Aslemetals Oy', 'ASMAR', 'ASRC Federal', 'ASRY', 'Assurance Tech', 'Assured Information Security Inc.', 'Aster Engineering', 'Astilleros Armon Vigo SA', 'Astilleros Navales', 'ASTIMAR', 'Astronics Test Systems', 'ASTRUM', 'AT&T', 'A-techSYN', 'Atheeb Integraph Saudi Co.', 'Atlas', 'Atlas Elektronik', 'Atlas Group', 'ATR', 'August Schell Enterprises', 'Aurora Flight Sciences', 'Austal Limited', 'Australian Target Systems', 'Autoespar SA', 'Automotive Ind Ltd', 'AUVERLAND', 'Aviation Repair Technologies', 'Aviation Systems Engineering', 'Aviation Training Consulting', 'Avibras', 'AVIC', 'AVNL', 'Avtech Corporation', 'Avtokraz Holding Co', 'AWEIL', 'AWSR Shipping', 'B&F', 'Babcock Group', 'BAE Systems', 'Ball Corporation', 'Baltic Workboats', 'BAMS', 'Bangkok Dock', 'Barrett Comm', 'Basler', 'Bason Shipyard', 'Bath Iron Works', 'Battelle', 'Baud Telecom Co', 'Baykar', 'Bechtel Group', 'Becker Avionics', 'Beechcraft', 'Beherman Demoen', 'Beijing JeepCorp', 'Bell', 'Bell Boeing', 'Bell Textron', 'Bellanca', 'BEML-India', 'Bender Shipbldg', 'Bergen Group', 'Beriev', 'BGI-ASI JV', 'Bharat Dynamics', 'Bharat Elec Ltd', 'Bharat Heavy Electricals', 'Bharat Sanchar', 'Bharati Shipyard', 'Bigelow Family Holdings', 'Bin Jabr Group', 'Bird Aerosystems', 'Birdon', 'Bittium', 'BL Halbert International', 'Black Box Corp', 'Black Micro Corp', 'Black River Systems', 'Blackberry', 'Blackned', 'BlackSky', 'BlindermanPower', 'Blue Air Training', 'Blue Ivy Partners', 'Blue River Consortium', 'Blue Tech Inc', 'Bluebird', 'BlueHalo', 'Boeing', 'Boelwerf Shipyard', 'Bollinger Shipyard', 'Bombardier', 'Booz Allen Hamilton', 'Boresight', 'Boustead DCNS JV', 'Boustead Holding', 'Bowhead', 'Brahmos Ltd', 'BrainGu LLC', 'Bridgestone Aircraft Tire Inc.', 'Britten-Norman', 'Brodosplit Shipyard', 'Brooke Marine', 'Bryan 77 Construction', 'BSVT', 'BSVT-NT', 'BT Group', 'BUAA', 'BwFuhrparkService', 'BWI', 'By Light', 'CACI', 'CAE USA', 'Cairns Slipways', 'Calian', 'Calidus', 'Cambridge Intl Systems', 'Cammell Laird SB', 'Canadair', 'Cantieri Navali', 'Carahsoft Inc.', 'Cardama', 'Carnegie Mellon University', 'CASC', 'CASIC', 'C-Astral Aerospace', 'C-AT', 'Caterpillar', 'CATIC', 'CDO Technologies', 'CDW Corporation', 'CEA Tech Pty Ltd', 'Celier Aviation', 'CENTECH GROUP', 'Cerbair', 'Cessna', 'CFM International', 'CGI', 'Chaiseri Metal & Rubber', 'Changhe', 'Chantier Davie Ship', 'Charles Stark Draper', 'Chas Kurz', 'Chemring', 'Chengdu', 'Chowgule and Company', 'Chrysler Group', 'Chugach Technical Solutions', 'Chung Shan Inst', 'Cianbro', 'CINAR', 'CIO', 'Cirrus Aircraft', 'Cisco Systems', 'Clark Construction Group', 'CM de N (France)', 'CNF Technologies', 'CNIM', 'CNN Navigation', 'Coastal Defense Inc.', 'Cobham', 'Cochin Shipyard', 'CODALTEC', 'Codan', 'Cohort plc', 'Cohu Inc', 'Colby Co. LLC', 'Cole Engineering Services', 'Collins Aerospace', 'COLSA', \"Colt's Manufacturing Co.\", 'Columbia Helicopters Inc.', 'COM DEV International', 'Comlenia', 'Commander Aircraft Corporation', 'Commtact', 'Computacentre', 'CompQsoft', 'Computer World Services', 'COMSOFT', 'ComtechTelecomm', 'Conco Inc.', 'Conlog Group', 'Conoship Intl', 'Conquest USA', 'Consigli Construction', 'Consortium Management Group', 'Conti Federal Services', 'Continental Maritime', 'Core Tech International', 'Core4ce', 'Corporacion De La Industria Aeronautica Colombiana', 'Corvid Technologies', 'COTECMAR', 'CounterTrade', 'CoVant Technologies', 'CPMIEC', 'Credence Mgmnt Sol', 'Creotech', 'Crew Training International', 'CRIST', 'Criterion Solutions', 'CRL Technologies', 'Crowley Maritime', 'CRSA', 'Crystal', 'CSBC Corp., Taiwan', 'CSC', 'Cubic Corporation', 'Cukurova Holding', 'Cummins Inc.', 'Curt Nyberg', 'Curtiss-Wright', 'Cybaero AB', 'Dae Sun Shipbldg', 'Daewoo', 'Daher', 'Daimler AG', 'Dakota Creek', 'Dalnyaya Radio', 'Damen Shipyards', 'DAMEX Shipbldg', 'Danbury Mission Technologies', 'Danish Maritime', 'Danish Yacht', 'Danyard Aalborg', 'Darkhive', 'DARPA', 'Dassault', 'Dassault Dornier', 'Data Link Solutions', 'Data Sys Analysts', 'Datamir', 'DataPath', 'Day & Zimmerman Lone Star', 'Dayton T. Brown Inc.', 'DCCA', 'DCD-DORBYL', 'DCI', 'DCNS Odebrecht', 'DCS Corp.', 'De Havilland Canada', 'Dearsan Shipyard', 'Decisive Analytics', 'Deep Trekker', 'Defense Ind Org', 'Defense Industries Organization Of Iran', 'Defense Solutions', 'Defense Technology Institute', 'Defenture', 'Deftools', 'Delaware Nation Industries Emerging Technologies', 'Dell Inc', 'Deloitte', 'Denel', 'Derecktor Shipyard', 'DESA', 'Design West Technologies', 'Destini Berhad', 'Detyens Shipyard', 'DEW Ltd', 'DFDS Group', 'Diamond Aircraft', 'DIANCA', 'DIDEP', 'Diehl', 'Digital Angel Corp', 'Digital Management', 'Diligent Consulting', 'Divelink Underwater', 'Diversified Tech Svcs', 'DJI', 'DKW Communications', 'DOF ASA', 'Domo Tactical Communications', 'Doosan Group', 'Dornier', 'Draken', 'Draper Labs', 'DRB-HICOM', 'DRDC Canada', 'DRDO', 'Drew Marine USA', 'DRS Network and Imaging Systems', 'DSD Laboratories', 'DSG', 'DSN Corp', 'DSTA', 'Ducommun Inc.', 'DXC Technology', 'Dynamic Systems', 'Dynamics Resrch', 'Dynamit Nobel', \"DynCorp Int'l\", 'Dynetics Technical Solutions', 'Eastern Shipbuilding', 'ECAN', 'ECRN', 'ECS Federal', 'Emcube Inc', 'Edgar Brothers', 'Edge Autonomy', 'EDGE Group', 'Edison Chouest', 'EFR Ltd', 'eGlobalTech', 'EID S.A.', 'Eire Forge and Steel', 'EINSA', 'ELAC Sonar GmbH', 'Elbit Systems', 'ELBO', 'Elebra', 'Electra', 'Electric Boat Corp.', 'Electro Optic Systems', 'Elettronica SpA', 'ELINC', 'EllisDon', 'EM Solutions', 'Embraer', 'EMESEC', 'EMGEPRON', 'Emit Aviation', 'EMPL Austria', 'EMPORDEF', 'EMS Tech', 'EMT', 'EMW', 'ENAER', 'EnerSys Energy Products', 'Engility Corporation', 'Engine Eng Oman', 'ENICS', 'Ensign Bickford', 'Enstrom Helicopter', 'Entrol', 'Environics Oy', 'Environmental Chemical Corp', 'Envision Technology', 'Envisioneering Inc.', 'EONIC', 'EOS', 'EPC2 Consortium', 'EPE', 'EPIIC Consortium', 'Eprius', 'EPS Corporation', 'Epsilon Systems', 'ESSI/SEI', 'Esterline', 'Eurofighter', 'EuroMIDS', 'EUROPAAMS', 'Eurosam', 'Euroshop SA', 'EuroSpike', 'Exail', 'Excellus Solutions', 'Exeter Group', 'Extra', 'FABREQUIPA', 'Fabryka Broni', 'FAdeA', 'Fairchild', 'Famae', 'FAME SAC', 'Fasharkan Ship', 'Fassmer', 'FAW Group', 'FCN Technology Sol', 'FEDITC', 'Federal Contracting', 'FedStore Corp', 'FemmeCompInc', 'Fenix Air Inc.', 'FFA', 'FFA Emmen', 'Firestorm Labs', 'Five Rivers Analytics', 'Fiat Group', 'Fiat-Leonardo', 'Flatter Inc.', 'Fidelity Technologies', 'Fincantieri', 'Fischer Panda', 'Flensburger Fahrzeugbau', 'Flensburger SB', 'Flight Technologies', 'Flightcell Intl', 'FLightSafety', 'FLIR', 'Fluor Marine Propulsion', 'Flyer', 'Flying Legend', 'FMA', 'FN Herstal', 'FNSS', 'Fokker', 'Force 3', 'Ford Motor Co.', 'Forum Energy Technologies', 'FREIRE Shipyard', 'Frequentis GmbH', 'Fresia SPA', 'Frontgrade Technologies', 'Frontier Electronic Systems', 'FSC Lublin Auto', 'FSUE Neptune', 'Fujitsu', 'Furuno Electric', 'G & F Technology', 'G1 Aviation', 'Gabler Maschine', 'GAF', 'Game Composites', 'Garco Construction Inc.', 'Garden Reach SB', 'Garmin', 'Gate Elektronik', 'GC Rieber Shipping', 'GDELS-Mowag', 'GECI', 'Gemelli', 'Genasys', 'GenCorp', 'General Atomics Aeronautical Systems', 'General Dynamics', 'General Electric', 'General Motors', 'Generic Supplier', 'Geneset Powerplants', 'Georgia Tech', 'German Naval Yards', 'GESPI', 'GFE', 'Gibbs & Cox Inc.', 'GIDS', 'Gilbane Federal', 'GKN Aerospace', 'Gladding-Hearn', 'Global GndSpt LLC', 'Global Military Products', 'Global Services LLC', 'Global Tech Res', 'Global Technical Sys', 'Globecomm', 'GMV Aerospace and Defense', 'Goa Shipyard Ltd', 'Golcuk', 'Goodrich Corp.', 'Goodyear Tire and Rubber Co.', 'Grabba', 'Granite-Obayashi', 'Granta Autonomy', 'Grevicom SAC', 'Griffon Corporation', 'Grob', 'GRYFIA', 'GTRI', 'Guimbal', 'Guizhou', 'Gulf Island Marine Fabricators LLC', 'Gulfstream', 'Guyco Inc.', 'GZAS', 'H2O Guam JV', 'Hadean', 'Hai Minh Corporation', 'Haivision Systems Inc.', 'HAL', \"Hanjin Indust'l SB\", 'Hanwha', 'Harbin', 'Harland & Wolff', 'Harper Construction', 'Harris', 'Harwar International Aviation Technology', 'Hatehof', 'Hawaiian Rock Products Corp.', 'HB Utveckling AB', 'HAVELSAN', 'HDT Expeditionary Systems', 'Head/Diaz 2022', 'Heavy Ind. Taxila', 'Heckler & Koch', 'Helibras', 'Helicentro Peru SAC', 'Hellenic Aerospace Industries', 'Hellfire LLC', 'Hensel Phelps Construction', 'Hensoldt', 'HESA', 'HexagonComposite', 'Hinduja Group', 'Hindustan Ship', 'Hi-Q Engineering', 'Hisdesat SA', 'Hitachi', 'Hitachi Kokusai', 'Hitzler Werft', 'HKV', 'Hodges Transportation', 'Honeywell', 'Hong Ha Shipbuilding', 'Hong Leong Group', 'Hongdu', 'Horizon Technologies', 'Hornbeck Offshore Operators', 'Howe and Howe', 'HP', 'HPI Solutions', 'HTX Labs', 'Hughes Comm', 'Humbert Aviation', 'Huneed Tech', 'Huntington Ingalls', 'Huta Stalowa Wola', 'HV Joint Venture', 'Hydra Technologies', 'Hydrema', 'Hyundai', 'Hyundai J Comm', 'IAI', 'IAP Worldwide Svc', 'IAR', 'IBM', 'ICF', 'Icom Inc.', 'ICOMM Tele Ltd.', 'IdeaForge', 'iGOV', 'IHI', 'II-VI Aerospace and Defense', 'Ilyushin', 'ImagineOneT&M', 'IMBEL', 'IMC Group', 'IMCO', 'immixGroup', 'IMMSI SPA', 'IMPSA', 'Imtech Marine', 'INACE', 'Indonesian Aerospace', 'Indra', 'Indrasoft', 'INDUS Technology', 'InDyne', 'InfoReliance Corp', 'Infotron', 'Inmarsat', 'Innocon', 'Innnovaero', 'Insitu', 'Insta ILS', 'Institute of International Education', 'INTA', 'Integ Surv Tech', 'Integral Consulting Services', 'Integral Systems', 'Integrated Convoy', 'Integrated Defense Solutions/Greit', 'Integrated Dynamic', 'Integrated Dynamics', 'Integrated Surveillance and Defense', 'Integration Innovation', 'Intelligent Decisions', 'Intelligent Waves', 'INTELSAT', 'Inter-Coastal Electronics', 'InterCaribbean Airways', 'Intermarine', 'International Business Machines Corp.', 'Intl Shipholding Corp', 'Intman SA', 'Intracom SA', 'INVAP', 'Invariant Corp.', 'INVISIO', 'IOMAX', 'IPS Inc', 'Iridium Satellite', 'Iron Bow Tech', 'Irving Shipbldg', 'Israel Military Industries', 'Israel Shipyards', 'ISRO Internal', 'Istanbul Shipyard', 'Isuzu Motor Co', 'Italcantieri', 'Italtel', 'Italthai Marine', 'ITG', 'ITI Limited', 'ITP Aero', 'ITT', 'Iveco Defence Vehicles', 'Iveco-Oto Melara Consortium', 'IVEMA', 'IWI', 'IXBlue', 'Izhmash Unmanned Systems', 'Jacobs Eng Group', 'Jacobs/B&V JV', 'James Fisher', 'Jankel', 'Japan Marine United', 'Japan Steel Works', 'Javelin JV Team', 'JCB', 'Jelcz-Komponenty', 'Jet Tekno', 'JetZero', 'JF Taylor', 'JHU/APL', 'Joby Aviation', 'Johns Hopkins University', 'Jong Shyn Ship', 'JRC Group', 'JSC Almaz-Antey', 'JSC Kurganmashzavod', 'JSC Tactical Missiles Corp', 'Junghans Microtec', 'Jupiter Wagons Ltd.', 'KADDB', 'Kader', 'KAI', 'Kaman', 'KAMAZ', 'Kamov', 'Kangnam Corp', 'Karachi Shipyard (KSEW)', 'Katmai Management Services', 'Katmerciler', 'KATO Engineering', 'Kawasaki', 'Kay and Associates', 'Kazakhstan Eng', 'RTX', 'Nan Inc', 'R&M Government Services', 'Kazan', 'KBM Kolumna', 'KBP Instrument', 'KBR', 'Kearfott Corp', 'Keppel Corp', 'Kerametal', 'Kership', 'Khan ResLabs', 'Kharkiv Morozov', 'Khulna Shipyard', 'Kiewit-Alberici SIOP MACC', 'King ICT', 'King Technologies', 'KIRINTEC', 'KNDS', 'Knight Sky', 'Knights Armament Co.', 'Koam Engineering', 'Koc Group', 'KomatsuIndustries', 'Kongsberg', 'KONSTRUKTA', 'Kord Technologies', 'Korea Shipbuilding & Offshore Engineering', 'Korte Construction', 'Agency for Defense Development', 'Korean Air Aerospace Division', 'KRAS - India', 'Krasmashzavod', 'Kratos Defense', 'Kronshtadt Group', 'Krauss-Maffei Wegmann', 'Kryukov Car Bldg', 'KT Consulting', 'KVH Industries', 'Kyndryl Finland', 'L3 Technologies', 'Lancair', 'Landmarc', 'Lane Construction Corp.', 'Larsen & Toubro', 'Leidos', 'Leonardo', 'LET', 'Level 3 Comm', 'Life Cycle Engineering', 'LG Group', 'LIG Nex1 Co', 'LinQuest Corp', 'LinTech Pragmatics JV', 'Lite Comms LLC', 'Lockheed Martin', 'Loc Performance Products', 'LOM PRAHA', 'Long Wave Inc', 'Longbow LLC', 'Loral', 'Lumen', 'Lumenier', 'Lung Teh Shipbldg', 'Lurssen Group', 'Lutch', 'Lutsk', 'M Ship Co', 'M1 Support Services', 'M2 Technologies', 'M7 Aerospace', 'Mach Industry Grp', 'Mack Defense', 'Mackay Comm', 'MAESTRAL', 'Maestranza AMSU', 'MAG Aerospace', 'Magellan Aerospace Corporation', 'Mahindra', 'MA Mortenson', 'MAN', 'Manhattan Construction', 'ManTech', 'Mapiex Aviation', 'Marine Alutech Oy', 'Marine Hydraulics', 'Marine United', 'MarineTec', 'Marinette Marine Corp.', 'MARS Shipyards', 'Marsh Aviation', 'Marshall Aerospace', 'MARSS', 'Marsun Company', 'Martifer Group', 'Marvin Land System', 'Mastodon Design', 'Mathtech', 'Maule Air', 'MAV', 'Maxar Technologies', 'Mazagon Dock', 'MBB', 'MBDA', 'McCrone Associates', 'McDermott Marine', 'McLean Contracting', 'MD Helicopters', 'MDA Space', 'MDT Armour', 'MechDB S Africa', 'Mectron', 'MEDAV GmbH', 'Mercedes-Benz', 'Mercer Engineering Research Centre', 'Mercury Systems Inc.', 'Merlin Labs Inc.', 'Merwede', 'Mesko', 'MESIT holding', 'Messer Construction', 'Metal Shark', 'MetalCraft Marine', 'Metalnor SA', 'Meyer Werft', 'Michelin', 'Micro Aviation', 'Microdis Electronics', 'Micropol Fiberoptic AB', 'Microsoft', 'MicroTech', 'Middle East Def', 'Mikal Group', 'Mikoyan', 'Mil', 'MilDef', 'Milenium Veladi Corp.', 'Millenium Space', 'MilSOFT Software', 'MineWolf Systems', 'MISC Berhad', 'Mission1st', 'Mistral Inc.', 'Mitie', 'Mitsubishi', 'Mitsui SB', 'MKEK', 'MMIST', 'MNDI Pacific JV', 'MO Porte-Avions', 'Modern Technology Solutions', 'Moller-Maersk', 'Moog Inc.', 'MorseCorp Inc.', 'Morye Shipyard', 'Motorola Solutions', 'MSI', 'Mudry', 'Mugin', 'MVL USA', 'MW Builders', 'Mythics', 'Nakilat', 'Nakupuna Consulting', 'NAMC', 'Nammo', 'Nan Inc.', 'Nanchang', 'National Academy of Sciences of Belarus', 'National Steel and Shipbuilding', 'Natl Radio Telecom', 'Nautica Nova', 'Naval Gijon Ship', 'Naval Group', 'Naval Shipyard Gdynia', 'Navantia', 'Naviris', 'Navistar International', 'Navmar', 'NCI Info Sys', 'NCSIST', 'ND Defense', 'NDMA', 'NEC', 'Neiva', 'Neorion Group', 'NES Associates', 'NetCentrics Corp', 'Netline Comm', 'New Directions Technologies', 'NewSpace India', 'NEWTEC', 'Nexter', 'NGV Tech', 'NH Industries', 'NICCO Comm', 'Nigerian Dockyard', 'NII STT', 'Niigata Shipbuilding', 'NIMR Auto', 'Nissan', 'nLIGHT Nutronics', 'Noble Supply and Logistics', 'Noblis MSD', 'Nokia', 'Nordic Terrain Solutions', 'Norinco', 'Norma Precision AB', 'Nortel', 'North Sea Boats', 'Northrop Grumman', 'Northstar Aviation', 'Nostromo', 'Novadem', 'NP Aerospace', \"NPO Elektro'ka\", 'NPO Lavochkin', 'NRL', 'NSSL', 'NSWC', 'NT Service', 'NTConcepts', 'nTSI', 'NTT Group', 'NUBURU', 'Nurol Co.', 'NVL Group', 'Oakwell Engineer', 'OBRUM', 'OCEA Group', 'Ocean Shipholdings', 'Ocean Tech Sys', 'Oceaneering', 'OCR Global', 'Odebrecht Group', 'Odyssey Systems Consulting Group', 'OGMA', 'OHB System AG', 'OIP Land Systems', 'Old North Utility Services', 'Olin Winchester', 'Omnisec AG', 'Omnisys', 'Ondas', 'Optics1 Inc.', 'Optima Government Solutions', 'Orbit Technologies', 'Orizzonte Sistemi Navali', 'Orskov Group', 'Oshkosh', 'OSI', 'Otobus Karoseri', 'Otokar', 'OTT Technologies', 'Out of Business', 'Overaasen AS', 'Ovzon', 'PAC', 'Paccar', 'Pacific Aerospace', 'Pacific Rim Constructors', 'Pacifics Propeller International', 'PAE Aviation and Technical Services', 'Pakistan Aeronautical Complex', 'Palantir Technologies', 'Palantir USG', 'Palfinger', 'PAMA-SP', 'PanAmSat', 'Panavia', 'Panha', 'Paramount Group', 'Parker-Hannifin', 'Parrot', 'Parsons Government Services', 'Patria', 'Patriot Contract Svcs', 'PCCI', 'PCM', 'Pearson Engineering', 'Peerless Technologies', 'Pelatron', 'Pelegrin', 'Penman Company', 'Peraton Technology Services', 'Persistent Systems', 'Peterson Bldrs', 'PGSUS', 'PGZ', 'PGZ-PILICA Consortium', 'PGZ-NAREW Consortium', 'Phacil Inc', 'Phoenix Air Group', 'Philadelphia Yard', 'Philippine Telephone', 'Piaggio', 'Pilatus', 'Pindad', 'Piper', 'Pipistrel', 'Piriou Naval Svcs', 'PJ Aviation', 'PKL Services', 'Plath', 'PN Dockyard', 'Polaris Industries', 'Polish Defence Holding', 'Polska Grupa', 'Polskie Zaklady Lotnicze', 'Poly Technologies', 'Polyot', 'Polysentry', 'Pragmatics', 'Presidio', 'Priboy', 'PRIMA Research', 'Proforce Defence', 'Programs Management Analytics and Technologies', 'Propmech Corp', 'Prox Dynamics', 'PS Engineering', 'PSI', 'PSM', 'PT Batam', 'Pt Bhinneka Dwi Persada', 'PT Citra Barahi Shipyard', 'PT Daya Radar Utama', 'PT Dirgantara', 'PT Dumas Shipyard', 'PT Kodja Bahari', 'PT PAL Indonesia', 'PT Palindo', 'PT Republik Defensindo', 'PZL-Mielec', 'PZL-Okƒôcie', 'PZL-Swidnik', 'Q-Techn LLC', 'Qbase, LLC.', 'QED Systems Inc', 'QinetiQ', 'Qioptiq', 'Qods Aviation Industries', 'Quad City Aircraft', 'QualX Corp.', 'Quantum Research', 'Quantum Systems', 'QuantX Labs', 'Qwest', 'R&W Contractors', 'Radiance Tech', 'Radmor SA', 'Rafael', 'RAM Systems', 'RAMET', 'Range Generation Next', 'Rannoch Corp', 'Rauma Marine', 'Ravenswood Solutions Inc.', 'RAVN Group', 'Raytheon Technologies', 'RC Construction', 'Rebellion Defense', 'ReconCraft LLC', 'Record Steel & Construction', 'Red Peak Technical Services', 'Red River Computer', 'Redflex Group', 'Redwire', 'Regional One', 'Reims-Cessna', 'Reiser', 'Reliance Defence', 'Reliance Test and Technology', 'Remdiesel', 'Remontowa Group', 'Remoy Shipping', 'Renk America', 'Repkon USA-Defense', 'Reshetnev Company', 'Ressenig', 'Reunert', 'Revolution Aviation', 'Rh-Alan', 'RHEA Group', 'Rheinmetall', 'Rheinmetall BAE Systems Land', 'Rheinmetall Denel', 'Rheinmetall MAN', 'Ribcraft USA', 'Ricardo PLC', 'Riga Shipyard', 'RIO Design Bureau', 'Rio Santiago Shipyard', 'Rise8 Inc.', 'RiverHawk Group', 'Robertson Fuel Systems', 'Robin Radar Systems', 'Robinson', 'Roboteam', 'Rocket Lab National Security LLC', 'Rockwell Collins', 'Rodman Group', 'Rohde & Schwarz', 'Roke', 'Roketsan', 'Rolls-Royce plc', 'Roman Brasov', 'ROMARM', 'Rosomak', 'Rostec', 'Rothe Development', 'Rovsing A/S', 'RQ Construction', 'RS-UAS', 'RTX', 'RUAG', 'RV Connex', 'RWG Repair & Overhauls USA', 'Saab', 'Sabiex Group', 'Sabre Systems', 'Sabreliner Corporation', 'SAFAT', 'Safe Boats Intl', 'Safran', 'Sagemcom', 'SAIC', 'Sako', 'SAL', 'Salient CRGT Inc', 'Sallyport Global Holdings', 'SAN', 'San Yang', 'Sandia Nat Labs', 'Sanmina-SCI', 'Sanska', 'Santana Motors', 'Santierul Naval', 'SANUKI Shipbldg', 'SAPURA', 'Sapura Thales', 'Sarco Defense', 'Sasebo Heavy Ind', 'Satuma', 'Savox Communications', 'SBIC', 'Scandinavian Avionics', 'Scania', 'Scheepvaart KB', 'Schiebel', 'Schweizer', 'Schutt Industries', 'Science and Engineering Services', 'Science Applications International', 'Scientia Global', 'Scientific Research Corp.', 'Scorpene JV', 'SCOTTY Group', 'SCR', 'SEA', 'Seabird Aviation', 'Sealift Inc', 'Seaspan Marine', 'Seaward Marine Services', 'Second-Hand', 'Sectra Comm Sys', 'SecuriGence', 'Sedef Shipbuilding', 'Seed Innovations', 'Seemann Composites LLC', 'Sefine Shipyard', 'Segue Technologies', 'Selah Shipbuilding', 'SELEX Elsag', 'Selex ES', 'SEMAN Peru', 'SEPECAT', 'SEPI', 'Sepura', 'Serbian State', 'Serco Group plc', 'SES', 'SETEL/REMSCO', 'SGJV', 'Shaanxi', 'Shaanxi Auto Grp', 'Shenyang', 'Shijiazhuang', 'Shin Maywa Industries', 'Shin Yang', 'Shoft Shipyard', 'Short Brothers', 'SI Systems Technologies', 'SICC', 'Sielman S.A.', 'Siemens', 'Sierra Nevada', 'SIG Sauer', 'Sigen Consortium', 'Sikorsky', 'Silent Sentinel', 'Silver Ships Inc.', 'SIMA Peru', 'Singapore Tech.', 'SingTel Group', 'SISDEF', 'Sistemprom', 'Sisu Auto', 'SITAB Consortium', 'SK Holdings', 'Skanska', 'SkyAlyne', 'Skydio', 'Slingsby', 'SmartShooter', 'Smartronix Inc', 'SMS Data Products', 'SNC-Lavalin', 'SNVI', 'Sobeca', 'Soby Vaerft', 'Socarenam', 'Socata', 'Sodexo Management Inc.', 'SOFIS-TRG', 'SOFRAME', 'Sojitz Corporation', 'Soko', 'Solar Industries', 'Solers', 'Solstad Offshore', 'SONAK', 'Sonalysts Inc.', 'Songthu Corporation', 'Southern African Ship', 'Southern Maryland Electric Cooperative', \"Southern Resc'h\", \"Southwest Resc'h\", 'Soviet Tank Plant', 'Sozvezdie JSC', 'SPA', 'Spaceflux', 'SpaceX', 'Spanish Missile Systems', 'Sparton De Leon Springs LLC', 'Special Technology Ctr', 'Spectra', 'Spectrum Comm', 'SpearUAV', 'SpeedCast', 'Sprint', 'SR Telecom', 'SRC', 'SRCTec', 'ST Aerospace', 'StandardAero Inc.', 'Stark Aerospace', 'Stauder Technologies', 'Sterling Computers', 'Steyr', 'STG', 'Stinger ProjectGP', 'STM Group', 'Streit Group', 'STS International', 'STX Corporation', 'Subaru', 'Submarine Manufacturing and Products', 'Sukhoi', 'Sumaria Systems', 'Sumidagawa Ship', 'Sumitomo', 'Summit Aviation', 'Sunair', 'Supacat', 'Superior Govt Sol', 'Superior Marine Ways', 'Surrey Satellite Technology', 'Survey Copter', 'Suzuki Motor Corp', 'SVI Engineering', 'Swan Hunter', 'Swecon', 'Swede Ship', 'SwedishSpace Cp', 'Swiftships SB LLC', 'Symetrics', 'Synectic Group', 'Sypaq Systems', 'Sypris Solutions', 'Sys for Def/GVS', 'System Studies & Simulation', 'Systematic', 'Systems Planning and Analysis', 'T. Mariotti', 'Tactical Air Support Inc.', 'Tactical Engineer', 'TADANO', 'TAE Aerospace', 'TAI', 'Talbert Manufacturing Inc.', 'Target Technologia', 'Taskizak Shipyard', 'TAT Technologies', 'Tata Advanced Systems', 'Tata Group', 'TATRA', 'Taurus Systems', 'Taylor Defense Products', 'TCG', 'TCIL', 'TDW GmbH', 'TDX International', 'Technica Corp', 'Technical Comms', 'Technology Unlim', 'Tecnam', 'TECNOBIT', 'Tekever', 'Telecomm Systems', 'Teledyne', 'Teledyne FLIR', 'Telephonics Corp.', 'Telespazio', 'Teletronics Technology', 'Telia Finland', 'Tellumat', 'Telos Corp', 'Telstra', 'Terberg Group', 'Terma A/S', 'Tesat Spacecom', 'TESCO INDOMARITIM', 'TESLA', 'TESS Defence', 'Tesseract Ventures', 'TETRAEDR', 'Texas A&M', 'Textron', 'Thales', 'Thales Alenia Sp', 'ThalesRaytheon', 'The MIL Corp.', 'The Whiting-Turner Contracting Co.', 'TWPG', 'THEON International', 'ThirdEye', 'Thoma-Sea Ship', 'Thrane & Thrane', 'Threod Systems', 'Thuraya', 'ThyssenKrupp AG', 'Timken Gears & Services', 'Titan Aircraft', 'TKC Global Solutions', 'TNO', 'Tobyhanna Army', 'Tomahawk Robotics', 'Top Aces', 'Toshiba', 'Toyota Motor Corp', 'Trans-Ce Cargo SA', 'Transall', 'Transas Group', 'Transbit', 'Transfield Services', 'TRAX International', 'TrellisWare Tech', 'Trideum Corp', 'Triman Industries', 'Triton Group Hold', 'TRU Simulation Plus Training', 'TRX System', 'TSS Solutions', 'TTC TELEKOM', 'TUBITAK', 'Tupolev', 'Turkish AFF', 'Turner Construction', 'Twin Commander Aircraft', 'TYBRIN', 'Tyco Intl', 'Tyovene', 'Tyto Athene', 'Tyvak International', 'UAV Communications', 'UAV Solutions', 'Uavision Aeronautics', 'UCOCAR', 'Uconsystem', 'UK Docks Marine Services', 'Ukraine Weapons', 'UkraineTank Plant', 'Ukroboronprom', 'Ukrspecsystems', 'Ulijanovsk', 'UltiSat', 'Ultra Dimensions Pvt. Ltd.', 'Ultra Electronics', 'Ultra I&C', 'Ultra Maritime', 'UMM', 'Umoe Group', 'Unicom', 'Unicom Government', 'Unknown', 'Unified Industries', 'UNIMO Technology', 'Unimor Radiocom', 'Unisys', 'Unit Co.', 'United Crane and Excavation Inc.', 'United Electronics', 'United Launch Alliance', 'Univ of Texas', 'Univ of Toronto', 'Universal Shipbldg', \"Unman'dDynamics\", 'Ural Works Civil Aviation', 'Uralvagonzavod', 'URC Systems', 'UROVESA', 'US Marine Inc', 'US Ordnance', 'USCG YARD', 'UTVA', 'UVision Global Aero', 'Valero Marketing and Supply', 'Valiant Global Defense', 'Valkyrie Aero', \"Van's Aircraft\", 'Multiple', 'Vector Scientific', 'Vector Solutions', 'Vectrus Systems Corp.', 'Vega Company', 'Vencore', 'Veritas Capital', 'Verizon', 'Vertex Aerospace', 'Vertex Standard', 'Vestel', 'ViaSat Inc', 'Victory Solutions Inc.', 'VideoRay LLC', 'Viettel Group', 'Vigor Industrial', 'Viking Air', 'Viking Arms', 'Vimpel', 'Vladimir Radio', 'Volkswagen Group', 'Volvo Group', 'Von Wolf', 'VOP 025', 'VOP 026 Sternberk', 'VPK', 'VSE Corp.', 'Vulcanair', 'V2X', 'Walsh Federal LLC', 'Wartsila', 'Watterson Construction Co.', 'WB Electronics', 'WBA Blindajes Alemanes', 'West Sea Shipyard', 'Weststar Group', 'WG Yates and Sons', 'Wildflower Intl', 'Windmill Intl', 'World Wide Tech', 'WULCO Inc.', 'WZE', 'WZM', 'X-Bow', 'Xian', 'Xian ASN Technical Group', 'XTAR', 'Yakovlev', 'Yamaha', 'Yaroslavl Radio', 'Yeonhab Precision', 'Yokohama Yacht', 'Yoland Corp.', 'Yonca-Onuk', 'Yugoimport-SDPR', 'Zala', 'Zamil Offshore', 'Zen Technologies', 'Zenair LTD', 'Zenit Shipyard', 'Zenith', 'Zlin', 'Zwijnenburg', 'ZyXEL Comm', 'Hydroid Inc', 'West Coast JV,', 'University of Dayton Research Institute', 'Saguaro Business Solutions LLC', 'Learjet', 'General Dynamics Electric Boat', 'Ball Aerospace & Technologies', 'TCOM', 'Raytheon Missiles and Defense', 'Lockheed Martin Missile and Fire Control', 'EFW', 'Amherst Systems', 'Lockheed Martin Sippican', 'Hamilton Sundstrand', 'Northrop Grumman Aerospace', 'R.A. Burch Construction', 'Lockheed Martin ‚Äì Rotary and Mission Systems', 'Trace Systems', 'Northrop Grumman Space Systems Sector', 'L-3 Communications Integrated Systems', 'Flint Electric Membership', 'Gray Analytics', 'Lockheed Martin Aeronautics', 'Lockheed Martin Space', 'LTM Inc', 'Alberici-Mortenson', 'Atlantic Signal', 'Haight Bey & Associates', 'Container Research Corp', 'Essex Electro Engineers', 'TechFlow Mission Support', 'Chugach Range and Facilities Services', 'Raytheon Space and Airborne Systems', 'Innovative Scientific Solutions', 'Delavan', 'Covalus', 'Chromalloy Component Services', 'Armorworks Enterprises', 'Metro Machine', 'Alloy Surfaces', 'Valley Tech Systems', 'Keysight Technologies', 'Azure Summit Technology', 'Isometrics', 'Stratascorp', 'Synergy Electric Company', 'Custom Manufacturing & Engineering', 'East West Industries', 'MPR Associates', 'ARCTOS Technology Solutions', 'Enlighten IT Consulting', 'Barrett Firearms', 'Ametek Programmable Power', 'Applied Physical Sciences', 'SupplyCore', 'Federal Resources', 'General Atomics', 'Penguin Computing', 'Mancon', 'Integrated Marine Services', 'Compass Systems', 'DRS Sustainment Systems', 'IronMountain Solutions', 'Ball Aerospace & Technologies', 'Yulista Services', 'SyQwest', 'Advanced Technology Systems', 'Cleveland Construction', 'Canadian Commercial Corp', 'Systima Technologies', 'Ocean Ships', 'Metro Machine Corp', 'ImSAR LLC', 'Systems Application & Technologies', 'Twin Disc', 'Konecranes Nuclear Equipment and Services', 'Progeny Systems', 'WEBCO', 'REEL COH', 'Waterman Transport', 'Western Metal Supply', 'Security Signals', 'Wolverine Tube', 'BC Customs LLC', 'TLD America', 'Crane Technologies Group', 'IDSC Holdings', 'AAR Manufacturing', 'B & D Electric', 'Vector CSP LLC', 'Accurate Machine & Tool Corp', 'Mississippi State University', 'Stephenson Stellar Corp', 'Earthly Dynamics', 'Woolpert Inc', 'Halter Marine', 'Marion Manufacturing', 'FN America LLC', 'CDM Constructors', 'Florida State University - Center for Advanced Power Systems', 'International Marine & Industrial Applicators', 'Zodiac-Poettker HBZ JV II LLC', 'DigiFlight', 'Globe Composite Solutions', 'Meggitt Polymers and Composites', 'Martin-Baker Aircraft', 'United Kingdom Ministry of Defence', 'Ultimate Training Munitions', 'PAS Technologies', 'DCM Clean Air Products', 'Management Services', 'Technology Service Corp', 'General Electric Aviation', 'ACME/RHB', 'Howell Industries', 'Airdyne Aerospace', 'Dominion Energy', 'Bionetics', 'Choctaw Defense Manufacturing', 'Centauri', 'DRS Naval Power Systems', 'Sentry View Systems', 'ERAPSCO', 'AAR Government Services', 'Management Services', 'L3 Doss Aviation', 'AgustaWestland Philadelphia', 'Marvin Engineering', 'Collins Elbit Vision Systems', 'FGS', 'Navistar Defense LLC', 'Voith Hydro', 'Delfasco']\n"
     ]
    }
   ],
   "source": [
    "def chunk_text(text: str, chunk_size: int = 1800, overlap: int = 250) -> List[str]:\n",
    "    \"\"\"\n",
    "    Deterministic chunking: stable + safe + prevents token overflow.\n",
    "    - chunk_size: number of characters per chunk\n",
    "    - overlap: overlapping characters to preserve boundaries\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    if not text.strip():\n",
    "        return []\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    n = len(text)\n",
    "\n",
    "    while start < n:\n",
    "        end = min(start + chunk_size, n)\n",
    "        chunk = text[start:end].strip()\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "\n",
    "        if end >= n:\n",
    "            break\n",
    "\n",
    "        start = max(0, end - overlap)\n",
    "\n",
    "    return chunks\n",
    "#--------------------------------------------\n",
    "\n",
    "def pick_best_non_empty(values: List[str]) -> str:\n",
    "    \"\"\"Return first strong value else empty.\"\"\"\n",
    "    for v in values:\n",
    "        if v and str(v).strip() and str(v).strip().lower() not in [\"unknown\", \"n/a\", \"not applicable\", \"none\"]:\n",
    "            return str(v).strip()\n",
    "    return \"\"\n",
    "#--------------------------------------------\n",
    "\n",
    "def normalize_customer_operator(raw_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Strictly maps input text to the allowed SOP drop-down list.\n",
    "    \"\"\"\n",
    "    if not raw_text:\n",
    "        return \"Unknown\"\n",
    "        \n",
    "    text = str(raw_text).strip().lower()\n",
    "\n",
    "    # 1. Ukraine (Assistance) - High Priority\n",
    "    # Detects: Ukraine Security Assistance Initiative, USAI, or explicitly \"for Ukraine\"\n",
    "    if \"ukraine\" in text:\n",
    "        return \"Ukraine (Assistance)\"\n",
    "\n",
    "    # 2. Foreign Assistance\n",
    "    # Detects: FMS, Foreign Military Sales, Foreign Customers\n",
    "    if any(k in text for k in [\"foreign military sales\", \"fms\", \"foreign customer\", \"foreign government\"]):\n",
    "        return \"Foreign Assistance\"\n",
    "\n",
    "    # 3. Air Force (Includes Space Force per SOP)\n",
    "    if any(k in text for k in [\"space force\", \"ussf\", \"air force\", \"usaf\"]):\n",
    "        return \"Air Force\"\n",
    "\n",
    "    # 4. Navy (Includes Marine Corps as they are Dept of Navy, unless 'Other' is preferred)\n",
    "    # Note: SOP didn't explicitly list Marine Corps. Standard practice maps USMC to Navy. \n",
    "    # If strict separation is needed, move 'marine' to Other. \n",
    "    if any(k in text for k in [\"navy\", \"usn\", \"marine\", \"usmc\", \"naval\"]):\n",
    "        return \"Navy\"\n",
    "\n",
    "    # 5. Army\n",
    "    if any(k in text for k in [\"army\", \"usa \", \"u.s. army\"]): # Space padding to avoid matching \"army\" inside other words\n",
    "        return \"Army\"\n",
    "\n",
    "    # 6. Defence Wide\n",
    "    # Detects: DLA, MDA, DTRA, DARPA, DISA, DCMA\n",
    "    if any(k in text for k in [\"defense logistics\", \"dla\", \"missile defense\", \"mda\", \"defense wide\", \"defence wide\", \"darpa\", \"disa\"]):\n",
    "        return \"Defence Wide\"\n",
    "\n",
    "    # 7. Other\n",
    "    # Detects: Coast Guard (per SOP), DIA, Joint, Special Ops\n",
    "    if any(k in text for k in [\"coast guard\", \"uscg\", \"defense intelligence\", \"dia\", \"joint\", \"special operations\", \"socom\"]):\n",
    "        return \"Other\"\n",
    "\n",
    "    # Fallback to Other if it looks like a government agency but didn't match above\n",
    "    if len(text) > 2:\n",
    "        return \"Other\"\n",
    "\n",
    "    return \"Unknown\"\n",
    "\n",
    "#--------------------------------------------\n",
    "\n",
    "def load_json_file(filename, default_value):\n",
    "    try:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            print(f\"Loaded: {filename}\")\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load {filename} ({e}). Using default.\")\n",
    "        return default_value\n",
    "#--------------------------------------------\n",
    "\n",
    "def normalize_country_name(c: str) -> str:\n",
    "    \"\"\"\n",
    "    Standardizes country names to ensure consistent Region mapping.\n",
    "    \"\"\"\n",
    "    if not c:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    t = str(c).strip().lower()\n",
    "    \n",
    "    # Common variations map\n",
    "    mappings = {\n",
    "        \"usa\": \"USA\", \"us\": \"USA\", \"u.s.\": \"USA\", \"united states\": \"USA\", \n",
    "        \"united states of america\": \"USA\", \"america\": \"USA\",\n",
    "        \"uk\": \"United Kingdom\", \"u.k.\": \"United Kingdom\", \"britain\": \"United Kingdom\", \n",
    "        \"great britain\": \"United Kingdom\", \"england\": \"United Kingdom\",\n",
    "        \"uae\": \"United Arab Emirates\",\n",
    "        \"sk\": \"South Korea\", \"rok\": \"South Korea\", \"republic of korea\": \"South Korea\",\n",
    "        \"prc\": \"China\", \"people's republic of china\": \"China\"\n",
    "    }\n",
    "\n",
    "    if t in mappings:\n",
    "        return mappings[t]\n",
    "        \n",
    "    # Return capitalized version if no match found\n",
    "    return str(c).strip().title()\n",
    "#--------------------------------------------\n",
    "\n",
    "def normalize_program_type(pt: str) -> str:\n",
    "    if not pt:\n",
    "        return \"Other Service\"\n",
    "\n",
    "    t = str(pt).strip().lower()\n",
    "\n",
    "    if any(k in t for k in [\"mro\", \"support\", \"maintenance\", \"repair\", \"overhaul\", \"sustainment\", \"logistics\"]):\n",
    "        return \"MRO/Support\"\n",
    "    if \"training\" in t:\n",
    "        return \"Training\"\n",
    "    if any(k in t for k in [\"rdte\", \"research\", \"development\", \"prototype\", \"test and evaluation\"]):\n",
    "        return \"RDT&E\"\n",
    "    if any(k in t for k in [\"upgrade\", \"modernization\", \"modification\"]):\n",
    "        return \"Upgrade\"\n",
    "    if any(k in t for k in [\"procure\", \"buy\", \"purchase\", \"production\", \"delivery\"]):\n",
    "        return \"Procurement\"\n",
    "\n",
    "    return \"Other Service\"\n",
    "#--------------------------------------------\n",
    "\n",
    "raw_taxonomy = load_json_file(TAXONOMY_PATH, {})\n",
    "TAXONOMY_STR = json.dumps(raw_taxonomy, separators=(\",\", \":\"))\n",
    "\n",
    "SUPPLIER_LIST = load_json_file(SUPPLIERS_PATH, {})\n",
    "print(SUPPLIER_LIST)\n",
    "\n",
    "#--------------------------------------------\n",
    "def get_best_supplier_match(extracted_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Refines the LLM-extracted supplier name against the official SUPPLIER_LIST.\n",
    "    \n",
    "    Logic:\n",
    "    1. Detect \"Multiple\" scenarios (semicolons, ' and ', etc).\n",
    "    2. Check for Exact Matches (Case Insensitive).\n",
    "    3. Check for Substring Matches (e.g., \"Raytheon\" inside \"Raytheon Technologies\").\n",
    "    4. Use Fuzzy Matching for typos (e.g., \"Lokheed Martin\").\n",
    "    \"\"\"\n",
    "    if not extracted_name or str(extracted_name).lower() in [\"unknown\", \"n/a\", \"\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    raw = str(extracted_name).strip()\n",
    "    raw_lower = raw.lower()\n",
    "\n",
    "    # --- RULE 1: DETECT \"MULTIPLE\" ---\n",
    "    # If LLM explicitly said \"Multiple\", keep it.\n",
    "    if raw_lower == \"multiple\":\n",
    "        return \"Multiple\"\n",
    "    \n",
    "    # If the text contains list delimiters, force \"Multiple\"\n",
    "    # Example: \"Boeing; Lockheed Martin; and Raytheon\"\n",
    "    if \";\" in raw or \" and \" in raw_lower or \" vs \" in raw_lower:\n",
    "        return \"Multiple\"\n",
    "\n",
    "    # --- PREPARE LIST ---\n",
    "    # Ensure list is strings and sort by length (longest first to catch specific names before generic ones)\n",
    "    valid_suppliers = sorted([str(s) for s in SUPPLIER_LIST], key=len, reverse=True)\n",
    "\n",
    "    # --- RULE 2: EXACT MATCH (Case Insensitive) ---\n",
    "    for s in valid_suppliers:\n",
    "        if s.lower() == raw_lower:\n",
    "            return s\n",
    "\n",
    "    # --- RULE 3: SUBSTRING MATCH ---\n",
    "    # Case A: Extracted is inside Official (e.g., Extracted \"Raytheon\" -> Official \"Raytheon Co.\")\n",
    "    for s in valid_suppliers:\n",
    "        if len(raw) > 4 and raw_lower in s.lower(): \n",
    "            return s\n",
    "            \n",
    "    # Case B: Official is inside Extracted (e.g., Extracted \"The Boeing Company\" -> Official \"Boeing\")\n",
    "    for s in valid_suppliers:\n",
    "        if len(s) > 4 and s.lower() in raw_lower:\n",
    "            return s\n",
    "\n",
    "    # --- RULE 4: FUZZY MATCH (Typos) ---\n",
    "    # uses difflib to find close matches (cutoff=0.8 means 80% similarity required)\n",
    "    matches = difflib.get_close_matches(raw, valid_suppliers, n=1, cutoff=0.8)\n",
    "    if matches:\n",
    "        return matches[0]\n",
    "\n",
    "    # --- FALLBACK ---\n",
    "    # If no match found in JSON list, return what the LLM found (it might be a new supplier)\n",
    "    return raw\n",
    "\n",
    "#--------------------------------------------\n",
    "\n",
    "def extract_awardee_supplier_strict(paragraph: str) -> Tuple[str, str]:\n",
    "    text = str(paragraph).strip()\n",
    "\n",
    "    patterns = [\n",
    "        r\"^([A-Z][A-Za-z0-9&\\-\\.\\s]+?),\\s+.*?\\s+(?:is|was|has been)\\s+awarded\\b\",\n",
    "        r\"^([A-Z][A-Za-z0-9&\\-\\.\\s]+?),\\s+.*?\\s+received\\s+an?\\s+award\\b\",\n",
    "    ]\n",
    "\n",
    "    for pat in patterns:\n",
    "        m = re.search(pat, text, flags=re.IGNORECASE)\n",
    "        if m:\n",
    "            raw_supplier = m.group(1).strip()\n",
    "            final_supplier = get_best_supplier_match(raw_supplier)\n",
    "            return final_supplier, raw_supplier\n",
    "\n",
    "    return \"Unknown\", \"Not Found\"\n",
    "\n",
    "#--------------------------------------------\n",
    "\n",
    "def calculate_mro_months(start_date_str, end_date_text, program_type):\n",
    "    if program_type != \"MRO/Support\":\n",
    "        return \"Not Applicable\"\n",
    "    try:\n",
    "        if not start_date_str or not end_date_text:\n",
    "            return \"Not Applicable\"\n",
    "\n",
    "        start = pd.to_datetime(start_date_str, dayfirst=True)\n",
    "        end = parser.parse(str(end_date_text), fuzzy=True)\n",
    "\n",
    "        diff = relativedelta(end, start)\n",
    "        total_months = diff.years * 12 + diff.months\n",
    "        return str(max(0, int(total_months)))\n",
    "    except:\n",
    "        return \"Not Applicable\"\n",
    "\n",
    "#--------------------------------------------\n",
    "\n",
    "def get_region_for_country(country_name):\n",
    "    if not country_name or str(country_name).strip().lower() in [\"unknown\", \"n/a\", \"not applicable\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    clean = str(country_name).strip().lower()\n",
    "\n",
    "    if clean in [\"us\", \"usa\", \"u.s.\", \"united states\", \"united states of america\"]:\n",
    "        return \"North America\"\n",
    "    if clean in [\"uk\", \"u.k.\", \"britain\", \"great britain\"]:\n",
    "        return \"Europe\"\n",
    "\n",
    "    for region, countries in GEOGRAPHY_MAPPING.items():\n",
    "        if any(c.lower() == clean for c in countries):\n",
    "            return region\n",
    "\n",
    "    return \"Unknown\"\n",
    "\n",
    "def extract_designators(text: str):\n",
    "    text = str(text)\n",
    "    found = []\n",
    "    for pat in DESIGNATOR_PATTERNS:\n",
    "        found.extend(re.findall(pat, text, flags=re.IGNORECASE))\n",
    "    cleaned = [f.upper().replace(\" \", \"\").replace(\"--\", \"-\") for f in found]\n",
    "    final, seen = [], set()\n",
    "    for x in cleaned:\n",
    "        if x not in seen:\n",
    "            final.append(x)\n",
    "            seen.add(x)\n",
    "    return final\n",
    "\n",
    "\n",
    "def detect_piloting_rule_based(text: str, designators: List[str]) -> str:\n",
    "    t = str(text).lower()\n",
    "\n",
    "    if any(d.startswith((\"MQ-\", \"RQ-\")) for d in designators):\n",
    "        return \"Uncrewed\"\n",
    "    if any(k in t for k in [\"unmanned\", \"uav\", \"drone\", \"autonomous\"]):\n",
    "        return \"Uncrewed\"\n",
    "\n",
    "    if any(d.startswith((\"DDG\", \"CVN\", \"SSN\", \"LCS\", \"LPD\", \"LHA\", \"LHD\")) for d in designators):\n",
    "        return \"Crewed\"\n",
    "    if \"uss \" in t:\n",
    "        return \"Crewed\"\n",
    "\n",
    "    return \"Not Applicable\"\n",
    "\n",
    "def detect_piloting_strict(text: str, designators: List[str], system_type: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Strictly determines System Piloting based on SOP definitions.\n",
    "    \"\"\"\n",
    "    t = str(text).lower()\n",
    "    \n",
    "    # 1. OPTIONAL (Explicitly stated)\n",
    "    if any(k in t for k in [\"optionally manned\", \"optional piloting\", \"manned-unmanned teaming\", \"manned/unmanned\"]):\n",
    "        return \"Optional\"\n",
    "\n",
    "    # 2. UNCREWED (UAVs, Drones, Autonomous)\n",
    "    # Check designators first (Strong signal)\n",
    "    if any(d.startswith((\"MQ-\", \"RQ-\", \"XQ-\", \"MQ-\", \"RQ-\")) for d in designators):\n",
    "        return \"Uncrewed\"\n",
    "    # Check keywords\n",
    "    if any(k in t for k in [\"unmanned\", \"uav\", \"uas\", \"drone\", \"autonomous\", \"remotely piloted\", \"rpa\"]):\n",
    "        return \"Uncrewed\"\n",
    "\n",
    "    # 3. CREWED (Requires human pilot/driver)\n",
    "    # Check designators (Ships, Fighters, Bombers, Transports)\n",
    "    if any(d.startswith((\"DDG\", \"CVN\", \"SSN\", \"LCS\", \"LPD\", \"LHA\", \"LHD\", \"CG-\", \"FFG\")) for d in designators):\n",
    "        return \"Crewed\"\n",
    "    if any(d.startswith((\"F-\", \"B-\", \"C-\", \"A-\", \"AH-\", \"UH-\", \"CH-\", \"MH-\")) and not d.startswith(\"C-UAS\") for d in designators):\n",
    "        return \"Crewed\"\n",
    "    # Check keywords\n",
    "    if any(k in t for k in [\"manned\", \"crew\", \"pilot\", \"cockpit\", \"fighter aircraft\", \"helicopter\", \"submarine\", \"frigate\", \"destroyer\", \"carrier\"]):\n",
    "        # Exclusion: \"unmanned\" check above handles \"unmanned surface vessel\"\n",
    "        if \"unmanned\" not in t: \n",
    "            return \"Crewed\"\n",
    "\n",
    "    # 4. NOT APPLICABLE (Default for non-vehicles)\n",
    "    # If the system is clearly a component, weapon, or support item, it's N/A.\n",
    "    # We use a broad check for \"Not Applicable\" candidates.\n",
    "    na_indicators = [\n",
    "        \"missile\", \"munition\", \"bomb\", \"ammunition\", \"round\", \"cartridge\", \n",
    "        \"radar\", \"sensor\", \"radio\", \"software\", \"training\", \"simulator\", \n",
    "        \"engine\", \"spare part\", \"container\", \"gun\", \"artillery\", \"howitzer\",\n",
    "        \"maintenance\", \"support\", \"logistics\", \"service\"\n",
    "    ]\n",
    "    if any(k in t for k in na_indicators):\n",
    "        return \"Not Applicable\"\n",
    "        \n",
    "    # If specific system type is known from Stage 3 and it's not a platform\n",
    "    if system_type and system_type not in [\"Air Platform\", \"Naval Platform\", \"Land Platform\"]:\n",
    "         return \"Not Applicable\"\n",
    "\n",
    "    # Default fallback if ambiguous (often best to leave blank or N/A, but SOP says N/A for non-driving)\n",
    "    return \"Not Applicable\"\n",
    "\n",
    "\n",
    "def normalize_program_type_improved(pt_llm: str, text: str) -> str:\n",
    "    \"\"\"\n",
    "    Improved Program Type logic with expanded keywords and better conflict resolution.\n",
    "    \"\"\"\n",
    "    text_lower = str(text).lower()\n",
    "    pt_llm = str(pt_llm).strip()\n",
    "\n",
    "    # 1. RDT&E (Strongest signal)\n",
    "    if any(k in text_lower for k in [\"rdt&e\", \"research\", \"development\", \"prototype\", \"demonstration\", \"sbir\", \"sttr\", \"study\", \"design phase\"]):\n",
    "        return \"RDT&E\"\n",
    "\n",
    "    # 2. MRO/Support (Strong signal)\n",
    "    # Added: \"sustainment\", \"cls\" (contractor logistics support), \"pbl\" (performance based logistics)\n",
    "    if any(k in text_lower for k in [\"mro\", \"sustainment\", \"maintenance\", \"repair\", \"overhaul\", \"logistics\", \"support services\", \"cls\", \"technical support\", \"engineering support\"]):\n",
    "        return \"MRO/Support\"\n",
    "\n",
    "    # 3. Upgrade (Specific action on existing)\n",
    "    if any(k in text_lower for k in [\"upgrade\", \"modernization\", \"retrofit\", \"modification\", \"life extension\", \"sle\", \"update\"]):\n",
    "        return \"Upgrade\"\n",
    "\n",
    "    # 4. Procurement (Broadest category, tricky vs Training)\n",
    "    # Explicit \"Procurement\" signals\n",
    "    procure_signals = [\"production\", \"delivery\", \"procurement\", \"acquisition\", \"supply\", \"purchase\", \"manufacture\", \"fabrication\", \"assembly\"]\n",
    "    if any(k in text_lower for k in procure_signals):\n",
    "        return \"Procurement\"\n",
    "\n",
    "    # Training HARDWARE check (Simulators -> Procurement)\n",
    "    if \"training\" in text_lower or \"simulator\" in text_lower:\n",
    "        if any(k in text_lower for k in [\"simulator\", \"device\", \"trainer\", \"hardware\", \"system\", \"kit\", \"aids\"]):\n",
    "             return \"Procurement\"\n",
    "    \n",
    "    # 5. Training (Services Only)\n",
    "    # If it says \"training\" and wasn't caught by Procurement above\n",
    "    if \"training\" in text_lower or \"instruction\" in text_lower:\n",
    "        return \"Training\"\n",
    "\n",
    "    # 6. Other Service (Catch-all for services)\n",
    "    if \"service\" in text_lower or \"labor\" in text_lower:\n",
    "        return \"Other Service\"\n",
    "\n",
    "    # Fallback: Trust LLM if it found a valid category\n",
    "    valid_types = [\"Procurement\", \"Training\", \"MRO/Support\", \"RDT&E\", \"Upgrade\", \"Other Service\"]\n",
    "    if pt_llm in valid_types:\n",
    "        return pt_llm\n",
    "\n",
    "    # Default if truly unknown but looks like a contract award\n",
    "    if \"award\" in text_lower:\n",
    "        return \"Procurement\" # Safe default for \"awarded contract for X\"\n",
    "\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "def calculate_value_certainty_strict(text: str, value_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Highly recommends 'Confirmed'. Only 'Estimated' if explicitly stated.\n",
    "    \"\"\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # 1. Strong \"Confirmed\" Default\n",
    "    # If we extracted a specific non-zero value, assume Confirmed unless proven otherwise.\n",
    "    if not value_str or value_str == \"0.000\":\n",
    "        return \"Estimated\" # No value = Estimated/Unknown\n",
    "\n",
    "    # 2. Explicit Estimation Modifiers (Strict)\n",
    "    # Only tag 'Estimated' if these words explicitly modify the value context.\n",
    "    # \"Ceiling\" implies IDIQ max, which is an estimate of potential spend.\n",
    "    estimation_signals = [\"estimated value\", \"estimated cost\", \"ceiling\", \"maximum value\", \"potential value\", \"not to exceed\"]\n",
    "    \n",
    "    if any(k in text_lower for k in estimation_signals):\n",
    "        return \"Confirmed\"\n",
    "\n",
    "    # 3. IDIQ / BPA (Usually Ceiling = Estimated)\n",
    "    # However, if user wants \"Confirmed\" for the stated face value, we can be lenient.\n",
    "    # SOP says: \"Select Estimated when the value is not confirmed and possibility of future modifications.\"\n",
    "    # IDIQ ceilings ARE limits, not confirmed spend. So we keep them as Estimated.\n",
    "    if \"indefinite-delivery\" in text_lower or \"idiq\" in text_lower:\n",
    "         # Often IDIQs have a \"face value\" (initial task order) vs \"ceiling\".\n",
    "         # If the text says \"awarded a $X task order\", it's confirmed.\n",
    "         # If it says \"awarded a $X IDIQ contract\", it's a ceiling (Estimated).\n",
    "         if \"task order\" in text_lower or \"delivery order\" in text_lower:\n",
    "             return \"Estimated\" \n",
    "         return \"Confirmed\"\n",
    "\n",
    "    return \"Confirmed\"\n",
    "\n",
    "def clean_money_string(val_str):\n",
    "    \"\"\"Converts '$12,345.67' or '12.5' to float 12345.67\"\"\"\n",
    "    try:\n",
    "        # Remove currency symbols, commas, and whitespace\n",
    "        clean = re.sub(r'[^\\d\\.]', '', str(val_str))\n",
    "        return float(clean)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def smart_value_extraction(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Robust extraction: Finds the largest 'Award' value while ignoring 'Obligated' funds.\n",
    "    Returns string in MILLIONS (e.g. \"12.500\")\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    \n",
    "    # 1. Find ALL dollar patterns with their context indices\n",
    "    # Matches: $100, $100.00, $100 million, $100,000\n",
    "    money_pattern = r'\\$([\\d,]+(?:\\.\\d+)?)\\s*(million|billion|b|m)?'\n",
    "    matches = []\n",
    "    \n",
    "    for m in re.finditer(money_pattern, text, re.IGNORECASE):\n",
    "        raw_val = m.group(1)\n",
    "        suffix = m.group(2)\n",
    "        start_idx = m.start()\n",
    "        \n",
    "        # Convert to raw float\n",
    "        val_float = clean_money_string(raw_val)\n",
    "        \n",
    "        # Handle \"million/billion\" word suffix\n",
    "        if suffix:\n",
    "            if suffix.lower().startswith('b'):\n",
    "                val_float *= 1_000_000_000\n",
    "            elif suffix.lower().startswith('m'):\n",
    "                val_float *= 1_000_000\n",
    "        \n",
    "        matches.append({\n",
    "            \"val\": val_float,\n",
    "            \"start\": start_idx,\n",
    "            \"context\": text[max(0, start_idx-50):min(len(text), start_idx+50)].lower() # Look at words around it\n",
    "        })\n",
    "\n",
    "    if not matches:\n",
    "        return \"\"\n",
    "\n",
    "    # 2. Filter out \"Obligated\" amounts (The Trap)\n",
    "    # If the text near the money says \"obligated\", \"fiscal\", \"funds\", it's likely NOT the total award\n",
    "    candidates = []\n",
    "    for m in matches:\n",
    "        # Penalize if \"obligated\" or \"expiration\" is very close\n",
    "        if \"obligated\" in m[\"context\"] or \"expire\" in m[\"context\"]:\n",
    "            continue \n",
    "        candidates.append(m[\"val\"])\n",
    "\n",
    "    # 3. Fallback: If all values were obligated, use the largest one found (better than zero)\n",
    "    if not candidates:\n",
    "        best_val = max(m[\"val\"] for m in matches)\n",
    "    else:\n",
    "        # 4. Selection: Usually the Award Value is the LARGEST non-obligated amount\n",
    "        best_val = max(candidates)\n",
    "\n",
    "    # 5. Convert to Millions string\n",
    "    return f\"{best_val / 1_000_000:.3f}\"\n",
    "\n",
    "def detect_quantity_should_be_na(paragraph: str) -> bool:\n",
    "    \"\"\"\n",
    "    If paragraph contains many item quantities -> treat Quantity as Not Applicable.\n",
    "    Example3: 483 missiles, 82 missiles, 156 missiles, 198 containers...\n",
    "    That is NOT a single contract-level quantity.\n",
    "    \"\"\"\n",
    "    t = str(paragraph)\n",
    "\n",
    "    # Count numeric patterns that look like item quantities\n",
    "    qty_candidates = re.findall(r\"\\b(\\d{1,5})\\b\", t)\n",
    "\n",
    "    # If too many numbers appear, it's almost always a line-item contract\n",
    "    if len(qty_candidates) >= 12:\n",
    "        return True\n",
    "\n",
    "    # Specific strong markers for line-item heavy paragraphs\n",
    "    if any(k in t.lower() for k in [\"as follows:\", \"lot\", \"containers\", \"spare\", \"tail cap\", \"guidance unit\"]):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def normalize_currency(cur: str) -> str:\n",
    "    if not cur:\n",
    "        return \"USD$\"\n",
    "    c = str(cur).strip().upper()\n",
    "    if c in [\"USD\", \"US$\", \"$\", \"US DOLLAR\", \"DOLLARS\"]:\n",
    "        return \"USD$\"\n",
    "    return c\n",
    "\n",
    "def word_to_int(token: str) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Converts word numbers to int:\n",
    "    eight -> 8, twenty one -> 21\n",
    "\n",
    "    Supports 0-99 safely.\n",
    "    Returns None if not a valid word-number.\n",
    "    \"\"\"\n",
    "    if not token:\n",
    "        return None\n",
    "\n",
    "    t = str(token).strip().lower()\n",
    "    t = t.replace(\"-\", \" \")\n",
    "    parts = [p for p in t.split() if p]\n",
    "\n",
    "    ones = {\n",
    "        \"zero\": 0, \"one\": 1, \"two\": 2, \"three\": 3, \"four\": 4, \"five\": 5,\n",
    "        \"six\": 6, \"seven\": 7, \"eight\": 8, \"nine\": 9, \"ten\": 10,\n",
    "        \"eleven\": 11, \"twelve\": 12, \"thirteen\": 13, \"fourteen\": 14,\n",
    "        \"fifteen\": 15, \"sixteen\": 16, \"seventeen\": 17, \"eighteen\": 18,\n",
    "        \"nineteen\": 19\n",
    "    }\n",
    "\n",
    "    tens = {\n",
    "        \"twenty\": 20, \"thirty\": 30, \"forty\": 40, \"fifty\": 50,\n",
    "        \"sixty\": 60, \"seventy\": 70, \"eighty\": 80, \"ninety\": 90\n",
    "    }\n",
    "\n",
    "    # single word\n",
    "    if len(parts) == 1:\n",
    "        if parts[0] in ones:\n",
    "            return ones[parts[0]]\n",
    "        if parts[0] in tens:\n",
    "            return tens[parts[0]]\n",
    "        return None\n",
    "\n",
    "    # two words: \"twenty one\"\n",
    "    if len(parts) == 2:\n",
    "        if parts[0] in tens and parts[1] in ones:\n",
    "            return tens[parts[0]] + ones[parts[1]]\n",
    "        return None\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_qty_token(qty_token: str) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Converts numeric token or word-number token into int.\n",
    "    \"\"\"\n",
    "    if qty_token is None:\n",
    "        return None\n",
    "    s = str(qty_token).strip().lower()\n",
    "\n",
    "    # numeric\n",
    "    if re.fullmatch(r\"\\d+\", s):\n",
    "        return int(s)\n",
    "\n",
    "    # word-number\n",
    "    return word_to_int(s)\n",
    "\n",
    "\n",
    "def parse_fms_countries(paragraph: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract FMS customer countries list.\n",
    "    Example: 'governments of Australia, Bahrain, Belgium...'\n",
    "    \"\"\"\n",
    "    text = str(paragraph)\n",
    "\n",
    "    m = re.search(\n",
    "        r\"governments of (.+?)(?:\\.\\s| Work will be performed| Fiscal| This contract|$)\",\n",
    "        text,\n",
    "        flags=re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "    if not m:\n",
    "        return []\n",
    "\n",
    "    block = m.group(1)\n",
    "    raw = re.split(r\",|\\band\\b\", block)\n",
    "\n",
    "    countries = []\n",
    "    for c in raw:\n",
    "        c = c.strip()\n",
    "        if 2 < len(c) <= 40:\n",
    "            countries.append(c)\n",
    "\n",
    "    final, seen = [], set()\n",
    "    for c in countries:\n",
    "        if c.lower() not in seen:\n",
    "            final.append(c)\n",
    "            seen.add(c.lower())\n",
    "\n",
    "    return final\n",
    "\n",
    "\n",
    "def detect_multiple_supplier_award(paragraph: str) -> bool:\n",
    "    \"\"\"\n",
    "    Detect Example2 pattern:\n",
    "    Many suppliers listed with semicolons + \"are awarded ...\"\n",
    "    \"\"\"\n",
    "    t = str(paragraph).strip()\n",
    "    if \";\" in t and re.search(r\"\\bare awarded\\b\", t, flags=re.IGNORECASE):\n",
    "        if re.search(r\"\\([A-Z0-9]{6,}\\)\", t):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def parse_line_item_operator_allocations(paragraph: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Extract line-item splits like:\n",
    "\n",
    "    '483 AIM-9X ... missiles (212 for the Navy, 187 for the Air Force and 84 for FMS customers);'\n",
    "    '82 AIM-9X ... missiles (eight for the Navy, eight for the Air Force and 66 for FMS customers);'\n",
    "\n",
    "    Output:\n",
    "      [\n",
    "        {\"item_name\": \"...\", \"operator\":\"Navy\", \"quantity\":\"212\", \"g2g_b2g\":\"B2G\"},\n",
    "        {\"item_name\": \"...\", \"operator\":\"Air Force\", \"quantity\":\"187\", \"g2g_b2g\":\"B2G\"},\n",
    "        {\"item_name\": \"...\", \"operator\":\"Foreign Assistance\", \"quantity\":\"84\", \"g2g_b2g\":\"G2G\"}\n",
    "      ]\n",
    "    \"\"\"\n",
    "    text = str(paragraph)\n",
    "\n",
    "    # This finds: <total qty> <item desc> ( <allocation block> )\n",
    "    # Example: 483 AIM-9X ... missiles (212 for the Navy, 187 for the Air Force and 84 for FMS customers)\n",
    "    item_pattern = r\"\\b(\\d+)\\s+(.+?)\\s*\\(([^)]*for[^)]*)\\)\"\n",
    "    matches = re.findall(item_pattern, text, flags=re.IGNORECASE)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for total_qty, item_desc, alloc_block in matches:\n",
    "        item_desc_clean = re.sub(r\"\\s+\", \" \", item_desc).strip(\" ;,. -\")\n",
    "\n",
    "        # --- BRANCH allocations (digit or word-number)\n",
    "        branch_pattern = r\"\\b(\\d+|[A-Za-z\\-]+)\\s+for\\s+the\\s+(Navy|Air Force|Army|Marine Corps|Space Force|Coast Guard|Defense Logistics Agency|Missile Defense Agency)\\b\"\n",
    "        for qty_token, op_raw in re.findall(branch_pattern, alloc_block, flags=re.IGNORECASE):\n",
    "            qty_val = parse_qty_token(qty_token)\n",
    "            if qty_val is None:\n",
    "                continue\n",
    "            normalized_op = normalize_customer_operator(op_raw)       \n",
    "            results.append({\n",
    "                \"item_name\": item_desc_clean,\n",
    "                \"operator\": normalized_op,\n",
    "                \"quantity\": str(qty_val),\n",
    "                \"g2g_b2g\": \"B2G\"\n",
    "            })\n",
    "\n",
    "        # --- FMS allocations (digit or word-number)\n",
    "        fms_pattern = r\"\\b(\\d+|[A-Za-z\\-]+)\\s+for\\s+(?:Foreign Military Sales\\s*\\(FMS\\)\\s*customers|Foreign Military Sales\\s*customers|FMS\\s*customers|FMS)\\b\"\n",
    "        for qty_token in re.findall(fms_pattern, alloc_block, flags=re.IGNORECASE):\n",
    "            qty_val = parse_qty_token(qty_token)\n",
    "            if qty_val is None:\n",
    "                continue\n",
    "\n",
    "            results.append({\n",
    "                \"item_name\": item_desc_clean,\n",
    "                \"operator\": \"Foreign Assistance\",\n",
    "                \"quantity\": str(qty_val),\n",
    "                \"g2g_b2g\": \"G2G\"\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def split_rows_engine(base_row: dict, paragraph: str) -> List[dict]:\n",
    "    \"\"\"\n",
    "    FINAL STAGE5 Split Engine (Your required behavior)\n",
    "\n",
    "    SPLITS:\n",
    "    1) Multi-supplier award => Supplier Name = Multiple (NO supplier split)\n",
    "    2) Line-item + operator allocation split (Navy/AirForce/FMS)\n",
    "    3) FMS country split ONLY for G2G rows\n",
    "\n",
    "    Only split fields are modified, rest remain unchanged.\n",
    "    \"\"\"\n",
    "    paragraph = str(paragraph).strip()\n",
    "    row = base_row.copy()\n",
    "\n",
    "    split_reasons = []\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 1) MULTIPLE SUPPLIER AWARD (Example2)\n",
    "    # ------------------------------------------------------------------\n",
    "    if detect_multiple_supplier_award(paragraph):\n",
    "        row[\"Supplier Name\"] = \"Multiple\"\n",
    "        row[\"Supplier Name Evidence\"] = \"Multiple Suppliers (Detected)\"\n",
    "        row[\"Split Flag\"] = \"No\"\n",
    "        row[\"Split Reason\"] = \"Multiple supplier award detected (no supplier split)\"\n",
    "        return [row]\n",
    "\n",
    "    rows = [row]\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 2) LINE-ITEM + OPERATOR SPLIT (Your expected output)\n",
    "    # ------------------------------------------------------------------\n",
    "    item_allocs = parse_line_item_operator_allocations(paragraph)\n",
    "\n",
    "    if item_allocs:\n",
    "        split_reasons.append(\"Line-item operator allocation split\")\n",
    "\n",
    "        new_rows = []\n",
    "        for r in rows:\n",
    "            for alloc in item_allocs:\n",
    "                rr = r.copy()\n",
    "\n",
    "                # Only split fields change\n",
    "                rr[\"Customer Operator\"] = alloc[\"operator\"]\n",
    "                rr[\"Quantity\"] = alloc[\"quantity\"]\n",
    "                rr[\"G2G/B2G\"] = alloc[\"g2g_b2g\"]\n",
    "\n",
    "                # Make system labels reflect line-item name (matches your expected output)\n",
    "                rr[\"System Name (General)\"] = alloc[\"item_name\"]\n",
    "                rr[\"System Name (Specific)\"] = alloc[\"item_name\"]\n",
    "\n",
    "                new_rows.append(rr)\n",
    "\n",
    "        rows = new_rows\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 3) FMS COUNTRY SPLIT (ONLY for G2G rows)\n",
    "    # ------------------------------------------------------------------\n",
    "    fms_countries = parse_fms_countries(paragraph)\n",
    "    if fms_countries:\n",
    "        split_reasons.append(\"FMS country split\")\n",
    "\n",
    "        final_rows = []\n",
    "        for r in rows:\n",
    "            is_g2g = str(r.get(\"G2G/B2G\", \"\")).strip().upper() == \"G2G\"\n",
    "            is_fms_operator = \"foreign\" in str(r.get(\"Customer Operator\", \"\")).lower()\n",
    "\n",
    "            if is_g2g or is_fms_operator:\n",
    "                for c in fms_countries:\n",
    "                    rr = r.copy()\n",
    "                    rr[\"Customer Country\"] = normalize_country_name(c)\n",
    "                    rr[\"Customer Region\"] = get_region_for_country(rr[\"Customer Country\"])\n",
    "                    final_rows.append(rr)\n",
    "            else:\n",
    "                final_rows.append(r)\n",
    "\n",
    "        rows = final_rows\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Final flags\n",
    "    # ------------------------------------------------------------------\n",
    "    if split_reasons:\n",
    "        reason = \" | \".join(split_reasons)\n",
    "        for r in rows:\n",
    "            r[\"Split Flag\"] = \"Yes\"\n",
    "            r[\"Split Reason\"] = reason\n",
    "    else:\n",
    "        for r in rows:\n",
    "            r[\"Split Flag\"] = \"No\"\n",
    "            r[\"Split Reason\"] = \"No split condition found\"\n",
    "\n",
    "    return rows\n",
    "\n",
    "## LLM CALL HELPER (OpenRouter Safe Wrapper)\n",
    "def call_llm_json(system_prompt: str, user_prompt: str, max_tokens: int):\n",
    "    \"\"\"\n",
    "    Safe OpenRouter call wrapper\n",
    "    - JSON response enforced\n",
    "    - max_tokens enforced\n",
    "    \"\"\"\n",
    "    completion = client.chat.completions.create(\n",
    "        model=OPENROUTER_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=max_tokens,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    return json.loads(completion.choices[0].message.content)\n",
    "\n",
    "# 11) EXCEL HIGHLIGHTING FEATURE\n",
    "\n",
    "def highlight_evidence_reason_columns(excel_path: str):\n",
    "    wb = load_workbook(excel_path)\n",
    "\n",
    "    # Always ensure at least one visible sheet\n",
    "    ws = wb.active\n",
    "    ws.sheet_state = \"visible\"\n",
    "\n",
    "    header = [cell.value for cell in ws[1]]\n",
    "\n",
    "    evidence_cols = []\n",
    "    reason_cols = []\n",
    "\n",
    "    for idx, col_name in enumerate(header, start=1):\n",
    "        if isinstance(col_name, str) and \"Evidence\" in col_name:\n",
    "            evidence_cols.append(idx)\n",
    "        if isinstance(col_name, str) and \"Reason\" in col_name:\n",
    "            reason_cols.append(idx)\n",
    "\n",
    "    evidence_fill = PatternFill(start_color=\"FFF2CC\", end_color=\"FFF2CC\", fill_type=\"solid\")\n",
    "    reason_fill = PatternFill(start_color=\"D9E1F2\", end_color=\"D9E1F2\", fill_type=\"solid\")\n",
    "    header_font = Font(bold=True)\n",
    "\n",
    "    for col_idx in evidence_cols:\n",
    "        ws.cell(row=1, column=col_idx).fill = evidence_fill\n",
    "        ws.cell(row=1, column=col_idx).font = header_font\n",
    "\n",
    "    for col_idx in reason_cols:\n",
    "        ws.cell(row=1, column=col_idx).fill = reason_fill\n",
    "        ws.cell(row=1, column=col_idx).font = header_font\n",
    "\n",
    "    for row in range(2, ws.max_row + 1):\n",
    "        for col_idx in evidence_cols:\n",
    "            ws.cell(row=row, column=col_idx).fill = evidence_fill\n",
    "        for col_idx in reason_cols:\n",
    "            ws.cell(row=row, column=col_idx).fill = reason_fill\n",
    "\n",
    "    wb.save(excel_path)\n",
    "    print(\"Evidence + Reason columns highlighted successfully.\")\n",
    "\n",
    "def apply_rule_book(text: str):\n",
    "    \"\"\"\n",
    "    Scans text against CUSTOM_RULE_BOOK triggers.\n",
    "    Returns the guidance dict if a match is found, else None.\n",
    "    \"\"\"\n",
    "    text_lower = text.lower()\n",
    "    best_match = None\n",
    "    \n",
    "    for rule_name, rule_data in RULE_BOOK.items():\n",
    "        for trigger in rule_data[\"triggers\"]:\n",
    "            if trigger in text_lower:\n",
    "                # If we find a trigger, we return the guidance\n",
    "                # You can add logic here to prioritize longer triggers\n",
    "                return rule_data[\"guidance\"]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1facc0a",
   "metadata": {},
   "source": [
    "**Using Knowledgebase to support my extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46ef5599",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RAG RETRIEVER (FAISS + METADATA)\n",
    "class SystemKBRetriever:\n",
    "    def __init__(self, kb_dir: str, embed_model: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self.kb_dir = kb_dir\n",
    "        self.embed_model = embed_model\n",
    "\n",
    "        index_path = os.path.join(kb_dir, \"system_kb.faiss\")\n",
    "        meta_path = os.path.join(kb_dir, \"system_kb_meta.pkl\")\n",
    "\n",
    "        if not os.path.exists(index_path) or not os.path.exists(meta_path):\n",
    "            raise FileNotFoundError(\n",
    "                f\"KB files not found in: {kb_dir}\\n\"\n",
    "                f\"Expected:\\n- {index_path}\\n- {meta_path}\\n\\n\"\n",
    "                f\"Build KB first using your KB builder script.\"\n",
    "            )\n",
    "        print(f\"Loading FAISS Index: {index_path}\")\n",
    "        self.index = faiss.read_index(index_path)\n",
    "\n",
    "        print(f\"Loading KB Metadata: {meta_path}\")\n",
    "        with open(meta_path, \"rb\") as f:\n",
    "            self.meta = pickle.load(f)\n",
    "\n",
    "        print(f\"KB Loaded rows: {len(self.meta)}\")\n",
    "\n",
    "        self.embedder = None\n",
    "\n",
    "    def _lazy_load_embedder(self):\n",
    "        if self.embedder is None:\n",
    "            from sentence_transformers import SentenceTransformer\n",
    "            self.embedder = SentenceTransformer(self.embed_model)\n",
    "\n",
    "    def retrieve(self, query_text: str, top_k: int = 3):\n",
    "        import numpy as np\n",
    "        query_text = str(query_text).strip()\n",
    "        if not query_text:\n",
    "            return []\n",
    "\n",
    "        self._lazy_load_embedder()\n",
    "\n",
    "        q_emb = self.embedder.encode([query_text], normalize_embeddings=True).astype(\"float32\")\n",
    "        scores, idxs = self.index.search(q_emb, top_k)\n",
    "\n",
    "        results = []\n",
    "        for score, idx in zip(scores[0], idxs[0]):\n",
    "            if idx < 0:\n",
    "                continue\n",
    "            results.append({\"score\": float(score), \"meta\": self.meta[idx]})\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2df4e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS Index: C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\system_kb_store\\system_kb.faiss\n",
      "Loading KB Metadata: C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\system_kb_store\\system_kb_meta.pkl\n",
      "KB Loaded rows: 600\n"
     ]
    }
   ],
   "source": [
    "retriever = SystemKBRetriever(kb_dir=RAG_KB_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8198e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_str(x, default=\"\"):\n",
    "    \"\"\"\n",
    "    Safely converts input to string, returning default if None or empty/whitespace.\n",
    "    \"\"\"\n",
    "    if x is None:\n",
    "        return default\n",
    "    s = str(x).strip()\n",
    "    return s if s else default\n",
    "\n",
    "def rag_best_hit(paragraph: str, top_k: int = 3):\n",
    "    \"\"\"\n",
    "    Retrieves the single best match from the Knowledge Base (FAISS).\n",
    "    Returns: (hit_object, score, metadata_dict)\n",
    "    \"\"\"\n",
    "    # Ensure the global retriever is loaded\n",
    "    if 'retriever' not in globals():\n",
    "        print(\"Warning: 'retriever' is not defined. Returning empty hit.\")\n",
    "        return None, 0.0, {}\n",
    "\n",
    "    hits = retriever.retrieve(paragraph, top_k=top_k)\n",
    "    \n",
    "    if not hits:\n",
    "        return None, 0.0, {}\n",
    "        \n",
    "    best = hits[0]\n",
    "    return best, float(best.get(\"score\", 0.0)), best.get(\"meta\", {})\n",
    "\n",
    "#-------------------------------------------\n",
    "RAG_STRONG_THRESHOLD = 0.78   # if >= this, trust KB fully\n",
    "RAG_MEDIUM_THRESHOLD = 0.70   # if >= this, use KB as strong hint\n",
    "\n",
    "def normalize_country_name(c: str) -> str:\n",
    "    if not c:\n",
    "        return \"Unknown\"\n",
    "    t = str(c).strip().lower()\n",
    "    if t in [\"united states\", \"united states of america\", \"us\", \"u.s.\", \"usa\", \"america\"]:\n",
    "        return \"USA\"\n",
    "    if t in [\"united kingdom\", \"uk\", \"u.k.\", \"britain\", \"great britain\"]:\n",
    "        return \"UK\"\n",
    "    return str(c).strip()\n",
    "\n",
    "def rag_best_hit(paragraph: str, top_k: int = 3):\n",
    "    hits = retriever.retrieve(paragraph, top_k=top_k)\n",
    "    if not hits:\n",
    "        return None, 0.0, {}\n",
    "    best = hits[0]\n",
    "    return best, float(best.get(\"score\", 0.0)), best.get(\"meta\", {})\n",
    "\n",
    "def safe_str(x, default=\"\"):\n",
    "    if x is None:\n",
    "        return default\n",
    "    s = str(x).strip()\n",
    "    return s if s else default\n",
    "\n",
    "def normalize_program_type_strict(pt_llm: str, text: str) -> str:\n",
    "    \"\"\"\n",
    "    Decides Program Type based on strict SOP hierarchy.\n",
    "    Priority: RDT&E > MRO > Upgrade > Procurement (Hardware/Simulators) > Training (Services).\n",
    "    \"\"\"\n",
    "    text_lower = str(text).lower()\n",
    "    pt_llm = str(pt_llm).strip()\n",
    "\n",
    "    # 1. RDT&E (Highest Priority)\n",
    "    # Detects: Prototypes, Research, Development, SBIR\n",
    "    if any(k in text_lower for k in [\"rdt&e\", \"research\", \"development\", \"prototype\", \"sbir\", \"demonstration\"]):\n",
    "        return \"RDT&E\"\n",
    "\n",
    "    # 2. MRO/Support\n",
    "    # Detects: Sustainment, Maintenance, Logistics, Repair, Overhaul\n",
    "    if any(k in text_lower for k in [\"mro\", \"sustainment\", \"maintenance\", \"logistics\", \"repair\", \"overhaul\", \"support services\"]):\n",
    "        return \"MRO/Support\"\n",
    "\n",
    "    # 3. Upgrade\n",
    "    # Detects: Modernization, Retrofit, Modification of existing platforms\n",
    "    if any(k in text_lower for k in [\"upgrade\", \"modernization\", \"retrofit\", \"modification\", \"life extension\"]):\n",
    "        return \"Upgrade\"\n",
    "\n",
    "    # 4. Training (Strict Split)\n",
    "    # Rule: Training SERVICES = Training.\n",
    "    # Rule: Training HARDWARE (Simulators, Aircraft) = Procurement.\n",
    "    if \"training\" in text_lower or \"training\" in pt_llm.lower():\n",
    "        # Check for hardware indicators\n",
    "        if any(k in text_lower for k in [\"simulator\", \"device\", \"trainer aircraft\", \"hardware\", \"system\", \"kit\"]):\n",
    "            return \"Procurement\"\n",
    "        return \"Training\"\n",
    "\n",
    "    # 5. Procurement\n",
    "    # Detects: Production, Delivery, Acquisition, Construction\n",
    "    if any(k in text_lower for k in [\"production\", \"delivery\", \"procurement\", \"acquisition\", \"supply\", \"purchase\"]):\n",
    "        return \"Procurement\"\n",
    "\n",
    "    # Fallback to LLM's choice if valid, otherwise Other\n",
    "    if pt_llm in [\"Procurement\", \"Training\", \"MRO/Support\", \"RDT&E\", \"Upgrade\", \"Other Service\"]:\n",
    "        return pt_llm\n",
    "\n",
    "    return \"Other Service\"\n",
    "\n",
    "\n",
    "def calculate_value_certainty(text: str, value_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Determines if value is 'Confirmed' or 'Estimated'.\n",
    "    \"\"\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # 1. Keywords indicating estimation/limit\n",
    "    if any(k in text_lower for k in [\"ceiling\", \"maximum\", \"estimated\", \"potential\", \"not to exceed\", \"idiq\", \"bpa\", \"blanket purchase agreement\"]):\n",
    "        return \"Estimated\"\n",
    "\n",
    "    # 2. Shared/Split Value Indicators\n",
    "    # If multiple companies share a pot, the value is Estimated for that specific row\n",
    "    if any(k in text_lower for k in [\"shared\", \"competing\", \"each awarded\", \"multiple award\", \"aggregate\"]):\n",
    "        return \"Estimated\"\n",
    "\n",
    "    # 3. If no value was extracted, it can't be confirmed\n",
    "    if not value_str or value_str == \"0.000\":\n",
    "        return \"Estimated\"\n",
    "\n",
    "    return \"Confirmed\"\n",
    "\n",
    "\n",
    "def calculate_usd_value(val_million_str: str, currency: str) -> str:\n",
    "    \"\"\"\n",
    "    Populates 'Value (USD$ Million)'.\n",
    "    Assuming 1:1 if already USD, otherwise leaves blank or requires conversion logic.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        val = float(val_million_str)\n",
    "        if val == 0:\n",
    "            return \"\"\n",
    "            \n",
    "        # If Currency is USD, copy the value\n",
    "        if \"USD\" in currency.upper() or \"$\" in currency:\n",
    "            return f\"{val:.3f}\"\n",
    "            \n",
    "        # (Optional) Add simplistic conversion if needed, e.g., GBP -> 1.25 * Val\n",
    "        # For now, we return extraction.\n",
    "        return f\"{val:.3f}\"\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdb994b",
   "metadata": {},
   "source": [
    "## AGENTS / TOOLS (Chunk-wise extraction + Merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06857a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AGENTS / TOOLS (Chunk-wise extraction + Merge)\n",
    "\n",
    "# Stage 1: SOURCING EXTRACTOR\n",
    "\n",
    "class SourcingInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    url: str = Field(description=\"Source URL of the contract announcement/news.\")\n",
    "    date: str = Field(description=\"Contract date in Excel (string).\")\n",
    "\n",
    "@tool(\"sourcing_extractor\")\n",
    "def sourcing_extractor(paragraph: str, url: str, date: str):\n",
    "    \"\"\"\n",
    "    Stage 1: SOURCING EXTRACTOR\n",
    "\n",
    "    Purpose:\n",
    "    - Creates the base skeleton row (stable fields).\n",
    "\n",
    "    Output columns created:\n",
    "    - Description of Contract\n",
    "    - Additional Notes (Internal Only)\n",
    "    - Source Link(s)\n",
    "    - Contract Date\n",
    "    - Reported Date (By SGA)\n",
    "\n",
    "    Important:\n",
    "    - These fields remain SAME even after splits.\n",
    "    - Every split row inherits these values.\n",
    "    \"\"\"\n",
    "    reported_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    notes = \"Standard extraction.\"\n",
    "    if \"modification\" in str(paragraph).lower():\n",
    "        notes = \"Contract Modification.\"\n",
    "    if \"multiple award\" in str(paragraph).lower():\n",
    "        notes = \"Multiple award contract detected (non-supplier split).\"\n",
    "\n",
    "    return {\n",
    "        \"Description of Contract\": paragraph,\n",
    "        \"Additional Notes (Internal Only)\": notes,\n",
    "        \"Source Link(s)\": url,\n",
    "        \"Contract Date\": date,\n",
    "        \"Reported Date (By SGA)\": reported_date\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c73d68b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## # Stage 2: GEOGRAPHY EXTRACTOR (Chunk -> Merge)\n",
    "\n",
    "class GeographyInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "\n",
    "@tool(\"geography_extractor\")\n",
    "def geography_extractor(paragraph: str):\n",
    "    \"\"\"\n",
    "    Stage 2: GEOGRAPHY EXTRACTOR\n",
    "    Updates Supplier Region based on the extracted Supplier Country.\n",
    "    \"\"\"\n",
    "    paragraph = str(paragraph).strip()\n",
    "    if not paragraph:\n",
    "        return {}\n",
    "\n",
    "    # --- RAG Optimization ---\n",
    "    best_hit, best_score, best_meta = rag_best_hit(paragraph, top_k=3)\n",
    "    \n",
    "    # Defaults\n",
    "    cust_country = \"Unknown\"\n",
    "    cust_op = \"Unknown\"\n",
    "    supp_country = \"Unknown\"\n",
    "\n",
    "    if best_hit and best_score >= 0.78:\n",
    "        # Trust KB if high confidence\n",
    "        cust_country = safe_str(best_meta.get(\"Customer Country\", \"\"))\n",
    "        cust_op = normalize_customer_operator(safe_str(best_meta.get(\"Customer Operator\", \"\")))\n",
    "        supp_country = safe_str(best_meta.get(\"Supplier Country\", \"\"))\n",
    "    else:\n",
    "        # LLM Extraction\n",
    "        chunks = chunk_text(paragraph, chunk_size=1800, overlap=250)\n",
    "        outputs = []\n",
    "        for ch in chunks:\n",
    "            try:\n",
    "                raw = call_llm_json(GEOGRAPHY_PROMPT, ch, max_tokens=250)\n",
    "                outputs.append(raw)\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        cust_country = pick_best_non_empty([o.get(\"Customer Country\") for o in outputs]) or \"Unknown\"\n",
    "        cust_op = normalize_customer_operator(pick_best_non_empty([o.get(\"Customer Operator\") for o in outputs]))\n",
    "        supp_country = pick_best_non_empty([o.get(\"Supplier Country\") for o in outputs]) or \"Unknown\"\n",
    "\n",
    "    # Normalize Countries\n",
    "    cust_country = normalize_country_name(cust_country)\n",
    "    supp_country = normalize_country_name(supp_country)\n",
    "\n",
    "    # Calculate Regions using the SHARED logic\n",
    "    cust_region = get_region_for_country(cust_country)\n",
    "    supp_region = get_region_for_country(supp_country) # Same list as Customer Region\n",
    "\n",
    "    return {\n",
    "        \"Customer Region\": cust_region,\n",
    "        \"Customer Country\": cust_country,\n",
    "        \"Customer Operator\": cust_op,\n",
    "        \"Supplier Region\": supp_region,   # Extracted here\n",
    "        \"Supplier Country\": supp_country,\n",
    "        \"Domestic Content\": \"Indigenous\" if cust_country == supp_country else \"Imported\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b3317ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3: SYSTEM CLASSIFIER (Chunk -> Merge)\n",
    "\n",
    "class SystemInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    item_focus: str = Field(description=\"Specific line-item focus (from Stage5), e.g. 'All up round containers'\")\n",
    "\n",
    "@tool(\"system_classifier\")\n",
    "def system_classifier(paragraph: str, item_focus: str = \"\"):\n",
    "    \"\"\"\n",
    "    Stage 3: RAG-Enhanced Classifier (Accuracy Mode)\n",
    "    \"\"\"\n",
    "    paragraph = str(paragraph).strip()\n",
    "    \n",
    "    # --- 1. RETRIEVE KNOWLEDGE (The \"Memory\") ---\n",
    "    # We query the KB for the specific item to see how we handled it before.\n",
    "    search_query = item_focus if len(item_focus) > 3 else paragraph\n",
    "    hits = retriever.retrieve(search_query, top_k=3)\n",
    "    \n",
    "    # Build the Context String\n",
    "    rag_context = \"No direct historical match found.\"\n",
    "    if hits:\n",
    "        rag_context = \"### HISTORICAL PRECEDENTS (GOLDEN EXAMPLES):\\n\"\n",
    "        for i, h in enumerate(hits, 1):\n",
    "            m = h['meta']\n",
    "            # We show the LLM the 'Correct Answer' from the past\n",
    "            rag_context += (\n",
    "                f\"[{i}] Description: \\\"{m.get('original_text', '')[:120]}...\\\"\\n\"\n",
    "                f\"    -> Classified As: {m.get('Market Segment', '?')} / {m.get('System Name (Specific)', '?')}\\n\"\n",
    "            )\n",
    "\n",
    "    # --- 2. GET KEYWORD HINTS (The \"Rule Book\") ---\n",
    "    rule_guidance = apply_rule_book(paragraph)\n",
    "    rule_str = \"\"\n",
    "    if rule_guidance:\n",
    "        rule_str = f\"Trace detected keywords: {json.dumps(rule_guidance)}\"\n",
    "\n",
    "    # --- 3. EXECUTE PROMPT ---\n",
    "    # We inject the RAG context directly into the User Prompt so it's 'top of mind'\n",
    "    formatted_system_prompt = SYSTEM_CLASSIFIER_PROMPT.format(\n",
    "        taxonomy_reference=TAXONOMY_STR,\n",
    "        rule_book_overrides=rule_str\n",
    "    )\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "    TARGET CONTRACT TEXT: \"{paragraph}\"\n",
    "    SPECIFIC ITEM TO CLASSIFY: \"{item_focus if item_focus else 'Main Deliverable'}\"\n",
    "    \n",
    "    {rag_context}\n",
    "    \n",
    "    TASK:\n",
    "    1. Check the 'HISTORICAL PRECEDENTS' above. If the item matches, align with that classification.\n",
    "    2. If no precedent, analyze the 'TARGET CONTRACT TEXT' functionally.\n",
    "    3. Extract the JSON.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Call LLM\n",
    "        res = call_llm_json(formatted_system_prompt, user_prompt, max_tokens=600)\n",
    "        \n",
    "        # --- 4. VALIDATION SAFETY NET ---\n",
    "        # Ensure Piloting is logically consistent (LLMs sometimes struggle with 'Crewed' vs 'N/A')\n",
    "        designators = extract_designators(paragraph)\n",
    "        sys_type = res.get(\"System Type (General)\", \"\")\n",
    "        \n",
    "        # If the LLM was unsure about piloting, run the strict rule checker\n",
    "        if res.get(\"System Piloting\") in [\"Unknown\", \"N/A\", None] and sys_type:\n",
    "            res[\"System Piloting\"] = detect_piloting_strict(paragraph, designators, sys_type)\n",
    "            \n",
    "        return res\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"Confidence\": \"Low\", \"Error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7017016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 4: CONTRACT EXTRACTOR (Chunk -> Merge + Strict Supplier)\n",
    "\n",
    "class ContractInfoInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    contract_date: str = Field(description=\"Contract date as string.\")\n",
    "\n",
    "def clean_llm_number(num_str):\n",
    "    \"\"\"Converts '$12.5M' or '12,000,000' to float.\"\"\"\n",
    "    if not num_str: return 0.0\n",
    "    try:\n",
    "        clean = str(num_str).upper().replace(\"$\", \"\").replace(\"MILLION\", \"\").replace(\"M\", \"\").replace(\",\", \"\").strip()\n",
    "        # Handle 'Billion' conversion if necessary\n",
    "        multiplier = 1000 if \"BILLION\" in str(num_str).upper() or \"B\" in str(num_str).upper() else 1\n",
    "        clean = clean.replace(\"BILLION\", \"\").replace(\"B\", \"\")\n",
    "        return float(clean) * multiplier\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def calculate_mro_duration_sop(contract_date_str, completion_date_text, program_type):\n",
    "    \"\"\"\n",
    "    SOP Calculation: Subtract completion date from contract date. \n",
    "    Capture difference in whole months (Round Down).\n",
    "    Applicable ONLY for MRO/Support.\n",
    "    \"\"\"\n",
    "    if program_type != \"MRO/Support\":\n",
    "        return \"Not Applicable\"\n",
    "    \n",
    "    if not contract_date_str or not completion_date_text or completion_date_text.lower() in [\"not applicable\", \"n/a\", \"unknown\"]:\n",
    "        return \"Not Applicable\"\n",
    "\n",
    "    try:\n",
    "        start_date = pd.to_datetime(contract_date_str)\n",
    "        # Fuzzy parse the completion text (e.g., \"September 2024\")\n",
    "        end_date = parser.parse(str(completion_date_text), fuzzy=True)\n",
    "        \n",
    "        # Calculate difference\n",
    "        diff = relativedelta(end_date, start_date)\n",
    "        total_months = (diff.years * 12) + diff.months\n",
    "        \n",
    "        # SOP: \"For fractional values, apply the round-down approach\"\n",
    "        # relativedelta typically gives whole integers, but if days are involved:\n",
    "        # If end day < start day, relativedelta usually handles this by reducing month count.\n",
    "        # We ensure it's at least 0.\n",
    "        return str(max(0, int(total_months)))\n",
    "    except:\n",
    "        return \"Not Applicable\"\n",
    "\n",
    "@tool(\"contract_extractor\")\n",
    "def contract_extractor(paragraph: str, contract_date: str):\n",
    "    \"\"\"\n",
    "    Stage 4: CONTRACT EXTRACTOR\n",
    "    \"\"\"\n",
    "    paragraph = str(paragraph).strip()\n",
    "\n",
    "    # 1. Prepare Prompt\n",
    "    formatted_prompt = CONTRACT_EXTRACTOR_PROMPT.format(\n",
    "        program_type_enum=str(PROGRAM_TYPE_ALLOWED)\n",
    "    )\n",
    "    user_message = f\"CONTRACT TEXT: {paragraph}\\nDATE: {contract_date}\"\n",
    "\n",
    "    # 2. Call LLM\n",
    "    try:\n",
    "        # Assuming call_llm_json is defined/imported\n",
    "        llm_data = call_llm_json(formatted_prompt, user_message, max_tokens=400)\n",
    "    except Exception as e:\n",
    "        print(f\"LLM Error: {e}\")\n",
    "        llm_data = {}\n",
    "\n",
    "    # 3. --- SUPPLIER MATCHING LOGIC (The Fix) ---\n",
    "    llm_supplier_raw = llm_data.get(\"extracted_supplier\", \"Unknown\")\n",
    "    \n",
    "    # Run the raw LLM output through your fuzzy matcher\n",
    "    final_supplier = get_best_supplier_match(llm_supplier_raw)\n",
    "\n",
    "    # 4. Financial Processing\n",
    "    raw_val = llm_data.get(\"value_million\", 0)\n",
    "    val_float = clean_llm_number(raw_val)\n",
    "    val_final_str = f\"{val_float:.3f}\"\n",
    "    \n",
    "    # Currency Handling\n",
    "    currency_code = llm_data.get(\"currency_code\", \"USD$\")\n",
    "    if \"USD\" in currency_code.upper() and \"$\" not in currency_code:\n",
    "        currency_code = \"USD$\"\n",
    "\n",
    "    if \"USD\" in currency_code:\n",
    "        usd_final_str = val_final_str\n",
    "    else:\n",
    "        usd_final_str = f\"{clean_llm_number(llm_data.get('value_usd_million', 0)):.3f}\"\n",
    "\n",
    "    # 5. Other Fields\n",
    "    final_program_type = normalize_program_type_improved(\n",
    "        llm_data.get(\"program_type\", \"Unknown\"), \n",
    "        paragraph\n",
    "    )\n",
    "\n",
    "    mro_months = calculate_mro_duration_sop(\n",
    "        contract_date, \n",
    "        llm_data.get(\"completion_date_text\", \"\"), \n",
    "        final_program_type\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"Supplier Name\": final_supplier,  # This now contains the clean JSON match or \"Multiple\"\n",
    "        \"Supplier Name Evidence\": \"LLM + Fuzzy Match\",\n",
    "        \"Program Type\": final_program_type,\n",
    "        \"Value (Million)\": val_final_str,\n",
    "        \"Value (USD$ Million)\": usd_final_str,\n",
    "        \"Currency\": currency_code,\n",
    "        \"Value Certainty\": llm_data.get(\"value_certainty\", \"Estimated\"),\n",
    "        \"Value Note (If Any)\": llm_data.get(\"value_note\", \"\"),\n",
    "        \"G2G/B2G\": llm_data.get(\"g2g_b2g\", \"B2G\"),\n",
    "        \"Expected MRO Contract Duration (Months)\": mro_months,\n",
    "        \"Quantity\": llm_data.get(\"quantity\", \"Not Applicable\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90a66e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 5: SPLITTER AGENT (FULL PARAGRAPH ALWAYS)\n",
    "\n",
    "class SplitterInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    base_row: dict = Field(description=\"Extracted row after Stage1-4.\")\n",
    "\n",
    "@tool(\"splitter_agent\")\n",
    "def splitter_agent(paragraph: str, base_row: dict):\n",
    "  \"\"\"\n",
    "  Stage 5: SPLITTER AGENT\n",
    "  Purpose:\n",
    "    - Applies deterministic split logic to generate multiple output rows\n",
    "      when paragraph has explicit multi allocations.\n",
    "  Supported splits:\n",
    "    - Operator/Quantity split (\"212 for the Navy\", \"187 for the Air Force\")\n",
    "    - FMS country split (only for rows marked as G2G)\n",
    "    - Multi-value note (does not split, only notes)\n",
    "\n",
    "  IMPORTANT:\n",
    "    - Supplier split is REMOVED to prevent wrong supplier explosions.\n",
    "  \"\"\"\n",
    "  try:\n",
    "      rows = split_rows_engine(base_row, paragraph)\n",
    "      for r in rows:\n",
    "          r.setdefault(\"Split Flag\", \"No\")\n",
    "          r.setdefault(\"Split Reason\", \"\")\n",
    "      return {\"rows\": rows}\n",
    "  except Exception as e:\n",
    "      base_row[\"Split Flag\"] = \"Error\"\n",
    "      base_row[\"Split Reason\"] = f\"Split failed: {str(e)}\"\n",
    "      return {\"rows\": [base_row]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a858a0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 6: QUALITY VALIDATOR AGENT\n",
    "\n",
    "class QAInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Original paragraph for reference.\")\n",
    "    rows: list = Field(description=\"Final split rows list output from Stage5.\")\n",
    "\n",
    "@tool(\"quality_validator\")\n",
    "def quality_validator(paragraph: str, rows: list):\n",
    "    \"\"\"\n",
    "    Stage 6: QUALITY VALIDATOR (Hybrid: Rule-Based + KB Check)\n",
    "    \"\"\"\n",
    "    text = str(paragraph).lower()\n",
    "    validated_rows = []\n",
    "\n",
    "    for r in rows:\n",
    "        flags = []\n",
    "        fixes = []\n",
    "\n",
    "        # --- Rule Based Checks ---\n",
    "        supplier = str(r.get(\"Supplier Name\", \"\")).strip()\n",
    "        if supplier.lower() in [\"unknown\", \"\", \"multiple\"]:\n",
    "             # If text clearly has an award, flag it\n",
    "             if \"awarded\" in text:\n",
    "                 flags.append(\"Supplier Unknown\")\n",
    "                 fixes.append(\"Check LLM Fallback\")\n",
    "\n",
    "        # --- KB/Taxonomy Validation (NEW) ---\n",
    "        sys_name = str(r.get(\"System Name (General)\", \"\")).strip()\n",
    "        \n",
    "        # If we have a system name, verify it against KB context\n",
    "        if sys_name and sys_name.lower() != \"unknown\":\n",
    "            # Quick check: does this system appear in our RAG hits?\n",
    "            # We assume 'retriever' is globally available as per notebook scope\n",
    "            hits = retriever.retrieve(sys_name, top_k=1)\n",
    "            if hits:\n",
    "                top_score = hits[0]['score']\n",
    "                # If score is very low, the system might be hallucinated or poorly named\n",
    "                if top_score < 0.35: \n",
    "                    flags.append(f\"System Name '{sys_name}' has low KB confidence ({top_score:.2f})\")\n",
    "                    fixes.append(\"Verify system name against standard taxonomy\")\n",
    "\n",
    "        # --- Final Status ---\n",
    "        qa_status = \"PASS\" if not flags else \"FAIL\"\n",
    "        \n",
    "        rr = r.copy()\n",
    "        rr[\"QA Status\"] = qa_status\n",
    "        rr[\"QA Flags\"] = \" | \".join(flags) if flags else \"None\"\n",
    "        rr[\"QA Fix Suggestion\"] = \" | \".join(fixes) if fixes else \"None\"\n",
    "        validated_rows.append(rr)\n",
    "\n",
    "    return {\"rows\": validated_rows}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53cf7860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 7: LLM VALIDATOR (FAIL ONLY) - Chunk Aware\n",
    "class LLMValidateInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Original paragraph text.\")\n",
    "    row: dict = Field(description=\"One FAIL row to validate/correct.\")\n",
    "\n",
    "@tool(\"llm_fail_row_validator\")\n",
    "def llm_fail_row_validator(paragraph: str, row: dict):\n",
    "    \"\"\"\n",
    "    Stage 7: VALIDATOR FIX (Linked to prompts.py)\n",
    "    \"\"\"\n",
    "    # LINK THE PROMPT\n",
    "    formatted_fix_prompt = VALIDATOR_FIX_PROMPT.format(\n",
    "        failed_row_json=json.dumps(row, indent=2),\n",
    "        program_type_enum=str(PROGRAM_TYPE_ALLOWED)\n",
    "    )\n",
    "\n",
    "    user_prompt = f\"ORIGINAL TEXT CHUNK: {paragraph[:2000]}\"\n",
    "\n",
    "    try:\n",
    "        fix = call_llm_json(formatted_fix_prompt, user_prompt, max_tokens=350)\n",
    "        \n",
    "        # Merge Fixes\n",
    "        corrected = row.copy()\n",
    "        if fix.get(\"Supplier Name\") and fix[\"Supplier Name\"] != \"Unknown\":\n",
    "            corrected[\"Supplier Name\"] = fix[\"Supplier Name\"]\n",
    "        if fix.get(\"Program Type\"):\n",
    "            corrected[\"Program Type\"] = fix[\"Program Type\"]\n",
    "        if fix.get(\"Value (Million)\"):\n",
    "            corrected[\"Value (Million)\"] = fix[\"Value (Million)\"]\n",
    "            \n",
    "        corrected[\"LLM QA Fix Summary\"] = fix.get(\"Fix Summary\", \"Auto-fixed by Agent\")\n",
    "        return {\"row\": corrected}\n",
    "\n",
    "    except Exception:\n",
    "        return {\"row\": row}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7982c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    input_text: str\n",
    "    input_date: str\n",
    "    input_url: str\n",
    "\n",
    "    final_data: dict\n",
    "    final_rows: list\n",
    "    validated_rows: list\n",
    "    final_rows_post_llm: list\n",
    "\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "def stage_1_sourcing(state: AgentState):\n",
    "    res = sourcing_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"url\": state[\"input_url\"],\n",
    "        \"date\": state[\"input_date\"],\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_2_geography(state: AgentState):\n",
    "    res = geography_extractor.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_3_system(state: AgentState):\n",
    "    \"\"\"\n",
    "    NEW Stage3 Node:\n",
    "    Runs system classification PER split row using item_focus.\n",
    "    \"\"\"\n",
    "\n",
    "    paragraph = state[\"input_text\"]\n",
    "    rows = state.get(\"final_rows\", [])\n",
    "\n",
    "    updated_rows = []\n",
    "\n",
    "    for r in rows:\n",
    "        item_focus = str(r.get(\"System Name (Specific)\", \"\")).strip()\n",
    "\n",
    "        res = system_classifier.invoke({\n",
    "            \"paragraph\": paragraph,\n",
    "            \"item_focus\": item_focus\n",
    "        })\n",
    "\n",
    "        rr = r.copy()\n",
    "        rr.update(res)   # merge system labels into the row\n",
    "        updated_rows.append(rr)\n",
    "\n",
    "    return {\"final_rows\": updated_rows}\n",
    "\n",
    "\n",
    "def stage_4_contract(state: AgentState):\n",
    "    res = contract_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"contract_date\": state[\"input_date\"]\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_5_split(state: AgentState):\n",
    "    \"\"\"\n",
    "    Stage5 Node: SplitterEngine\n",
    "\n",
    "     Ensures output is ALWAYS stored in `final_rows`\n",
    "    so Stage3 SystemClassifierRAG can loop through them.\n",
    "    \"\"\"\n",
    "\n",
    "    base_row = state.get(\"final_data\", {}) or {}\n",
    "    paragraph = state.get(\"input_text\", \"\")\n",
    "\n",
    "    try:\n",
    "        res = splitter_agent.invoke({\n",
    "            \"paragraph\": paragraph,\n",
    "            \"base_row\": base_row\n",
    "        })\n",
    "\n",
    "        rows = res.get(\"rows\", None)\n",
    "\n",
    "        # Hard safety fallback\n",
    "        if not rows or not isinstance(rows, list):\n",
    "            rows = [base_row]\n",
    "\n",
    "        return {\"final_rows\": rows}\n",
    "\n",
    "    except Exception as e:\n",
    "        # Never crash pipeline due to split failure\n",
    "        fallback = base_row.copy()\n",
    "        fallback[\"Split Flag\"] = \"Error\"\n",
    "        fallback[\"Split Reason\"] = f\"SplitterEngine failed: {str(e)}\"\n",
    "        return {\"final_rows\": [fallback]}\n",
    "\n",
    "\n",
    "def stage_6_quality_validator(state: AgentState):\n",
    "    res = quality_validator.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"rows\": state[\"final_rows\"]\n",
    "    })\n",
    "    return {\"validated_rows\": res.get(\"rows\", state[\"final_rows\"])}\n",
    "\n",
    "\n",
    "def stage_7_llm_fix_fail_rows(state: AgentState):\n",
    "    paragraph = state[\"input_text\"]\n",
    "    validated_rows = state.get(\"validated_rows\", [])\n",
    "\n",
    "    fixed_rows = []\n",
    "    for r in validated_rows:\n",
    "        if r.get(\"QA Status\") == \"FAIL\":\n",
    "            fix_res = llm_fail_row_validator.invoke({\"paragraph\": paragraph, \"row\": r})\n",
    "            fixed_rows.append(fix_res.get(\"row\", r))\n",
    "        else:\n",
    "            fixed_rows.append(r)\n",
    "\n",
    "    return {\"final_rows_post_llm\": fixed_rows}\n",
    "\n",
    "def node_system_classifier_rag(state: AgentState):\n",
    "    \"\"\"\n",
    "    Stage3 Node (AFTER SplitterEngine)\n",
    "\n",
    "    Runs system classification per split-row using:\n",
    "       item_focus = row[\"System Name (Specific)\"] or row[\"System Name (General)\"]\n",
    "\n",
    "    Updates each row with Market Segment / System Type / System Name / Evidence / Reason\n",
    "    \"\"\"\n",
    "\n",
    "    paragraph = state[\"input_text\"]\n",
    "    rows = state.get(\"final_rows\", [])\n",
    "\n",
    "    # If split engine didn't create rows, fallback to single final_data row\n",
    "    if not rows:\n",
    "        base = state.get(\"final_data\", {})\n",
    "        rows = [base] if base else []\n",
    "\n",
    "    updated_rows = []\n",
    "\n",
    "    for r in rows:\n",
    "        item_focus = str(r.get(\"System Name (Specific)\", \"\")).strip()\n",
    "        if not item_focus:\n",
    "            item_focus = str(r.get(\"System Name (General)\", \"\")).strip()\n",
    "\n",
    "        # invoke your Stage3 tool\n",
    "        sys_res = system_classifier.invoke({\n",
    "            \"paragraph\": paragraph,\n",
    "            \"item_focus\": item_focus\n",
    "        })\n",
    "\n",
    "        rr = r.copy()\n",
    "        rr.update(sys_res)\n",
    "        updated_rows.append(rr)\n",
    "\n",
    "    return {\"final_rows\": updated_rows}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d1af922",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"SourcingExtractor\", stage_1_sourcing)\n",
    "workflow.add_node(\"GeographyExtractor\", stage_2_geography)\n",
    "workflow.add_node(\"ContractExtractor\", stage_4_contract)\n",
    "workflow.add_node(\"SplitterEngine\", stage_5_split)\n",
    "workflow.add_node(\"SystemClassifierRAG\", node_system_classifier_rag)  # \n",
    "workflow.add_node(\"QualityValidator\", stage_6_quality_validator)\n",
    "workflow.add_node(\"LLMFailRowFixer\", stage_7_llm_fix_fail_rows)\n",
    "\n",
    "workflow.add_edge(START, \"SourcingExtractor\")\n",
    "workflow.add_edge(\"SourcingExtractor\", \"GeographyExtractor\")\n",
    "workflow.add_edge(\"GeographyExtractor\", \"ContractExtractor\")\n",
    "workflow.add_edge(\"ContractExtractor\", \"SplitterEngine\")   # \n",
    "workflow.add_edge(\"SplitterEngine\", \"SystemClassifierRAG\") # \n",
    "workflow.add_edge(\"SystemClassifierRAG\", \"QualityValidator\")\n",
    "workflow.add_edge(\"QualityValidator\", \"LLMFailRowFixer\")\n",
    "workflow.add_edge(\"LLMFailRowFixer\", END)\n",
    "app = workflow.compile()\n",
    "\n",
    "\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac0b5819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reach https://mermaid.ink API while trying to render your graph after 1 retries. To resolve this issue:\n",
      "1. Check your internet connection and try again\n",
      "2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n",
      "3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "try:\n",
    "  display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4afc2903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) GRAPH EXPORT (OFFLINE SAFE)\n",
    "\n",
    "def export_workflow_mermaid(app_obj, out_file=\"workflow.mmd\"):\n",
    "    mmd = app_obj.get_graph().draw_mermaid()\n",
    "    with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(mmd)\n",
    "    print(f\"Workflow Mermaid saved locally: {out_file}\")\n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be954ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loading Input File: C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\data\\source_file.xlsx\n",
      "Workflow Mermaid saved locally: workflow.mmd\n",
      "Processing 9 rows...\n",
      "\n",
      " Row 1/9\n",
      "\n",
      " Row 2/9\n",
      "\n",
      " Row 3/9\n",
      "\n",
      " Row 4/9\n",
      "\n",
      " Row 5/9\n",
      "\n",
      " Row 6/9\n",
      "\n",
      " Row 7/9\n",
      "\n",
      " Row 8/9\n",
      "\n",
      " Row 9/9\n",
      "Saving to Excel: Processed_Defense_Data.xlsx\n",
      "Applying Highlighting...\n",
      "Evidence + Reason columns highlighted successfully.\n",
      "\n",
      "Processing Complete!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(f\"\\n Loading Input File: {INPUT_EXCEL_PATH}\")\n",
    "    \n",
    "    # Define Output Path as Excel\n",
    "    OUTPUT_EXCEL_PATH = \"Processed_Defense_Data.xlsx\"\n",
    "\n",
    "    export_workflow_mermaid(app, out_file=\"workflow.mmd\")\n",
    "\n",
    "    try:\n",
    "        df_input = pd.read_excel(INPUT_EXCEL_PATH)\n",
    "        \n",
    "        # Basic validation\n",
    "        required_cols = [\"Source URL\", \"Contract Date\", \"Contract Description\"]\n",
    "        # Allow loose matching or strip whitespace from columns if needed\n",
    "        df_input.columns = [c.strip() for c in df_input.columns]\n",
    "        \n",
    "        if not all(col in df_input.columns for col in required_cols):\n",
    "             raise ValueError(f\"Excel file must contain columns: {required_cols}\")\n",
    "\n",
    "        print(f\"Processing {len(df_input)} rows...\")\n",
    "        results = []\n",
    "\n",
    "        for index, row in df_input.iterrows():\n",
    "            print(f\"\\n Row {index + 1}/{len(df_input)}\")\n",
    "\n",
    "            desc = str(row[\"Contract Description\"]) if pd.notna(row[\"Contract Description\"]) else \"\"\n",
    "            c_date = str(row[\"Contract Date\"]) if pd.notna(row[\"Contract Date\"]) else str(datetime.date.today())\n",
    "            c_url = str(row[\"Source URL\"]) if pd.notna(row[\"Source URL\"]) else \"\"\n",
    "\n",
    "            initial_state: AgentState = {\n",
    "                \"input_text\": desc,\n",
    "                \"input_date\": c_date,\n",
    "                \"input_url\": c_url,\n",
    "                \"final_data\": {},\n",
    "                \"final_rows\": [],\n",
    "                \"validated_rows\": [],\n",
    "                \"final_rows_post_llm\": [],\n",
    "                \"messages\": []\n",
    "            }\n",
    "\n",
    "            output_state = app.invoke(initial_state)\n",
    "\n",
    "            # Hierarchy of fallback for getting rows\n",
    "            rows = output_state.get(\"final_rows_post_llm\", [])\n",
    "            if not rows:\n",
    "                rows = output_state.get(\"validated_rows\", [])\n",
    "            if not rows:\n",
    "                rows = output_state.get(\"final_rows\", [])\n",
    "            if not rows:\n",
    "                rows = [output_state.get(\"final_data\", {})]\n",
    "\n",
    "            results.extend(rows)\n",
    "\n",
    "        df_final = pd.DataFrame(results)\n",
    "\n",
    "        FINAL_COLUMNS = [\n",
    "            \"Customer Region\", \"Customer Country\", \"Customer Operator\",\n",
    "            \"Supplier Region\", \"Supplier Country\", \"Domestic Content\",\n",
    "\n",
    "            \"Split Flag\", \"Split Reason\",\n",
    "\n",
    "            \"Market Segment\", \"Market Segment Evidence\", \"Market Segment Reason\",\n",
    "            \"System Type (General)\", \"System Type (General) Evidence\", \"System Type (General) Reason\",\n",
    "            \"System Type (Specific)\", \"System Type (Specific) Evidence\", \"System Type (Specific) Reason\",\n",
    "            \"System Name (General)\", \"System Name (General) Evidence\", \"System Name (General) Reason\",\n",
    "            \"System Name (Specific)\", \"System Name (Specific) Evidence\", \"System Name (Specific) Reason\",\n",
    "            \"System Piloting\", \"System Piloting Evidence\", \"System Piloting Reason\",\n",
    "            \"Confidence\",\n",
    "\n",
    "            \"Supplier Name\", \"Supplier Name Evidence\",\n",
    "            \"Program Type\", \"Expected MRO Contract Duration (Months)\",\n",
    "            \"Quantity\", \"Value Certainty\", \"Value (Million)\", \"Currency\",\n",
    "            \"Value (USD$ Million)\", \"Value Note (If Any)\", \"G2G/B2G\",\n",
    "            \"Signing Month\", \"Signing Year\",\n",
    "\n",
    "            \"QA Status\", \"QA Flags\", \"QA Fix Suggestion\",\n",
    "            \"LLM QA Fix Summary\",\n",
    "\n",
    "            \"Description of Contract\",\n",
    "            \"Additional Notes (Internal Only)\",\n",
    "            \"Source Link(s)\",\n",
    "            \"Contract Date\",\n",
    "            \"Reported Date (By SGA)\"\n",
    "        ]\n",
    "\n",
    "        # Reindex ensures all columns exist, filling missing ones with empty string\n",
    "        df_final = df_final.reindex(columns=FINAL_COLUMNS, fill_value=\"\")\n",
    "\n",
    "        # 1. Save as Excel\n",
    "        print(f\"Saving to Excel: {OUTPUT_EXCEL_PATH}\")\n",
    "        df_final.to_excel(OUTPUT_EXCEL_PATH, index=False, engine='openpyxl')\n",
    "        \n",
    "        # 2. Apply Formatting/Highlighting\n",
    "        print(\"Applying Highlighting...\")\n",
    "        highlight_evidence_reason_columns(OUTPUT_EXCEL_PATH)\n",
    "\n",
    "        print(\"\\nProcessing Complete!\")\n",
    "        #print(df_final[[\"Supplier Name\", \"Value (USD$ Million)\", \"Customer Operator\", \"Supplier Region\"]].head(3).to_string(index=False))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n ERROR: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f82fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# DEFENSE AGENTIC PIPELINE ‚Äî 7 AGENTS (FINAL)\n",
    "# ==========================================================\n",
    "\n",
    "import os, json, pickle, datetime, getpass\n",
    "from typing import TypedDict, List, Annotated\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ---------------- LangGraph ----------------\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# ---------------- LLM ----------------\n",
    "from openai import OpenAI\n",
    "\n",
    "# ---------------- Excel ----------------\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "\n",
    "# ==========================================================\n",
    "# CONFIG\n",
    "# ==========================================================\n",
    "\n",
    "INPUT_EXCEL = \"source_file.xlsx\"\n",
    "OUTPUT_EXCEL = \"Processed_Defense_Data.xlsx\"\n",
    "KB_DIR = \"system_kb_store\"\n",
    "\n",
    "RAG_STRONG = 0.78\n",
    "RAG_MEDIUM = 0.70\n",
    "\n",
    "# ==========================================================\n",
    "# PROMPT PLACEHOLDERS (PASTE YOUR REAL PROMPTS)\n",
    "# ==========================================================\n",
    "\n",
    "GEOGRAPHY_PROMPT = \"\"\"<<< GEOGRAPHY PROMPT HERE >>>\"\"\"\n",
    "SYSTEM_CLASSIFIER_PROMPT = \"\"\"<<< SYSTEM CLASSIFIER PROMPT HERE >>>\"\"\"\n",
    "CONTRACT_EXTRACTOR_PROMPT = \"\"\"<<< CONTRACT EXTRACTOR PROMPT HERE >>>\"\"\"\n",
    "VALIDATOR_FIX_PROMPT = \"\"\"<<< OPTIONAL VALIDATOR PROMPT HERE >>>\"\"\"\n",
    "\n",
    "# ==========================================================\n",
    "# LLM CLIENT\n",
    "# ==========================================================\n",
    "\n",
    "if \"LLMFOUNDRY_TOKEN\" not in os.environ:\n",
    "    os.environ[\"LLMFOUNDRY_TOKEN\"] = getpass.getpass(\"Enter LLM Foundry API Key: \")\n",
    "\n",
    "if \"OPENROUTER_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENROUTER_API_KEY\"] = getpass.getpass(\"Enter OpenRouter API Key: \")\n",
    "\n",
    "# ===== LLM FOUNDRY (PRIMARY ‚Äì INTERNAL) =====\n",
    "llm_foundry_client = OpenAI(\n",
    "    api_key=f'{os.environ[\"LLMFOUNDRY_TOKEN\"]}:agentic',\n",
    "    base_url=\"https://llmfoundry.straive.com/openai/v1/\"\n",
    ")\n",
    "\n",
    "FOUNDRY_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "\n",
    "# ===== OPENROUTER (SECONDARY / FALLBACK / COMPARISON) =====\n",
    "openrouter_client = OpenAI(\n",
    "    api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
    "    base_url=\"https://openrouter.ai/api/v1\"\n",
    ")\n",
    "\n",
    "OPENROUTER_MODEL = \"openai/gpt-4o-mini\"\n",
    "\n",
    "def call_llm(\n",
    "    prompt: str,\n",
    "    backend: str = \"foundry\",   # \"foundry\" | \"openrouter\"\n",
    "    max_tokens: int = 500\n",
    "):\n",
    "    \"\"\"\n",
    "    Unified LLM call wrapper.\n",
    "    You decide backend per agent / per confidence / per column.\n",
    "    \"\"\"\n",
    "\n",
    "    if backend == \"openrouter\":\n",
    "        client = openrouter_client\n",
    "        model = OPENROUTER_MODEL\n",
    "    else:\n",
    "        client = llm_foundry_client\n",
    "        model = FOUNDRY_MODEL\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=max_tokens,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    return json.loads(response.choices[0].message.content)\n",
    "# ==========================================================\n",
    "# KB RETRIEVER\n",
    "# ==========================================================\n",
    "\n",
    "class KBRetriever:\n",
    "    def __init__(self, kb_dir):\n",
    "        self.index = faiss.read_index(os.path.join(kb_dir, \"system_kb.faiss\"))\n",
    "        with open(os.path.join(kb_dir, \"system_kb_meta.pkl\"), \"rb\") as f:\n",
    "            self.meta = pickle.load(f)\n",
    "        self.embedder = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "    def best_hit(self, text):\n",
    "        emb = self.embedder.encode([text], normalize_embeddings=True).astype(\"float32\")\n",
    "        scores, idxs = self.index.search(emb, 1)\n",
    "        if idxs[0][0] < 0:\n",
    "            return {}, 0.0, None\n",
    "        return self.meta[idxs[0][0]], float(scores[0][0]), idxs[0][0]\n",
    "\n",
    "retriever = KBRetriever(KB_DIR)\n",
    "\n",
    "# ==========================================================\n",
    "# MODE / CONFIDENCE\n",
    "# ==========================================================\n",
    "\n",
    "def mode_from_score(score):\n",
    "    if score >= RAG_STRONG:\n",
    "        return \"KB_ONLY\"\n",
    "    if score >= RAG_MEDIUM:\n",
    "        return \"KB_GUIDED\"\n",
    "    return \"LLM_ONLY\"\n",
    "\n",
    "def confidence_from_mode(mode):\n",
    "    return {\n",
    "        \"KB_ONLY\": \"High (KB)\",\n",
    "        \"KB_GUIDED\": \"Medium (KB+LLM)\",\n",
    "        \"LLM_ONLY\": \"Low (LLM)\"\n",
    "    }.get(mode, \"Unknown\")\n",
    "\n",
    "# ==========================================================\n",
    "# AGENT STATE\n",
    "# ==========================================================\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    text: str\n",
    "    date: str\n",
    "    url: str\n",
    "\n",
    "    kb_meta: dict\n",
    "    kb_score: float\n",
    "    kb_mode: str\n",
    "    kb_row_id: int | None\n",
    "\n",
    "    row: dict\n",
    "    rows: list\n",
    "\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "\n",
    "# ==========================================================\n",
    "# AGENT 1 ‚Äî KB ROUTER\n",
    "# ==========================================================\n",
    "\n",
    "def kb_router_agent(state: AgentState):\n",
    "    meta, score, row_id = retriever.best_hit(state[\"text\"])\n",
    "    return {\n",
    "        \"kb_meta\": meta,\n",
    "        \"kb_score\": score,\n",
    "        \"kb_mode\": mode_from_score(score),\n",
    "        \"kb_row_id\": row_id\n",
    "    }\n",
    "\n",
    "# ==========================================================\n",
    "# AGENT 2 ‚Äî SOURCING\n",
    "# ==========================================================\n",
    "\n",
    "def sourcing_agent(state: AgentState):\n",
    "    return {\n",
    "        \"row\": {\n",
    "            \"Description of Contract\": state[\"text\"],\n",
    "            \"Contract Date\": state[\"date\"],\n",
    "            \"Source Link(s)\": state[\"url\"],\n",
    "            \"Reported Date (By SGA)\": datetime.date.today().isoformat()\n",
    "        }\n",
    "    }\n",
    "\n",
    "# ==========================================================\n",
    "# AGENT 3 ‚Äî GEOGRAPHY\n",
    "# ==========================================================\n",
    "\n",
    "def geography_agent(state: AgentState):\n",
    "    row = state[\"row\"].copy()\n",
    "\n",
    "    if state[\"kb_mode\"] != \"LLM_ONLY\":\n",
    "        for k in [\"Customer Country\", \"Customer Region\",\n",
    "                  \"Customer Operator\", \"Supplier Country\",\n",
    "                  \"Supplier Region\", \"Domestic Content\"]:\n",
    "            if state[\"kb_meta\"].get(k):\n",
    "                row[k] = state[\"kb_meta\"][k]\n",
    "    else:\n",
    "        llm = call_llm(GEOGRAPHY_PROMPT + \"\\n\" + state[\"text\"],backend=\"foundry\" if state[\"kb_mode\"] != \"LLM_ONLY\" else \"openrouter\")\n",
    "\n",
    "    return {\"row\": row}\n",
    "\n",
    "# ==========================================================\n",
    "# AGENT 4 ‚Äî SYSTEM CLASSIFIER\n",
    "# ==========================================================\n",
    "\n",
    "def system_classifier_agent(state: AgentState):\n",
    "    row = state[\"row\"].copy()\n",
    "\n",
    "    if state[\"kb_mode\"] != \"LLM_ONLY\":\n",
    "        for k in [\"Market Segment\", \"System Type (General)\",\n",
    "                  \"System Type (Specific)\", \"System Name (General)\",\n",
    "                  \"System Name (Specific)\", \"System Piloting\"]:\n",
    "            if state[\"kb_meta\"].get(k):\n",
    "                row[k] = state[\"kb_meta\"][k]\n",
    "    else:\n",
    "        llm = call_llm(SYSTEM_CLASSIFIER_PROMPT + \"\\n\" + state[\"text\"],backend=\"foundry\" if state[\"kb_mode\"] != \"LLM_ONLY\" else \"openrouter\")\n",
    "\n",
    "\n",
    "    return {\"row\": row}\n",
    "\n",
    "# ==========================================================\n",
    "# AGENT 5 ‚Äî CONTRACT EXTRACTOR\n",
    "# ==========================================================\n",
    "\n",
    "def contract_extractor_agent(state: AgentState):\n",
    "    row = state[\"row\"].copy()\n",
    "\n",
    "    if state[\"kb_mode\"] != \"LLM_ONLY\":\n",
    "        for k in [\"Supplier Name\", \"Program Type\", \"Value (Million)\",\n",
    "                  \"Value (USD$ Million)\", \"Currency\",\n",
    "                  \"Value Certainty\", \"Quantity\", \"G2G/B2G\"]:\n",
    "            if state[\"kb_meta\"].get(k):\n",
    "                row[k] = state[\"kb_meta\"][k]\n",
    "    else:\n",
    "        llm = call_llm(CONTRACT_EXTRACTOR_PROMPT + \"\\n\" + state[\"text\"],backend=\"openrouter\")\n",
    "\n",
    "    return {\"rows\": [row]}\n",
    "\n",
    "# ==========================================================\n",
    "# AGENT 6 ‚Äî EVALUATION (ALL COLUMNS)\n",
    "# ==========================================================\n",
    "\n",
    "def evaluation_agent(state: AgentState):\n",
    "    evaluated = []\n",
    "\n",
    "    for r in state[\"rows\"]:\n",
    "        row = r.copy()\n",
    "\n",
    "        for col in list(row.keys()):\n",
    "            row[f\"{col} Source\"] = (\n",
    "                \"KB\" if state[\"kb_mode\"] == \"KB_ONLY\"\n",
    "                else \"KB+LLM\" if state[\"kb_mode\"] == \"KB_GUIDED\"\n",
    "                else \"LLM\"\n",
    "            )\n",
    "            row[f\"{col} Confidence\"] = confidence_from_mode(state[\"kb_mode\"])\n",
    "            row[f\"{col} Reason\"] = f\"Mode={state['kb_mode']} KBscore={state['kb_score']:.2f}\"\n",
    "\n",
    "        row[\"Accuracy Score\"] = 90 if state[\"kb_mode\"] == \"KB_ONLY\" else 70 if state[\"kb_mode\"] == \"KB_GUIDED\" else 50\n",
    "        row[\"Evaluation Status\"] = (\n",
    "            \"HIGH CONFIDENCE\" if row[\"Accuracy Score\"] >= 85 else\n",
    "            \"MEDIUM CONFIDENCE\" if row[\"Accuracy Score\"] >= 65 else\n",
    "            \"LOW CONFIDENCE\"\n",
    "        )\n",
    "\n",
    "        evaluated.append(row)\n",
    "\n",
    "    return {\"rows\": evaluated}\n",
    "\n",
    "# ==========================================================\n",
    "# AGENT 7 ‚Äî EXCEL FORMATTER\n",
    "# ==========================================================\n",
    "\n",
    "def excel_formatter_agent(state: AgentState):\n",
    "    df = pd.DataFrame(state[\"rows\"])\n",
    "    df.to_excel(OUTPUT_EXCEL, index=False)\n",
    "\n",
    "    wb = load_workbook(OUTPUT_EXCEL)\n",
    "    ws = wb.active\n",
    "    headers = [c.value for c in ws[1]]\n",
    "\n",
    "    if \"Accuracy Score\" in headers:\n",
    "        idx = headers.index(\"Accuracy Score\") + 1\n",
    "        green = PatternFill(\"solid\", fgColor=\"C6EFCE\")\n",
    "        yellow = PatternFill(\"solid\", fgColor=\"FFEB9C\")\n",
    "        red = PatternFill(\"solid\", fgColor=\"F4CCCC\")\n",
    "\n",
    "        for r in range(2, ws.max_row + 1):\n",
    "            cell = ws.cell(row=r, column=idx)\n",
    "            try:\n",
    "                v = int(cell.value)\n",
    "            except:\n",
    "                continue\n",
    "            cell.fill = green if v >= 85 else yellow if v >= 65 else red\n",
    "\n",
    "    wb.save(OUTPUT_EXCEL)\n",
    "    return {}\n",
    "\n",
    "# ==========================================================\n",
    "# LANGGRAPH\n",
    "# ==========================================================\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"KBRouter\", kb_router_agent)\n",
    "graph.add_node(\"Sourcing\", sourcing_agent)\n",
    "graph.add_node(\"Geography\", geography_agent)\n",
    "graph.add_node(\"System\", system_classifier_agent)\n",
    "graph.add_node(\"Contract\", contract_extractor_agent)\n",
    "graph.add_node(\"Evaluation\", evaluation_agent)\n",
    "graph.add_node(\"ExcelFormatter\", excel_formatter_agent)\n",
    "\n",
    "graph.add_edge(START, \"KBRouter\")\n",
    "graph.add_edge(\"KBRouter\", \"Sourcing\")\n",
    "graph.add_edge(\"Sourcing\", \"Geography\")\n",
    "graph.add_edge(\"Geography\", \"System\")\n",
    "graph.add_edge(\"System\", \"Contract\")\n",
    "graph.add_edge(\"Contract\", \"Evaluation\")\n",
    "graph.add_edge(\"Evaluation\", \"ExcelFormatter\")\n",
    "graph.add_edge(\"ExcelFormatter\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# ==========================================================\n",
    "# MAIN\n",
    "# ==========================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    df = pd.read_excel(INPUT_EXCEL)\n",
    "\n",
    "    for _, r in df.iterrows():\n",
    "        state = {\n",
    "            \"text\": str(r[\"Contract Description\"]),\n",
    "            \"date\": str(r[\"Contract Date\"]),\n",
    "            \"url\": str(r[\"Source URL\"]),\n",
    "            \"row\": {},\n",
    "            \"rows\": [],\n",
    "            \"messages\": []\n",
    "        }\n",
    "\n",
    "        app.invoke(state)\n",
    "\n",
    "    print(\"‚úÖ 7-AGENT DEFENSE PIPELINE EXECUTED SUCCESSFULLY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecabfbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# DEFENSE AGENTIC PIPELINE ‚Äî 7 AGENTS (FINAL)\n",
    "# ==========================================================\n",
    "\n",
    "import os, json, pickle, datetime, getpass\n",
    "from typing import TypedDict, List, Annotated\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# ---------------- LangGraph ----------------\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# ---------------- LLM ----------------\n",
    "from openai import OpenAI\n",
    "\n",
    "# ---------------- Excel ----------------\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "\n",
    "# ==========================================================\n",
    "# CONFIG\n",
    "# ==========================================================\n",
    "\n",
    "INPUT_EXCEL = \"/content/sample_data.xlsx\"\n",
    "OUTPUT_EXCEL = \"Processed_Defense_Data.xlsx\"\n",
    "KB_DIR = \"/content/system_kb_store\"\n",
    "\n",
    "RAG_STRONG = 0.78\n",
    "RAG_MEDIUM = 0.70\n",
    "\n",
    "# ==========================================================\n",
    "# PROMPT PLACEHOLDERS (PASTE YOUR REAL PROMPTS)\n",
    "# ==========================================================\n",
    "\n",
    "GEOGRAPHY_PROMPT = \"\"\"\n",
    "You are a Defense Geography Analyst. \n",
    "Extract the Customer Country, Customer Operator, and Supplier Country from the text.\n",
    "\n",
    "STRICT RULES:\n",
    "1. **Customer Country**: \n",
    "   - Identify the government/nation PAYING for or RECEIVING the goods.\n",
    "   - If \"Foreign Military Sales (FMS)\" is mentioned, look for the specific country name (e.g., \"FMS to Japan\").\n",
    "   - Do NOT assume the \"Work Location\" is the Customer. (e.g., Work in Alabama for a contract supporting the UK -> Customer is UK).\n",
    "\n",
    "2. **Customer Operator**:\n",
    "   - Extract the specific service branch (e.g., \"Navy\", \"Air Force\", \"Army\", \"Coast Guard\", \"Marines\").\n",
    "   - If a specific foreign military branch is named (e.g., \"Royal Australian Air Force\"), extract that.\n",
    "\n",
    "3. **Supplier Country**:\n",
    "   - Identify the country where the Supplier Company's headquarters is located.\n",
    "\n",
    "Return JSON ONLY:\n",
    "{{\n",
    "  \"Customer Country\": \"...\",\n",
    "  \"Customer Operator\": \"...\",\n",
    "  \"Supplier Country\": \"...\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "# --- STAGE 3: SYSTEM CLASSIFIER ---\n",
    "SYSTEM_CLASSIFIER_PROMPT = \"\"\"\n",
    "You are a Senior Defense System Classification Analyst.\n",
    "\n",
    "1. **REFERENCE TAXONOMY**:\n",
    "{taxonomy_reference}\n",
    "\n",
    "2. **RULE BOOK OVERRIDES**:\n",
    "{rule_book_overrides}\n",
    "\n",
    "3. **TASK**:\n",
    "   - Classify the system described in the contract into **Market Segment**, **System Type (General)**, and **System Name**.\n",
    "   - **CRITICAL**: If \"ITEM_FOCUS\" is provided, classify THAT specific item. If empty, classify the main system in the text.\n",
    "   - Use the \"RAG Examples\" provided to guide your choice if the text is similar.\n",
    "\n",
    "4. **CLASSIFICATION RULES**:\n",
    "   - **Generic IT/Enterprise Software**: If the contract is for generic office software (e.g., Microsoft 365, DoD ESI), cloud services, or non-tactical IT, classify Market Segment as **\"Unknown\"** or **\"Not Applicable\"**.\n",
    "   - **Air vs Navy**: If the system is an Aircraft (e.g., P-8, E-2D, F-35), Market Segment is **\"Air Platforms\"**, even if the customer is the Navy.\n",
    "   - **Ship/Submarine**: Market Segment is **\"Naval Platforms\"**.\n",
    "\n",
    "5. **SYSTEM NAME EXTRACTION**:\n",
    "   - **System Name (General)**: The **Host Platform** or **Class** (e.g., \"E-2D Advanced Hawkeye\", \"Arleigh Burke-class\", \"Los Angeles-class\").\n",
    "   - **System Name (Specific)**: The **Specific Subject** of the contract.\n",
    "     - If it's a specific ship/aircraft instance: Extract the name/hull number (e.g., \"USS Pinckney (DDG-91)\", \"USS Hartford (SSN-768)\", \"USNS Robert Ballard (T-AGS 67)\").\n",
    "     - If it's a service/mod description: Extract the description (e.g., \"Extend Services and Adds Hours...\", \"Depot Modernization Period\").\n",
    "     - If it's a component: Extract the component name.\n",
    "\n",
    "6. **OUTPUT RULES**:\n",
    "   - Return ONLY a FLAT JSON object.\n",
    "   - Evidence must be copied EXACTLY from the text.\n",
    "   - If evidence is not present, output \"Not Found\".\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"Market Segment\": \"...\",\n",
    "  \"Market Segment Evidence\": \"...\",\n",
    "  \"Market Segment Reason\": \"...\",\n",
    "  \n",
    "  \"System Type (General)\": \"...\",\n",
    "  \"System Type (General) Evidence\": \"...\",\n",
    "  \"System Type (General) Reason\": \"...\",\n",
    "\n",
    "  \"System Type (Specific)\": \"...\",\n",
    "  \"System Type (Specific) Evidence\": \"...\",\n",
    "  \"System Type (Specific) Reason\": \"...\",\n",
    "\n",
    "  \"System Name (General)\": \"...\",\n",
    "  \"System Name (General) Evidence\": \"...\",\n",
    "  \"System Name (General) Reason\": \"...\",\n",
    "\n",
    "  \"System Name (Specific)\": \"...\",\n",
    "  \"System Name (Specific) Evidence\": \"...\",\n",
    "  \"System Name (Specific) Reason\": \"...\",\n",
    "\n",
    "  \"Confidence\": \"High/Medium/Low\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "CONTRACT_EXTRACTOR_PROMPT = \"\"\"\n",
    "You are a Defense Contract Financial Analyst.\n",
    "\n",
    "1. **TASK**: Extract supplier, program type, financial certainty, FMS status, completion date, and currency.\n",
    "2. **PROGRAM TYPE ENUM**:\n",
    "   {program_type_enum}\n",
    "\n",
    "3. **STRICT RULES**:\n",
    "   - **Supplier Name**: Extract the **Clean Entity Name**. Include the **Major Division** if specified (e.g., \"General Dynamics Electric Boat\", \"Northrop Grumman Aerospace\"). Do not include legal suffixes like \"Corp\", \"Inc\", \"L.P.\" unless part of the brand.\n",
    "   - **Program Type**:\n",
    "     - **MRO/Support**: Includes \"depot modernization\", \"maintenance\", \"overhaul\", \"repair\", \"sustainment\", \"logistics support\".\n",
    "     - **Procurement**: Includes \"production\", \"manufacture\", \"delivery\" of new hardware.\n",
    "     - **RDT&E**: Research, development, prototyping.\n",
    "   - **Value Certainty**: \n",
    "     - \"Confirmed\" for definite contracts/mods.\n",
    "     - \"Estimated\" for IDIQ ceilings, \"potential value\", or \"maximum value\".\n",
    "   - **G2G/B2G**: \"G2G\" ONLY if \"Foreign Military Sales\" (FMS) is explicitly mentioned. Otherwise \"B2G\".\n",
    "   - **Value Note**: Capture notes about IDIQs, options, or ceilings.\n",
    "\n",
    "Return JSON ONLY:\n",
    "{{\n",
    "  \"program_type\": \"...\",\n",
    "  \"currency_code\": \"...\",\n",
    "  \"value_certainty\": \"...\",\n",
    "  \"completion_date_text\": \"...\",\n",
    "  \"g2g_b2g\": \"...\",\n",
    "  \"value_note\": \"...\",\n",
    "  \"extracted_supplier\": \"...\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "# ==========================================================\n",
    "# LLM CLIENT\n",
    "# ==========================================================\n",
    "\n",
    "if \"LLMFOUNDRY_TOKEN\" not in os.environ:\n",
    "    os.environ[\"LLMFOUNDRY_TOKEN\"] = getpass.getpass(\"Enter LLM Foundry API Key: \")\n",
    "\n",
    "if \"OPENROUTER_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENROUTER_API_KEY\"] = getpass.getpass(\"Enter OpenRouter API Key: \")\n",
    "\n",
    "# ===== LLM FOUNDRY (PRIMARY ‚Äì INTERNAL) =====\n",
    "llm_foundry_client = OpenAI(\n",
    "    api_key=f'{os.environ[\"LLMFOUNDRY_TOKEN\"]}:agentic',\n",
    "    base_url=\"https://llmfoundry.straive.com/openai/v1/\"\n",
    ")\n",
    "\n",
    "FOUNDRY_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "\n",
    "# ===== OPENROUTER (SECONDARY / FALLBACK / COMPARISON) =====\n",
    "openrouter_client = OpenAI(\n",
    "    api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
    "    base_url=\"https://openrouter.ai/api/v1\"\n",
    ")\n",
    "\n",
    "OPENROUTER_MODEL = \"openai/gpt-4o-mini\"\n",
    "\n",
    "def call_llm(\n",
    "    prompt: str,\n",
    "    backend: str = \"foundry\",   # \"foundry\" | \"openrouter\"\n",
    "    max_tokens: int = 500\n",
    "):\n",
    "    \"\"\"\n",
    "    Unified LLM call wrapper.\n",
    "    You decide backend per agent / per confidence / per column.\n",
    "    \"\"\"\n",
    "\n",
    "    if backend == \"openrouter\":\n",
    "        client = openrouter_client\n",
    "        model = OPENROUTER_MODEL\n",
    "    else:\n",
    "        client = llm_foundry_client\n",
    "        model = FOUNDRY_MODEL\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=max_tokens,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    return json.loads(response.choices[0].message.content)\n",
    "# ==========================================================\n",
    "# KB RETRIEVER\n",
    "# ==========================================================\n",
    "\n",
    "class KBRetriever:\n",
    "    def __init__(self, kb_dir):\n",
    "        self.index = faiss.read_index(os.path.join(kb_dir, \"system_kb.faiss\"))\n",
    "        with open(os.path.join(kb_dir, \"system_kb_meta.pkl\"), \"rb\") as f:\n",
    "            self.meta = pickle.load(f)\n",
    "        self.embedder = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "    def best_hit(self, text):\n",
    "        emb = self.embedder.encode([text], normalize_embeddings=True).astype(\"float32\")\n",
    "        scores, idxs = self.index.search(emb, 1)\n",
    "        if idxs[0][0] < 0:\n",
    "            return {}, 0.0, None\n",
    "        return self.meta[idxs[0][0]], float(scores[0][0]), idxs[0][0]\n",
    "\n",
    "retriever = KBRetriever(KB_DIR)\n",
    "\n",
    "# ==========================================================\n",
    "# MODE / CONFIDENCE\n",
    "# ==========================================================\n",
    "\n",
    "def mode_from_score(score):\n",
    "    if score >= RAG_STRONG:\n",
    "        return \"KB_ONLY\"\n",
    "    if score >= RAG_MEDIUM:\n",
    "        return \"KB_GUIDED\"\n",
    "    return \"LLM_ONLY\"\n",
    "\n",
    "def confidence_from_mode(mode):\n",
    "    return {\n",
    "        \"KB_ONLY\": \"High (KB)\",\n",
    "        \"KB_GUIDED\": \"Medium (KB+LLM)\",\n",
    "        \"LLM_ONLY\": \"Low (LLM)\"\n",
    "    }.get(mode, \"Unknown\")\n",
    "\n",
    "# ==========================================================\n",
    "# AGENT STATE\n",
    "# ==========================================================\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    text: str\n",
    "    date: str\n",
    "    url: str\n",
    "\n",
    "    kb_meta: dict\n",
    "    kb_score: float\n",
    "    kb_mode: str\n",
    "    kb_row_id: int | None\n",
    "\n",
    "    row: dict\n",
    "    rows: list\n",
    "\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "\n",
    "# ==========================================================\n",
    "# AGENT 1 ‚Äî KB ROUTER\n",
    "# ==========================================================\n",
    "\n",
    "def kb_router_agent(state: AgentState):\n",
    "    meta, score, row_id = retriever.best_hit(state[\"text\"])\n",
    "    return {\n",
    "        \"kb_meta\": meta,\n",
    "        \"kb_score\": score,\n",
    "        \"kb_mode\": mode_from_score(score),\n",
    "        \"kb_row_id\": row_id\n",
    "    }\n",
    "\n",
    "# ==========================================================\n",
    "# AGENT 2 ‚Äî SOURCING\n",
    "# ==========================================================\n",
    "\n",
    "def sourcing_agent(state: AgentState):\n",
    "    return {\n",
    "        \"row\": {\n",
    "            \"Description of Contract\": state[\"text\"],\n",
    "            \"Contract Date\": state[\"date\"],\n",
    "            \"Source Link(s)\": state[\"url\"],\n",
    "            \"Reported Date (By SGA)\": datetime.date.today().isoformat()\n",
    "        }\n",
    "    }\n",
    "\n",
    "# ==========================================================\n",
    "# AGENT 3 ‚Äî GEOGRAPHY\n",
    "# ==========================================================\n",
    "\n",
    "def geography_agent(state: AgentState):\n",
    "    row = state[\"row\"].copy()\n",
    "\n",
    "    if state[\"kb_mode\"] != \"LLM_ONLY\":\n",
    "        for k in [\"Customer Country\", \"Customer Region\",\n",
    "                  \"Customer Operator\", \"Supplier Country\",\n",
    "                  \"Supplier Region\", \"Domestic Content\"]:\n",
    "            if state[\"kb_meta\"].get(k):\n",
    "                row[k] = state[\"kb_meta\"][k]\n",
    "    else:\n",
    "        llm = call_llm(GEOGRAPHY_PROMPT + \"\\n\" + state[\"text\"],backend=\"foundry\" if state[\"kb_mode\"] != \"LLM_ONLY\" else \"openrouter\")\n",
    "\n",
    "    return {\"row\": row}\n",
    "\n",
    "# ==========================================================\n",
    "# AGENT 4 ‚Äî SYSTEM CLASSIFIER\n",
    "# ==========================================================\n",
    "\n",
    "def system_classifier_agent(state: AgentState):\n",
    "    row = state[\"row\"].copy()\n",
    "\n",
    "    if state[\"kb_mode\"] != \"LLM_ONLY\":\n",
    "        for k in [\"Market Segment\", \"System Type (General)\",\n",
    "                  \"System Type (Specific)\", \"System Name (General)\",\n",
    "                  \"System Name (Specific)\", \"System Piloting\"]:\n",
    "            if state[\"kb_meta\"].get(k):\n",
    "                row[k] = state[\"kb_meta\"][k]\n",
    "    else:\n",
    "        llm = call_llm(SYSTEM_CLASSIFIER_PROMPT + \"\\n\" + state[\"text\"],backend=\"foundry\" if state[\"kb_mode\"] != \"LLM_ONLY\" else \"openrouter\")\n",
    "\n",
    "\n",
    "    return {\"row\": row}\n",
    "\n",
    "# ==========================================================\n",
    "# AGENT 5 ‚Äî CONTRACT EXTRACTOR\n",
    "# ==========================================================\n",
    "\n",
    "def contract_extractor_agent(state: AgentState):\n",
    "    row = state[\"row\"].copy()\n",
    "\n",
    "    if state[\"kb_mode\"] != \"LLM_ONLY\":\n",
    "        for k in [\"Supplier Name\", \"Program Type\", \"Value (Million)\",\n",
    "                  \"Value (USD$ Million)\", \"Currency\",\n",
    "                  \"Value Certainty\", \"Quantity\", \"G2G/B2G\"]:\n",
    "            if state[\"kb_meta\"].get(k):\n",
    "                row[k] = state[\"kb_meta\"][k]\n",
    "    else:\n",
    "        llm = call_llm(CONTRACT_EXTRACTOR_PROMPT + \"\\n\" + state[\"text\"],backend=\"openrouter\")\n",
    "\n",
    "    return {\"rows\": [row]}\n",
    "\n",
    "# ==========================================================\n",
    "# AGENT 6 ‚Äî EVALUATION (ALL COLUMNS)\n",
    "# ==========================================================\n",
    "\n",
    "def evaluation_agent(state: AgentState):\n",
    "    evaluated = []\n",
    "\n",
    "    for r in state[\"rows\"]:\n",
    "        row = r.copy()\n",
    "\n",
    "        for col in list(row.keys()):\n",
    "            row[f\"{col} Source\"] = (\n",
    "                \"KB\" if state[\"kb_mode\"] == \"KB_ONLY\"\n",
    "                else \"KB+LLM\" if state[\"kb_mode\"] == \"KB_GUIDED\"\n",
    "                else \"LLM\"\n",
    "            )\n",
    "            row[f\"{col} Confidence\"] = confidence_from_mode(state[\"kb_mode\"])\n",
    "            row[f\"{col} Reason\"] = f\"Mode={state['kb_mode']} KBscore={state['kb_score']:.2f}\"\n",
    "\n",
    "        row[\"Accuracy Score\"] = 90 if state[\"kb_mode\"] == \"KB_ONLY\" else 70 if state[\"kb_mode\"] == \"KB_GUIDED\" else 50\n",
    "        row[\"Evaluation Status\"] = (\n",
    "            \"HIGH CONFIDENCE\" if row[\"Accuracy Score\"] >= 85 else\n",
    "            \"MEDIUM CONFIDENCE\" if row[\"Accuracy Score\"] >= 65 else\n",
    "            \"LOW CONFIDENCE\"\n",
    "        )\n",
    "\n",
    "        evaluated.append(row)\n",
    "\n",
    "    return {\"rows\": evaluated}\n",
    "\n",
    "# ==========================================================\n",
    "# AGENT 7 ‚Äî EXCEL FORMATTER\n",
    "# ==========================================================\n",
    "\n",
    "def excel_formatter_agent(state: AgentState):\n",
    "    df = pd.DataFrame(state[\"rows\"])\n",
    "    df.to_excel(OUTPUT_EXCEL, index=False)\n",
    "\n",
    "    wb = load_workbook(OUTPUT_EXCEL)\n",
    "    ws = wb.active\n",
    "    headers = [c.value for c in ws[1]]\n",
    "\n",
    "    if \"Accuracy Score\" in headers:\n",
    "        idx = headers.index(\"Accuracy Score\") + 1\n",
    "        green = PatternFill(\"solid\", fgColor=\"C6EFCE\")\n",
    "        yellow = PatternFill(\"solid\", fgColor=\"FFEB9C\")\n",
    "        red = PatternFill(\"solid\", fgColor=\"F4CCCC\")\n",
    "\n",
    "        for r in range(2, ws.max_row + 1):\n",
    "            cell = ws.cell(row=r, column=idx)\n",
    "            try:\n",
    "                v = int(cell.value)\n",
    "            except:\n",
    "                continue\n",
    "            cell.fill = green if v >= 85 else yellow if v >= 65 else red\n",
    "\n",
    "    wb.save(OUTPUT_EXCEL)\n",
    "    return {}\n",
    "\n",
    "# ==========================================================\n",
    "# LANGGRAPH\n",
    "# ==========================================================\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"KBRouter\", kb_router_agent)\n",
    "graph.add_node(\"Sourcing\", sourcing_agent)\n",
    "graph.add_node(\"Geography\", geography_agent)\n",
    "graph.add_node(\"System\", system_classifier_agent)\n",
    "graph.add_node(\"Contract\", contract_extractor_agent)\n",
    "graph.add_node(\"Evaluation\", evaluation_agent)\n",
    "graph.add_node(\"ExcelFormatter\", excel_formatter_agent)\n",
    "\n",
    "graph.add_edge(START, \"KBRouter\")\n",
    "graph.add_edge(\"KBRouter\", \"Sourcing\")\n",
    "graph.add_edge(\"Sourcing\", \"Geography\")\n",
    "graph.add_edge(\"Geography\", \"System\")\n",
    "graph.add_edge(\"System\", \"Contract\")\n",
    "graph.add_edge(\"Contract\", \"Evaluation\")\n",
    "graph.add_edge(\"Evaluation\", \"ExcelFormatter\")\n",
    "graph.add_edge(\"ExcelFormatter\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "display(Image(app.get_graph().draw_mermaid_png()))\n",
    "# ==========================================================\n",
    "# MAIN\n",
    "# ==========================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    df = pd.read_excel(INPUT_EXCEL)\n",
    "    all_rows = []\n",
    "\n",
    "    for i, r in df.iterrows():\n",
    "        print(f\"Processing row {i + 1}/{len(df)}\")\n",
    "\n",
    "        state = {\n",
    "            \"text\": str(r[\"Contract Description\"]),\n",
    "            \"date\": str(r[\"Contract Date\"]),\n",
    "            \"url\": str(r[\"Source URL\"]),\n",
    "            \"row\": {},\n",
    "            \"rows\": [],\n",
    "            \"messages\": []\n",
    "        }\n",
    "\n",
    "        output_state = app.invoke(state)\n",
    "\n",
    "        if \"rows\" in output_state and isinstance(output_state[\"rows\"], list):\n",
    "            all_rows.extend(output_state[\"rows\"])\n",
    "        elif \"row\" in output_state and isinstance(output_state[\"row\"], dict):\n",
    "            all_rows.append(output_state[\"row\"])\n",
    "\n",
    "    # ==========================\n",
    "    # ENSURE ALL COLUMNS\n",
    "    # ==========================\n",
    "    all_columns = set()\n",
    "    for row in all_rows:\n",
    "        all_columns.update(row.keys())\n",
    "\n",
    "    df_out = pd.DataFrame(all_rows)\n",
    "    df_out = df_out.reindex(columns=sorted(all_columns), fill_value=\"\")\n",
    "\n",
    "    # ==========================\n",
    "    # SAVE EXCEL\n",
    "    # ==========================\n",
    "    print(f\"\\nSaving output to: {OUTPUT_EXCEL}\")\n",
    "    df_out.to_excel(OUTPUT_EXCEL, index=False)\n",
    "\n",
    "    # ==========================\n",
    "    # CONDITIONAL FORMATTING\n",
    "    # ==========================\n",
    "    wb = load_workbook(OUTPUT_EXCEL)\n",
    "    ws = wb.active\n",
    "\n",
    "    headers = [c.value for c in ws[1]]\n",
    "    if \"Accuracy Score\" in headers:\n",
    "        idx = headers.index(\"Accuracy Score\") + 1\n",
    "        green = PatternFill(\"solid\", fgColor=\"C6EFCE\")\n",
    "        yellow = PatternFill(\"solid\", fgColor=\"FFEB9C\")\n",
    "        red = PatternFill(\"solid\", fgColor=\"F4CCCC\")\n",
    "\n",
    "        for r in range(2, ws.max_row + 1):\n",
    "            cell = ws.cell(row=r, column=idx)\n",
    "            try:\n",
    "                v = int(cell.value)\n",
    "            except:\n",
    "                continue\n",
    "            cell.fill = green if v >= 85 else yellow if v >= 65 else red\n",
    "\n",
    "    wb.save(OUTPUT_EXCEL)\n",
    "\n",
    "    print(\"‚úÖ ALL COLUMNS SAVED + EXCEL GENERATED SUCCESSFULLY\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
