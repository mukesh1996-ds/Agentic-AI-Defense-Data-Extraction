{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b965354",
   "metadata": {},
   "source": [
    "## **Stage-1**\n",
    "\n",
    "Creating a knowledge base system which will act as brain to my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd9f3f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loading Excel Knowledge Base: C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\data\\sample_data.xlsx\n",
      "Loaded rows=2068 col=29\n",
      "KB rows kept after cleaning: 600\n",
      "Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: b94d340d-9491-4534-9001-a3ba8a140304)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.32s/it]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.28s/it]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.20s/it]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.22s/it]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.27s/it]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.32s/it]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.31s/it]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.35s/it]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.28s/it]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Shape:(600, 384)\n",
      "System KB Created Successfully!\n",
      "Index saved: system_kb_store\\system_kb.faiss\n",
      "Meta Saved: system_kb_store\\system_kb_meta.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "## Configuration \n",
    "DEFAULT_MODEL_NAME=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "def clean_text(text:str) -> str:\n",
    "    \"\"\"This function is used to clean the entire text [description]\"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    text = re.sub(r'\\s+',' ',text).strip()\n",
    "    return text\n",
    "\n",
    "def safe_to_str(x):\n",
    "    \"\"\"This is a helper function\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    return str(x).strip()\n",
    "\n",
    "def build_system_kb_store_all_columns(\n",
    "        excel_path: str,\n",
    "        save_dir: str = \"system_kb_store\",\n",
    "        model_name: str = DEFAULT_MODEL_NAME,\n",
    "        batch_size: int = 64,\n",
    "        embed_column: str = 'Description of Contract'\n",
    "):\n",
    "    \"\"\"This function will create embedding on my description for my knowledge base\"\"\"\n",
    "    os.makedirs(save_dir,exist_ok=True)\n",
    "    print(f\"\\n Loading Excel Knowledge Base: {excel_path}\")\n",
    "    df = pd.read_excel(excel_path)\n",
    "    print(f\"Loaded rows={len(df)} col={len(df.columns)}\")\n",
    "\n",
    "    if embed_column not in df.columns:\n",
    "        raise ValueError(f\"Embed column '{embed_column}' not found in Excel!\")\n",
    "    \n",
    "    df = df.fillna('')\n",
    "    kb_texts=[]\n",
    "    kb_meta=[]\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        desc=clean_text(row[embed_column])\n",
    "        if not desc or len(desc) < 20:\n",
    "            continue\n",
    "        meta = {'row_id':int(idx)}\n",
    "        for col in df.columns:\n",
    "            meta[col]=safe_to_str(row[col])\n",
    "        meta[embed_column]=desc\n",
    "        kb_texts.append(desc)\n",
    "        kb_meta.append(meta)\n",
    "    print(f\"KB rows kept after cleaning: {len(kb_texts)}\")\n",
    "    if len(kb_texts) == 0:\n",
    "        print(\"ERROR:No text rows remained after cleaning. Check your 'clean_text' logic or input data.\")\n",
    "        return None, None\n",
    "    print(f\"Loading embedding model: {model_name}\")\n",
    "    embedder=SentenceTransformer(model_name)\n",
    "    print(\"Creating Embeddings...\")\n",
    "    embeddings=[]\n",
    "    for i in range(0,len(kb_texts),batch_size):\n",
    "        batch=kb_texts[i:i + batch_size]\n",
    "        batch_emb=embedder.encode(batch,show_progress_bar=True,normalize_embeddings=True)\n",
    "        embeddings.append(batch_emb)\n",
    "    embeddings=np.vstack(embeddings).astype('float32')\n",
    "    dim=embeddings.shape[1]\n",
    "    print(f\"Embedding Shape:{embeddings.shape}\")\n",
    "    index=faiss.IndexFlatIP(dim)\n",
    "    index.add(embeddings)\n",
    "    index_path=os.path.join(save_dir,\"system_kb.faiss\")\n",
    "    meta_path=os.path.join(save_dir,'system_kb_meta.pkl')\n",
    "    faiss.write_index(index,index_path)\n",
    "    with open(meta_path,'wb') as f:\n",
    "        pickle.dump(kb_meta,f)\n",
    "    print(\"System KB Created Successfully!\")\n",
    "    print(f\"Index saved: {index_path}\")\n",
    "    print(f\"Meta Saved: {meta_path}\")\n",
    "    return index_path, meta_path\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    EXCEL_PATH=r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\data\\sample_data.xlsx\"\n",
    "    build_system_kb_store_all_columns(\n",
    "        excel_path=EXCEL_PATH,\n",
    "        save_dir='system_kb_store',\n",
    "        model_name=DEFAULT_MODEL_NAME,\n",
    "        batch_size=64,\n",
    "        embed_column=\"Description of Contract\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96bfed05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: a7b0a49c-5ed7-4137-a283-22884e9d1ce4)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS index: system_kb_store\\system_kb.faiss\n",
      "Loading metadata: system_kb_store\\system_kb_meta.pkl\n",
      "Loaded KB rows: 600\n",
      "Loading embedder: sentence-transformers/all-MiniLM-L6-v2\n",
      "\n",
      "Score: 0.6228203773498535\n",
      "Supplier: Dell Inc\n",
      "Market: Unknown\n",
      "System: Department of Defense Enterprise Software Initiative (DOD ESI)\n",
      "\n",
      "Score: 0.6228203773498535\n",
      "Supplier: Dell Inc\n",
      "Market: Unknown\n",
      "System: Department of Defense Enterprise Software Initiative (DOD ESI)\n",
      "\n",
      "Score: 0.6024371385574341\n",
      "Supplier: \n",
      "Market: Unknown\n",
      "System: Department of Defense Enterprise Software Initiative (DOD ESI)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pickle\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "DEFAULT_MODEL_NAME='sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "class SystemKBRetriever:\n",
    "    def __init__(self, kb_dir='system_kb_store', model_name=DEFAULT_MODEL_NAME):\n",
    "        index_path = os.path.join(kb_dir, 'system_kb.faiss')\n",
    "        meta_path = os.path.join(kb_dir, 'system_kb_meta.pkl')\n",
    "\n",
    "        if not os.path.exists(index_path) or not os.path.exists(meta_path):\n",
    "            raise FileNotFoundError(\"KB files are missing. Build KB first.\")\n",
    "        \n",
    "        print(f\"Loading FAISS index: {index_path}\")\n",
    "        self.index = faiss.read_index(index_path)\n",
    "        \n",
    "        print(f\"Loading metadata: {meta_path}\")\n",
    "        with open(meta_path, 'rb') as f:\n",
    "            self.meta = pickle.load(f)\n",
    "            \n",
    "        print(f\"Loaded KB rows: {len(self.meta)}\")\n",
    "        print(f\"Loading embedder: {model_name}\")\n",
    "        self.embedder = SentenceTransformer(model_name)\n",
    "    \n",
    "    def retrieve(self, query_text: str, top_k: int = 5):\n",
    "        # FIX 1: Do not use .split(). We want to embed the whole sentence, not a list of words.\n",
    "        query_text = str(query_text).strip()\n",
    "        \n",
    "        if not query_text:\n",
    "            return []\n",
    "        \n",
    "        # Encode returns shape (1, 384) because we pass a list with 1 string\n",
    "        q_emb = self.embedder.encode([query_text], normalize_embeddings=True).astype('float32')\n",
    "        \n",
    "        scores, idxs = self.index.search(q_emb, top_k)\n",
    "        results = []\n",
    "        \n",
    "        # FIX 2: Corrected typo 'socre' -> 'score'\n",
    "        for score, idx in zip(scores[0], idxs[0]):\n",
    "            if idx < 0:\n",
    "                continue\n",
    "            results.append({\n",
    "                'score': float(score),  # FIX 3: Use individual 'score', not the array 'scores'\n",
    "                \"meta\": self.meta[idx]\n",
    "            })\n",
    "        return results\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    # Ensure the directory exists and contains files created by the builder script\n",
    "    if os.path.exists('system_kb_store'):\n",
    "        r = SystemKBRetriever(kb_dir='system_kb_store')\n",
    "        q = 'Dell Marketing L.P., Round Rock, Texas, is awarded a single-award, firm-fixed-price blanket purchase agreement'\n",
    "        \n",
    "        hits = r.retrieve(q, top_k=3)\n",
    "\n",
    "        for h in hits:\n",
    "            print(\"\\nScore:\", h['score'])\n",
    "            print(\"Supplier:\", h['meta'].get('Supplier Name'))\n",
    "            print(\"Market:\", h['meta'].get(\"Market Segment\"))\n",
    "            print(\"System:\", h['meta'].get('System Name (Specific)'))\n",
    "    else:\n",
    "        print(\"Error: 'system_kb_store' directory not found. Please run the builder script first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5a89f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS Index: C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\system_kb_store\\system_kb.faiss\n",
      "Loading KB Metadata: C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\system_kb_store\\system_kb_meta.pkl\n",
      "KB Loaded: 600 rows\n",
      "Loaded C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\taxonomy.json\n",
      "Loaded C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\suppliers.json\n",
      "Loading Input File: C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\data\\source_file.xlsx...\n",
      "üöÄ Processing 1 rows...\n",
      "   -> Row 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mukeshkr\\AppData\\Local\\Temp\\ipykernel_19764\\1953562160.py:184: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  start = pd.to_datetime(start_date_str, dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing Complete!\n",
      "File saved to: Processed_Defense_Data.xlsx\n",
      "  Customer Region Customer Country Customer Operator Supplier Region Supplier Country Domestic Content   Market Segment                                                                                                                                                                                                   Market Segment Evidence                                          Market Segment Reason System Type (General)                                                                                                                                                                                            System Type (General) Evidence                                                  System Type (General) Reason System Type (Specific)                                                                                                                                                                                           System Type (Specific) Evidence                                                         System Type (Specific) Reason System Name (General)                                                                                                                                                                                            System Name (General) Evidence                            System Name (General) Reason System Name (Specific)                                                                                                                                                                                           System Name (Specific) Evidence                                        System Name (Specific) Reason System Piloting System Piloting Evidence                                           System Piloting Reason Confidence                      Supplier Name Program Type Expected MRO Contract Duration (Months)        Quantity Value Certainty Value (Million) Currency Value (USD$ Million)                                          Value Note (If Any) G2G/B2G Signing Month Signing Year                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Description of Contract Additional Notes (Internal Only)                                                Source Link(s)        Contract Date Reported Date (By SGA)\n",
      "0   North America    United States              Navy   North America    United States       Indigenous  Naval Platforms  BAE Systems - Norfolk Ship Repair, Norfolk, Virginia, is awarded a $107,736,087, firm-fixed-price contract for the execution of the USS Ross (DDG 71) fiscal 2023 extended dry-docking selected restricted availability.  Matched with similar examples in the Naval Platforms segment.    Surface Combatants  BAE Systems - Norfolk Ship Repair, Norfolk, Virginia, is awarded a $107,736,087, firm-fixed-price contract for the execution of the USS Ross (DDG 71) fiscal 2023 extended dry-docking selected restricted availability.  Aligned with the general type of Surface Combatants as per similar examples.             Destroyers  BAE Systems - Norfolk Ship Repair, Norfolk, Virginia, is awarded a $107,736,087, firm-fixed-price contract for the execution of the USS Ross (DDG 71) fiscal 2023 extended dry-docking selected restricted availability.  Specific type identified as Destroyers, consistent with the USS Ross classification.   Arleigh Burke-class  BAE Systems - Norfolk Ship Repair, Norfolk, Virginia, is awarded a $107,736,087, firm-fixed-price contract for the execution of the USS Ross (DDG 71) fiscal 2023 extended dry-docking selected restricted availability.  General name corresponds to the class of the USS Ross.      USS Ross (DDG-71)  BAE Systems - Norfolk Ship Repair, Norfolk, Virginia, is awarded a $107,736,087, firm-fixed-price contract for the execution of the USS Ross (DDG 71) fiscal 2023 extended dry-docking selected restricted availability.  Exact match with the specific system name provided in the evidence.          Crewed                   Crewed  Confirmed piloting type as crewed based on rule-based piloting.       High  BAE Systems - Norfolk Ship Repair  MRO/Support                                      19  Not Applicable       Confirmed         107.736      USD              107.736  Cumulative value if options exercised would be $123,876,183     B2G        August         2022  BAE Systems - Norfolk Ship Repair, Norfolk, Virginia, is awarded a $107,736,087, firm-fixed-price contract for the execution of the USS Ross (DDG 71) fiscal 2023 extended dry-docking selected restricted availability. This availability will include a combination of maintenance, modernization and repair of the USS Ross. This contract includes options which, if exercised, would bring the cumulative value of this contract to $123,876,183. Work will be performed in Norfolk, Virginia, and is expected to be completed by March 2024. Fiscal 2022 operations and maintenance (Navy) funds in the amount of $93,897,036 (87%); and fiscal 2022 other procurement (Navy) funds in the amount of $13,839,051 (13%) will be obligated at time of award, of which $93,897,036 will expire at the end of the current fiscal year. This contract was competitively procured using full and open competition via the System for Award Management website. Competitive proposals were received in response to Solicitation Number (N00024-22-R-4422). The Naval Sea Systems Command, Washington, D.C., is the contracting activity (N00024-22-C-4422).             Standard extraction.  https://www.war.gov/News/Contracts/Contract/Article/3134553/  2022-08-19 00:00:00             2026-01-23\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import difflib\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import getpass\n",
    "from typing import Annotated, TypedDict, List\n",
    "import re\n",
    "import pickle\n",
    "import faiss\n",
    "\n",
    "# LangChain / LangGraph Imports\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "\n",
    "# ==============================================================================\n",
    "# RAG RETRIEVER (Single File Implementation)\n",
    "# ==============================================================================\n",
    "\n",
    "class SystemKBRetriever:\n",
    "    \"\"\"\n",
    "    Loads FAISS index + metadata created from your KB excel.\n",
    "    Uses ONLY the contract paragraph to retrieve similar examples.\n",
    "    \"\"\"\n",
    "    def __init__(self, kb_dir: str):\n",
    "        index_path = os.path.join(kb_dir, \"system_kb.faiss\")\n",
    "        meta_path = os.path.join(kb_dir, \"system_kb_meta.pkl\")\n",
    "\n",
    "        if not os.path.exists(index_path) or not os.path.exists(meta_path):\n",
    "            raise FileNotFoundError(\n",
    "                f\"‚ùå KB files not found in: {kb_dir}\\n\"\n",
    "                f\"Expected:\\n- {index_path}\\n- {meta_path}\\n\\n\"\n",
    "                f\"Build the KB first using your KB builder script.\"\n",
    "            )\n",
    "\n",
    "        print(f\"Loading FAISS Index: {index_path}\")\n",
    "        self.index = faiss.read_index(index_path)\n",
    "\n",
    "        print(f\"Loading KB Metadata: {meta_path}\")\n",
    "        with open(meta_path, \"rb\") as f:\n",
    "            self.meta = pickle.load(f)\n",
    "\n",
    "        print(f\"KB Loaded: {len(self.meta)} rows\")\n",
    "\n",
    "    def retrieve(self, query_text: str, top_k: int = 3):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        [\n",
    "          {\"score\": float, \"meta\": {...all 29 cols...}},\n",
    "          ...\n",
    "        ]\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "\n",
    "        query_text = str(query_text).strip()\n",
    "        if not query_text:\n",
    "            return []\n",
    "\n",
    "        # Use embedding model only when needed (lazy load)\n",
    "        if not hasattr(self, \"embedder\"):\n",
    "            self.embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "        q_emb = self.embedder.encode([query_text], normalize_embeddings=True).astype(\"float32\")\n",
    "        scores, idxs = self.index.search(q_emb, top_k)\n",
    "\n",
    "        results = []\n",
    "        for score, idx in zip(scores[0], idxs[0]):\n",
    "            if idx < 0:\n",
    "                continue\n",
    "            results.append({\n",
    "                \"score\": float(score),\n",
    "                \"meta\": self.meta[idx]\n",
    "            })\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. CONFIGURATION & FILE PATHS\n",
    "# ==============================================================================\n",
    "\n",
    "# UPDATE PATHS HERE\n",
    "TAXONOMY_PATH = r'C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\taxonomy.json'\n",
    "SUPPLIERS_PATH = r'C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\suppliers.json'\n",
    "INPUT_EXCEL_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\data\\source_file.xlsx\"\n",
    "OUTPUT_EXCEL_PATH = \"Processed_Defense_Data.xlsx\"\n",
    "\n",
    "# RAG KB Directory (must contain system_kb.faiss + system_kb_meta.pkl)\n",
    "RAG_KB_DIR = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\system_kb_store\"\n",
    "\n",
    "# Setup API Key\n",
    "if \"LLMFOUNDRY_TOKEN\" not in os.environ:\n",
    "    os.environ[\"LLMFOUNDRY_TOKEN\"] = getpass.getpass(\"Enter the LLM Foundry API Key: \")\n",
    "\n",
    "# Shared Client\n",
    "client = OpenAI(\n",
    "    api_key=f'{os.environ.get(\"LLMFOUNDRY_TOKEN\")}:my-test-project',\n",
    "    base_url=\"https://llmfoundry.straive.com/openai/v1/\",\n",
    ")\n",
    "\n",
    "# Load retriever once globally\n",
    "retriever = SystemKBRetriever(kb_dir=RAG_KB_DIR)\n",
    "\n",
    "# --- FILE LOADING HELPERS ---\n",
    "def load_json_file(filename, default_value):\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            print(f\"Loaded {filename}\")\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load {filename} ({e}). Using default.\")\n",
    "        return default_value\n",
    "\n",
    "# 1. Load Taxonomy\n",
    "raw_taxonomy = load_json_file(TAXONOMY_PATH, {})\n",
    "TAXONOMY_STR = json.dumps(raw_taxonomy, separators=(',', ':'))\n",
    "\n",
    "# 2. Load Suppliers\n",
    "SUPPLIER_LIST = load_json_file(SUPPLIERS_PATH, [\n",
    "    \"Dell Inc\", \"Boeing\", \"Lockheed Martin\", \"Raytheon Technologies\",\n",
    "    \"Northrop Grumman\", \"L3Harris\", \"BAE Systems\", \"General Dynamics\"\n",
    "])\n",
    "\n",
    "# 3. System Rules\n",
    "RULE_BOOK = {\n",
    "    \"defensive_countermeasures\": {\n",
    "        \"triggers\": [\"flare\", \"chaff\", \"countermeasure\", \"decoy\", \"mju-\", \"ale-\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Defensive Systems', Specific: 'Defensive Aid Suite'\"\n",
    "    },\n",
    "    \"radars_and_sensors\": {\n",
    "        \"triggers\": [\"radar\", \"sonar\", \"sensor\", \"an/apy\", \"an/tpy\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Sensors'\"\n",
    "    },\n",
    "    \"ammunition\": {\n",
    "        \"triggers\": [\"cartridge\", \"round\", \"projectile\", \" 5.56\", \" 7.62\", \"ammo\"],\n",
    "        \"guidance\": \"Market Segment: 'Weapon Systems', System Type (General): 'Ammunition'\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# 4. Geography Mapping\n",
    "GEOGRAPHY_MAPPING = {\n",
    "    \"North America\": [\"USA\", \"United States\", \"US\", \"Canada\", \"America\"],\n",
    "    \"Europe\": [\"UK\", \"United Kingdom\", \"Ukraine\", \"Germany\", \"France\", \"Italy\", \"Spain\", \"Poland\", \"Netherlands\", \"Norway\", \"Sweden\", \"Finland\", \"Denmark\", \"Belgium\"],\n",
    "    \"Asia-Pacific\": [\"Australia\", \"Japan\", \"South Korea\", \"Taiwan\", \"India\", \"Singapore\", \"New Zealand\"],\n",
    "    \"Middle East and North Africa\": [\"Israel\", \"Saudi Arabia\", \"UAE\", \"Egypt\", \"Qatar\", \"Kuwait\", \"Iraq\"],\n",
    "    \"International Organisations\": [\"NATO\", \"EU\", \"IFU\", \"UN\", \"NSPA\"]\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. HELPER FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def get_best_supplier_match(extracted_name):\n",
    "    \"\"\"Fuzzy matches the extracted name against the loaded SUPPLIER_LIST.\"\"\"\n",
    "    if not extracted_name or extracted_name.lower() in [\"unknown\", \"n/a\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    clean_name = extracted_name.strip()\n",
    "\n",
    "    supplier_map = {s.lower(): s for s in SUPPLIER_LIST}\n",
    "    if clean_name.lower() in supplier_map:\n",
    "        return supplier_map[clean_name.lower()]\n",
    "\n",
    "    matches = difflib.get_close_matches(clean_name, SUPPLIER_LIST, n=1, cutoff=0.6)\n",
    "    return matches[0] if matches else clean_name\n",
    "\n",
    "\n",
    "def calculate_mro_months(start_date_str, end_date_text, program_type):\n",
    "    \"\"\"Calculates duration only if Program Type is MRO/Support.\"\"\"\n",
    "    if program_type != \"MRO/Support\":\n",
    "        return \"Not Applicable\"\n",
    "\n",
    "    try:\n",
    "        if not start_date_str or not end_date_text or str(end_date_text).lower() in [\"unknown\", \"n/a\"]:\n",
    "            return \"Not Applicable\"\n",
    "\n",
    "        start = pd.to_datetime(start_date_str, dayfirst=True)\n",
    "        end = parser.parse(end_date_text, fuzzy=True)\n",
    "\n",
    "        diff = relativedelta(end, start)\n",
    "        total_months = (diff.years * 12) + diff.months\n",
    "        return str(max(0, int(total_months)))\n",
    "    except:\n",
    "        return \"Not Applicable\"\n",
    "\n",
    "\n",
    "def get_region_for_country(country_name):\n",
    "    \"\"\"Robust lookup handling casing/whitespace.\"\"\"\n",
    "    if not country_name or country_name.lower() in [\"unknown\", \"n/a\", \"not applicable\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    clean = country_name.strip().lower()\n",
    "\n",
    "    if clean in [\"us\", \"usa\", \"united states\", \"united states of america\"]:\n",
    "        return \"North America\"\n",
    "    if clean in [\"uk\", \"britain\", \"great britain\"]:\n",
    "        return \"Europe\"\n",
    "\n",
    "    for region, countries in GEOGRAPHY_MAPPING.items():\n",
    "        if any(c.lower() == clean for c in countries):\n",
    "            return region\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "# Regex Designator Extractors (for System Name + Piloting)\n",
    "DESIGNATOR_PATTERNS = [\n",
    "    r\"\\bDDG[-\\s]?\\d+\\b\", r\"\\bCVN[-\\s]?\\d+\\b\", r\"\\bSSN[-\\s]?\\d+\\b\",\n",
    "    r\"\\bLCS[-\\s]?\\d+\\b\", r\"\\bLPD[-\\s]?\\d+\\b\", r\"\\bLHA[-\\s]?\\d+\\b\", r\"\\bLHD[-\\s]?\\d+\\b\",\n",
    "    r\"\\bF-\\d+\\b\", r\"\\bB-\\d+\\b\", r\"\\bC-\\d+\\b\", r\"\\bA-\\d+\\b\",\n",
    "    r\"\\bMQ-\\d+\\b\", r\"\\bRQ-\\d+\\b\",\n",
    "    r\"\\bAN\\/[A-Z0-9\\-]+\\b\",\n",
    "    r\"\\b(AIM|AGM|SM|RIM|MIM)-\\d+\\b\",\n",
    "]\n",
    "\n",
    "def extract_designators(text: str):\n",
    "    text = str(text)\n",
    "    found = []\n",
    "    for pat in DESIGNATOR_PATTERNS:\n",
    "        found.extend(re.findall(pat, text, flags=re.IGNORECASE))\n",
    "    cleaned = []\n",
    "    for f in found:\n",
    "        cleaned.append(f.upper().replace(\" \", \"\").replace(\"--\", \"-\"))\n",
    "    seen = set()\n",
    "    final = []\n",
    "    for x in cleaned:\n",
    "        if x not in seen:\n",
    "            final.append(x)\n",
    "            seen.add(x)\n",
    "    return final\n",
    "\n",
    "def detect_piloting_rule_based(text: str, designators: List[str]) -> str:\n",
    "    t = str(text).lower()\n",
    "\n",
    "    if any(d.startswith((\"MQ-\", \"RQ-\")) for d in designators):\n",
    "        return \"Uncrewed\"\n",
    "    if any(k in t for k in [\"unmanned\", \"uav\", \"drone\", \"autonomous\"]):\n",
    "        return \"Uncrewed\"\n",
    "\n",
    "    if any(d.startswith((\"DDG\", \"CVN\", \"SSN\", \"LCS\", \"LPD\", \"LHA\", \"LHD\")) for d in designators):\n",
    "        return \"Crewed\"\n",
    "    if \"uss \" in t:\n",
    "        return \"Crewed\"\n",
    "\n",
    "    return \"Not Applicable\"\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. TOOL DEFINITIONS (AGENTS)\n",
    "# ==============================================================================\n",
    "\n",
    "# --- AGENT 1: SOURCING ---\n",
    "class SourcingInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "    url: str = Field(description=\"Source URL.\")\n",
    "    date: str = Field(description=\"Contract Date.\")\n",
    "\n",
    "@tool(\"sourcing_extractor\")\n",
    "def sourcing_extractor(paragraph: str, url: str, date: str):\n",
    "    \"\"\"Stage 1: Prepares Metadata.\"\"\"\n",
    "    reported_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    notes = \"Standard extraction.\"\n",
    "    if \"modification\" in paragraph.lower():\n",
    "        notes = \"Contract Modification.\"\n",
    "    if \"split\" in paragraph.lower():\n",
    "        notes = \"Split award detected.\"\n",
    "\n",
    "    return {\n",
    "        \"Description of Contract\": paragraph,\n",
    "        \"Additional Notes (Internal Only)\": notes,\n",
    "        \"Source Link(s)\": url,\n",
    "        \"Contract Date\": date,\n",
    "        \"Reported Date (By SGA)\": reported_date\n",
    "    }\n",
    "\n",
    "\n",
    "# --- AGENT 2: GEOGRAPHY ---\n",
    "class GeographyInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "\n",
    "@tool(\"geography_extractor\")\n",
    "def geography_extractor(paragraph: str):\n",
    "    \"\"\"Stage 2: Geography Logic.\"\"\"\n",
    "    sys_prompt = \"\"\"\n",
    "Extract: Customer Country, Supplier Country, Customer Operator.\n",
    "Logic: If 'Navy awarded...', Operator is Navy.\n",
    "Return JSON:\n",
    "{\n",
    "  \"Customer Country\": \"...\",\n",
    "  \"Customer Operator\": \"...\",\n",
    "  \"Supplier Country\": \"...\"\n",
    "}\n",
    "\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": paragraph}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "    except Exception:\n",
    "        raw = {}\n",
    "\n",
    "    cust = raw.get(\"Customer Country\", \"Unknown\")\n",
    "    supp = raw.get(\"Supplier Country\", \"Unknown\")\n",
    "\n",
    "    domestic = \"Indigenous\" if cust.lower() == supp.lower() else \"Imported\"\n",
    "    if \"united states\" in cust.lower() and \"usa\" in supp.lower():\n",
    "        domestic = \"Indigenous\"\n",
    "\n",
    "    return {\n",
    "        \"Customer Region\": get_region_for_country(cust),\n",
    "        \"Customer Country\": cust,\n",
    "        \"Customer Operator\": raw.get(\"Customer Operator\", \"Unknown\"),\n",
    "        \"Supplier Region\": get_region_for_country(supp),\n",
    "        \"Supplier Country\": supp,\n",
    "        \"Domestic Content\": domestic\n",
    "    }\n",
    "\n",
    "\n",
    "# --- AGENT 3: SYSTEM (UPGRADED WITH RAG + Evidence + Reason) ---\n",
    "class SystemInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "\n",
    "@tool(\"system_classifier\")\n",
    "def system_classifier(paragraph: str):\n",
    "    \"\"\"Stage 3: System classification using RAG + Rule Book + Evidence & Reason.\"\"\"\n",
    "    paragraph = str(paragraph).strip()\n",
    "    if not paragraph:\n",
    "        return {}\n",
    "\n",
    "    lower_text = paragraph.lower()\n",
    "\n",
    "    # RULE BOOK triggers\n",
    "    hints = [\n",
    "        f\"RULE: {v['guidance']}\"\n",
    "        for _, v in RULE_BOOK.items()\n",
    "        if any(t in lower_text for t in v[\"triggers\"])\n",
    "    ]\n",
    "    hint_str = \"\\n\".join(hints) if hints else \"No special override rules triggered.\"\n",
    "\n",
    "    # Local extraction\n",
    "    designators = extract_designators(paragraph)\n",
    "\n",
    "    # Rule-based piloting\n",
    "    piloting_rule = detect_piloting_rule_based(paragraph, designators)\n",
    "\n",
    "    # RAG Retrieval\n",
    "    rag_hits = retriever.retrieve(paragraph, top_k=3)\n",
    "\n",
    "    rag_examples = []\n",
    "    for hit in rag_hits:\n",
    "        meta = hit[\"meta\"]\n",
    "        rag_examples.append({\n",
    "            \"score\": round(hit[\"score\"], 4),\n",
    "            \"Market Segment\": meta.get(\"Market Segment\", \"\"),\n",
    "            \"System Type (General)\": meta.get(\"System Type (General)\", \"\"),\n",
    "            \"System Type (Specific)\": meta.get(\"System Type (Specific)\", \"\"),\n",
    "            \"System Name (General)\": meta.get(\"System Name (General)\", \"\"),\n",
    "            \"System Name (Specific)\": meta.get(\"System Name (Specific)\", \"\"),\n",
    "            \"System Piloting\": meta.get(\"System Piloting\", \"\"),\n",
    "            \"Supplier Name\": meta.get(\"Supplier Name\", \"\"),\n",
    "            \"Customer Operator\": meta.get(\"Customer Operator\", \"\"),\n",
    "            \"Snippet\": meta.get(\"Description of Contract\", \"\")[:220] + \"...\"\n",
    "        })\n",
    "\n",
    "    sys_prompt = f\"\"\"\n",
    "You are a Senior Defense System Classification Analyst.\n",
    "\n",
    "Use these inputs:\n",
    "1) RAG Similar Examples (top 3)\n",
    "2) Rule Book Overrides\n",
    "3) Extracted Designators\n",
    "\n",
    "RULE BOOK OVERRIDES:\n",
    "{hint_str}\n",
    "\n",
    "OUTPUT RULES:\n",
    "- Return ONLY a FLAT JSON object.\n",
    "- Every value must be a STRING.\n",
    "- Do NOT return nested JSON or lists.\n",
    "- Evidence must be copied EXACTLY from paragraph.\n",
    "- If evidence not present, use \"Not Found\".\n",
    "\n",
    "Return JSON exactly:\n",
    "{{\n",
    "  \"Market Segment\": \"\",\n",
    "  \"Market Segment Evidence\": \"\",\n",
    "  \"Market Segment Reason\": \"\",\n",
    "\n",
    "  \"System Type (General)\": \"\",\n",
    "  \"System Type (General) Evidence\": \"\",\n",
    "  \"System Type (General) Reason\": \"\",\n",
    "\n",
    "  \"System Type (Specific)\": \"\",\n",
    "  \"System Type (Specific) Evidence\": \"\",\n",
    "  \"System Type (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Name (General)\": \"\",\n",
    "  \"System Name (General) Evidence\": \"\",\n",
    "  \"System Name (General) Reason\": \"\",\n",
    "\n",
    "  \"System Name (Specific)\": \"\",\n",
    "  \"System Name (Specific) Evidence\": \"\",\n",
    "  \"System Name (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Piloting\": \"\",\n",
    "  \"System Piloting Evidence\": \"\",\n",
    "  \"System Piloting Reason\": \"\",\n",
    "\n",
    "  \"Confidence\": \"High/Medium/Low\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "INPUT PARAGRAPH:\n",
    "{paragraph}\n",
    "\n",
    "DESIGNATORS (regex extracted):\n",
    "{designators if designators else \"None\"}\n",
    "\n",
    "RULE-BASED PILOTING:\n",
    "{piloting_rule}\n",
    "\n",
    "RAG SIMILAR EXAMPLES:\n",
    "{json.dumps(rag_examples, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        result = json.loads(completion.choices[0].message.content)\n",
    "\n",
    "        # Hard override piloting (best accuracy)\n",
    "        result[\"System Piloting\"] = piloting_rule\n",
    "        if not result.get(\"System Piloting Reason\"):\n",
    "            result[\"System Piloting Reason\"] = \"Piloting derived using deterministic rules.\"\n",
    "        if not result.get(\"System Piloting Evidence\"):\n",
    "            result[\"System Piloting Evidence\"] = \"Not Found\"\n",
    "\n",
    "        # Ensure flat\n",
    "        for k, v in result.items():\n",
    "            if isinstance(v, (dict, list)):\n",
    "                result[k] = str(v)\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"Market Segment\": \"\",\n",
    "            \"System Type (General)\": \"\",\n",
    "            \"System Type (Specific)\": \"\",\n",
    "            \"System Name (General)\": \"\",\n",
    "            \"System Name (Specific)\": \"\",\n",
    "            \"System Piloting\": piloting_rule,\n",
    "            \"Market Segment Evidence\": \"Not Found\",\n",
    "            \"System Type (General) Evidence\": \"Not Found\",\n",
    "            \"System Type (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Name (General) Evidence\": \"Not Found\",\n",
    "            \"System Name (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Piloting Evidence\": \"Not Found\",\n",
    "            \"Market Segment Reason\": \"\",\n",
    "            \"System Type (General) Reason\": \"\",\n",
    "            \"System Type (Specific) Reason\": \"\",\n",
    "            \"System Name (General) Reason\": \"\",\n",
    "            \"System Name (Specific) Reason\": \"\",\n",
    "            \"System Piloting Reason\": \"Piloting derived using deterministic rules.\",\n",
    "            \"Confidence\": \"Low\",\n",
    "            \"Error\": str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "# --- AGENT 4: CONTRACT ---\n",
    "class ContractInfoInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Contract text.\")\n",
    "    contract_date: str = Field(description=\"Signed date.\")\n",
    "\n",
    "@tool(\"contract_extractor\")\n",
    "def contract_extractor(paragraph: str, contract_date: str):\n",
    "    \"\"\"Stage 4: Extracts Financials, Program Type, and Dates based on strict SOP.\"\"\"\n",
    "\n",
    "    system_instruction = \"\"\"\n",
    "You are a Defense Contract Financial Analyst. Extract data strictly following these SOP rules:\n",
    "\n",
    "1) Supplier Name: Extract the exact company name text found in paragraph.\n",
    "2) Program Type: Procurement / Training / MRO/Support / RDT&E / Upgrade / Other Service\n",
    "3) Value Certainty:\n",
    "   - Confirmed: fixed price/obligated stated\n",
    "   - Estimated: ceiling/potential/IDIQ/multi-award\n",
    "4) Quantity: number or Not Applicable\n",
    "5) G2G/B2G:\n",
    "   - G2G only if Foreign Military Sales (FMS)\n",
    "   - else B2G\n",
    "6) Completion Date: only needed for MRO duration calc\n",
    "\n",
    "Return JSON only.\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "Analyze contract:\n",
    "\"{paragraph}\"\n",
    "\n",
    "Signed Date: {contract_date}\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"raw_supplier_name\": \"\",\n",
    "  \"program_type\": \"\",\n",
    "  \"value_million_raw\": \"\",\n",
    "  \"currency_code\": \"\",\n",
    "  \"value_certainty\": \"\",\n",
    "  \"quantity\": \"\",\n",
    "  \"completion_date_text\": \"\",\n",
    "  \"g2g_b2g\": \"\",\n",
    "  \"value_note\": \"\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_instruction},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        return {\"Error\": str(e)}\n",
    "\n",
    "    final_supplier = get_best_supplier_match(raw.get(\"raw_supplier_name\"))\n",
    "    prog_type = raw.get(\"program_type\", \"Unknown\")\n",
    "    mro_months = calculate_mro_months(contract_date, raw.get(\"completion_date_text\"), prog_type)\n",
    "\n",
    "    try:\n",
    "        val_str = str(raw.get(\"value_million_raw\", \"0\")).replace(\",\", \"\").replace(\"$\", \"\")\n",
    "        val_float = float(val_str)\n",
    "        val_formatted = \"{:.3f}\".format(val_float)\n",
    "    except:\n",
    "        val_formatted = \"0.000\"\n",
    "\n",
    "    try:\n",
    "        dt = pd.to_datetime(contract_date)\n",
    "        sign_month = dt.strftime(\"%B\")\n",
    "        sign_year = str(dt.year)\n",
    "    except:\n",
    "        sign_month, sign_year = \"Unknown\", \"Unknown\"\n",
    "\n",
    "    val_note = raw.get(\"value_note\", \"Not Applicable\")\n",
    "    if \"split\" in paragraph.lower() and val_note == \"Not Applicable\":\n",
    "        val_note = \"Split contract; value distribution unclear.\"\n",
    "\n",
    "    return {\n",
    "        \"Supplier Name\": final_supplier,\n",
    "        \"Program Type\": prog_type,\n",
    "        \"Expected MRO Contract Duration (Months)\": mro_months,\n",
    "        \"Quantity\": raw.get(\"quantity\", \"Not Applicable\"),\n",
    "        \"Value Certainty\": raw.get(\"value_certainty\", \"Confirmed\"),\n",
    "        \"Value (Million)\": val_formatted,\n",
    "        \"Currency\": raw.get(\"currency_code\", \"USD$\"),\n",
    "        \"Value (USD$ Million)\": val_formatted,\n",
    "        \"Value Note (If Any)\": val_note,\n",
    "        \"G2G/B2G\": raw.get(\"g2g_b2g\", \"B2G\"),\n",
    "        \"Signing Month\": sign_month,\n",
    "        \"Signing Year\": sign_year\n",
    "    }\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. LANGGRAPH PIPELINE\n",
    "# ==============================================================================\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input_text: str\n",
    "    input_date: str\n",
    "    input_url: str\n",
    "    final_data: dict\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "\n",
    "def stage_1_sourcing(state: AgentState):\n",
    "    res = sourcing_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"url\": state[\"input_url\"],\n",
    "        \"date\": state[\"input_date\"]\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "def stage_2_geography(state: AgentState):\n",
    "    res = geography_extractor.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "def stage_3_system(state: AgentState):\n",
    "    res = system_classifier.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "def stage_4_contract(state: AgentState):\n",
    "    res = contract_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"contract_date\": state[\"input_date\"]\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Stage1\", stage_1_sourcing)\n",
    "workflow.add_node(\"Stage2\", stage_2_geography)\n",
    "workflow.add_node(\"Stage3\", stage_3_system)\n",
    "workflow.add_node(\"Stage4\", stage_4_contract)\n",
    "\n",
    "workflow.add_edge(START, \"Stage1\")\n",
    "workflow.add_edge(\"Stage1\", \"Stage2\")\n",
    "workflow.add_edge(\"Stage2\", \"Stage3\")\n",
    "workflow.add_edge(\"Stage3\", \"Stage4\")\n",
    "workflow.add_edge(\"Stage4\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. EXECUTION & FORMATTING\n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(f\"Loading Input File: {INPUT_EXCEL_PATH}...\")\n",
    "\n",
    "    try:\n",
    "        df_input = pd.read_excel(INPUT_EXCEL_PATH)\n",
    "\n",
    "        required_cols = [\"Source URL\", \"Contract Date\", \"Contract Description\"]\n",
    "        if not all(col in df_input.columns for col in required_cols):\n",
    "            raise ValueError(f\"Excel file must contain columns: {required_cols}\")\n",
    "\n",
    "        print(f\"üöÄ Processing {len(df_input)} rows...\")\n",
    "        results = []\n",
    "\n",
    "        for index, row in df_input.iterrows():\n",
    "            print(f\"   -> Row {index + 1}...\")\n",
    "\n",
    "            desc = str(row[\"Contract Description\"]) if pd.notna(row[\"Contract Description\"]) else \"\"\n",
    "            c_date = str(row[\"Contract Date\"]) if pd.notna(row[\"Contract Date\"]) else str(datetime.date.today())\n",
    "            c_url = str(row[\"Source URL\"]) if pd.notna(row[\"Source URL\"]) else \"\"\n",
    "\n",
    "            initial_state = {\n",
    "                \"input_text\": desc,\n",
    "                \"input_date\": c_date,\n",
    "                \"input_url\": c_url,\n",
    "                \"final_data\": {},\n",
    "                \"messages\": []\n",
    "            }\n",
    "\n",
    "            output_state = app.invoke(initial_state)\n",
    "            results.append(output_state[\"final_data\"])\n",
    "\n",
    "        df_final = pd.DataFrame(results)\n",
    "\n",
    "        FINAL_COLUMNS = [\n",
    "            \"Customer Region\", \"Customer Country\", \"Customer Operator\",\n",
    "            \"Supplier Region\", \"Supplier Country\", \"Domestic Content\",\n",
    "\n",
    "            \"Market Segment\", \"Market Segment Evidence\", \"Market Segment Reason\",\n",
    "            \"System Type (General)\", \"System Type (General) Evidence\", \"System Type (General) Reason\",\n",
    "            \"System Type (Specific)\", \"System Type (Specific) Evidence\", \"System Type (Specific) Reason\",\n",
    "            \"System Name (General)\", \"System Name (General) Evidence\", \"System Name (General) Reason\",\n",
    "            \"System Name (Specific)\", \"System Name (Specific) Evidence\", \"System Name (Specific) Reason\",\n",
    "            \"System Piloting\", \"System Piloting Evidence\", \"System Piloting Reason\",\n",
    "            \"Confidence\",\n",
    "\n",
    "            \"Supplier Name\", \"Program Type\", \"Expected MRO Contract Duration (Months)\",\n",
    "            \"Quantity\", \"Value Certainty\", \"Value (Million)\", \"Currency\",\n",
    "            \"Value (USD$ Million)\", \"Value Note (If Any)\", \"G2G/B2G\",\n",
    "            \"Signing Month\", \"Signing Year\",\n",
    "\n",
    "            \"Description of Contract\",\n",
    "            \"Additional Notes (Internal Only)\",\n",
    "            \"Source Link(s)\",\n",
    "            \"Contract Date\",\n",
    "            \"Reported Date (By SGA)\"\n",
    "        ]\n",
    "\n",
    "        df_final = df_final.reindex(columns=FINAL_COLUMNS, fill_value=\"\")\n",
    "\n",
    "        df_final.to_excel(OUTPUT_EXCEL_PATH, index=False)\n",
    "\n",
    "        print(\"\\n Processing Complete!\")\n",
    "        print(f\"File saved to: {OUTPUT_EXCEL_PATH}\")\n",
    "        print(df_final.head().to_string())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9b2c98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
