{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b965354",
   "metadata": {},
   "source": [
    "## **Stage-1**\n",
    "\n",
    "Creating a knowledge base system which will act as brain to my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd9f3f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loading Excel Knowledge Base: C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\data\\sample_data.xlsx\n",
      "Loaded rows=2068 col=29\n",
      "KB rows kept after cleaning: 600\n",
      "Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: b94d340d-9491-4534-9001-a3ba8a140304)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.32s/it]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.28s/it]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.20s/it]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.22s/it]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.27s/it]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.32s/it]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.31s/it]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.35s/it]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.28s/it]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Shape:(600, 384)\n",
      "System KB Created Successfully!\n",
      "Index saved: system_kb_store\\system_kb.faiss\n",
      "Meta Saved: system_kb_store\\system_kb_meta.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "## Configuration \n",
    "DEFAULT_MODEL_NAME=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "def clean_text(text:str) -> str:\n",
    "    \"\"\"This function is used to clean the entire text [description]\"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    text = re.sub(r'\\s+',' ',text).strip()\n",
    "    return text\n",
    "\n",
    "def safe_to_str(x):\n",
    "    \"\"\"This is a helper function\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    return str(x).strip()\n",
    "\n",
    "def build_system_kb_store_all_columns(\n",
    "        excel_path: str,\n",
    "        save_dir: str = \"system_kb_store\",\n",
    "        model_name: str = DEFAULT_MODEL_NAME,\n",
    "        batch_size: int = 64,\n",
    "        embed_column: str = 'Description of Contract'\n",
    "):\n",
    "    \"\"\"This function will create embedding on my description for my knowledge base\"\"\"\n",
    "    os.makedirs(save_dir,exist_ok=True)\n",
    "    print(f\"\\n Loading Excel Knowledge Base: {excel_path}\")\n",
    "    df = pd.read_excel(excel_path)\n",
    "    print(f\"Loaded rows={len(df)} col={len(df.columns)}\")\n",
    "\n",
    "    if embed_column not in df.columns:\n",
    "        raise ValueError(f\"Embed column '{embed_column}' not found in Excel!\")\n",
    "    \n",
    "    df = df.fillna('')\n",
    "    kb_texts=[]\n",
    "    kb_meta=[]\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        desc=clean_text(row[embed_column])\n",
    "        if not desc or len(desc) < 20:\n",
    "            continue\n",
    "        meta = {'row_id':int(idx)}\n",
    "        for col in df.columns:\n",
    "            meta[col]=safe_to_str(row[col])\n",
    "        meta[embed_column]=desc\n",
    "        kb_texts.append(desc)\n",
    "        kb_meta.append(meta)\n",
    "    print(f\"KB rows kept after cleaning: {len(kb_texts)}\")\n",
    "    if len(kb_texts) == 0:\n",
    "        print(\"ERROR:No text rows remained after cleaning. Check your 'clean_text' logic or input data.\")\n",
    "        return None, None\n",
    "    print(f\"Loading embedding model: {model_name}\")\n",
    "    embedder=SentenceTransformer(model_name)\n",
    "    print(\"Creating Embeddings...\")\n",
    "    embeddings=[]\n",
    "    for i in range(0,len(kb_texts),batch_size):\n",
    "        batch=kb_texts[i:i + batch_size]\n",
    "        batch_emb=embedder.encode(batch,show_progress_bar=True,normalize_embeddings=True)\n",
    "        embeddings.append(batch_emb)\n",
    "    embeddings=np.vstack(embeddings).astype('float32')\n",
    "    dim=embeddings.shape[1]\n",
    "    print(f\"Embedding Shape:{embeddings.shape}\")\n",
    "    index=faiss.IndexFlatIP(dim)\n",
    "    index.add(embeddings)\n",
    "    index_path=os.path.join(save_dir,\"system_kb.faiss\")\n",
    "    meta_path=os.path.join(save_dir,'system_kb_meta.pkl')\n",
    "    faiss.write_index(index,index_path)\n",
    "    with open(meta_path,'wb') as f:\n",
    "        pickle.dump(kb_meta,f)\n",
    "    print(\"System KB Created Successfully!\")\n",
    "    print(f\"Index saved: {index_path}\")\n",
    "    print(f\"Meta Saved: {meta_path}\")\n",
    "    return index_path, meta_path\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    EXCEL_PATH=r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\data\\sample_data.xlsx\"\n",
    "    build_system_kb_store_all_columns(\n",
    "        excel_path=EXCEL_PATH,\n",
    "        save_dir='system_kb_store',\n",
    "        model_name=DEFAULT_MODEL_NAME,\n",
    "        batch_size=64,\n",
    "        embed_column=\"Description of Contract\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96bfed05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: a7b0a49c-5ed7-4137-a283-22884e9d1ce4)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS index: system_kb_store\\system_kb.faiss\n",
      "Loading metadata: system_kb_store\\system_kb_meta.pkl\n",
      "Loaded KB rows: 600\n",
      "Loading embedder: sentence-transformers/all-MiniLM-L6-v2\n",
      "\n",
      "Score: 0.6228203773498535\n",
      "Supplier: Dell Inc\n",
      "Market: Unknown\n",
      "System: Department of Defense Enterprise Software Initiative (DOD ESI)\n",
      "\n",
      "Score: 0.6228203773498535\n",
      "Supplier: Dell Inc\n",
      "Market: Unknown\n",
      "System: Department of Defense Enterprise Software Initiative (DOD ESI)\n",
      "\n",
      "Score: 0.6024371385574341\n",
      "Supplier: \n",
      "Market: Unknown\n",
      "System: Department of Defense Enterprise Software Initiative (DOD ESI)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pickle\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "DEFAULT_MODEL_NAME='sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "class SystemKBRetriever:\n",
    "    def __init__(self, kb_dir='system_kb_store', model_name=DEFAULT_MODEL_NAME):\n",
    "        index_path = os.path.join(kb_dir, 'system_kb.faiss')\n",
    "        meta_path = os.path.join(kb_dir, 'system_kb_meta.pkl')\n",
    "\n",
    "        if not os.path.exists(index_path) or not os.path.exists(meta_path):\n",
    "            raise FileNotFoundError(\"KB files are missing. Build KB first.\")\n",
    "        \n",
    "        print(f\"Loading FAISS index: {index_path}\")\n",
    "        self.index = faiss.read_index(index_path)\n",
    "        \n",
    "        print(f\"Loading metadata: {meta_path}\")\n",
    "        with open(meta_path, 'rb') as f:\n",
    "            self.meta = pickle.load(f)\n",
    "            \n",
    "        print(f\"Loaded KB rows: {len(self.meta)}\")\n",
    "        print(f\"Loading embedder: {model_name}\")\n",
    "        self.embedder = SentenceTransformer(model_name)\n",
    "    \n",
    "    def retrieve(self, query_text: str, top_k: int = 5):\n",
    "        # FIX 1: Do not use .split(). We want to embed the whole sentence, not a list of words.\n",
    "        query_text = str(query_text).strip()\n",
    "        \n",
    "        if not query_text:\n",
    "            return []\n",
    "        \n",
    "        # Encode returns shape (1, 384) because we pass a list with 1 string\n",
    "        q_emb = self.embedder.encode([query_text], normalize_embeddings=True).astype('float32')\n",
    "        \n",
    "        scores, idxs = self.index.search(q_emb, top_k)\n",
    "        results = []\n",
    "        \n",
    "        # FIX 2: Corrected typo 'socre' -> 'score'\n",
    "        for score, idx in zip(scores[0], idxs[0]):\n",
    "            if idx < 0:\n",
    "                continue\n",
    "            results.append({\n",
    "                'score': float(score),  # FIX 3: Use individual 'score', not the array 'scores'\n",
    "                \"meta\": self.meta[idx]\n",
    "            })\n",
    "        return results\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    # Ensure the directory exists and contains files created by the builder script\n",
    "    if os.path.exists('system_kb_store'):\n",
    "        r = SystemKBRetriever(kb_dir='system_kb_store')\n",
    "        q = 'Dell Marketing L.P., Round Rock, Texas, is awarded a single-award, firm-fixed-price blanket purchase agreement'\n",
    "        \n",
    "        hits = r.retrieve(q, top_k=3)\n",
    "\n",
    "        for h in hits:\n",
    "            print(\"\\nScore:\", h['score'])\n",
    "            print(\"Supplier:\", h['meta'].get('Supplier Name'))\n",
    "            print(\"Market:\", h['meta'].get(\"Market Segment\"))\n",
    "            print(\"System:\", h['meta'].get('System Name (Specific)'))\n",
    "    else:\n",
    "        print(\"Error: 'system_kb_store' directory not found. Please run the builder script first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17648c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS Index: C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\system_kb_store\\system_kb.faiss\n",
      "Loading KB Metadata: C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\system_kb_store\\system_kb_meta.pkl\n",
      "KB Loaded rows: 600\n",
      "Loaded: C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\taxonomy.json\n",
      "Loaded: C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\suppliers.json\n",
      "\n",
      "üìå Loading Input File: C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\data\\source_file.xlsx\n",
      "Workflow Mermaid saved locally: workflow.mmd\n",
      "üöÄ Processing 1 rows...\n",
      "\n",
      "üîπ Row 1/1\n",
      "\n",
      "==============================================================================================================\n",
      "HUMAN MESSAGE (Stage2 - Geography)\n",
      "==============================================================================================================\n",
      "Northrop Grumman Systems Corp., Aerospace Systems, Melbourne, Florida, is awarded a $12,015,026 modification (P00036) to a previously awarded cost-plus-fixed-fee contract (N0001914C0036). This modification increases the ceiling to extend services and adds hours increasing the full-scale fatigue repair time to achieve the required simulated flight hours in support of E-2D Advanced Hawkeye aircraft development. Work will be performed in El Segundo, California (59%); Melbourne, Florida (35%); and Bethpage, New York (6%), and is expected to be completed in June 2023. No funds will be obligated at time of award. The Naval Air Systems Command, Patuxent River, Maryland, is the contracting activity.\n",
      "\n",
      "==============================================================================================================\n",
      "AI RESPONSE (Stage2 - Geography)\n",
      "==============================================================================================================\n",
      "{\n",
      "  \"Customer Country\": \"United States\",\n",
      "  \"Customer Operator\": \"Navy\",\n",
      "  \"Supplier Country\": \"United States\"\n",
      "}\n",
      "\n",
      "==============================================================================================================\n",
      "HUMAN MESSAGE (Stage3 - System)\n",
      "==============================================================================================================\n",
      "Northrop Grumman Systems Corp., Aerospace Systems, Melbourne, Florida, is awarded a $12,015,026 modification (P00036) to a previously awarded cost-plus-fixed-fee contract (N0001914C0036). This modification increases the ceiling to extend services and adds hours increasing the full-scale fatigue repair time to achieve the required simulated flight hours in support of E-2D Advanced Hawkeye aircraft development. Work will be performed in El Segundo, California (59%); Melbourne, Florida (35%); and Bethpage, New York (6%), and is expected to be completed in June 2023. No funds will be obligated at time of award. The Naval Air Systems Command, Patuxent River, Maryland, is the contracting activity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================================================================================\n",
      "AI RESPONSE (Stage3 - System)\n",
      "==============================================================================================================\n",
      "{\n",
      "  \"Market Segment\": \"Air Platforms\",\n",
      "  \"Market Segment Evidence\": \"Northrop Grumman Systems Corp., Aerospace Systems, Melbourne, Florida, is awarded a $12,015,026 modification (P00036) to a previously awarded cost-plus-fixed-fee contract (N0001914C0036).\",\n",
      "  \"Market Segment Reason\": \"The context involves aerospace systems related to aircraft development.\",\n",
      "  \"System Type (General)\": \"Fixed Wing\",\n",
      "  \"System Type (General) Evidence\": \"This modification increases the ceiling to extend services and adds hours increasing the full-scale fatigue repair time to achieve the required simulated flight hours in support of E-2D Advanced Hawkeye aircraft development.\",\n",
      "  \"System Type (General) Reason\": \"The E-2D Advanced Hawkeye is a fixed-wing aircraft.\",\n",
      "  \"System Type (Specific)\": \"AEW&C\",\n",
      "  \"System Type (Specific) Evidence\": \"in support of E-2D Advanced Hawkeye aircraft development.\",\n",
      "  \"System Type (Specific) Reason\": \"The E-2D Advanced Hawkeye is classified as an Airborne Early Warning and Control (AEW&C) system.\",\n",
      "  \"System Name (General)\": \"E-2D Advanced Hawkeye\",\n",
      "  \"System Name (General) Evidence\": \"in support of E-2D Advanced Hawkeye aircraft development.\",\n",
      "  \"System Name (General) Reason\": \"The specific aircraft mentioned is the E-2D Advanced Hawkeye.\",\n",
      "  \"System Name (Specific)\": \"Extend Services and Adds Hours Increasing the Full-scale Fatigue Repair Time to Achieve the Required Simulated Flight Hours\",\n",
      "  \"System Name (Specific) Evidence\": \"This modification increases the ceiling to extend services and adds hours increasing the full-scale fatigue repair time to achieve the required simulated flight hours.\",\n",
      "  \"System Name (Specific) Reason\": \"The modification details the specific services being extended and the purpose of the work.\",\n",
      "  \"System Piloting\": \"Crewed\",\n",
      "  \"System Piloting Evidence\": \"in support of E-2D Advanced Hawkeye aircraft development.\",\n",
      "  \"System Piloting Reason\": \"The E-2D Advanced Hawkeye is a crewed aircraft.\",\n",
      "  \"Confidence\": \"High\"\n",
      "}\n",
      "\n",
      "==============================================================================================================\n",
      "HUMAN MESSAGE (Stage4 - Contract)\n",
      "==============================================================================================================\n",
      "Northrop Grumman Systems Corp., Aerospace Systems, Melbourne, Florida, is awarded a $12,015,026 modification (P00036) to a previously awarded cost-plus-fixed-fee contract (N0001914C0036). This modification increases the ceiling to extend services and adds hours increasing the full-scale fatigue repair time to achieve the required simulated flight hours in support of E-2D Advanced Hawkeye aircraft development. Work will be performed in El Segundo, California (59%); Melbourne, Florida (35%); and Bethpage, New York (6%), and is expected to be completed in June 2023. No funds will be obligated at time of award. The Naval Air Systems Command, Patuxent River, Maryland, is the contracting activity.\n",
      "\n",
      "==============================================================================================================\n",
      "AI RESPONSE (Stage4 - Contract)\n",
      "==============================================================================================================\n",
      "{\n",
      "  \"program_type\": \"RDT&E\",\n",
      "  \"value_million_raw\": \"12.015026\",\n",
      "  \"currency_code\": \"USD\",\n",
      "  \"value_certainty\": \"Confirmed\",\n",
      "  \"quantity\": \"Not Applicable\",\n",
      "  \"completion_date_text\": \"expected to be completed in June 2023\",\n",
      "  \"g2g_b2g\": \"B2G\",\n",
      "  \"value_note\": \"\"\n",
      "}\n",
      "Evidence + Reason columns highlighted successfully.\n",
      "\n",
      " Processing Complete!\n",
      "Output File Saved: Processed_Defense_Data.xlsx\n",
      "Customer Region Customer Country Customer Operator Supplier Region Supplier Country Domestic Content Split Flag             Split Reason Market Segment                                                                                                                                                                     Market Segment Evidence                                                   Market Segment Reason System Type (General)                                                                                                                                                                                                   System Type (General) Evidence                        System Type (General) Reason System Type (Specific)                           System Type (Specific) Evidence                                                                    System Type (Specific) Reason System Name (General)                            System Name (General) Evidence                                  System Name (General) Reason                                                                                                      System Name (Specific)                                                                                                                                         System Name (Specific) Evidence                                                              System Name (Specific) Reason System Piloting                                  System Piloting Evidence                          System Piloting Reason Confidence    Supplier Name         Supplier Name Evidence  Program Type Expected MRO Contract Duration (Months)       Quantity Value Certainty Value (Million) Currency Value (USD$ Million) Value Note (If Any) G2G/B2G Signing Month Signing Year QA Status QA Flags QA Fix Suggestion LLM QA Fix Summary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Description of Contract Additional Notes (Internal Only) Source Link(s)       Contract Date Reported Date (By SGA)\n",
      "  North America    United States              Navy   North America    United States       Indigenous         No No split condition found  Air Platforms Northrop Grumman Systems Corp., Aerospace Systems, Melbourne, Florida, is awarded a $12,015,026 modification (P00036) to a previously awarded cost-plus-fixed-fee contract (N0001914C0036). The context involves aerospace systems related to aircraft development.            Fixed Wing This modification increases the ceiling to extend services and adds hours increasing the full-scale fatigue repair time to achieve the required simulated flight hours in support of E-2D Advanced Hawkeye aircraft development. The E-2D Advanced Hawkeye is a fixed-wing aircraft.                  AEW&C in support of E-2D Advanced Hawkeye aircraft development. The E-2D Advanced Hawkeye is classified as an Airborne Early Warning and Control (AEW&C) system. E-2D Advanced Hawkeye in support of E-2D Advanced Hawkeye aircraft development. The specific aircraft mentioned is the E-2D Advanced Hawkeye. Extend Services and Adds Hours Increasing the Full-scale Fatigue Repair Time to Achieve the Required Simulated Flight Hours This modification increases the ceiling to extend services and adds hours increasing the full-scale fatigue repair time to achieve the required simulated flight hours. The modification details the specific services being extended and the purpose of the work.  Not Applicable in support of E-2D Advanced Hawkeye aircraft development. The E-2D Advanced Hawkeye is a crewed aircraft.       High Northrop Grumman Northrop Grumman Systems Corp. Other Service                          Not Applicable Not Applicable       Confirmed          12.015      USD               12.015                         B2G          June         2021      PASS     None              None                    Northrop Grumman Systems Corp., Aerospace Systems, Melbourne, Florida, is awarded a $12,015,026 modification (P00036) to a previously awarded cost-plus-fixed-fee contract (N0001914C0036). This modification increases the ceiling to extend services and adds hours increasing the full-scale fatigue repair time to achieve the required simulated flight hours in support of E-2D Advanced Hawkeye aircraft development. Work will be performed in El Segundo, California (59%); Melbourne, Florida (35%); and Bethpage, New York (6%), and is expected to be completed in June 2023. No funds will be obligated at time of award. The Naval Air Systems Command, Patuxent River, Maryland, is the contracting activity.           Contract Modification.     Source URL 2021-06-03 00:00:00             2026-01-27\n"
     ]
    }
   ],
   "source": [
    "## Final Code \n",
    "\n",
    "\"\"\"\n",
    "================================================================================\n",
    "AGENTIC DEFENSE CONTRACT EXTRACTION PIPELINE (0 -> END)\n",
    "================================================================================\n",
    "\n",
    "Author: Mukesh \n",
    "\n",
    "This pipeline extracts defense contract structured information from raw paragraphs\n",
    "(typically DoD / defense news contract announcements) using:\n",
    "\n",
    "Stage1: Sourcing Extractor (Base row skeleton)\n",
    "Stage2: Geography Extractor (Countries, operator, regions)\n",
    "Stage3: System Classifier (RAG + Taxonomy + Evidence + Reason)\n",
    "Stage4: Contract Extractor (Supplier, program type, value, quantity, G2G/B2G)\n",
    "Stage5: Split Engine (Operator + FMS country splitting only; NO supplier split)\n",
    "Stage6: Quality Validator (Rule-based sanity checks ‚Üí PASS/FAIL)\n",
    "Stage7: LLM Validator (ONLY for FAIL rows) ‚Üí correct or confirm FAIL\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "IMPORTANT FIXES INCLUDED\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Supplier Name Fix:\n",
    "- Supplier is extracted ONLY from strict DoD award patterns:\n",
    "  \", , is awarded ...\"\n",
    "  \", , has been awarded ...\"\n",
    "  \", , was awarded ...\"\n",
    "\n",
    "- This prevents wrong supplier explosion like:\n",
    "  \"BAE Systems, LET, MEN\" => wrongly interpreted as 3 suppliers\n",
    "\n",
    "- Program Type Fix:\n",
    "- Program type values must match EXACT allowed set:\n",
    "  Procurement / Training / MRO/Support / RDT&E / Upgrade / Other Service\n",
    "\n",
    " Splitting Fix:\n",
    "- Supplier-based splitting is REMOVED completely.\n",
    "- Split logic focuses only on:\n",
    "  - multi-operator allocations\n",
    "  - FMS multi-country allocations (only when G2G)\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "Output:\n",
    "- One output Excel row per ‚Äúlogical contract event‚Äù\n",
    "- Evidence + Reason columns are highlighted\n",
    "- QA validator produces:\n",
    "  - \"QA Status\" (PASS/FAIL)\n",
    "  - \"QA Flags\"   (human-readable reasons)\n",
    "  - \"QA Fix Suggestion\" (what likely needs correction)\n",
    "\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "# ==============================================================================\n",
    "# 0) IMPORTS\n",
    "# ==============================================================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import difflib\n",
    "import datetime\n",
    "from typing import Annotated, TypedDict, List, Dict, Any, Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import getpass\n",
    "\n",
    "# LangGraph / LangChain\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "\n",
    "# Excel formatting\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill, Font\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 0.1) DEBUG LOGGING HELPERS\n",
    "# ==============================================================================\n",
    "\n",
    "def log_block(title: str, content: str):\n",
    "    \"\"\"\n",
    "    Debug logger that prints clean separated blocks.\n",
    "\n",
    "    Why this matters:\n",
    "    - Your pipeline depends on multi-stage LLM and deterministic logic.\n",
    "    - Debugging extraction errors becomes easier if every stage logs:\n",
    "        - input paragraph\n",
    "        - system prompt output\n",
    "        - intermediate decision flags\n",
    "        - final values\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 110)\n",
    "    print(title)\n",
    "    print(\"=\" * 110)\n",
    "    print(content)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 1) RAG RETRIEVER (FAISS + METADATA)\n",
    "# ==============================================================================\n",
    "\n",
    "class SystemKBRetriever:\n",
    "    \"\"\"\n",
    "    FAISS-based semantic retriever to improve SYSTEM classification accuracy.\n",
    "\n",
    "    What it does:\n",
    "    - Loads vector DB index from:\n",
    "        system_kb.faiss\n",
    "    - Loads metadata from:\n",
    "        system_kb_meta.pkl\n",
    "\n",
    "    Why:\n",
    "    - Your taxonomy-based system classification improves drastically when the LLM\n",
    "      sees similar ‚Äúknown-good labeled‚Äù examples from your KB.\n",
    "\n",
    "    Output format (retrieve):\n",
    "        [\n",
    "          {\"score\": float, \"meta\": {KB columns}},\n",
    "          ...\n",
    "        ]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kb_dir: str, embed_model: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self.kb_dir = kb_dir\n",
    "        self.embed_model = embed_model\n",
    "\n",
    "        index_path = os.path.join(kb_dir, \"system_kb.faiss\")\n",
    "        meta_path = os.path.join(kb_dir, \"system_kb_meta.pkl\")\n",
    "\n",
    "        if not os.path.exists(index_path) or not os.path.exists(meta_path):\n",
    "            raise FileNotFoundError(\n",
    "                f\"KB files not found in: {kb_dir}\\n\"\n",
    "                f\"Expected:\\n- {index_path}\\n- {meta_path}\\n\\n\"\n",
    "                f\"Build the KB first using your KB builder script.\"\n",
    "            )\n",
    "\n",
    "        print(f\"Loading FAISS Index: {index_path}\")\n",
    "        self.index = faiss.read_index(index_path)\n",
    "\n",
    "        print(f\"Loading KB Metadata: {meta_path}\")\n",
    "        with open(meta_path, \"rb\") as f:\n",
    "            self.meta = pickle.load(f)\n",
    "\n",
    "        print(f\"KB Loaded rows: {len(self.meta)}\")\n",
    "\n",
    "        self.embedder = None\n",
    "\n",
    "    def _lazy_load_embedder(self):\n",
    "        \"\"\"\n",
    "        Lazy load embedding model.\n",
    "\n",
    "        Why:\n",
    "        - Faster pipeline startup\n",
    "        - Avoids memory overhead until retrieval is actually needed\n",
    "        \"\"\"\n",
    "        if self.embedder is None:\n",
    "            from sentence_transformers import SentenceTransformer\n",
    "            self.embedder = SentenceTransformer(self.embed_model)\n",
    "\n",
    "    def retrieve(self, query_text: str, top_k: int = 3):\n",
    "        \"\"\"\n",
    "        Retrieve top-k similar KB rows.\n",
    "\n",
    "        Args:\n",
    "            query_text: paragraph text to retrieve similar examples\n",
    "            top_k: number of results\n",
    "\n",
    "        Returns:\n",
    "            List[Dict] with {score, meta}\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "\n",
    "        query_text = str(query_text).strip()\n",
    "        if not query_text:\n",
    "            return []\n",
    "\n",
    "        self._lazy_load_embedder()\n",
    "\n",
    "        q_emb = self.embedder.encode([query_text], normalize_embeddings=True).astype(\"float32\")\n",
    "        scores, idxs = self.index.search(q_emb, top_k)\n",
    "\n",
    "        results = []\n",
    "        for score, idx in zip(scores[0], idxs[0]):\n",
    "            if idx < 0:\n",
    "                continue\n",
    "            results.append({\"score\": float(score), \"meta\": self.meta[idx]})\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2) CONFIGURATION & FILE PATHS\n",
    "# ==============================================================================\n",
    "\n",
    "TAXONOMY_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\taxonomy.json\"\n",
    "SUPPLIERS_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\suppliers.json\"\n",
    "INPUT_EXCEL_PATH = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\data\\source_file.xlsx\"\n",
    "OUTPUT_EXCEL_PATH = \"Processed_Defense_Data.xlsx\"\n",
    "\n",
    "RAG_KB_DIR = r\"C:\\Users\\mukeshkr\\Agentic-AI-Defense-Data-Extraction\\notebook\\system_kb_store\"\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2.1) LLM CLIENT SETUP (LLMFOUNDRY)\n",
    "# ==============================================================================\n",
    "\n",
    "if \"LLMFOUNDRY_TOKEN\" not in os.environ:\n",
    "    os.environ[\"LLMFOUNDRY_TOKEN\"] = getpass.getpass(\"Enter the LLM Foundry API Key: \")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=f'{os.environ.get(\"LLMFOUNDRY_TOKEN\")}:my-test-project',\n",
    "    base_url=\"https://llmfoundry.straive.com/openai/v1/\",\n",
    ")\n",
    "\n",
    "retriever = SystemKBRetriever(kb_dir=RAG_KB_DIR)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3) LOAD JSON HELPERS\n",
    "# ==============================================================================\n",
    "\n",
    "def load_json_file(filename, default_value):\n",
    "    \"\"\"\n",
    "    Safely loads JSON files like:\n",
    "    - taxonomy.json\n",
    "    - suppliers.json\n",
    "\n",
    "    Why:\n",
    "    - Your pipeline should never crash just because file path breaks.\n",
    "    - If missing, fallback to default_value.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            print(f\"Loaded: {filename}\")\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load {filename} ({e}). Using default.\")\n",
    "        return default_value\n",
    "\n",
    "\n",
    "raw_taxonomy = load_json_file(TAXONOMY_PATH, {})\n",
    "TAXONOMY_STR = json.dumps(raw_taxonomy, separators=(\",\", \":\"))\n",
    "\n",
    "SUPPLIER_LIST = load_json_file(SUPPLIERS_PATH, [\n",
    "    \"Dell Inc\", \"Boeing\", \"Lockheed Martin\", \"Raytheon Technologies\",\n",
    "    \"Northrop Grumman\", \"L3Harris\", \"BAE Systems\", \"General Dynamics\"\n",
    "])\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4) RULE BOOK + GEOGRAPHY\n",
    "# ==============================================================================\n",
    "\n",
    "RULE_BOOK = {\n",
    "    \"defensive_countermeasures\": {\n",
    "        \"triggers\": [\"flare\", \"chaff\", \"countermeasure\", \"decoy\", \"mju-\", \"ale-\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Defensive Systems', Specific: 'Defensive Aid Suite'\"\n",
    "    },\n",
    "    \"radars_and_sensors\": {\n",
    "        \"triggers\": [\"radar\", \"sonar\", \"sensor\", \"an/apy\", \"an/tpy\"],\n",
    "        \"guidance\": \"Market Segment: 'C4ISR Systems', System Type (General): 'Sensors'\"\n",
    "    },\n",
    "    \"ammunition\": {\n",
    "        \"triggers\": [\"cartridge\", \"round\", \"projectile\", \" 5.56\", \" 7.62\", \"ammo\"],\n",
    "        \"guidance\": \"Market Segment: 'Weapon Systems', System Type (General): 'Ammunition'\"\n",
    "    }\n",
    "}\n",
    "\n",
    "GEOGRAPHY_MAPPING = {\n",
    "    \"North America\": [\"USA\", \"United States\", \"US\", \"United States of America\", \"Canada\", \"America\"],\n",
    "    \"Europe\": [\"UK\", \"United Kingdom\", \"Ukraine\", \"Germany\", \"France\", \"Italy\", \"Spain\", \"Poland\", \"Netherlands\",\n",
    "               \"Norway\", \"Sweden\", \"Finland\", \"Denmark\", \"Belgium\"],\n",
    "    \"Asia-Pacific\": [\"Australia\", \"Japan\", \"South Korea\", \"Taiwan\", \"India\", \"Singapore\", \"New Zealand\"],\n",
    "    \"Middle East and North Africa\": [\"Israel\", \"Saudi Arabia\", \"UAE\", \"United Arab Emirates\", \"Egypt\", \"Qatar\", \"Kuwait\", \"Iraq\"],\n",
    "    \"International Organisations\": [\"NATO\", \"EU\", \"IFU\", \"UN\", \"NSPA\"]\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# 5) BASE HELPERS (Supplier + Dates + Region + Designators)\n",
    "# ==============================================================================\n",
    "\n",
    "PROGRAM_TYPE_ALLOWED = [\n",
    "    \"Procurement\",\n",
    "    \"Training\",\n",
    "    \"MRO/Support\",\n",
    "    \"RDT&E\",\n",
    "    \"Upgrade\",\n",
    "    \"Other Service\"\n",
    "]\n",
    "\n",
    "def normalize_program_type(pt: str) -> str:\n",
    "    \"\"\"\n",
    "    Ensures Program Type always matches exact allowed taxonomy.\n",
    "    \"\"\"\n",
    "    if not pt:\n",
    "        return \"Other Service\"\n",
    "\n",
    "    t = str(pt).strip().lower()\n",
    "\n",
    "    if any(k in t for k in [\"mro\", \"support\", \"maintenance\", \"repair\", \"overhaul\", \"sustainment\", \"logistics\"]):\n",
    "        return \"MRO/Support\"\n",
    "    if \"training\" in t:\n",
    "        return \"Training\"\n",
    "    if any(k in t for k in [\"rdte\", \"research\", \"development\", \"prototype\", \"test and evaluation\"]):\n",
    "        return \"RDT&E\"\n",
    "    if any(k in t for k in [\"upgrade\", \"modernization\", \"modification\"]):\n",
    "        return \"Upgrade\"\n",
    "    if any(k in t for k in [\"procure\", \"buy\", \"purchase\", \"production\", \"delivery\"]):\n",
    "        return \"Procurement\"\n",
    "\n",
    "    return \"Other Service\"\n",
    "\n",
    "\n",
    "def get_best_supplier_match(extracted_name: str) -> str:\n",
    "    \"\"\"\n",
    "    FIXED SUPPLIER MATCHING LOGIC (Priority Order):\n",
    "    \n",
    "    1. Exact Match: \"Boeing\" == \"Boeing\"\n",
    "    2. Substring Match (Known in Extracted): \n",
    "       If valid list has \"BAE Systems\" and extracted is \"BAE Systems - Norfolk Ship Repair\",\n",
    "       we detect \"BAE Systems\" is INSIDE the extracted text.\n",
    "       -> Returns \"BAE Systems\"\n",
    "    3. Substring Match (Extracted in Known):\n",
    "       extracted=\"Raytheon\" -> matches \"Raytheon Technologies\"\n",
    "    4. Fuzzy Match (Strict): Only high confidence (0.8) to prevent \"Ship Repair\" matching \"Admiralty Ship\".\n",
    "    5. Fallback: Return raw extracted text.\n",
    "    \"\"\"\n",
    "    if not extracted_name or str(extracted_name).strip().lower() in [\"unknown\", \"n/a\", \"not applicable\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    raw_name = str(extracted_name).strip()\n",
    "    raw_lower = raw_name.lower()\n",
    "    \n",
    "    # 0) Prepare List: Sort by length (descending) so we match \"General Dynamics\" before \"General\"\n",
    "    # This ensures we get the most specific match first.\n",
    "    valid_suppliers = sorted([str(s) for s in SUPPLIER_LIST], key=len, reverse=True)\n",
    "\n",
    "    # 1) Exact Match\n",
    "    for s in valid_suppliers:\n",
    "        if s.lower() == raw_lower:\n",
    "            return s\n",
    "\n",
    "    # 2) Reverse Substring: Check if a VALID SUPPLIER exists inside the EXTRACTED text\n",
    "    # Case: Extracted = \"BAE Systems - Norfolk Ship Repair\"\n",
    "    #       Valid List has \"BAE Systems\"\n",
    "    #       Match Found!\n",
    "    for s in valid_suppliers:\n",
    "        # We ensure 's' is not just a tiny generic word like \"Inc\" (length check > 3)\n",
    "        if len(s) > 3 and s.lower() in raw_lower:\n",
    "            return s\n",
    "\n",
    "    # 3) Forward Substring: Check if EXTRACTED text exists inside a VALID SUPPLIER\n",
    "    # Case: Extracted = \"Raytheon\"\n",
    "    #       Valid List has \"Raytheon Technologies\"\n",
    "    for s in valid_suppliers:\n",
    "        if raw_lower in s.lower():\n",
    "            return s\n",
    "\n",
    "    # 4) Strict Fuzzy Match (High Cutoff 0.8)\n",
    "    # cutoff=0.8 ensures \"Ship Repair\" does NOT match \"Admiralty Ship\" (which usually shares only ~40-50%)\n",
    "    matches = difflib.get_close_matches(raw_name, valid_suppliers, n=1, cutoff=0.8)\n",
    "    if matches:\n",
    "        return matches[0]\n",
    "\n",
    "    # 5) No Match -> Return the raw extracted text (Better than a wrong guess)\n",
    "    return raw_name\n",
    "\n",
    "\n",
    "def extract_awardee_supplier_strict(paragraph: str) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Extract supplier name STRICTLY using DoD awardee sentence format.\n",
    "    Then passes the raw extraction to get_best_supplier_match for fuzzy mapping.\n",
    "\n",
    "    Patterns:\n",
    "    - \", , is awarded ...\"\n",
    "    - \", , has been awarded ...\"\n",
    "    \"\"\"\n",
    "    text = str(paragraph).strip()\n",
    "\n",
    "    # IMPORTANT: We stop at first comma group before \"is awarded/was awarded/has been awarded\"\n",
    "    patterns = [\n",
    "        r\"^([A-Z][A-Za-z0-9&\\-\\.\\s]+?),\\s+.*?\\s+(?:is|was|has been)\\s+awarded\\b\",\n",
    "        r\"^([A-Z][A-Za-z0-9&\\-\\.\\s]+?),\\s+.*?\\s+received\\s+an?\\s+award\\b\",\n",
    "    ]\n",
    "\n",
    "    for pat in patterns:\n",
    "        m = re.search(pat, text, flags=re.IGNORECASE)\n",
    "        if m:\n",
    "            raw_supplier = m.group(1).strip()\n",
    "            # Standardize using the updated fuzzy logic function\n",
    "            final_supplier = get_best_supplier_match(raw_supplier)\n",
    "            return final_supplier, raw_supplier\n",
    "\n",
    "    return \"Unknown\", \"Not Found\"\n",
    "\n",
    "\n",
    "def calculate_mro_months(start_date_str, end_date_text, program_type):\n",
    "    \"\"\"\n",
    "    Calculates MRO duration (months) ONLY for program_type == \"MRO/Support\".\n",
    "    \"\"\"\n",
    "    if program_type != \"MRO/Support\":\n",
    "        return \"Not Applicable\"\n",
    "    try:\n",
    "        if not start_date_str or not end_date_text:\n",
    "            return \"Not Applicable\"\n",
    "\n",
    "        start = pd.to_datetime(start_date_str, dayfirst=True)\n",
    "        end = parser.parse(str(end_date_text), fuzzy=True)\n",
    "\n",
    "        diff = relativedelta(end, start)\n",
    "        total_months = diff.years * 12 + diff.months\n",
    "        return str(max(0, int(total_months)))\n",
    "    except:\n",
    "        return \"Not Applicable\"\n",
    "\n",
    "\n",
    "def get_region_for_country(country_name):\n",
    "    \"\"\"\n",
    "    Maps country -> region using GEOGRAPHY_MAPPING.\n",
    "    \"\"\"\n",
    "    if not country_name or str(country_name).strip().lower() in [\"unknown\", \"n/a\", \"not applicable\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    clean = str(country_name).strip().lower()\n",
    "\n",
    "    if clean in [\"us\", \"usa\", \"u.s.\", \"united states\", \"united states of america\"]:\n",
    "        return \"North America\"\n",
    "    if clean in [\"uk\", \"u.k.\", \"britain\", \"great britain\"]:\n",
    "        return \"Europe\"\n",
    "\n",
    "    for region, countries in GEOGRAPHY_MAPPING.items():\n",
    "        if any(c.lower() == clean for c in countries):\n",
    "            return region\n",
    "\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "DESIGNATOR_PATTERNS = [\n",
    "    r\"\\bDDG[-\\s]?\\d+\\b\", r\"\\bCVN[-\\s]?\\d+\\b\", r\"\\bSSN[-\\s]?\\d+\\b\",\n",
    "    r\"\\bLCS[-\\s]?\\d+\\b\", r\"\\bLPD[-\\s]?\\d+\\b\", r\"\\bLHA[-\\s]?\\d+\\b\", r\"\\bLHD[-\\s]?\\d+\\b\",\n",
    "    r\"\\bF-\\d+\\b\", r\"\\bB-\\d+\\b\", r\"\\bC-\\d+\\b\", r\"\\bA-\\d+\\b\",\n",
    "    r\"\\bMQ-\\d+\\b\", r\"\\bRQ-\\d+\\b\",\n",
    "    r\"\\bAN\\/[A-Z0-9\\-]+\\b\",\n",
    "    r\"\\b(AIM|AGM|SM|RIM|MIM)-\\d+\\b\",\n",
    "]\n",
    "\n",
    "def extract_designators(text: str):\n",
    "    \"\"\"\n",
    "    Extract common platform/system designators from paragraph.\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    found = []\n",
    "    for pat in DESIGNATOR_PATTERNS:\n",
    "        found.extend(re.findall(pat, text, flags=re.IGNORECASE))\n",
    "    cleaned = []\n",
    "    for f in found:\n",
    "        cleaned.append(f.upper().replace(\" \", \"\").replace(\"--\", \"-\"))\n",
    "    final = []\n",
    "    seen = set()\n",
    "    for x in cleaned:\n",
    "        if x not in seen:\n",
    "            final.append(x)\n",
    "            seen.add(x)\n",
    "    return final\n",
    "\n",
    "\n",
    "def detect_piloting_rule_based(text: str, designators: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Deterministic piloting classification to reduce LLM mistakes.\n",
    "    \"\"\"\n",
    "    t = str(text).lower()\n",
    "\n",
    "    if any(d.startswith((\"MQ-\", \"RQ-\")) for d in designators):\n",
    "        return \"Uncrewed\"\n",
    "    if any(k in t for k in [\"unmanned\", \"uav\", \"drone\", \"autonomous\"]):\n",
    "        return \"Uncrewed\"\n",
    "\n",
    "    if any(d.startswith((\"DDG\", \"CVN\", \"SSN\", \"LCS\", \"LPD\", \"LHA\", \"LHD\")) for d in designators):\n",
    "        return \"Crewed\"\n",
    "    if \"uss \" in t:\n",
    "        return \"Crewed\"\n",
    "\n",
    "    return \"Not Applicable\"\n",
    "\n",
    "# ==============================================================================\n",
    "# 6) SPLIT ENGINE (UPDATED: Multi-Operator Fallback)\n",
    "# ==============================================================================\n",
    "\n",
    "def parse_operator_quantity_allocations(paragraph: str):\n",
    "    \"\"\"\n",
    "    Detect quantity allocations by operator.\n",
    "    Supported patterns:\n",
    "      - \"212 for the Navy\"\n",
    "      - \"187 for the Air Force\"\n",
    "      - \"84 for Foreign Military Sales (FMS) customers\"\n",
    "    \"\"\"\n",
    "    text = str(paragraph)\n",
    "    allocations = []\n",
    "\n",
    "    # Standard \"Qty for Branch\" pattern\n",
    "    pattern = r\"(\\d+)\\s+for\\s+the\\s+(Navy|Air Force|Army|Marine Corps|Space Force|Coast Guard)\"\n",
    "    matches = re.findall(pattern, text, flags=re.IGNORECASE)\n",
    "    for qty, op in matches:\n",
    "        allocations.append({\"operator\": op.title(), \"quantity\": qty, \"g2g_b2g\": \"B2G\"})\n",
    "\n",
    "    # FMS Pattern\n",
    "    fms_pattern = r\"(\\d+)\\s+for\\s+(?:Foreign Military Sales\\s*\\s*customers|FMS\\s*customers|a\\s*FMS\\s*customer|FMS)\"\n",
    "    fms_matches = re.findall(fms_pattern, text, flags=re.IGNORECASE)\n",
    "    for qty in fms_matches:\n",
    "        allocations.append({\"operator\": \"Foreign Assistance\", \"quantity\": qty, \"g2g_b2g\": \"G2G\"})\n",
    "\n",
    "    # Deduplicate\n",
    "    unique = []\n",
    "    seen = set()\n",
    "    for a in allocations:\n",
    "        key = (a[\"operator\"], a[\"quantity\"], a[\"g2g_b2g\"])\n",
    "        if key not in seen:\n",
    "            unique.append(a)\n",
    "            seen.add(key)\n",
    "\n",
    "    return unique\n",
    "\n",
    "\n",
    "def parse_fms_countries(paragraph: str):\n",
    "    \"\"\"\n",
    "    Extract FMS customer countries list.\n",
    "    Example: \"governments of Australia, Bahrain, Belgium...\"\n",
    "    \"\"\"\n",
    "    text = str(paragraph)\n",
    "\n",
    "    m = re.search(\n",
    "        r\"governments of (.+?)(?:\\.\\s| Work will be performed| Fiscal| This contract|$)\",\n",
    "        text,\n",
    "        flags=re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "    if not m:\n",
    "        return []\n",
    "\n",
    "    block = m.group(1)\n",
    "    raw = re.split(r\",|\\band\\b\", block)\n",
    "\n",
    "    countries = []\n",
    "    for c in raw:\n",
    "        c = c.strip()\n",
    "        if 2 < len(c) <= 40:\n",
    "            countries.append(c)\n",
    "\n",
    "    final = []\n",
    "    seen = set()\n",
    "    for c in countries:\n",
    "        if c.lower() not in seen:\n",
    "            final.append(c)\n",
    "            seen.add(c.lower())\n",
    "\n",
    "    return final\n",
    "\n",
    "\n",
    "def parse_multiple_values(paragraph: str):\n",
    "    \"\"\"\n",
    "    Detect multiple values inside paragraph.\n",
    "    \"\"\"\n",
    "    text = str(paragraph)\n",
    "    money_pattern = r\"\\$([\\d,]+(?:\\.\\d+)?)\"\n",
    "    vals = re.findall(money_pattern, text)\n",
    "    vals = list(dict.fromkeys(vals))\n",
    "    return vals\n",
    "\n",
    "\n",
    "def split_rows_engine(base_row: dict, paragraph: str):\n",
    "    \"\"\"\n",
    "    MASTER SPLIT ENGINE (Updated for Explicit Operator Split)\n",
    "\n",
    "    Logic Priorities:\n",
    "    1. Quantity-based Split: If \"5 for Navy, 2 for Army\" found -> Split with quantities.\n",
    "    2. Explicit Operator List: If no quantities found, but 'Customer Operator' column \n",
    "       contains commas (e.g. \"Navy, Air Force\") -> Split into rows with \"Not Applicable\" quantity.\n",
    "    3. FMS Split: If G2G, split by FMS countries.\n",
    "    \"\"\"\n",
    "    paragraph = str(paragraph)\n",
    "\n",
    "    # 1. Parse regex-based allocations (High Precision)\n",
    "    allocations = parse_operator_quantity_allocations(paragraph)\n",
    "    \n",
    "    # 2. Parse FMS countries\n",
    "    fms_countries = parse_fms_countries(paragraph)\n",
    "    \n",
    "    # 3. Check for multi-value notes\n",
    "    multi_values = parse_multiple_values(paragraph)\n",
    "\n",
    "    split_reasons = []\n",
    "    \n",
    "    # Check 1: Did we find \"Qty for Operator\"?\n",
    "    if allocations:\n",
    "        split_reasons.append(\"Multi-operator quantity allocation found\")\n",
    "    \n",
    "    # Check 2: If NOT, did the LLM extract multiple operators in the column?\n",
    "    # e.g. base_row[\"Customer Operator\"] = \"Air Force, Navy\"\n",
    "    raw_operators = str(base_row.get(\"Customer Operator\", \"\")).split(\",\")\n",
    "    clean_operators = [op.strip() for op in raw_operators if op.strip() and op.strip().lower() != \"unknown\"]\n",
    "    \n",
    "    has_operator_list_split = False\n",
    "    if not allocations and len(clean_operators) > 1:\n",
    "        has_operator_list_split = True\n",
    "        split_reasons.append(\"Multiple Customer Operators detected (Text Split)\")\n",
    "\n",
    "    if fms_countries:\n",
    "        split_reasons.append(\"FMS multi-country list found\")\n",
    "    if len(multi_values) >= 2:\n",
    "        split_reasons.append(\"Multiple financial values found\")\n",
    "\n",
    "    # --- NO SPLIT CASE ---\n",
    "    if not split_reasons:\n",
    "        base_row[\"Split Flag\"] = \"No\"\n",
    "        base_row[\"Split Reason\"] = \"No split condition found\"\n",
    "        return [base_row]\n",
    "\n",
    "    # --- EXECUTE SPLITS ---\n",
    "    rows = [base_row.copy()]\n",
    "    base_reason = \" | \".join(split_reasons)\n",
    "\n",
    "    # Priority A: Quantity-based Allocation Split\n",
    "    if allocations:\n",
    "        new_rows = []\n",
    "        for r in rows:\n",
    "            for alloc in allocations:\n",
    "                rr = r.copy()\n",
    "                rr[\"Customer Operator\"] = alloc[\"operator\"]\n",
    "                rr[\"Quantity\"] = alloc[\"quantity\"]\n",
    "                rr[\"G2G/B2G\"] = alloc[\"g2g_b2g\"]\n",
    "                rr[\"Split Flag\"] = \"Yes\"\n",
    "                rr[\"Split Reason\"] = f\"{base_reason} (allocations)\"\n",
    "                new_rows.append(rr)\n",
    "        rows = new_rows\n",
    "    \n",
    "    # Priority B: Explicit Operator List Split (Fallback if no quantities)\n",
    "    elif has_operator_list_split:\n",
    "        new_rows = []\n",
    "        for r in rows:\n",
    "            for op_name in clean_operators:\n",
    "                rr = r.copy()\n",
    "                rr[\"Customer Operator\"] = op_name\n",
    "                # We don't know the quantity split, so we keep original or mark N/A\n",
    "                rr[\"Quantity\"] = \"Not Applicable\" \n",
    "                rr[\"Split Flag\"] = \"Yes\"\n",
    "                rr[\"Split Reason\"] = f\"{base_reason} (operator list)\"\n",
    "                new_rows.append(rr)\n",
    "        rows = new_rows\n",
    "\n",
    "    # Priority C: Multi-value annotation (Just adds a note)\n",
    "    if len(multi_values) >= 2:\n",
    "        for r in rows:\n",
    "            note = r.get(\"Value Note (If Any)\", \"Not Applicable\")\n",
    "            r[\"Value Note (If Any)\"] = f\"{note} | Multiple values detected: {multi_values[:5]}\"\n",
    "\n",
    "    # Priority D: FMS Country Split (Only for G2G rows)\n",
    "    if fms_countries:\n",
    "        final_rows = []\n",
    "        for r in rows:\n",
    "            # Only split if it's actually a G2G row OR the operator is Generic FMS\n",
    "            is_g2g = r.get(\"G2G/B2G\") == \"G2G\"\n",
    "            is_fms_op = \"foreign\" in str(r.get(\"Customer Operator\")).lower()\n",
    "            \n",
    "            if is_g2g or is_fms_op:\n",
    "                for c in fms_countries:\n",
    "                    rr = r.copy()\n",
    "                    rr[\"Customer Country\"] = c\n",
    "                    rr[\"Customer Region\"] = get_region_for_country(c)\n",
    "                    rr[\"Split Flag\"] = \"Yes\"\n",
    "                    rr[\"Split Reason\"] = f\"{base_reason} (FMS countries)\"\n",
    "                    final_rows.append(rr)\n",
    "            else:\n",
    "                final_rows.append(r)\n",
    "        rows = final_rows\n",
    "\n",
    "    # Final cleanup of flags\n",
    "    for r in rows:\n",
    "        r.setdefault(\"Split Flag\", \"Yes\")\n",
    "        r.setdefault(\"Split Reason\", base_reason)\n",
    "\n",
    "    return rows\n",
    "\n",
    "# ==============================================================================\n",
    "# 7) AGENTS / TOOLS\n",
    "# ==============================================================================\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Stage 1: SOURCING EXTRACTOR\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "class SourcingInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    url: str = Field(description=\"Source URL of the contract announcement/news.\")\n",
    "    date: str = Field(description=\"Contract date in Excel (string).\")\n",
    "\n",
    "@tool(\"sourcing_extractor\")\n",
    "def sourcing_extractor(paragraph: str, url: str, date: str):\n",
    "    \"\"\"\n",
    "    Stage 1: SOURCING EXTRACTOR\n",
    "\n",
    "    Purpose:\n",
    "    - Creates the base skeleton row (stable fields).\n",
    "\n",
    "    Output columns created:\n",
    "    - Description of Contract\n",
    "    - Additional Notes (Internal Only)\n",
    "    - Source Link(s)\n",
    "    - Contract Date\n",
    "    - Reported Date (By SGA)\n",
    "\n",
    "    Important:\n",
    "    - These fields remain SAME even after splits.\n",
    "    - Every split row inherits these values.\n",
    "    \"\"\"\n",
    "    reported_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    notes = \"Standard extraction.\"\n",
    "    if \"modification\" in str(paragraph).lower():\n",
    "        notes = \"Contract Modification.\"\n",
    "    if \"multiple award\" in str(paragraph).lower():\n",
    "        notes = \"Multiple award contract detected (non-supplier split).\"\n",
    "\n",
    "    return {\n",
    "        \"Description of Contract\": paragraph,\n",
    "        \"Additional Notes (Internal Only)\": notes,\n",
    "        \"Source Link(s)\": url,\n",
    "        \"Contract Date\": date,\n",
    "        \"Reported Date (By SGA)\": reported_date\n",
    "    }\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Stage 2: GEOGRAPHY EXTRACTOR\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "class GeographyInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "\n",
    "@tool(\"geography_extractor\")\n",
    "def geography_extractor(paragraph: str):\n",
    "    \"\"\"\n",
    "    Stage 2: GEOGRAPHY EXTRACTOR\n",
    "\n",
    "    Purpose:\n",
    "    - Extract geo + operator fields:\n",
    "      - Customer Country\n",
    "      - Customer Operator\n",
    "      - Supplier Country\n",
    "\n",
    "    Derivations:\n",
    "      - Customer Region\n",
    "      - Supplier Region\n",
    "      - Domestic Content (Indigenous vs Imported)\n",
    "\n",
    "    Notes:\n",
    "    - Supplier Country is NOT supplier name.\n",
    "    - Supplier Name is extracted later in Stage4.\n",
    "    \"\"\"\n",
    "    sys_prompt = \"\"\"\n",
    "Extract: Customer Country, Supplier Country, Customer Operator.\n",
    "\n",
    "Strict Rules:\n",
    "- If the paragraph mentions \"Navy\", \"Air Force\", \"Army\", \"Marine Corps\"\n",
    "  and it is in buyer context -> set Customer Operator accordingly.\n",
    "- If the paragraph is FMS, customer might be \"Foreign Military Sales\",\n",
    "  but country list is handled later in split stage.\n",
    "- Return ONLY JSON.\n",
    "\n",
    "Return JSON:\n",
    "{\n",
    "  \"Customer Country\": \"...\",\n",
    "  \"Customer Operator\": \"...\",\n",
    "  \"Supplier Country\": \"...\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "    log_block(\"HUMAN MESSAGE (Stage2 - Geography)\", paragraph)\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"system\", \"content\": sys_prompt},\n",
    "                      {\"role\": \"user\", \"content\": paragraph}],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "        log_block(\"AI RESPONSE (Stage2 - Geography)\", json.dumps(raw, indent=2))\n",
    "    except Exception as e:\n",
    "        raw = {}\n",
    "        log_block(\"AI ERROR (Stage2 - Geography)\", str(e))\n",
    "\n",
    "    cust = raw.get(\"Customer Country\", \"Unknown\")\n",
    "    supp = raw.get(\"Supplier Country\", \"Unknown\")\n",
    "\n",
    "    domestic = \"Indigenous\" if str(cust).lower() == str(supp).lower() else \"Imported\"\n",
    "\n",
    "    return {\n",
    "        \"Customer Region\": get_region_for_country(cust),\n",
    "        \"Customer Country\": cust,\n",
    "        \"Customer Operator\": raw.get(\"Customer Operator\", \"Unknown\"),\n",
    "        \"Supplier Region\": get_region_for_country(supp),\n",
    "        \"Supplier Country\": supp,\n",
    "        \"Domestic Content\": domestic\n",
    "    }\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Stage 3: SYSTEM CLASSIFIER (RAG-ENHANCED)\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "class SystemInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "\n",
    "@tool(\"system_classifier\")\n",
    "def system_classifier(paragraph: str):\n",
    "    \"\"\"\n",
    "    Stage 3: SYSTEM CLASSIFIER (RAG-Enhanced)\n",
    "\n",
    "    Purpose:\n",
    "    - Determine defense system labels using:\n",
    "      Taxonomy reference\n",
    "      Rule book overrides\n",
    "      RAG KB similar examples\n",
    "      Deterministic piloting override\n",
    "\n",
    "    Output:\n",
    "    - Market Segment\n",
    "    - System Type (General)\n",
    "    - System Type (Specific)\n",
    "    - System Name (General)\n",
    "    - System Name (Specific)\n",
    "    - System Piloting\n",
    "    - Evidence + Reason for each label\n",
    "    - Confidence\n",
    "\n",
    "    Strict output rules:\n",
    "    - Return FLAT JSON object only\n",
    "    - Each value must be STRING\n",
    "    - Evidence must be exact copied substring or \"Not Found\"\n",
    "    \"\"\"\n",
    "    paragraph = str(paragraph).strip()\n",
    "    if not paragraph:\n",
    "        return {}\n",
    "\n",
    "    log_block(\"HUMAN MESSAGE (Stage3 - System)\", paragraph)\n",
    "\n",
    "    lower_text = paragraph.lower()\n",
    "    hints = [\n",
    "        f\"RULE: {v['guidance']}\"\n",
    "        for _, v in RULE_BOOK.items()\n",
    "        if any(t in lower_text for t in v[\"triggers\"])\n",
    "    ]\n",
    "    hint_str = \"\\n\".join(hints) if hints else \"No special override rules triggered.\"\n",
    "\n",
    "    designators = extract_designators(paragraph)\n",
    "    piloting_rule = detect_piloting_rule_based(paragraph, designators)\n",
    "\n",
    "    rag_hits = retriever.retrieve(paragraph, top_k=3)\n",
    "    rag_examples = []\n",
    "    for hit in rag_hits:\n",
    "        meta = hit[\"meta\"]\n",
    "        rag_examples.append({\n",
    "            \"score\": round(hit[\"score\"], 4),\n",
    "            \"Market Segment\": meta.get(\"Market Segment\", \"\"),\n",
    "            \"System Type (General)\": meta.get(\"System Type (General)\", \"\"),\n",
    "            \"System Type (Specific)\": meta.get(\"System Type (Specific)\", \"\"),\n",
    "            \"System Name (General)\": meta.get(\"System Name (General)\", \"\"),\n",
    "            \"System Name (Specific)\": meta.get(\"System Name (Specific)\", \"\"),\n",
    "            \"System Piloting\": meta.get(\"System Piloting\", \"\"),\n",
    "            \"Snippet\": meta.get(\"Description of Contract\", \"\")[:220] + \"...\"\n",
    "        })\n",
    "\n",
    "    sys_prompt = f\"\"\"\n",
    "You are a Senior Defense System Classification Analyst.\n",
    "\n",
    "REFERENCE TAXONOMY:\n",
    "{TAXONOMY_STR}\n",
    "\n",
    "RULE BOOK OVERRIDES:\n",
    "{hint_str}\n",
    "\n",
    "OUTPUT RULES:\n",
    "- Return ONLY a FLAT JSON object.\n",
    "- Every value must be a STRING.\n",
    "- Do NOT return nested objects or lists.\n",
    "- Evidence must be copied EXACTLY from paragraph text.\n",
    "- If evidence not present, output \"Not Found\".\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"Market Segment\": \"\",\n",
    "  \"Market Segment Evidence\": \"\",\n",
    "  \"Market Segment Reason\": \"\",\n",
    "\n",
    "  \"System Type (General)\": \"\",\n",
    "  \"System Type (General) Evidence\": \"\",\n",
    "  \"System Type (General) Reason\": \"\",\n",
    "\n",
    "  \"System Type (Specific)\": \"\",\n",
    "  \"System Type (Specific) Evidence\": \"\",\n",
    "  \"System Type (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Name (General)\": \"\",\n",
    "  \"System Name (General) Evidence\": \"\",\n",
    "  \"System Name (General) Reason\": \"\",\n",
    "\n",
    "  \"System Name (Specific)\": \"\",\n",
    "  \"System Name (Specific) Evidence\": \"\",\n",
    "  \"System Name (Specific) Reason\": \"\",\n",
    "\n",
    "  \"System Piloting\": \"\",\n",
    "  \"System Piloting Evidence\": \"\",\n",
    "  \"System Piloting Reason\": \"\",\n",
    "\n",
    "  \"Confidence\": \"High/Medium/Low\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "PARAGRAPH:\n",
    "{paragraph}\n",
    "\n",
    "DESIGNATORS (regex extracted):\n",
    "{designators if designators else \"None\"}\n",
    "\n",
    "RULE BASED PILOTING:\n",
    "{piloting_rule}\n",
    "\n",
    "RAG EXAMPLES:\n",
    "{json.dumps(rag_examples, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"system\", \"content\": sys_prompt},\n",
    "                      {\"role\": \"user\", \"content\": user_prompt}],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        result = json.loads(completion.choices[0].message.content)\n",
    "        log_block(\"AI RESPONSE (Stage3 - System)\", json.dumps(result, indent=2))\n",
    "\n",
    "        # Hard override piloting rule\n",
    "        result[\"System Piloting\"] = piloting_rule\n",
    "        result.setdefault(\"System Piloting Evidence\", \"Not Found\")\n",
    "        result.setdefault(\"System Piloting Reason\", \"Derived from deterministic piloting rules.\")\n",
    "\n",
    "        # Ensure flat\n",
    "        for k, v in result.items():\n",
    "            if isinstance(v, (dict, list)):\n",
    "                result[k] = str(v)\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        log_block(\"AI ERROR (Stage3 - System)\", str(e))\n",
    "        return {\n",
    "            \"Market Segment\": \"\",\n",
    "            \"Market Segment Evidence\": \"Not Found\",\n",
    "            \"Market Segment Reason\": \"\",\n",
    "\n",
    "            \"System Type (General)\": \"\",\n",
    "            \"System Type (General) Evidence\": \"Not Found\",\n",
    "            \"System Type (General) Reason\": \"\",\n",
    "\n",
    "            \"System Type (Specific)\": \"\",\n",
    "            \"System Type (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Type (Specific) Reason\": \"\",\n",
    "\n",
    "            \"System Name (General)\": \"\",\n",
    "            \"System Name (General) Evidence\": \"Not Found\",\n",
    "            \"System Name (General) Reason\": \"\",\n",
    "\n",
    "            \"System Name (Specific)\": \"\",\n",
    "            \"System Name (Specific) Evidence\": \"Not Found\",\n",
    "            \"System Name (Specific) Reason\": \"\",\n",
    "\n",
    "            \"System Piloting\": piloting_rule,\n",
    "            \"System Piloting Evidence\": \"Not Found\",\n",
    "            \"System Piloting Reason\": \"Derived from deterministic piloting rules.\",\n",
    "\n",
    "            \"Confidence\": \"Low\",\n",
    "            \"Error\": str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Stage 4: CONTRACT EXTRACTOR (SUPPLIER FIXED)\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "class ContractInfoInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    contract_date: str = Field(description=\"Contract date as string.\")\n",
    "\n",
    "@tool(\"contract_extractor\")\n",
    "def contract_extractor(paragraph: str, contract_date: str):\n",
    "    \"\"\"\n",
    "    Stage 4: CONTRACT EXTRACTOR (Supplier + Financial + Program details)\n",
    "\n",
    "    Purpose:\n",
    "    - Extract:\n",
    "      Supplier Name  (STRICT award-pattern extraction only)\n",
    "      Program Type   (must be EXACT allowed set; MRO/Support fixed)\n",
    "      Quantity\n",
    "      Value (Million)\n",
    "      Currency\n",
    "      Value Certainty\n",
    "      G2G/B2G\n",
    "      Completion Date Text\n",
    "\n",
    "    CRITICAL SUPPLIER FIX:\n",
    "    - Supplier Name must come from the DoD award format:\n",
    "      \", , is awarded ...\"\n",
    "    - We DO NOT scan paragraph for multiple suppliers.\n",
    "    - We DO NOT split on supplier.\n",
    "    - If strict pattern fails -> Supplier = Unknown\n",
    "\n",
    "    Output JSON:\n",
    "    - Flat dictionary with correct normalized fields\n",
    "    \"\"\"\n",
    "    # STRICT supplier extraction first\n",
    "    supplier_name, supplier_evidence = extract_awardee_supplier_strict(paragraph)\n",
    "\n",
    "    # Program type + financial extraction by LLM\n",
    "    system_instruction = \"\"\"\n",
    "You are a Defense Contract Financial Analyst.\n",
    "\n",
    "Your job:\n",
    "- Extract only factual contract financial + program info.\n",
    "\n",
    "STRICT PROGRAM TYPE ENUM (must output EXACT string from list):\n",
    "- Procurement\n",
    "- Training\n",
    "- MRO/Support\n",
    "- RDT&E\n",
    "- Upgrade\n",
    "- Other Service\n",
    "\n",
    "Rules:\n",
    "1) program_type MUST be one of the allowed strings above.\n",
    "2) value_certainty must be Confirmed or Estimated\n",
    "3) quantity must be numeric if possible else \"Not Applicable\"\n",
    "4) g2g_b2g:\n",
    "   - \"G2G\" ONLY if FMS/Foreign Military Sales is clearly mentioned\n",
    "   - Otherwise \"B2G\"\n",
    "5) completion_date_text: keep raw completion date phrase if exists\n",
    "\n",
    "Return ONLY JSON object.\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "PARAGRAPH:\n",
    "{paragraph}\n",
    "\n",
    "SIGNED DATE:\n",
    "{contract_date}\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"program_type\": \"\",\n",
    "  \"value_million_raw\": \"\",\n",
    "  \"currency_code\": \"\",\n",
    "  \"value_certainty\": \"\",\n",
    "  \"quantity\": \"\",\n",
    "  \"completion_date_text\": \"\",\n",
    "  \"g2g_b2g\": \"\",\n",
    "  \"value_note\": \"\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    log_block(\"HUMAN MESSAGE (Stage4 - Contract)\", paragraph)\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"system\", \"content\": system_instruction},\n",
    "                      {\"role\": \"user\", \"content\": user_prompt}],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw = json.loads(completion.choices[0].message.content)\n",
    "        log_block(\"AI RESPONSE (Stage4 - Contract)\", json.dumps(raw, indent=2))\n",
    "    except Exception as e:\n",
    "        log_block(\"AI ERROR (Stage4 - Contract)\", str(e))\n",
    "        raw = {}\n",
    "\n",
    "    # Normalize Program Type strictly\n",
    "    pt_raw = raw.get(\"program_type\", \"\")\n",
    "    program_type = normalize_program_type(pt_raw)\n",
    "\n",
    "    mro_months = calculate_mro_months(contract_date, raw.get(\"completion_date_text\"), program_type)\n",
    "\n",
    "    # Parse value\n",
    "    try:\n",
    "        val_str = str(raw.get(\"value_million_raw\", \"0\")).replace(\",\", \"\").replace(\"$\", \"\")\n",
    "        val_float = float(val_str)\n",
    "        val_formatted = \"{:.3f}\".format(val_float)\n",
    "    except:\n",
    "        val_formatted = \"0.000\"\n",
    "\n",
    "    # Signing month/year\n",
    "    try:\n",
    "        dt = pd.to_datetime(contract_date)\n",
    "        sign_month = dt.strftime(\"%B\")\n",
    "        sign_year = str(dt.year)\n",
    "    except:\n",
    "        sign_month, sign_year = \"Unknown\", \"Unknown\"\n",
    "\n",
    "    return {\n",
    "        \"Supplier Name\": supplier_name,\n",
    "        \"Supplier Name Evidence\": supplier_evidence,\n",
    "\n",
    "        \"Program Type\": program_type,\n",
    "        \"Expected MRO Contract Duration (Months)\": mro_months,\n",
    "\n",
    "        \"Quantity\": raw.get(\"quantity\", \"Not Applicable\"),\n",
    "        \"Value Certainty\": raw.get(\"value_certainty\", \"Confirmed\"),\n",
    "\n",
    "        \"Value (Million)\": val_formatted,\n",
    "        \"Currency\": raw.get(\"currency_code\", \"USD$\"),\n",
    "        \"Value (USD$ Million)\": val_formatted,\n",
    "\n",
    "        \"Value Note (If Any)\": raw.get(\"value_note\", \"Not Applicable\"),\n",
    "        \"G2G/B2G\": raw.get(\"g2g_b2g\", \"B2G\"),\n",
    "\n",
    "        \"Signing Month\": sign_month,\n",
    "        \"Signing Year\": sign_year\n",
    "    }\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Stage 5: SPLITTER AGENT\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "class SplitterInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Full contract paragraph/description text.\")\n",
    "    base_row: dict = Field(description=\"Extracted row after Stage1-4.\")\n",
    "\n",
    "@tool(\"splitter_agent\")\n",
    "def splitter_agent(paragraph: str, base_row: dict):\n",
    "    \"\"\"\n",
    "    Stage 5: SPLITTER AGENT\n",
    "\n",
    "    Purpose:\n",
    "    - Applies deterministic split logic to generate multiple output rows\n",
    "      when paragraph has explicit multi allocations.\n",
    "\n",
    "    Supported splits:\n",
    "    Operator/Quantity split (\"212 for the Navy\", \"187 for the Air Force\")\n",
    "    FMS country split (only for rows marked as G2G)\n",
    "    Multi-value note (does not split, only notes)\n",
    "\n",
    "    IMPORTANT:\n",
    "    - Supplier split is REMOVED to prevent wrong supplier explosions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        rows = split_rows_engine(base_row, paragraph)\n",
    "        for r in rows:\n",
    "            r.setdefault(\"Split Flag\", \"No\")\n",
    "            r.setdefault(\"Split Reason\", \"\")\n",
    "        return {\"rows\": rows}\n",
    "    except Exception as e:\n",
    "        base_row[\"Split Flag\"] = \"Error\"\n",
    "        base_row[\"Split Reason\"] = f\"Split failed: {str(e)}\"\n",
    "        return {\"rows\": [base_row]}\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Stage 6: QUALITY VALIDATOR AGENT (RULE-BASED)\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "class QAInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Original paragraph for reference and validation.\")\n",
    "    rows: list = Field(description=\"Final split rows list output from Stage5.\")\n",
    "\n",
    "@tool(\"quality_validator\")\n",
    "def quality_validator(paragraph: str, rows: list):\n",
    "    \"\"\"\n",
    "    Stage 6: QUALITY VALIDATOR (Rule-Based)\n",
    "\n",
    "    Purpose:\n",
    "    - Detect obvious wrong extractions and flag them.\n",
    "    - This helps reduce garbage rows going to the output Excel.\n",
    "\n",
    "    Validation Checks (examples):\n",
    "    1) Supplier Name must NOT be Unknown if strict award pattern exists\n",
    "    2) Supplier Name must NOT be numeric or short garbage tokens\n",
    "    3) Program Type must always be one of allowed enum\n",
    "    4) System Market/System Type should not be empty\n",
    "    5) If G2G then FMS keyword must exist (soft check)\n",
    "    6) Value must be numeric >= 0\n",
    "\n",
    "    Output:\n",
    "    - Adds columns to each row:\n",
    "        QA Status = PASS/FAIL\n",
    "        QA Flags = \"...\" reasons\n",
    "        QA Fix Suggestion = what to correct\n",
    "    \"\"\"\n",
    "    text = str(paragraph).lower()\n",
    "\n",
    "    validated_rows = []\n",
    "    for r in rows:\n",
    "        flags = []\n",
    "        fixes = []\n",
    "\n",
    "        supplier = str(r.get(\"Supplier Name\", \"\")).strip()\n",
    "        supplier_ev = str(r.get(\"Supplier Name Evidence\", \"\")).strip()\n",
    "        program_type = str(r.get(\"Program Type\", \"\")).strip()\n",
    "\n",
    "        market = str(r.get(\"Market Segment\", \"\")).strip()\n",
    "        sys_gen = str(r.get(\"System Type (General)\", \"\")).strip()\n",
    "\n",
    "        g2g_b2g = str(r.get(\"G2G/B2G\", \"\")).strip()\n",
    "\n",
    "        value_m = str(r.get(\"Value (Million)\", \"\")).strip()\n",
    "\n",
    "        # --- Supplier validations\n",
    "        if supplier.lower() in [\"unknown\", \"n/a\", \"not applicable\", \"\"]:\n",
    "            # If paragraph looks like award pattern exists -> supplier must not be unknown\n",
    "            if re.search(r\"\\b(is|was|has been)\\s+awarded\\b\", text):\n",
    "                flags.append(\"Supplier is Unknown but award pattern exists\")\n",
    "                fixes.append(\"Re-extract supplier using strict awardee supplier extraction\")\n",
    "\n",
    "        if len(supplier) > 0 and len(supplier) <= 2:\n",
    "            flags.append(\"Supplier name too short / garbage\")\n",
    "            fixes.append(\"Supplier extraction likely wrong; enforce strict pattern\")\n",
    "\n",
    "        if supplier.isdigit():\n",
    "            flags.append(\"Supplier name is numeric\")\n",
    "            fixes.append(\"Supplier extraction corrupted; enforce strict pattern\")\n",
    "\n",
    "        # If supplier evidence exists, it must not contain commas indicating location misuse\n",
    "        if supplier_ev != \"Not Found\" and \",\" in supplier_ev:\n",
    "            flags.append(\"Supplier evidence contains commas (may include location)\")\n",
    "            fixes.append(\"Ensure only supplier name captured before first comma\")\n",
    "\n",
    "        # --- Program type validations\n",
    "        if program_type not in PROGRAM_TYPE_ALLOWED:\n",
    "            flags.append(\"Program Type not in allowed enum\")\n",
    "            fixes.append(f\"Normalize Program Type using allowed enum: {PROGRAM_TYPE_ALLOWED}\")\n",
    "\n",
    "        # --- System classification validations\n",
    "        if not market:\n",
    "            flags.append(\"Market Segment empty\")\n",
    "            fixes.append(\"System classifier must output Market Segment\")\n",
    "        if not sys_gen:\n",
    "            flags.append(\"System Type (General) empty\")\n",
    "            fixes.append(\"System classifier must output System Type (General)\")\n",
    "\n",
    "        # --- G2G soft check\n",
    "        if g2g_b2g == \"G2G\" and \"fms\" not in text and \"foreign military sales\" not in text:\n",
    "            flags.append(\"Row marked G2G but paragraph does not mention FMS\")\n",
    "            fixes.append(\"Re-evaluate G2G/B2G detection\")\n",
    "\n",
    "        # --- Value validation\n",
    "        try:\n",
    "            v = float(value_m)\n",
    "            if v < 0:\n",
    "                flags.append(\"Value (Million) is negative\")\n",
    "                fixes.append(\"Fix financial value extraction\")\n",
    "        except:\n",
    "            flags.append(\"Value (Million) not numeric\")\n",
    "            fixes.append(\"Fix value parsing and enforce numeric output\")\n",
    "\n",
    "        qa_status = \"PASS\" if len(flags) == 0 else \"FAIL\"\n",
    "\n",
    "        rr = r.copy()\n",
    "        rr[\"QA Status\"] = qa_status\n",
    "        rr[\"QA Flags\"] = \" | \".join(flags) if flags else \"None\"\n",
    "        rr[\"QA Fix Suggestion\"] = \" | \".join(fixes) if fixes else \"None\"\n",
    "\n",
    "        validated_rows.append(rr)\n",
    "\n",
    "    return {\"rows\": validated_rows}\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Stage 7: LLM VALIDATOR (ONLY FOR FAIL ROWS)\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "class LLMValidateInput(BaseModel):\n",
    "    paragraph: str = Field(description=\"Original paragraph text.\")\n",
    "    row: dict = Field(description=\"One single FAIL row to validate/correct.\")\n",
    "\n",
    "@tool(\"llm_fail_row_validator\")\n",
    "def llm_fail_row_validator(paragraph: str, row: dict):\n",
    "    \"\"\"\n",
    "    Stage 7: LLM FAIL ROW VALIDATOR (Runs ONLY if QA Status = FAIL)\n",
    "\n",
    "    Purpose:\n",
    "    - For FAIL rows, ask LLM to:\n",
    "      confirm which fields are wrong\n",
    "      propose corrected values\n",
    "      keep stable fields unchanged\n",
    "\n",
    "    This stage is OPTIONAL but very useful because:\n",
    "    - Rule-based validator detects the mistake\n",
    "    - LLM can fix the row if fix is obvious\n",
    "\n",
    "    Strong Rules:\n",
    "    - Do NOT hallucinate supplier names\n",
    "    - Supplier must follow award pattern\n",
    "    - Program Type must match allowed enum\n",
    "\n",
    "    Output:\n",
    "    - corrected_row JSON (flat)\n",
    "    - keep original if correction uncertain\n",
    "    \"\"\"\n",
    "    sys_prompt = f\"\"\"\n",
    "You are a Defense Contract Data Quality Auditor.\n",
    "\n",
    "You will receive:\n",
    "1) Original paragraph\n",
    "2) A structured extracted row marked as FAIL\n",
    "\n",
    "Your task:\n",
    "- Fix ONLY fields that are clearly wrong.\n",
    "- Do NOT invent values.\n",
    "- Supplier Name MUST come from award pattern:\n",
    "  \", , is/was/has been awarded\"\n",
    "\n",
    "Program Type MUST be one of:\n",
    "{PROGRAM_TYPE_ALLOWED}\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"Supplier Name\": \"\",\n",
    "  \"Program Type\": \"\",\n",
    "  \"G2G/B2G\": \"\",\n",
    "  \"Value (Million)\": \"\",\n",
    "  \"Quantity\": \"\",\n",
    "  \"Fix Summary\": \"\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "PARAGRAPH:\n",
    "{paragraph}\n",
    "\n",
    "FAIL ROW JSON:\n",
    "{json.dumps(row, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"system\", \"content\": sys_prompt},\n",
    "                      {\"role\": \"user\", \"content\": user_prompt}],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        fix = json.loads(completion.choices[0].message.content)\n",
    "        log_block(\"AI RESPONSE (Stage7 - LLM FAIL FIX)\", json.dumps(fix, indent=2))\n",
    "    except Exception as e:\n",
    "        log_block(\"AI ERROR (Stage7 - LLM FAIL FIX)\", str(e))\n",
    "        return {\"row\": row}\n",
    "\n",
    "    # Apply corrections carefully\n",
    "    corrected = row.copy()\n",
    "\n",
    "    if fix.get(\"Supplier Name\"):\n",
    "        corrected[\"Supplier Name\"] = get_best_supplier_match(fix[\"Supplier Name\"])\n",
    "\n",
    "    if fix.get(\"Program Type\"):\n",
    "        corrected[\"Program Type\"] = normalize_program_type(fix[\"Program Type\"])\n",
    "\n",
    "    if fix.get(\"G2G/B2G\"):\n",
    "        corrected[\"G2G/B2G\"] = fix[\"G2G/B2G\"]\n",
    "\n",
    "    if fix.get(\"Value (Million)\"):\n",
    "        corrected[\"Value (Million)\"] = fix[\"Value (Million)\"]\n",
    "        corrected[\"Value (USD$ Million)\"] = fix[\"Value (Million)\"]\n",
    "\n",
    "    if fix.get(\"Quantity\"):\n",
    "        corrected[\"Quantity\"] = fix[\"Quantity\"]\n",
    "\n",
    "    corrected[\"LLM QA Fix Summary\"] = fix.get(\"Fix Summary\", \"Not Provided\")\n",
    "\n",
    "    return {\"row\": corrected}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 8) LANGGRAPH PIPELINE\n",
    "# ==============================================================================\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    LangGraph state flowing between nodes.\n",
    "\n",
    "    Fields:\n",
    "    - input_text: contract paragraph\n",
    "    - input_date: signed date\n",
    "    - input_url: source link\n",
    "    - final_data: aggregated dict from Stage1-4\n",
    "    - final_rows: list rows after Stage5 split\n",
    "    - validated_rows: list rows after Stage6 QA\n",
    "    - final_rows_post_llm: optional rows after Stage7 fixes\n",
    "    - messages: LangGraph internal\n",
    "    \"\"\"\n",
    "    input_text: str\n",
    "    input_date: str\n",
    "    input_url: str\n",
    "\n",
    "    final_data: dict\n",
    "    final_rows: list\n",
    "    validated_rows: list\n",
    "    final_rows_post_llm: list\n",
    "\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "def stage_1_sourcing(state: AgentState):\n",
    "    \"\"\"\n",
    "    Node Stage1:\n",
    "    - Runs sourcing_extractor\n",
    "    - Creates base stable metadata row skeleton\n",
    "    \"\"\"\n",
    "    res = sourcing_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"url\": state[\"input_url\"],\n",
    "        \"date\": state[\"input_date\"],\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_2_geography(state: AgentState):\n",
    "    \"\"\"\n",
    "    Node Stage2:\n",
    "    - Extract geography + operator fields\n",
    "    - Adds region mapping + domestic content\n",
    "    \"\"\"\n",
    "    res = geography_extractor.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_3_system(state: AgentState):\n",
    "    \"\"\"\n",
    "    Node Stage3:\n",
    "    - Classifies system-level taxonomy labels\n",
    "    - Uses RAG + evidence + reason + piloting rules\n",
    "    \"\"\"\n",
    "    res = system_classifier.invoke({\"paragraph\": state[\"input_text\"]})\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_4_contract(state: AgentState):\n",
    "    \"\"\"\n",
    "    Node Stage4:\n",
    "    - Extracts contract-level fields like:\n",
    "        Supplier Name (STRICT award pattern extraction)\n",
    "        Program Type (normalized to allowed enum; MRO/Support fixed)\n",
    "        Value, Quantity, Currency, G2G/B2G\n",
    "\n",
    "    IMPORTANT:\n",
    "    - Supplier Name is NEVER split into multiple suppliers.\n",
    "    - This fixes your major corruption issue.\n",
    "    \"\"\"\n",
    "    res = contract_extractor.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"contract_date\": state[\"input_date\"]\n",
    "    })\n",
    "    new_data = state.get(\"final_data\", {}).copy()\n",
    "    new_data.update(res)\n",
    "    return {\"final_data\": new_data}\n",
    "\n",
    "\n",
    "def stage_5_split(state: AgentState):\n",
    "    \"\"\"\n",
    "    Node Stage5:\n",
    "    - Applies deterministic split logic.\n",
    "    - Supported splits:\n",
    "        Operator allocation split\n",
    "        FMS country split (G2G only)\n",
    "    - Supplier splitting is completely removed.\n",
    "    \"\"\"\n",
    "    res = splitter_agent.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"base_row\": state[\"final_data\"]\n",
    "    })\n",
    "    return {\"final_rows\": res.get(\"rows\", [state[\"final_data\"]])}\n",
    "\n",
    "\n",
    "def stage_6_quality_validator(state: AgentState):\n",
    "    \"\"\"\n",
    "    Node Stage6:\n",
    "    - Runs rule-based quality validator.\n",
    "    - Adds QA Status and QA Flags to each output row.\n",
    "\n",
    "    Output:\n",
    "    - validated_rows\n",
    "    \"\"\"\n",
    "    res = quality_validator.invoke({\n",
    "        \"paragraph\": state[\"input_text\"],\n",
    "        \"rows\": state[\"final_rows\"]\n",
    "    })\n",
    "    return {\"validated_rows\": res.get(\"rows\", state[\"final_rows\"])}\n",
    "\n",
    "\n",
    "def stage_7_llm_fix_fail_rows(state: AgentState):\n",
    "    \"\"\"\n",
    "    Node Stage7:\n",
    "    - Runs LLM validator ONLY on FAIL rows.\n",
    "    - PASS rows remain unchanged.\n",
    "\n",
    "    Why:\n",
    "    - Optimizes cost + avoids LLM touching correct rows unnecessarily\n",
    "    \"\"\"\n",
    "    paragraph = state[\"input_text\"]\n",
    "    validated_rows = state.get(\"validated_rows\", [])\n",
    "\n",
    "    fixed_rows = []\n",
    "    for r in validated_rows:\n",
    "        if r.get(\"QA Status\") == \"FAIL\":\n",
    "            fix_res = llm_fail_row_validator.invoke({\"paragraph\": paragraph, \"row\": r})\n",
    "            fixed_rows.append(fix_res.get(\"row\", r))\n",
    "        else:\n",
    "            fixed_rows.append(r)\n",
    "\n",
    "    return {\"final_rows_post_llm\": fixed_rows}\n",
    "\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"Stage1\", stage_1_sourcing)\n",
    "workflow.add_node(\"Stage2\", stage_2_geography)\n",
    "workflow.add_node(\"Stage3\", stage_3_system)\n",
    "workflow.add_node(\"Stage4\", stage_4_contract)\n",
    "workflow.add_node(\"Stage5\", stage_5_split)\n",
    "workflow.add_node(\"Stage6\", stage_6_quality_validator)\n",
    "workflow.add_node(\"Stage7\", stage_7_llm_fix_fail_rows)\n",
    "\n",
    "workflow.add_edge(START, \"Stage1\")\n",
    "workflow.add_edge(\"Stage1\", \"Stage2\")\n",
    "workflow.add_edge(\"Stage2\", \"Stage3\")\n",
    "workflow.add_edge(\"Stage3\", \"Stage4\")\n",
    "workflow.add_edge(\"Stage4\", \"Stage5\")\n",
    "workflow.add_edge(\"Stage5\", \"Stage6\")\n",
    "workflow.add_edge(\"Stage6\", \"Stage7\")\n",
    "workflow.add_edge(\"Stage7\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 9) GRAPH EXPORT (OFFLINE SAFE)\n",
    "# ==============================================================================\n",
    "\n",
    "def export_workflow_mermaid(app_obj, out_file=\"workflow.mmd\"):\n",
    "    \"\"\"\n",
    "    Exports Mermaid graph as TEXT locally.\n",
    "\n",
    "    Why:\n",
    "    - Some machines block online Mermaid rendering\n",
    "    - This provides offline documentation\n",
    "\n",
    "    Output:\n",
    "    - workflow.mmd text file\n",
    "    \"\"\"\n",
    "    mmd = app_obj.get_graph().draw_mermaid()\n",
    "    with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(mmd)\n",
    "    print(f\"Workflow Mermaid saved locally: {out_file}\")\n",
    "    return out_file\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 10) EXCEL HIGHLIGHTING FEATURE\n",
    "# ==============================================================================\n",
    "\n",
    "def highlight_evidence_reason_columns(excel_path: str):\n",
    "    \"\"\"\n",
    "    Highlights Evidence + Reason columns in output Excel.\n",
    "\n",
    "    Evidence Columns:\n",
    "    - Light yellow\n",
    "\n",
    "    Reason Columns:\n",
    "    - Light blue\n",
    "\n",
    "    Purpose:\n",
    "    - Your team can validate WHY the label was chosen quickly.\n",
    "    \"\"\"\n",
    "    wb = load_workbook(excel_path)\n",
    "    ws = wb.active\n",
    "\n",
    "    header = [cell.value for cell in ws[1]]\n",
    "\n",
    "    evidence_cols = []\n",
    "    reason_cols = []\n",
    "\n",
    "    for idx, col_name in enumerate(header, start=1):\n",
    "        if isinstance(col_name, str) and \"Evidence\" in col_name:\n",
    "            evidence_cols.append(idx)\n",
    "        if isinstance(col_name, str) and \"Reason\" in col_name:\n",
    "            reason_cols.append(idx)\n",
    "\n",
    "    evidence_fill = PatternFill(start_color=\"FFF2CC\", end_color=\"FFF2CC\", fill_type=\"solid\")\n",
    "    reason_fill = PatternFill(start_color=\"D9E1F2\", end_color=\"D9E1F2\", fill_type=\"solid\")\n",
    "    header_font = Font(bold=True)\n",
    "\n",
    "    for col_idx in evidence_cols:\n",
    "        ws.cell(row=1, column=col_idx).fill = evidence_fill\n",
    "        ws.cell(row=1, column=col_idx).font = header_font\n",
    "\n",
    "    for col_idx in reason_cols:\n",
    "        ws.cell(row=1, column=col_idx).fill = reason_fill\n",
    "        ws.cell(row=1, column=col_idx).font = header_font\n",
    "\n",
    "    for row in range(2, ws.max_row + 1):\n",
    "        for col_idx in evidence_cols:\n",
    "            ws.cell(row=row, column=col_idx).fill = evidence_fill\n",
    "        for col_idx in reason_cols:\n",
    "            ws.cell(row=row, column=col_idx).fill = reason_fill\n",
    "\n",
    "    wb.save(excel_path)\n",
    "    print(\"Evidence + Reason columns highlighted successfully.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 11) MAIN EXECUTION\n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(f\"\\nüìå Loading Input File: {INPUT_EXCEL_PATH}\")\n",
    "\n",
    "    # offline safe workflow graph\n",
    "    export_workflow_mermaid(app, out_file=\"workflow.mmd\")\n",
    "\n",
    "    try:\n",
    "        df_input = pd.read_excel(INPUT_EXCEL_PATH)\n",
    "\n",
    "        required_cols = [\"Source URL\", \"Contract Date\", \"Contract Description\"]\n",
    "        if not all(col in df_input.columns for col in required_cols):\n",
    "            raise ValueError(f\"Excel file must contain columns: {required_cols}\")\n",
    "\n",
    "        print(f\"üöÄ Processing {len(df_input)} rows...\")\n",
    "        results = []\n",
    "\n",
    "        for index, row in df_input.iterrows():\n",
    "            print(f\"\\nüîπ Row {index + 1}/{len(df_input)}\")\n",
    "\n",
    "            desc = str(row[\"Contract Description\"]) if pd.notna(row[\"Contract Description\"]) else \"\"\n",
    "            c_date = str(row[\"Contract Date\"]) if pd.notna(row[\"Contract Date\"]) else str(datetime.date.today())\n",
    "            c_url = str(row[\"Source URL\"]) if pd.notna(row[\"Source URL\"]) else \"\"\n",
    "\n",
    "            initial_state: AgentState = {\n",
    "                \"input_text\": desc,\n",
    "                \"input_date\": c_date,\n",
    "                \"input_url\": c_url,\n",
    "\n",
    "                \"final_data\": {},\n",
    "                \"final_rows\": [],\n",
    "                \"validated_rows\": [],\n",
    "                \"final_rows_post_llm\": [],\n",
    "\n",
    "                \"messages\": []\n",
    "            }\n",
    "\n",
    "            output_state = app.invoke(initial_state)\n",
    "\n",
    "            rows = output_state.get(\"final_rows_post_llm\", [])\n",
    "            if not rows:\n",
    "                rows = output_state.get(\"validated_rows\", [])\n",
    "            if not rows:\n",
    "                rows = output_state.get(\"final_rows\", [])\n",
    "            if not rows:\n",
    "                rows = [output_state.get(\"final_data\", {})]\n",
    "\n",
    "            results.extend(rows)\n",
    "\n",
    "        df_final = pd.DataFrame(results)\n",
    "\n",
    "        FINAL_COLUMNS = [\n",
    "            \"Customer Region\", \"Customer Country\", \"Customer Operator\",\n",
    "            \"Supplier Region\", \"Supplier Country\", \"Domestic Content\",\n",
    "\n",
    "            \"Split Flag\", \"Split Reason\",\n",
    "\n",
    "            \"Market Segment\", \"Market Segment Evidence\", \"Market Segment Reason\",\n",
    "            \"System Type (General)\", \"System Type (General) Evidence\", \"System Type (General) Reason\",\n",
    "            \"System Type (Specific)\", \"System Type (Specific) Evidence\", \"System Type (Specific) Reason\",\n",
    "            \"System Name (General)\", \"System Name (General) Evidence\", \"System Name (General) Reason\",\n",
    "            \"System Name (Specific)\", \"System Name (Specific) Evidence\", \"System Name (Specific) Reason\",\n",
    "            \"System Piloting\", \"System Piloting Evidence\", \"System Piloting Reason\",\n",
    "            \"Confidence\",\n",
    "\n",
    "            \"Supplier Name\", \"Supplier Name Evidence\",\n",
    "            \"Program Type\", \"Expected MRO Contract Duration (Months)\",\n",
    "            \"Quantity\", \"Value Certainty\", \"Value (Million)\", \"Currency\",\n",
    "            \"Value (USD$ Million)\", \"Value Note (If Any)\", \"G2G/B2G\",\n",
    "            \"Signing Month\", \"Signing Year\",\n",
    "\n",
    "            \"QA Status\", \"QA Flags\", \"QA Fix Suggestion\",\n",
    "            \"LLM QA Fix Summary\",\n",
    "\n",
    "            \"Description of Contract\",\n",
    "            \"Additional Notes (Internal Only)\",\n",
    "            \"Source Link(s)\",\n",
    "            \"Contract Date\",\n",
    "            \"Reported Date (By SGA)\"\n",
    "        ]\n",
    "\n",
    "        df_final = df_final.reindex(columns=FINAL_COLUMNS, fill_value=\"\")\n",
    "        df_final.to_excel(OUTPUT_EXCEL_PATH, index=False)\n",
    "\n",
    "        highlight_evidence_reason_columns(OUTPUT_EXCEL_PATH)\n",
    "\n",
    "        print(\"\\n Processing Complete!\")\n",
    "        print(f\"Output File Saved: {OUTPUT_EXCEL_PATH}\")\n",
    "        print(df_final.head(3).to_string(index=False))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n ERROR: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4e0aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
